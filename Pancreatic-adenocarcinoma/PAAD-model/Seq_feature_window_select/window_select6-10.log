nohup: ignoring input
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
样本个数 668
样本个数 1336
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fbf8749c110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fbf8749c110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fbf87404290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fbf87404290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65aa55d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65aa55d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf65a30110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf65a30110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf659ab4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf659ab4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf659a6e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf659a6e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf65a30310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf65a30310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf6599b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf6599b550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf657835d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf657835d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf655f5dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf655f5dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf656e3690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf656e3690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf65a24c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf65a24c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf654b6f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf654b6f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf65635d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf65635d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf65490850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf65490850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65672a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65672a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf5d30fe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf5d30fe90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5d3558d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5d3558d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf5d111510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf5d111510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf5d132bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf5d132bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5d002090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5d002090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf5d111d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf5d111d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5cfb3150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5cfb3150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf5ce57650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf5ce57650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf5ce13410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf5ce13410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65638cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65638cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf5d02d890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf5d02d890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5cd14f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5cd14f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf54acaa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf54acaa50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf5ce13410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf5ce13410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5cd016d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5cd016d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf54acae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf54acae10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5d06df50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf5d06df50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf54862bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf54862bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf547e87d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf547e87d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf547aae90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf547aae90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf54810b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf54810b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf545ae950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf545ae950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf5452e090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf5452e090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf543ab9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf543ab9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf54472350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf54472350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf5452e490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf5452e490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4c283e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4c283e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf4c174110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf4c174110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf4c120090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf4c120090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4c197f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4c197f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf54406550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf54406550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4c18a650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4c18a650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf4bf08990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf4bf08990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf4be570d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf4be570d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4c1aa790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4c1aa790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf4bf43f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf4bf43f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4bdafa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4bdafa50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf4bc62a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf4bc62a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf4be0fa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf4be0fa10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4bdbab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4bdbab10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf4be48290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf4be48290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4bee8610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf4bee8610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf43ad0cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf43ad0cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf4384e290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf4384e290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf438fa850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf438fa850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf43b55e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf43b55e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf438645d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf438645d0>>: AttributeError: module 'gast' has no attribute 'Str'
2023-01-11 17:02:11.353358: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-01-11 17:02:11.419907: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2023-01-11 17:02:11.471696: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5650ca2590c0 executing computations on platform Host. Devices:
2023-01-11 17:02:11.471766: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-01-11 17:02:12.013516: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 3:40 - loss: 0.7500 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 2:30 - loss: 0.7496 - acc: 0.5469
 192/1202 [===>..........................] - ETA: 2:02 - loss: 0.7585 - acc: 0.5156
 256/1202 [=====>........................] - ETA: 1:59 - loss: 0.7616 - acc: 0.5117
 320/1202 [======>.......................] - ETA: 1:47 - loss: 0.7500 - acc: 0.5312
 384/1202 [========>.....................] - ETA: 1:36 - loss: 0.7448 - acc: 0.5365
 448/1202 [==========>...................] - ETA: 1:26 - loss: 0.7398 - acc: 0.5268
 512/1202 [===========>..................] - ETA: 1:16 - loss: 0.7395 - acc: 0.5254
 576/1202 [=============>................] - ETA: 1:07 - loss: 0.7415 - acc: 0.5243
 640/1202 [==============>...............] - ETA: 1:00 - loss: 0.7389 - acc: 0.5266
 704/1202 [================>.............] - ETA: 53s - loss: 0.7382 - acc: 0.5227 
 768/1202 [==================>...........] - ETA: 46s - loss: 0.7324 - acc: 0.5260
 832/1202 [===================>..........] - ETA: 39s - loss: 0.7311 - acc: 0.5264
 896/1202 [=====================>........] - ETA: 32s - loss: 0.7288 - acc: 0.5301
 960/1202 [======================>.......] - ETA: 25s - loss: 0.7319 - acc: 0.5302
1024/1202 [========================>.....] - ETA: 18s - loss: 0.7300 - acc: 0.5352
1088/1202 [==========================>...] - ETA: 11s - loss: 0.7314 - acc: 0.5303
1152/1202 [===========================>..] - ETA: 5s - loss: 0.7338 - acc: 0.5269 
1202/1202 [==============================] - 129s 107ms/step - loss: 0.7318 - acc: 0.5291 - val_loss: 0.7012 - val_acc: 0.5299

Epoch 00001: val_acc improved from -inf to 0.52985, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window06/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:31 - loss: 0.7285 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 1:36 - loss: 0.7357 - acc: 0.5234
 192/1202 [===>..........................] - ETA: 1:32 - loss: 0.7320 - acc: 0.5104
 256/1202 [=====>........................] - ETA: 1:26 - loss: 0.7148 - acc: 0.5312
 320/1202 [======>.......................] - ETA: 1:20 - loss: 0.7030 - acc: 0.5469
 384/1202 [========>.....................] - ETA: 1:13 - loss: 0.7014 - acc: 0.5547
 448/1202 [==========>...................] - ETA: 1:06 - loss: 0.7047 - acc: 0.5580
 512/1202 [===========>..................] - ETA: 59s - loss: 0.7092 - acc: 0.5547 
 576/1202 [=============>................] - ETA: 53s - loss: 0.7077 - acc: 0.5521
 640/1202 [==============>...............] - ETA: 47s - loss: 0.7111 - acc: 0.5437
 704/1202 [================>.............] - ETA: 41s - loss: 0.7129 - acc: 0.5412
 768/1202 [==================>...........] - ETA: 36s - loss: 0.7107 - acc: 0.5417
 832/1202 [===================>..........] - ETA: 31s - loss: 0.7104 - acc: 0.5385
 896/1202 [=====================>........] - ETA: 25s - loss: 0.7109 - acc: 0.5379
 960/1202 [======================>.......] - ETA: 20s - loss: 0.7112 - acc: 0.5375
1024/1202 [========================>.....] - ETA: 14s - loss: 0.7095 - acc: 0.5381
1088/1202 [==========================>...] - ETA: 9s - loss: 0.7078 - acc: 0.5395 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.7062 - acc: 0.5391
1202/1202 [==============================] - 104s 87ms/step - loss: 0.7064 - acc: 0.5391 - val_loss: 0.6870 - val_acc: 0.5373

Epoch 00002: val_acc improved from 0.52985 to 0.53731, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window06/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:14 - loss: 0.6941 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:18 - loss: 0.6788 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:14 - loss: 0.6983 - acc: 0.5521
 256/1202 [=====>........................] - ETA: 1:10 - loss: 0.6947 - acc: 0.5430
 320/1202 [======>.......................] - ETA: 1:07 - loss: 0.7131 - acc: 0.5281
 384/1202 [========>.....................] - ETA: 1:01 - loss: 0.7110 - acc: 0.5312
 448/1202 [==========>...................] - ETA: 55s - loss: 0.7067 - acc: 0.5335 
 512/1202 [===========>..................] - ETA: 49s - loss: 0.7112 - acc: 0.5176
 576/1202 [=============>................] - ETA: 45s - loss: 0.7123 - acc: 0.5156
 640/1202 [==============>...............] - ETA: 40s - loss: 0.7072 - acc: 0.5250
 704/1202 [================>.............] - ETA: 35s - loss: 0.7058 - acc: 0.5270
 768/1202 [==================>...........] - ETA: 31s - loss: 0.7037 - acc: 0.5312
 832/1202 [===================>..........] - ETA: 27s - loss: 0.7018 - acc: 0.5361
 896/1202 [=====================>........] - ETA: 22s - loss: 0.7034 - acc: 0.5301
 960/1202 [======================>.......] - ETA: 17s - loss: 0.7030 - acc: 0.5323
1024/1202 [========================>.....] - ETA: 12s - loss: 0.7030 - acc: 0.5303
1088/1202 [==========================>...] - ETA: 8s - loss: 0.7036 - acc: 0.5294 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6993 - acc: 0.5382
1202/1202 [==============================] - 88s 73ms/step - loss: 0.6990 - acc: 0.5458 - val_loss: 0.6882 - val_acc: 0.5299

Epoch 00003: val_acc did not improve from 0.53731
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:29 - loss: 0.7137 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:19 - loss: 0.6838 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:14 - loss: 0.6990 - acc: 0.5208
 256/1202 [=====>........................] - ETA: 1:07 - loss: 0.6967 - acc: 0.5273
 320/1202 [======>.......................] - ETA: 1:00 - loss: 0.6878 - acc: 0.5500
 384/1202 [========>.....................] - ETA: 55s - loss: 0.6863 - acc: 0.5625 
 448/1202 [==========>...................] - ETA: 50s - loss: 0.6938 - acc: 0.5603
 512/1202 [===========>..................] - ETA: 46s - loss: 0.6876 - acc: 0.5742
 576/1202 [=============>................] - ETA: 41s - loss: 0.6877 - acc: 0.5729
 640/1202 [==============>...............] - ETA: 37s - loss: 0.6871 - acc: 0.5750
 704/1202 [================>.............] - ETA: 33s - loss: 0.6890 - acc: 0.5767
 768/1202 [==================>...........] - ETA: 29s - loss: 0.6896 - acc: 0.5755
 832/1202 [===================>..........] - ETA: 24s - loss: 0.6920 - acc: 0.5721
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6912 - acc: 0.5681
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6898 - acc: 0.5687
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6916 - acc: 0.5645
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6914 - acc: 0.5671 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6887 - acc: 0.5694
1202/1202 [==============================] - 86s 72ms/step - loss: 0.6913 - acc: 0.5682 - val_loss: 0.6783 - val_acc: 0.5970

Epoch 00004: val_acc improved from 0.53731 to 0.59701, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window06/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:33 - loss: 0.6985 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:27 - loss: 0.6812 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:20 - loss: 0.6827 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 1:11 - loss: 0.6924 - acc: 0.5547
 320/1202 [======>.......................] - ETA: 1:05 - loss: 0.6933 - acc: 0.5500
 384/1202 [========>.....................] - ETA: 1:01 - loss: 0.6923 - acc: 0.5547
 448/1202 [==========>...................] - ETA: 54s - loss: 0.6911 - acc: 0.5469 
 512/1202 [===========>..................] - ETA: 50s - loss: 0.6920 - acc: 0.5508
 576/1202 [=============>................] - ETA: 45s - loss: 0.6921 - acc: 0.5486
 640/1202 [==============>...............] - ETA: 41s - loss: 0.6903 - acc: 0.5531
 704/1202 [================>.............] - ETA: 36s - loss: 0.6918 - acc: 0.5483
 768/1202 [==================>...........] - ETA: 32s - loss: 0.6925 - acc: 0.5482
 832/1202 [===================>..........] - ETA: 27s - loss: 0.6927 - acc: 0.5469
 896/1202 [=====================>........] - ETA: 22s - loss: 0.6912 - acc: 0.5446
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6907 - acc: 0.5469
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6913 - acc: 0.5449
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6902 - acc: 0.5478 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6901 - acc: 0.5530
1202/1202 [==============================] - 92s 76ms/step - loss: 0.6905 - acc: 0.5549 - val_loss: 0.6731 - val_acc: 0.5672

Epoch 00005: val_acc did not improve from 0.59701
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:16 - loss: 0.6348 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:10 - loss: 0.6562 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 1:07 - loss: 0.6634 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 1:03 - loss: 0.6835 - acc: 0.5352
 320/1202 [======>.......................] - ETA: 1:01 - loss: 0.6824 - acc: 0.5312
 384/1202 [========>.....................] - ETA: 56s - loss: 0.6758 - acc: 0.5443 
 448/1202 [==========>...................] - ETA: 51s - loss: 0.6756 - acc: 0.5424
 512/1202 [===========>..................] - ETA: 46s - loss: 0.6758 - acc: 0.5469
 576/1202 [=============>................] - ETA: 43s - loss: 0.6784 - acc: 0.5503
 640/1202 [==============>...............] - ETA: 38s - loss: 0.6822 - acc: 0.5484
 704/1202 [================>.............] - ETA: 33s - loss: 0.6810 - acc: 0.5483
 768/1202 [==================>...........] - ETA: 29s - loss: 0.6864 - acc: 0.5443
 832/1202 [===================>..........] - ETA: 24s - loss: 0.6882 - acc: 0.5469
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6844 - acc: 0.5513
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6850 - acc: 0.5521
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6870 - acc: 0.5498
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6859 - acc: 0.5515 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6844 - acc: 0.5582
1202/1202 [==============================] - 83s 69ms/step - loss: 0.6857 - acc: 0.5549 - val_loss: 0.6772 - val_acc: 0.5821

Epoch 00006: val_acc did not improve from 0.59701
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:12 - loss: 0.6944 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:04 - loss: 0.6906 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 1:08 - loss: 0.7055 - acc: 0.5260
 256/1202 [=====>........................] - ETA: 1:06 - loss: 0.6953 - acc: 0.5547
 320/1202 [======>.......................] - ETA: 1:02 - loss: 0.6947 - acc: 0.5656
 384/1202 [========>.....................] - ETA: 55s - loss: 0.6960 - acc: 0.5573 
 448/1202 [==========>...................] - ETA: 50s - loss: 0.6977 - acc: 0.5513
 512/1202 [===========>..................] - ETA: 47s - loss: 0.6943 - acc: 0.5527
 576/1202 [=============>................] - ETA: 43s - loss: 0.6947 - acc: 0.5503
 640/1202 [==============>...............] - ETA: 38s - loss: 0.6982 - acc: 0.5453
 704/1202 [================>.............] - ETA: 33s - loss: 0.6948 - acc: 0.5497
 768/1202 [==================>...........] - ETA: 29s - loss: 0.6962 - acc: 0.5521
 832/1202 [===================>..........] - ETA: 24s - loss: 0.6953 - acc: 0.5541
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6924 - acc: 0.5547
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6909 - acc: 0.5604
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6896 - acc: 0.5645
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6924 - acc: 0.5597 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6922 - acc: 0.5582
1202/1202 [==============================] - 83s 69ms/step - loss: 0.6921 - acc: 0.5574 - val_loss: 0.6821 - val_acc: 0.5970

Epoch 00007: val_acc did not improve from 0.59701
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:32 - loss: 0.6785 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:24 - loss: 0.6912 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 1:11 - loss: 0.6760 - acc: 0.5938
 256/1202 [=====>........................] - ETA: 1:05 - loss: 0.6763 - acc: 0.5938
 320/1202 [======>.......................] - ETA: 1:00 - loss: 0.6879 - acc: 0.5875
 384/1202 [========>.....................] - ETA: 57s - loss: 0.6895 - acc: 0.5859 
 448/1202 [==========>...................] - ETA: 52s - loss: 0.6925 - acc: 0.5781
 512/1202 [===========>..................] - ETA: 49s - loss: 0.6936 - acc: 0.5703
 576/1202 [=============>................] - ETA: 45s - loss: 0.6941 - acc: 0.5625
 640/1202 [==============>...............] - ETA: 41s - loss: 0.6935 - acc: 0.5672
 704/1202 [================>.............] - ETA: 37s - loss: 0.6948 - acc: 0.5625
 768/1202 [==================>...........] - ETA: 32s - loss: 0.6911 - acc: 0.5716
 832/1202 [===================>..........] - ETA: 27s - loss: 0.6918 - acc: 0.5709
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6924 - acc: 0.5703
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6923 - acc: 0.5708
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6929 - acc: 0.5664
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6940 - acc: 0.5634 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6927 - acc: 0.5651
1202/1202 [==============================] - 98s 81ms/step - loss: 0.6927 - acc: 0.5691 - val_loss: 0.6795 - val_acc: 0.5597

Epoch 00008: val_acc did not improve from 0.59701
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:29 - loss: 0.7309 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:20 - loss: 0.7101 - acc: 0.5234
 192/1202 [===>..........................] - ETA: 1:20 - loss: 0.6957 - acc: 0.5573
 256/1202 [=====>........................] - ETA: 1:15 - loss: 0.6933 - acc: 0.5625
 320/1202 [======>.......................] - ETA: 1:10 - loss: 0.6789 - acc: 0.5781
 384/1202 [========>.....................] - ETA: 1:06 - loss: 0.6774 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 1:00 - loss: 0.6773 - acc: 0.5871
 512/1202 [===========>..................] - ETA: 54s - loss: 0.6805 - acc: 0.5801 
 576/1202 [=============>................] - ETA: 49s - loss: 0.6763 - acc: 0.5833
 640/1202 [==============>...............] - ETA: 45s - loss: 0.6780 - acc: 0.5844
 704/1202 [================>.............] - ETA: 40s - loss: 0.6780 - acc: 0.5852
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6762 - acc: 0.5898
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6748 - acc: 0.5913
 896/1202 [=====================>........] - ETA: 25s - loss: 0.6766 - acc: 0.5882
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6774 - acc: 0.5844
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6767 - acc: 0.5850
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6773 - acc: 0.5809 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6787 - acc: 0.5738
1202/1202 [==============================] - 103s 86ms/step - loss: 0.6782 - acc: 0.5740 - val_loss: 0.6930 - val_acc: 0.5299

Epoch 00009: val_acc did not improve from 0.59701
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:33 - loss: 0.6848 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:31 - loss: 0.7181 - acc: 0.5469
 192/1202 [===>..........................] - ETA: 1:26 - loss: 0.6885 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 1:21 - loss: 0.6937 - acc: 0.5586
 320/1202 [======>.......................] - ETA: 1:15 - loss: 0.6909 - acc: 0.5656
 384/1202 [========>.....................] - ETA: 1:10 - loss: 0.6922 - acc: 0.5703
 448/1202 [==========>...................] - ETA: 1:04 - loss: 0.6901 - acc: 0.5647
 512/1202 [===========>..................] - ETA: 59s - loss: 0.6957 - acc: 0.5547 
 576/1202 [=============>................] - ETA: 53s - loss: 0.6976 - acc: 0.5538
 640/1202 [==============>...............] - ETA: 47s - loss: 0.6983 - acc: 0.5516
 704/1202 [================>.............] - ETA: 41s - loss: 0.6975 - acc: 0.5526
 768/1202 [==================>...........] - ETA: 36s - loss: 0.6979 - acc: 0.5482
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6961 - acc: 0.5469
 896/1202 [=====================>........] - ETA: 25s - loss: 0.6955 - acc: 0.5435
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6956 - acc: 0.5479
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6965 - acc: 0.5439
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6942 - acc: 0.5515 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6942 - acc: 0.5495
1202/1202 [==============================] - 106s 88ms/step - loss: 0.6909 - acc: 0.5566 - val_loss: 0.6809 - val_acc: 0.5746

Epoch 00010: val_acc did not improve from 0.59701
样本个数 167
样本个数 334
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 11s
128/334 [==========>...................] - ETA: 7s 
192/334 [================>.............] - ETA: 4s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 10s 29ms/step
loss: 0.6769326814634358
acc: 0.5808383244240355
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fb920224b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fb920224b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fb9201aa190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fb9201aa190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65ae5250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65ae5250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf7eb2c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf7eb2c7d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb9200ddc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb9200ddc50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb9200cd490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb9200cd490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf43504050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf43504050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb9200cf250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb9200cf250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb9186de810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb9186de810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb9185a5210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb9185a5210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb91869bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb91869bc50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb9186de510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb9186de510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb9184a7a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb9184a7a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb9183c2c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb9183c2c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb9201a9dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb9201a9dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb9183a41d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb9183a41d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb920196390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb920196390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c07ba610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c07ba610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb8e01d4950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb8e01d4950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8c07abc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8c07abc10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c0711a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c0711a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8c0746b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8c0746b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c06bea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c06bea50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb8c05664d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb8c05664d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8c034ef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8c034ef10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c063ac10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c063ac10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb9183c2fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb9183c2fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c0278050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c0278050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb8c015fed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb8c015fed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8c00d4090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8c00d4090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c044b6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c044b6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8c015fd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8c015fd90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c017afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c017afd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb8a8630e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb8a8630e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8a8481f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8a8481f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a85e6110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a85e6110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8a8630fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8a8630fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a847f290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a847f290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb8a82e4850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb8a82e4850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8a82761d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8a82761d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a809be50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a809be50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8a83d9b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8a83d9b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a82765d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a82765d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb9201a6090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb9201a6090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8a81d8c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8a81d8c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a8264e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a8264e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb9201aacd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb9201aacd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a81f1f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8a81f1f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb89c670550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb89c670550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb89c367f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb89c367f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c07e3150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8c07e3150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb89c5fb510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb89c5fb510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb89c6cb150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb89c6cb150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb89c142e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb89c142e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8847cded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8847cded0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8846d6f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8846d6f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb89c26ddd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb89c26ddd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8846e9e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8846e9e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb884614610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb884614610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8845cc0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb8845cc0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb88460c6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb88460c6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8847d5990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8847d5990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8845433d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb8845433d0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 3:35 - loss: 0.6917 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 2:24 - loss: 0.7127 - acc: 0.5156
 192/1202 [===>..........................] - ETA: 1:57 - loss: 0.7124 - acc: 0.5521
 256/1202 [=====>........................] - ETA: 1:39 - loss: 0.7112 - acc: 0.5703
 320/1202 [======>.......................] - ETA: 1:28 - loss: 0.7282 - acc: 0.5437
 384/1202 [========>.....................] - ETA: 1:19 - loss: 0.7219 - acc: 0.5573
 448/1202 [==========>...................] - ETA: 1:10 - loss: 0.7212 - acc: 0.5536
 512/1202 [===========>..................] - ETA: 1:02 - loss: 0.7204 - acc: 0.5488
 576/1202 [=============>................] - ETA: 55s - loss: 0.7235 - acc: 0.5538 
 640/1202 [==============>...............] - ETA: 49s - loss: 0.7233 - acc: 0.5625
 704/1202 [================>.............] - ETA: 43s - loss: 0.7206 - acc: 0.5668
 768/1202 [==================>...........] - ETA: 37s - loss: 0.7230 - acc: 0.5677
 832/1202 [===================>..........] - ETA: 31s - loss: 0.7283 - acc: 0.5577
 896/1202 [=====================>........] - ETA: 26s - loss: 0.7264 - acc: 0.5625
 960/1202 [======================>.......] - ETA: 20s - loss: 0.7261 - acc: 0.5615
1024/1202 [========================>.....] - ETA: 15s - loss: 0.7271 - acc: 0.5635
1088/1202 [==========================>...] - ETA: 9s - loss: 0.7234 - acc: 0.5671 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.7233 - acc: 0.5608
1202/1202 [==============================] - 108s 90ms/step - loss: 0.7249 - acc: 0.5566 - val_loss: 0.6808 - val_acc: 0.5597

Epoch 00001: val_acc improved from -inf to 0.55970, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window07/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:23 - loss: 0.7051 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 1:23 - loss: 0.6976 - acc: 0.5078
 192/1202 [===>..........................] - ETA: 1:17 - loss: 0.7105 - acc: 0.4896
 256/1202 [=====>........................] - ETA: 1:13 - loss: 0.6911 - acc: 0.5156
 320/1202 [======>.......................] - ETA: 1:07 - loss: 0.7102 - acc: 0.5219
 384/1202 [========>.....................] - ETA: 1:03 - loss: 0.7129 - acc: 0.5286
 448/1202 [==========>...................] - ETA: 59s - loss: 0.7061 - acc: 0.5312 
 512/1202 [===========>..................] - ETA: 54s - loss: 0.6991 - acc: 0.5488
 576/1202 [=============>................] - ETA: 49s - loss: 0.7071 - acc: 0.5347
 640/1202 [==============>...............] - ETA: 44s - loss: 0.7130 - acc: 0.5297
 704/1202 [================>.............] - ETA: 39s - loss: 0.7073 - acc: 0.5327
 768/1202 [==================>...........] - ETA: 34s - loss: 0.7033 - acc: 0.5404
 832/1202 [===================>..........] - ETA: 29s - loss: 0.7077 - acc: 0.5373
 896/1202 [=====================>........] - ETA: 24s - loss: 0.7054 - acc: 0.5413
 960/1202 [======================>.......] - ETA: 19s - loss: 0.7063 - acc: 0.5385
1024/1202 [========================>.....] - ETA: 14s - loss: 0.7065 - acc: 0.5410
1088/1202 [==========================>...] - ETA: 9s - loss: 0.7102 - acc: 0.5368 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7086 - acc: 0.5365
1202/1202 [==============================] - 100s 83ms/step - loss: 0.7090 - acc: 0.5349 - val_loss: 0.7074 - val_acc: 0.4701

Epoch 00002: val_acc did not improve from 0.55970
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:20 - loss: 0.6849 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:20 - loss: 0.6903 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:18 - loss: 0.7291 - acc: 0.5208
 256/1202 [=====>........................] - ETA: 1:12 - loss: 0.7294 - acc: 0.5078
 320/1202 [======>.......................] - ETA: 1:06 - loss: 0.7230 - acc: 0.5094
 384/1202 [========>.....................] - ETA: 1:02 - loss: 0.7162 - acc: 0.5234
 448/1202 [==========>...................] - ETA: 56s - loss: 0.7101 - acc: 0.5312 
 512/1202 [===========>..................] - ETA: 52s - loss: 0.7065 - acc: 0.5449
 576/1202 [=============>................] - ETA: 47s - loss: 0.7058 - acc: 0.5451
 640/1202 [==============>...............] - ETA: 42s - loss: 0.7018 - acc: 0.5500
 704/1202 [================>.............] - ETA: 37s - loss: 0.6991 - acc: 0.5597
 768/1202 [==================>...........] - ETA: 33s - loss: 0.6971 - acc: 0.5651
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6972 - acc: 0.5673
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6936 - acc: 0.5759
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6934 - acc: 0.5729
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6988 - acc: 0.5625
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6990 - acc: 0.5625 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7023 - acc: 0.5573
1202/1202 [==============================] - 98s 82ms/step - loss: 0.7003 - acc: 0.5599 - val_loss: 0.7134 - val_acc: 0.4925

Epoch 00003: val_acc did not improve from 0.55970
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:17 - loss: 0.7048 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:20 - loss: 0.7086 - acc: 0.5078
 192/1202 [===>..........................] - ETA: 1:16 - loss: 0.7246 - acc: 0.4740
 256/1202 [=====>........................] - ETA: 1:10 - loss: 0.7109 - acc: 0.5078
 320/1202 [======>.......................] - ETA: 1:05 - loss: 0.7071 - acc: 0.5219
 384/1202 [========>.....................] - ETA: 1:02 - loss: 0.7052 - acc: 0.5130
 448/1202 [==========>...................] - ETA: 59s - loss: 0.6995 - acc: 0.5268 
 512/1202 [===========>..................] - ETA: 55s - loss: 0.6960 - acc: 0.5332
 576/1202 [=============>................] - ETA: 49s - loss: 0.6969 - acc: 0.5295
 640/1202 [==============>...............] - ETA: 44s - loss: 0.6975 - acc: 0.5312
 704/1202 [================>.............] - ETA: 39s - loss: 0.6987 - acc: 0.5298
 768/1202 [==================>...........] - ETA: 34s - loss: 0.6983 - acc: 0.5326
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6964 - acc: 0.5385
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6965 - acc: 0.5435
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6946 - acc: 0.5417
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6920 - acc: 0.5439
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6923 - acc: 0.5460 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6932 - acc: 0.5469
1202/1202 [==============================] - 93s 78ms/step - loss: 0.6928 - acc: 0.5466 - val_loss: 0.6983 - val_acc: 0.5448

Epoch 00004: val_acc did not improve from 0.55970
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:16 - loss: 0.6692 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:11 - loss: 0.6746 - acc: 0.5234
 192/1202 [===>..........................] - ETA: 1:08 - loss: 0.6747 - acc: 0.5469
 256/1202 [=====>........................] - ETA: 1:03 - loss: 0.6749 - acc: 0.5547
 320/1202 [======>.......................] - ETA: 1:00 - loss: 0.6766 - acc: 0.5719
 384/1202 [========>.....................] - ETA: 56s - loss: 0.6823 - acc: 0.5729 
 448/1202 [==========>...................] - ETA: 52s - loss: 0.6891 - acc: 0.5692
 512/1202 [===========>..................] - ETA: 47s - loss: 0.6911 - acc: 0.5605
 576/1202 [=============>................] - ETA: 42s - loss: 0.6898 - acc: 0.5625
 640/1202 [==============>...............] - ETA: 37s - loss: 0.6919 - acc: 0.5641
 704/1202 [================>.............] - ETA: 33s - loss: 0.6932 - acc: 0.5582
 768/1202 [==================>...........] - ETA: 29s - loss: 0.6896 - acc: 0.5599
 832/1202 [===================>..........] - ETA: 25s - loss: 0.6878 - acc: 0.5649
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6867 - acc: 0.5681
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6879 - acc: 0.5677
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6891 - acc: 0.5635
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6889 - acc: 0.5607 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6871 - acc: 0.5616
1202/1202 [==============================] - 84s 70ms/step - loss: 0.6860 - acc: 0.5616 - val_loss: 0.6720 - val_acc: 0.5672

Epoch 00005: val_acc improved from 0.55970 to 0.56716, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window07/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1202 [>.............................] - ETA: 59s - loss: 0.7149 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 57s - loss: 0.6849 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 56s - loss: 0.6850 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 55s - loss: 0.6847 - acc: 0.5781
 320/1202 [======>.......................] - ETA: 52s - loss: 0.6865 - acc: 0.5656
 384/1202 [========>.....................] - ETA: 48s - loss: 0.6885 - acc: 0.5495
 448/1202 [==========>...................] - ETA: 44s - loss: 0.6840 - acc: 0.5603
 512/1202 [===========>..................] - ETA: 41s - loss: 0.6846 - acc: 0.5605
 576/1202 [=============>................] - ETA: 36s - loss: 0.6895 - acc: 0.5590
 640/1202 [==============>...............] - ETA: 33s - loss: 0.6883 - acc: 0.5594
 704/1202 [================>.............] - ETA: 29s - loss: 0.6805 - acc: 0.5682
 768/1202 [==================>...........] - ETA: 26s - loss: 0.6857 - acc: 0.5651
 832/1202 [===================>..........] - ETA: 22s - loss: 0.6877 - acc: 0.5661
 896/1202 [=====================>........] - ETA: 18s - loss: 0.6853 - acc: 0.5658
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6850 - acc: 0.5635
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6857 - acc: 0.5654
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6871 - acc: 0.5625 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6843 - acc: 0.5660
1202/1202 [==============================] - 74s 62ms/step - loss: 0.6864 - acc: 0.5632 - val_loss: 0.6840 - val_acc: 0.5970

Epoch 00006: val_acc improved from 0.56716 to 0.59701, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window07/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:03 - loss: 0.7401 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:06 - loss: 0.6779 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 1:02 - loss: 0.6964 - acc: 0.5729
 256/1202 [=====>........................] - ETA: 54s - loss: 0.6991 - acc: 0.5703 
 320/1202 [======>.......................] - ETA: 50s - loss: 0.6914 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 46s - loss: 0.6870 - acc: 0.5833
 448/1202 [==========>...................] - ETA: 43s - loss: 0.6841 - acc: 0.5804
 512/1202 [===========>..................] - ETA: 40s - loss: 0.6809 - acc: 0.5859
 576/1202 [=============>................] - ETA: 37s - loss: 0.6846 - acc: 0.5799
 640/1202 [==============>...............] - ETA: 32s - loss: 0.6813 - acc: 0.5906
 704/1202 [================>.............] - ETA: 29s - loss: 0.6777 - acc: 0.5994
 768/1202 [==================>...........] - ETA: 26s - loss: 0.6758 - acc: 0.5977
 832/1202 [===================>..........] - ETA: 22s - loss: 0.6765 - acc: 0.5986
 896/1202 [=====================>........] - ETA: 18s - loss: 0.6782 - acc: 0.5926
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6818 - acc: 0.5854
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6846 - acc: 0.5791
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6835 - acc: 0.5800 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6826 - acc: 0.5790
1202/1202 [==============================] - 77s 64ms/step - loss: 0.6816 - acc: 0.5815 - val_loss: 0.6687 - val_acc: 0.6343

Epoch 00007: val_acc improved from 0.59701 to 0.63433, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window07/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:18 - loss: 0.6811 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:09 - loss: 0.6731 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 1:08 - loss: 0.6649 - acc: 0.6198
 256/1202 [=====>........................] - ETA: 1:02 - loss: 0.6696 - acc: 0.6055
 320/1202 [======>.......................] - ETA: 57s - loss: 0.6742 - acc: 0.5875 
 384/1202 [========>.....................] - ETA: 53s - loss: 0.6803 - acc: 0.5781
 448/1202 [==========>...................] - ETA: 49s - loss: 0.6781 - acc: 0.5848
 512/1202 [===========>..................] - ETA: 45s - loss: 0.6758 - acc: 0.5898
 576/1202 [=============>................] - ETA: 41s - loss: 0.6767 - acc: 0.5903
 640/1202 [==============>...............] - ETA: 37s - loss: 0.6776 - acc: 0.5891
 704/1202 [================>.............] - ETA: 33s - loss: 0.6798 - acc: 0.5838
 768/1202 [==================>...........] - ETA: 28s - loss: 0.6770 - acc: 0.5781
 832/1202 [===================>..........] - ETA: 24s - loss: 0.6786 - acc: 0.5769
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6800 - acc: 0.5748
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6778 - acc: 0.5823
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6792 - acc: 0.5820
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6801 - acc: 0.5809 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6827 - acc: 0.5799
1202/1202 [==============================] - 86s 71ms/step - loss: 0.6812 - acc: 0.5799 - val_loss: 0.6715 - val_acc: 0.6045

Epoch 00008: val_acc did not improve from 0.63433
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:28 - loss: 0.6579 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 1:24 - loss: 0.6792 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 1:19 - loss: 0.6877 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 1:12 - loss: 0.6955 - acc: 0.5586
 320/1202 [======>.......................] - ETA: 1:07 - loss: 0.6959 - acc: 0.5563
 384/1202 [========>.....................] - ETA: 1:00 - loss: 0.6993 - acc: 0.5443
 448/1202 [==========>...................] - ETA: 57s - loss: 0.6977 - acc: 0.5491 
 512/1202 [===========>..................] - ETA: 52s - loss: 0.6939 - acc: 0.5547
 576/1202 [=============>................] - ETA: 47s - loss: 0.6883 - acc: 0.5694
 640/1202 [==============>...............] - ETA: 43s - loss: 0.6806 - acc: 0.5875
 704/1202 [================>.............] - ETA: 38s - loss: 0.6821 - acc: 0.5852
 768/1202 [==================>...........] - ETA: 33s - loss: 0.6764 - acc: 0.5911
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6769 - acc: 0.5913
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6738 - acc: 0.5982
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6755 - acc: 0.5906
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6765 - acc: 0.5908
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6773 - acc: 0.5892 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6795 - acc: 0.5842
1202/1202 [==============================] - 96s 80ms/step - loss: 0.6795 - acc: 0.5849 - val_loss: 0.6668 - val_acc: 0.6194

Epoch 00009: val_acc did not improve from 0.63433
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:32 - loss: 0.6659 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:22 - loss: 0.6652 - acc: 0.5859
 192/1202 [===>..........................] - ETA: 1:17 - loss: 0.6530 - acc: 0.6198
 256/1202 [=====>........................] - ETA: 1:14 - loss: 0.6724 - acc: 0.5977
 320/1202 [======>.......................] - ETA: 1:11 - loss: 0.6775 - acc: 0.5844
 384/1202 [========>.....................] - ETA: 1:05 - loss: 0.6807 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 1:01 - loss: 0.6763 - acc: 0.5826
 512/1202 [===========>..................] - ETA: 55s - loss: 0.6714 - acc: 0.5820 
 576/1202 [=============>................] - ETA: 51s - loss: 0.6741 - acc: 0.5764
 640/1202 [==============>...............] - ETA: 46s - loss: 0.6805 - acc: 0.5687
 704/1202 [================>.............] - ETA: 40s - loss: 0.6811 - acc: 0.5668
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6838 - acc: 0.5599
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6807 - acc: 0.5685
 896/1202 [=====================>........] - ETA: 25s - loss: 0.6830 - acc: 0.5658
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6829 - acc: 0.5646
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6805 - acc: 0.5674
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6787 - acc: 0.5689 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6782 - acc: 0.5694
1202/1202 [==============================] - 105s 88ms/step - loss: 0.6789 - acc: 0.5707 - val_loss: 0.6691 - val_acc: 0.6045

Epoch 00010: val_acc did not improve from 0.63433
样本个数 167
样本个数 334
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 12s
128/334 [==========>...................] - ETA: 7s 
192/334 [================>.............] - ETA: 4s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 9s 26ms/step
loss: 0.702326140717832
acc: 0.5419161676646707
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fb7c0721e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fb7c0721e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fb7c0699810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fb7c0699810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65ae5590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65ae5590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf7eab80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fbf7eab80d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf6e19f4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fbf6e19f4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf6e1c1950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf6e1c1950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf7eab8910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fbf7eab8910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7c0640910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7c0640910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7c03c2810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7c03c2810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7c0450210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7c0450210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7c03d97d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7c03d97d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8c00ec950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb8c00ec950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7c0340910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7c0340910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7c01d1950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7c01d1950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7c032e690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7c032e690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb79857eed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb79857eed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb7c02e0250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb7c02e0250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7986d1450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7986d1450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb798757690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb798757690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7986c3490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7986c3490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb798518a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb798518a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb79857e690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb79857e690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbb4007cbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbb4007cbd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7983d98d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7983d98d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb798108810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb798108810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb760770b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb760770b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb7986b9c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb7986b9c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7981082d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7981082d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7606f5f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7606f5f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7605dcb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7605dcb90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb760670c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb760670c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb760640890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb760640890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb76050df10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb76050df10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7980f5fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7980f5fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb76036e510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb76036e510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb760510110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb760510110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb79807c990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb79807c990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7600f1c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7600f1c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7600a5750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7600a5750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7486d9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7486d9050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7487b9410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7487b9410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb7600a5dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb7600a5dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7485e1cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7485e1cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7484d7650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7484d7650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7483dd190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7483dd190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb748453650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb748453650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb7484d7c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb7484d7c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb74850db50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb74850db50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7483ec0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7483ec0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb74812e650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb74812e650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7481c70d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7481c70d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb748407350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb748407350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb748080b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb748080b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7406a9090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb7406a9090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb740536a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb740536a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb74061c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb74061c550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb740774050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb740774050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb740576bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb740576bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb740576e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb740576e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7402180d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb7402180d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7402eaad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7402eaad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb740528490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb740528490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7400bdd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7400bdd90>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 4:34 - loss: 0.7034 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 2:43 - loss: 0.7076 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:57 - loss: 0.7041 - acc: 0.5677
 256/1202 [=====>........................] - ETA: 1:33 - loss: 0.7141 - acc: 0.5625
 320/1202 [======>.......................] - ETA: 1:21 - loss: 0.7377 - acc: 0.5406
 384/1202 [========>.....................] - ETA: 1:10 - loss: 0.7377 - acc: 0.5443
 448/1202 [==========>...................] - ETA: 1:01 - loss: 0.7423 - acc: 0.5424
 512/1202 [===========>..................] - ETA: 54s - loss: 0.7489 - acc: 0.5391 
 576/1202 [=============>................] - ETA: 48s - loss: 0.7599 - acc: 0.5243
 640/1202 [==============>...............] - ETA: 42s - loss: 0.7564 - acc: 0.5234
 704/1202 [================>.............] - ETA: 36s - loss: 0.7638 - acc: 0.5128
 768/1202 [==================>...........] - ETA: 31s - loss: 0.7617 - acc: 0.5117
 832/1202 [===================>..........] - ETA: 25s - loss: 0.7539 - acc: 0.5240
 896/1202 [=====================>........] - ETA: 20s - loss: 0.7508 - acc: 0.5268
 960/1202 [======================>.......] - ETA: 16s - loss: 0.7522 - acc: 0.5260
1024/1202 [========================>.....] - ETA: 11s - loss: 0.7494 - acc: 0.5293
1088/1202 [==========================>...] - ETA: 7s - loss: 0.7504 - acc: 0.5276 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7509 - acc: 0.5269
1202/1202 [==============================] - 82s 68ms/step - loss: 0.7494 - acc: 0.5300 - val_loss: 0.6975 - val_acc: 0.5522

Epoch 00001: val_acc improved from -inf to 0.55224, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window08/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:03 - loss: 0.7299 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:00 - loss: 0.7052 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 55s - loss: 0.7125 - acc: 0.5000 
 256/1202 [=====>........................] - ETA: 52s - loss: 0.6893 - acc: 0.5391
 320/1202 [======>.......................] - ETA: 50s - loss: 0.6943 - acc: 0.5375
 384/1202 [========>.....................] - ETA: 47s - loss: 0.6862 - acc: 0.5547
 448/1202 [==========>...................] - ETA: 43s - loss: 0.6935 - acc: 0.5469
 512/1202 [===========>..................] - ETA: 38s - loss: 0.6978 - acc: 0.5469
 576/1202 [=============>................] - ETA: 34s - loss: 0.7002 - acc: 0.5399
 640/1202 [==============>...............] - ETA: 31s - loss: 0.7016 - acc: 0.5437
 704/1202 [================>.............] - ETA: 27s - loss: 0.7046 - acc: 0.5483
 768/1202 [==================>...........] - ETA: 23s - loss: 0.7009 - acc: 0.5521
 832/1202 [===================>..........] - ETA: 19s - loss: 0.6965 - acc: 0.5541
 896/1202 [=====================>........] - ETA: 16s - loss: 0.6984 - acc: 0.5502
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6968 - acc: 0.5583
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6924 - acc: 0.5615 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6975 - acc: 0.5551
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6978 - acc: 0.5564
1202/1202 [==============================] - 68s 56ms/step - loss: 0.6992 - acc: 0.5574 - val_loss: 0.7574 - val_acc: 0.4701

Epoch 00002: val_acc did not improve from 0.55224
Epoch 3/10

  64/1202 [>.............................] - ETA: 59s - loss: 0.6581 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 56s - loss: 0.6456 - acc: 0.6016
 192/1202 [===>..........................] - ETA: 50s - loss: 0.6775 - acc: 0.5573
 256/1202 [=====>........................] - ETA: 48s - loss: 0.7061 - acc: 0.5352
 320/1202 [======>.......................] - ETA: 46s - loss: 0.6939 - acc: 0.5406
 384/1202 [========>.....................] - ETA: 42s - loss: 0.6872 - acc: 0.5547
 448/1202 [==========>...................] - ETA: 39s - loss: 0.6930 - acc: 0.5513
 512/1202 [===========>..................] - ETA: 36s - loss: 0.6897 - acc: 0.5605
 576/1202 [=============>................] - ETA: 32s - loss: 0.6898 - acc: 0.5625
 640/1202 [==============>...............] - ETA: 29s - loss: 0.6946 - acc: 0.5563
 704/1202 [================>.............] - ETA: 26s - loss: 0.6997 - acc: 0.5526
 768/1202 [==================>...........] - ETA: 22s - loss: 0.7020 - acc: 0.5482
 832/1202 [===================>..........] - ETA: 19s - loss: 0.7004 - acc: 0.5541
 896/1202 [=====================>........] - ETA: 16s - loss: 0.6995 - acc: 0.5558
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6992 - acc: 0.5531
1024/1202 [========================>.....] - ETA: 9s - loss: 0.7042 - acc: 0.5439 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.7104 - acc: 0.5349
1152/1202 [===========================>..] - ETA: 2s - loss: 0.7086 - acc: 0.5356
1202/1202 [==============================] - 67s 56ms/step - loss: 0.7073 - acc: 0.5358 - val_loss: 0.6972 - val_acc: 0.4776

Epoch 00003: val_acc did not improve from 0.55224
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:06 - loss: 0.7446 - acc: 0.3906
 128/1202 [==>...........................] - ETA: 1:04 - loss: 0.7476 - acc: 0.4219
 192/1202 [===>..........................] - ETA: 57s - loss: 0.7289 - acc: 0.5000 
 256/1202 [=====>........................] - ETA: 53s - loss: 0.7139 - acc: 0.5234
 320/1202 [======>.......................] - ETA: 49s - loss: 0.7193 - acc: 0.5156
 384/1202 [========>.....................] - ETA: 45s - loss: 0.7231 - acc: 0.4974
 448/1202 [==========>...................] - ETA: 41s - loss: 0.7200 - acc: 0.5045
 512/1202 [===========>..................] - ETA: 36s - loss: 0.7185 - acc: 0.5059
 576/1202 [=============>................] - ETA: 32s - loss: 0.7173 - acc: 0.5122
 640/1202 [==============>...............] - ETA: 28s - loss: 0.7127 - acc: 0.5266
 704/1202 [================>.............] - ETA: 26s - loss: 0.7088 - acc: 0.5327
 768/1202 [==================>...........] - ETA: 22s - loss: 0.7090 - acc: 0.5339
 832/1202 [===================>..........] - ETA: 19s - loss: 0.7088 - acc: 0.5349
 896/1202 [=====================>........] - ETA: 15s - loss: 0.7086 - acc: 0.5324
 960/1202 [======================>.......] - ETA: 12s - loss: 0.7075 - acc: 0.5344
1024/1202 [========================>.....] - ETA: 9s - loss: 0.7056 - acc: 0.5371 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.7039 - acc: 0.5423
1152/1202 [===========================>..] - ETA: 2s - loss: 0.7021 - acc: 0.5486
1202/1202 [==============================] - 67s 55ms/step - loss: 0.7023 - acc: 0.5499 - val_loss: 0.6884 - val_acc: 0.5821

Epoch 00004: val_acc improved from 0.55224 to 0.58209, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window08/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 5/10

  64/1202 [>.............................] - ETA: 58s - loss: 0.6555 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 56s - loss: 0.6689 - acc: 0.6094
 192/1202 [===>..........................] - ETA: 53s - loss: 0.6585 - acc: 0.6146
 256/1202 [=====>........................] - ETA: 49s - loss: 0.6711 - acc: 0.5977
 320/1202 [======>.......................] - ETA: 45s - loss: 0.6744 - acc: 0.6031
 384/1202 [========>.....................] - ETA: 41s - loss: 0.6697 - acc: 0.6042
 448/1202 [==========>...................] - ETA: 37s - loss: 0.6763 - acc: 0.5938
 512/1202 [===========>..................] - ETA: 34s - loss: 0.6745 - acc: 0.5938
 576/1202 [=============>................] - ETA: 32s - loss: 0.6761 - acc: 0.5903
 640/1202 [==============>...............] - ETA: 29s - loss: 0.6749 - acc: 0.5875
 704/1202 [================>.............] - ETA: 26s - loss: 0.6765 - acc: 0.5838
 768/1202 [==================>...........] - ETA: 23s - loss: 0.6809 - acc: 0.5794
 832/1202 [===================>..........] - ETA: 19s - loss: 0.6833 - acc: 0.5745
 896/1202 [=====================>........] - ETA: 16s - loss: 0.6833 - acc: 0.5748
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6833 - acc: 0.5740
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6826 - acc: 0.5752 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6843 - acc: 0.5708
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6850 - acc: 0.5703
1202/1202 [==============================] - 69s 57ms/step - loss: 0.6830 - acc: 0.5715 - val_loss: 0.6931 - val_acc: 0.5299

Epoch 00005: val_acc did not improve from 0.58209
Epoch 6/10

  64/1202 [>.............................] - ETA: 54s - loss: 0.7159 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 50s - loss: 0.7068 - acc: 0.5234
 192/1202 [===>..........................] - ETA: 48s - loss: 0.6972 - acc: 0.5104
 256/1202 [=====>........................] - ETA: 47s - loss: 0.6951 - acc: 0.5156
 320/1202 [======>.......................] - ETA: 44s - loss: 0.6939 - acc: 0.5281
 384/1202 [========>.....................] - ETA: 41s - loss: 0.6995 - acc: 0.5339
 448/1202 [==========>...................] - ETA: 37s - loss: 0.6922 - acc: 0.5424
 512/1202 [===========>..................] - ETA: 35s - loss: 0.6929 - acc: 0.5410
 576/1202 [=============>................] - ETA: 32s - loss: 0.6909 - acc: 0.5538
 640/1202 [==============>...............] - ETA: 29s - loss: 0.6909 - acc: 0.5563
 704/1202 [================>.............] - ETA: 25s - loss: 0.6889 - acc: 0.5582
 768/1202 [==================>...........] - ETA: 22s - loss: 0.6884 - acc: 0.5534
 832/1202 [===================>..........] - ETA: 19s - loss: 0.6916 - acc: 0.5445
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6930 - acc: 0.5413
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6947 - acc: 0.5406
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6925 - acc: 0.5430 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6925 - acc: 0.5441
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6927 - acc: 0.5434
1202/1202 [==============================] - 66s 55ms/step - loss: 0.6952 - acc: 0.5399 - val_loss: 0.6845 - val_acc: 0.5373

Epoch 00006: val_acc did not improve from 0.58209
Epoch 7/10

  64/1202 [>.............................] - ETA: 53s - loss: 0.7169 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 52s - loss: 0.7190 - acc: 0.5625
 192/1202 [===>..........................] - ETA: 58s - loss: 0.7103 - acc: 0.5677
 256/1202 [=====>........................] - ETA: 52s - loss: 0.7035 - acc: 0.5625
 320/1202 [======>.......................] - ETA: 47s - loss: 0.6965 - acc: 0.5563
 384/1202 [========>.....................] - ETA: 44s - loss: 0.6889 - acc: 0.5651
 448/1202 [==========>...................] - ETA: 40s - loss: 0.6897 - acc: 0.5692
 512/1202 [===========>..................] - ETA: 37s - loss: 0.6879 - acc: 0.5742
 576/1202 [=============>................] - ETA: 34s - loss: 0.6902 - acc: 0.5677
 640/1202 [==============>...............] - ETA: 32s - loss: 0.6922 - acc: 0.5625
 704/1202 [================>.............] - ETA: 28s - loss: 0.6887 - acc: 0.5710
 768/1202 [==================>...........] - ETA: 24s - loss: 0.6861 - acc: 0.5768
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6822 - acc: 0.5865
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6826 - acc: 0.5837
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6833 - acc: 0.5833
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6821 - acc: 0.5830
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6846 - acc: 0.5800 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6831 - acc: 0.5816
1202/1202 [==============================] - 74s 62ms/step - loss: 0.6843 - acc: 0.5790 - val_loss: 0.7277 - val_acc: 0.4776

Epoch 00007: val_acc did not improve from 0.58209
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:09 - loss: 0.6567 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 1:03 - loss: 0.6493 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 1:03 - loss: 0.6643 - acc: 0.6094
 256/1202 [=====>........................] - ETA: 57s - loss: 0.6666 - acc: 0.6055 
 320/1202 [======>.......................] - ETA: 54s - loss: 0.6627 - acc: 0.6125
 384/1202 [========>.....................] - ETA: 51s - loss: 0.6604 - acc: 0.6068
 448/1202 [==========>...................] - ETA: 46s - loss: 0.6710 - acc: 0.5915
 512/1202 [===========>..................] - ETA: 41s - loss: 0.6733 - acc: 0.5957
 576/1202 [=============>................] - ETA: 38s - loss: 0.6722 - acc: 0.5885
 640/1202 [==============>...............] - ETA: 34s - loss: 0.6770 - acc: 0.5844
 704/1202 [================>.............] - ETA: 30s - loss: 0.6810 - acc: 0.5739
 768/1202 [==================>...........] - ETA: 26s - loss: 0.6838 - acc: 0.5690
 832/1202 [===================>..........] - ETA: 22s - loss: 0.6842 - acc: 0.5721
 896/1202 [=====================>........] - ETA: 18s - loss: 0.6855 - acc: 0.5658
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6851 - acc: 0.5646
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6818 - acc: 0.5684
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6856 - acc: 0.5588 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6842 - acc: 0.5625
1202/1202 [==============================] - 81s 68ms/step - loss: 0.6835 - acc: 0.5657 - val_loss: 0.7512 - val_acc: 0.4851

Epoch 00008: val_acc did not improve from 0.58209
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:22 - loss: 0.6354 - acc: 0.6875
 128/1202 [==>...........................] - ETA: 1:13 - loss: 0.6834 - acc: 0.6016
 192/1202 [===>..........................] - ETA: 1:10 - loss: 0.6986 - acc: 0.5521
 256/1202 [=====>........................] - ETA: 1:06 - loss: 0.7002 - acc: 0.5352
 320/1202 [======>.......................] - ETA: 1:00 - loss: 0.6996 - acc: 0.5469
 384/1202 [========>.....................] - ETA: 57s - loss: 0.6901 - acc: 0.5521 
 448/1202 [==========>...................] - ETA: 52s - loss: 0.6906 - acc: 0.5603
 512/1202 [===========>..................] - ETA: 49s - loss: 0.6869 - acc: 0.5645
 576/1202 [=============>................] - ETA: 44s - loss: 0.6850 - acc: 0.5642
 640/1202 [==============>...............] - ETA: 39s - loss: 0.6864 - acc: 0.5609
 704/1202 [================>.............] - ETA: 35s - loss: 0.6914 - acc: 0.5497
 768/1202 [==================>...........] - ETA: 30s - loss: 0.6882 - acc: 0.5534
 832/1202 [===================>..........] - ETA: 26s - loss: 0.6876 - acc: 0.5577
 896/1202 [=====================>........] - ETA: 21s - loss: 0.6891 - acc: 0.5547
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6836 - acc: 0.5667
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6858 - acc: 0.5625
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6851 - acc: 0.5625 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6830 - acc: 0.5634
1202/1202 [==============================] - 89s 74ms/step - loss: 0.6808 - acc: 0.5657 - val_loss: 0.7011 - val_acc: 0.5448

Epoch 00009: val_acc did not improve from 0.58209
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:08 - loss: 0.7099 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:17 - loss: 0.6681 - acc: 0.6094
 192/1202 [===>..........................] - ETA: 1:11 - loss: 0.6539 - acc: 0.6302
 256/1202 [=====>........................] - ETA: 1:07 - loss: 0.6591 - acc: 0.6094
 320/1202 [======>.......................] - ETA: 1:03 - loss: 0.6656 - acc: 0.6000
 384/1202 [========>.....................] - ETA: 57s - loss: 0.6746 - acc: 0.5755 
 448/1202 [==========>...................] - ETA: 52s - loss: 0.6793 - acc: 0.5692
 512/1202 [===========>..................] - ETA: 47s - loss: 0.6802 - acc: 0.5684
 576/1202 [=============>................] - ETA: 43s - loss: 0.6792 - acc: 0.5677
 640/1202 [==============>...............] - ETA: 39s - loss: 0.6742 - acc: 0.5750
 704/1202 [================>.............] - ETA: 35s - loss: 0.6780 - acc: 0.5724
 768/1202 [==================>...........] - ETA: 30s - loss: 0.6776 - acc: 0.5742
 832/1202 [===================>..........] - ETA: 26s - loss: 0.6782 - acc: 0.5721
 896/1202 [=====================>........] - ETA: 21s - loss: 0.6776 - acc: 0.5703
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6804 - acc: 0.5687
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6795 - acc: 0.5703
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6807 - acc: 0.5671 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6797 - acc: 0.5703
1202/1202 [==============================] - 92s 76ms/step - loss: 0.6808 - acc: 0.5691 - val_loss: 0.6891 - val_acc: 0.5448

Epoch 00010: val_acc did not improve from 0.58209
样本个数 167
样本个数 334
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 24s
128/334 [==========>...................] - ETA: 12s
192/334 [================>.............] - ETA: 6s 
256/334 [=====================>........] - ETA: 3s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 12s 35ms/step
loss: 0.686934162042812
acc: 0.5598802396994151
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fb67c460e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fb67c460e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fb64056bf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fb64056bf90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65ae5990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65ae5990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb67c3e92d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb67c3e92d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb67c3ccc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb67c3ccc50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf6e143dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf6e143dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb67c3e97d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb67c3e97d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb67c366f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb67c366f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb67c36c490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb67c36c490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb67c33bbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb67c33bbd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb67c0587d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb67c0587d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb67c101f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb67c101f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb67c05c890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb67c05c890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb664662ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb664662ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb64042ccd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb64042ccd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb66466cb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb66466cb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb67c0ea090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb67c0ea090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb640324e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb640324e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb664631e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb664631e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb6400c7f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb6400c7f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb640209750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb640209750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb640464250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb640464250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb640276a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb640276a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb6207ac310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb6207ac310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb6205e0910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb6205e0910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb6204a6890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb6204a6890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb640477050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb640477050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb6206865d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb6206865d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb6203b1850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb6203b1850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb6205d6110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb6205d6110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb620144d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb620144d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb620487790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb620487790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb62018ead0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb62018ead0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb6200ea450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb6200ea450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb60075e810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb60075e810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb600624cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb600624cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb6007220d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb6007220d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb6200abc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb6200abc10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb600543a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb600543a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb60077add0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb60077add0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf6e195790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf6e195790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb600628650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb600628650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb6002ebad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb6002ebad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb600518850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb600518850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb6004a5050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb6004a5050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e079a710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e079a710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb6200ea990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb6200ea990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb67c4111d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb67c4111d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb5e0715810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb5e0715810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb5e079dd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb5e079dd90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e060a6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e060a6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb5e058c0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb5e058c0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e04a5950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e04a5950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb5e039a890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb5e039a890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb5e0264910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb5e0264910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e03dd310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e03dd310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb5e039af10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb5e039af10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e02a90d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e02a90d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb5e0257090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb5e0257090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb5e00564d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb5e00564d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e028f910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5e028f910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb5e0257310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb5e0257310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5c0702cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb5c0702cd0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 5:57 - loss: 0.7352 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 3:20 - loss: 0.8484 - acc: 0.4844
 192/1202 [===>..........................] - ETA: 2:22 - loss: 0.7936 - acc: 0.5417
 256/1202 [=====>........................] - ETA: 1:54 - loss: 0.8290 - acc: 0.5234
 320/1202 [======>.......................] - ETA: 1:35 - loss: 0.8311 - acc: 0.5125
 384/1202 [========>.....................] - ETA: 1:20 - loss: 0.8245 - acc: 0.5208
 448/1202 [==========>...................] - ETA: 1:09 - loss: 0.8074 - acc: 0.5290
 512/1202 [===========>..................] - ETA: 1:01 - loss: 0.8042 - acc: 0.5254
 576/1202 [=============>................] - ETA: 53s - loss: 0.7939 - acc: 0.5295 
 640/1202 [==============>...............] - ETA: 46s - loss: 0.7872 - acc: 0.5281
 704/1202 [================>.............] - ETA: 40s - loss: 0.7817 - acc: 0.5327
 768/1202 [==================>...........] - ETA: 34s - loss: 0.7716 - acc: 0.5443
 832/1202 [===================>..........] - ETA: 28s - loss: 0.7692 - acc: 0.5421
 896/1202 [=====================>........] - ETA: 23s - loss: 0.7663 - acc: 0.5424
 960/1202 [======================>.......] - ETA: 17s - loss: 0.7588 - acc: 0.5521
1024/1202 [========================>.....] - ETA: 12s - loss: 0.7580 - acc: 0.5508
1088/1202 [==========================>...] - ETA: 8s - loss: 0.7556 - acc: 0.5515 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7529 - acc: 0.5538
1202/1202 [==============================] - 87s 73ms/step - loss: 0.7519 - acc: 0.5524 - val_loss: 0.7102 - val_acc: 0.5373

Epoch 00001: val_acc improved from -inf to 0.53731, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window09/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:18 - loss: 0.7433 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:00 - loss: 0.7105 - acc: 0.5859
 192/1202 [===>..........................] - ETA: 59s - loss: 0.7209 - acc: 0.5573 
 256/1202 [=====>........................] - ETA: 54s - loss: 0.7102 - acc: 0.5664
 320/1202 [======>.......................] - ETA: 53s - loss: 0.7162 - acc: 0.5563
 384/1202 [========>.....................] - ETA: 50s - loss: 0.7236 - acc: 0.5469
 448/1202 [==========>...................] - ETA: 46s - loss: 0.7110 - acc: 0.5580
 512/1202 [===========>..................] - ETA: 41s - loss: 0.7040 - acc: 0.5586
 576/1202 [=============>................] - ETA: 37s - loss: 0.7064 - acc: 0.5521
 640/1202 [==============>...............] - ETA: 33s - loss: 0.7049 - acc: 0.5516
 704/1202 [================>.............] - ETA: 29s - loss: 0.7016 - acc: 0.5568
 768/1202 [==================>...........] - ETA: 25s - loss: 0.7007 - acc: 0.5599
 832/1202 [===================>..........] - ETA: 21s - loss: 0.7027 - acc: 0.5553
 896/1202 [=====================>........] - ETA: 17s - loss: 0.7002 - acc: 0.5603
 960/1202 [======================>.......] - ETA: 14s - loss: 0.7003 - acc: 0.5604
1024/1202 [========================>.....] - ETA: 10s - loss: 0.7042 - acc: 0.5557
1088/1202 [==========================>...] - ETA: 6s - loss: 0.7059 - acc: 0.5542 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.7064 - acc: 0.5538
1202/1202 [==============================] - 72s 60ms/step - loss: 0.7058 - acc: 0.5541 - val_loss: 0.7392 - val_acc: 0.4851

Epoch 00002: val_acc did not improve from 0.53731
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:09 - loss: 0.7429 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:04 - loss: 0.7126 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 56s - loss: 0.7053 - acc: 0.5990 
 256/1202 [=====>........................] - ETA: 53s - loss: 0.6972 - acc: 0.6016
 320/1202 [======>.......................] - ETA: 48s - loss: 0.7058 - acc: 0.5656
 384/1202 [========>.....................] - ETA: 44s - loss: 0.7036 - acc: 0.5625
 448/1202 [==========>...................] - ETA: 41s - loss: 0.6946 - acc: 0.5692
 512/1202 [===========>..................] - ETA: 37s - loss: 0.6900 - acc: 0.5762
 576/1202 [=============>................] - ETA: 34s - loss: 0.6989 - acc: 0.5608
 640/1202 [==============>...............] - ETA: 31s - loss: 0.7024 - acc: 0.5500
 704/1202 [================>.............] - ETA: 27s - loss: 0.6999 - acc: 0.5540
 768/1202 [==================>...........] - ETA: 23s - loss: 0.6958 - acc: 0.5586
 832/1202 [===================>..........] - ETA: 20s - loss: 0.6977 - acc: 0.5529
 896/1202 [=====================>........] - ETA: 16s - loss: 0.7001 - acc: 0.5458
 960/1202 [======================>.......] - ETA: 13s - loss: 0.7014 - acc: 0.5437
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6989 - acc: 0.5469 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6981 - acc: 0.5469
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6963 - acc: 0.5530
1202/1202 [==============================] - 69s 57ms/step - loss: 0.6969 - acc: 0.5566 - val_loss: 0.7386 - val_acc: 0.4627

Epoch 00003: val_acc did not improve from 0.53731
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:12 - loss: 0.6546 - acc: 0.6406
 128/1202 [==>...........................] - ETA: 1:00 - loss: 0.6785 - acc: 0.6016
 192/1202 [===>..........................] - ETA: 54s - loss: 0.6728 - acc: 0.6042 
 256/1202 [=====>........................] - ETA: 50s - loss: 0.6801 - acc: 0.5898
 320/1202 [======>.......................] - ETA: 47s - loss: 0.6713 - acc: 0.6031
 384/1202 [========>.....................] - ETA: 46s - loss: 0.6732 - acc: 0.6042
 448/1202 [==========>...................] - ETA: 41s - loss: 0.6716 - acc: 0.6049
 512/1202 [===========>..................] - ETA: 38s - loss: 0.6828 - acc: 0.5898
 576/1202 [=============>................] - ETA: 35s - loss: 0.6795 - acc: 0.5938
 640/1202 [==============>...............] - ETA: 30s - loss: 0.6823 - acc: 0.5875
 704/1202 [================>.............] - ETA: 27s - loss: 0.6806 - acc: 0.5866
 768/1202 [==================>...........] - ETA: 24s - loss: 0.6904 - acc: 0.5742
 832/1202 [===================>..........] - ETA: 20s - loss: 0.6884 - acc: 0.5769
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6894 - acc: 0.5737
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6835 - acc: 0.5781
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6827 - acc: 0.5820 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6839 - acc: 0.5800
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6873 - acc: 0.5712
1202/1202 [==============================] - 69s 57ms/step - loss: 0.6886 - acc: 0.5691 - val_loss: 0.6933 - val_acc: 0.5299

Epoch 00004: val_acc did not improve from 0.53731
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:00 - loss: 0.6652 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 58s - loss: 0.6700 - acc: 0.5781 
 192/1202 [===>..........................] - ETA: 54s - loss: 0.6794 - acc: 0.5469
 256/1202 [=====>........................] - ETA: 48s - loss: 0.6751 - acc: 0.5352
 320/1202 [======>.......................] - ETA: 46s - loss: 0.6807 - acc: 0.5406
 384/1202 [========>.....................] - ETA: 42s - loss: 0.6828 - acc: 0.5339
 448/1202 [==========>...................] - ETA: 37s - loss: 0.6750 - acc: 0.5603
 512/1202 [===========>..................] - ETA: 34s - loss: 0.6734 - acc: 0.5684
 576/1202 [=============>................] - ETA: 31s - loss: 0.6770 - acc: 0.5677
 640/1202 [==============>...............] - ETA: 28s - loss: 0.6792 - acc: 0.5641
 704/1202 [================>.............] - ETA: 24s - loss: 0.6848 - acc: 0.5611
 768/1202 [==================>...........] - ETA: 21s - loss: 0.6872 - acc: 0.5508
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6905 - acc: 0.5457
 896/1202 [=====================>........] - ETA: 14s - loss: 0.6903 - acc: 0.5480
 960/1202 [======================>.......] - ETA: 11s - loss: 0.6859 - acc: 0.5552
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6838 - acc: 0.5576 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6842 - acc: 0.5588
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6838 - acc: 0.5599
1202/1202 [==============================] - 64s 53ms/step - loss: 0.6812 - acc: 0.5641 - val_loss: 0.7026 - val_acc: 0.5149

Epoch 00005: val_acc did not improve from 0.53731
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:13 - loss: 0.6723 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:02 - loss: 0.6827 - acc: 0.5156
 192/1202 [===>..........................] - ETA: 1:02 - loss: 0.6969 - acc: 0.4948
 256/1202 [=====>........................] - ETA: 58s - loss: 0.6939 - acc: 0.5117 
 320/1202 [======>.......................] - ETA: 53s - loss: 0.6924 - acc: 0.5281
 384/1202 [========>.....................] - ETA: 50s - loss: 0.6815 - acc: 0.5625
 448/1202 [==========>...................] - ETA: 47s - loss: 0.6836 - acc: 0.5580
 512/1202 [===========>..................] - ETA: 43s - loss: 0.6790 - acc: 0.5645
 576/1202 [=============>................] - ETA: 39s - loss: 0.6851 - acc: 0.5556
 640/1202 [==============>...............] - ETA: 35s - loss: 0.6830 - acc: 0.5609
 704/1202 [================>.............] - ETA: 31s - loss: 0.6855 - acc: 0.5582
 768/1202 [==================>...........] - ETA: 27s - loss: 0.6871 - acc: 0.5612
 832/1202 [===================>..........] - ETA: 23s - loss: 0.6869 - acc: 0.5637
 896/1202 [=====================>........] - ETA: 19s - loss: 0.6904 - acc: 0.5580
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6951 - acc: 0.5531
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6948 - acc: 0.5527
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6949 - acc: 0.5542 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6957 - acc: 0.5538
1202/1202 [==============================] - 80s 67ms/step - loss: 0.6932 - acc: 0.5574 - val_loss: 0.7388 - val_acc: 0.4776

Epoch 00006: val_acc did not improve from 0.53731
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:00 - loss: 0.6534 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 1:04 - loss: 0.6370 - acc: 0.6562
 192/1202 [===>..........................] - ETA: 1:00 - loss: 0.6393 - acc: 0.6562
 256/1202 [=====>........................] - ETA: 57s - loss: 0.6574 - acc: 0.6328 
 320/1202 [======>.......................] - ETA: 54s - loss: 0.6583 - acc: 0.6250
 384/1202 [========>.....................] - ETA: 50s - loss: 0.6620 - acc: 0.6198
 448/1202 [==========>...................] - ETA: 47s - loss: 0.6652 - acc: 0.6004
 512/1202 [===========>..................] - ETA: 43s - loss: 0.6696 - acc: 0.5938
 576/1202 [=============>................] - ETA: 38s - loss: 0.6698 - acc: 0.5990
 640/1202 [==============>...............] - ETA: 35s - loss: 0.6705 - acc: 0.6000
 704/1202 [================>.............] - ETA: 31s - loss: 0.6701 - acc: 0.5994
 768/1202 [==================>...........] - ETA: 27s - loss: 0.6681 - acc: 0.6042
 832/1202 [===================>..........] - ETA: 23s - loss: 0.6679 - acc: 0.6046
 896/1202 [=====================>........] - ETA: 19s - loss: 0.6684 - acc: 0.6004
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6722 - acc: 0.5938
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6773 - acc: 0.5850
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6787 - acc: 0.5846 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6763 - acc: 0.5885
1202/1202 [==============================] - 84s 70ms/step - loss: 0.6764 - acc: 0.5899 - val_loss: 0.7044 - val_acc: 0.5224

Epoch 00007: val_acc did not improve from 0.53731
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:17 - loss: 0.7058 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:12 - loss: 0.6725 - acc: 0.6172
 192/1202 [===>..........................] - ETA: 1:11 - loss: 0.6808 - acc: 0.6042
 256/1202 [=====>........................] - ETA: 1:08 - loss: 0.6793 - acc: 0.6016
 320/1202 [======>.......................] - ETA: 1:05 - loss: 0.6791 - acc: 0.5938
 384/1202 [========>.....................] - ETA: 1:02 - loss: 0.6747 - acc: 0.5859
 448/1202 [==========>...................] - ETA: 58s - loss: 0.6752 - acc: 0.5871 
 512/1202 [===========>..................] - ETA: 52s - loss: 0.6783 - acc: 0.5820
 576/1202 [=============>................] - ETA: 47s - loss: 0.6756 - acc: 0.5851
 640/1202 [==============>...............] - ETA: 42s - loss: 0.6771 - acc: 0.5734
 704/1202 [================>.............] - ETA: 36s - loss: 0.6708 - acc: 0.5810
 768/1202 [==================>...........] - ETA: 31s - loss: 0.6727 - acc: 0.5768
 832/1202 [===================>..........] - ETA: 27s - loss: 0.6702 - acc: 0.5805
 896/1202 [=====================>........] - ETA: 22s - loss: 0.6710 - acc: 0.5815
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6688 - acc: 0.5885
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6715 - acc: 0.5811
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6703 - acc: 0.5836 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6705 - acc: 0.5816
1202/1202 [==============================] - 92s 77ms/step - loss: 0.6721 - acc: 0.5799 - val_loss: 0.6973 - val_acc: 0.5746

Epoch 00008: val_acc improved from 0.53731 to 0.57463, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window09/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:32 - loss: 0.6916 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:25 - loss: 0.6626 - acc: 0.5859
 192/1202 [===>..........................] - ETA: 1:17 - loss: 0.6434 - acc: 0.6042
 256/1202 [=====>........................] - ETA: 1:10 - loss: 0.6518 - acc: 0.5938
 320/1202 [======>.......................] - ETA: 1:04 - loss: 0.6578 - acc: 0.5844
 384/1202 [========>.....................] - ETA: 1:00 - loss: 0.6641 - acc: 0.5833
 448/1202 [==========>...................] - ETA: 55s - loss: 0.6629 - acc: 0.5804 
 512/1202 [===========>..................] - ETA: 51s - loss: 0.6640 - acc: 0.5801
 576/1202 [=============>................] - ETA: 47s - loss: 0.6617 - acc: 0.5816
 640/1202 [==============>...............] - ETA: 42s - loss: 0.6685 - acc: 0.5719
 704/1202 [================>.............] - ETA: 37s - loss: 0.6701 - acc: 0.5739
 768/1202 [==================>...........] - ETA: 33s - loss: 0.6688 - acc: 0.5755
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6674 - acc: 0.5769
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6672 - acc: 0.5804
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6678 - acc: 0.5854
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6676 - acc: 0.5908
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6691 - acc: 0.5882 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6698 - acc: 0.5877
1202/1202 [==============================] - 97s 81ms/step - loss: 0.6707 - acc: 0.5890 - val_loss: 0.6960 - val_acc: 0.5224

Epoch 00009: val_acc did not improve from 0.57463
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:21 - loss: 0.6816 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:18 - loss: 0.7160 - acc: 0.5156
 192/1202 [===>..........................] - ETA: 1:17 - loss: 0.6859 - acc: 0.5677
 256/1202 [=====>........................] - ETA: 1:14 - loss: 0.6767 - acc: 0.5820
 320/1202 [======>.......................] - ETA: 1:10 - loss: 0.6758 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 1:03 - loss: 0.6741 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 57s - loss: 0.6758 - acc: 0.5737 
 512/1202 [===========>..................] - ETA: 52s - loss: 0.6735 - acc: 0.5723
 576/1202 [=============>................] - ETA: 46s - loss: 0.6734 - acc: 0.5677
 640/1202 [==============>...............] - ETA: 41s - loss: 0.6734 - acc: 0.5656
 704/1202 [================>.............] - ETA: 36s - loss: 0.6695 - acc: 0.5696
 768/1202 [==================>...........] - ETA: 32s - loss: 0.6693 - acc: 0.5755
 832/1202 [===================>..........] - ETA: 27s - loss: 0.6680 - acc: 0.5805
 896/1202 [=====================>........] - ETA: 22s - loss: 0.6699 - acc: 0.5781
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6694 - acc: 0.5792
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6678 - acc: 0.5850
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6682 - acc: 0.5827 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6693 - acc: 0.5799
1202/1202 [==============================] - 92s 76ms/step - loss: 0.6682 - acc: 0.5815 - val_loss: 0.7079 - val_acc: 0.4701

Epoch 00010: val_acc did not improve from 0.57463
样本个数 167
样本个数 334
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 18s
128/334 [==========>...................] - ETA: 8s 
192/334 [================>.............] - ETA: 4s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 9s 28ms/step
loss: 0.6884108492714203
acc: 0.5778443124479876
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fb5941687d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fb5941687d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fb59411ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fb59411ff90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65ae5b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fbf65ae5b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb594120050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb594120050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb9181d0690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb9181d0690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb594091790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb594091790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb5941207d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb5941207d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb594040c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb594040c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb53c672b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb53c672b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb53c6629d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb53c6629d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb53c580950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb53c580950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb53c672490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb53c672490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb53c573dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb53c573dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb53c302d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb53c302d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb53c346310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb53c346310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb53c57e0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb53c57e0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb53c302bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb53c302bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4e4758590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4e4758590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb51c147190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb51c147190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4e470c750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4e470c750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb51c1c4d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb51c1c4d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb51c147490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb51c147490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7401332d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb7401332d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4e44e0190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4e44e0190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4e461db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4e461db10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4e43bf1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4e43bf1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4e45db090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4e45db090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4e4434050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4e4434050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4e40d1cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4e40d1cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4e404d750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4e404d750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4e4223c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4e4223c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4e4319f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4e4319f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c07e3c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c07e3c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4c05d3b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4c05d3b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4c0598c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4c0598c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c06a6d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c06a6d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4c05d3750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4c05d3750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c0520410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c0520410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4c025d9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4c025d9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4c021bfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4c021bfd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c01cb190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c01cb190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4c025de50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4c025de50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c0044c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c0044c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4a46b9150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4a46b9150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4c02598d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4c02598d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c0140ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4c0140ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4c016d4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4c016d4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4a4747c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4a4747c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4a43cbe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4a43cbe90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4a42e79d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4a42e79d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4a41ea910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4a41ea910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4a43347d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4a43347d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4a41ea890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4a41ea890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4a42c6390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4a42c6390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4a40c6590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4a40c6590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb488646a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb488646a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4a42c67d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4a42c67d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4e4434750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4e4434750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4a40f3c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fb4a40f3c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4885ce590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fb4885ce590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4886a6510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb4886a6510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4887986d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fb4887986d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb488512e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fb488512e10>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 5:58 - loss: 0.7926 - acc: 0.4531
 128/1202 [==>...........................] - ETA: 3:15 - loss: 0.7621 - acc: 0.4922
 192/1202 [===>..........................] - ETA: 2:20 - loss: 0.7741 - acc: 0.4896
 256/1202 [=====>........................] - ETA: 1:49 - loss: 0.7723 - acc: 0.4727
 320/1202 [======>.......................] - ETA: 1:32 - loss: 0.7652 - acc: 0.4844
 384/1202 [========>.....................] - ETA: 1:19 - loss: 0.7575 - acc: 0.4792
 448/1202 [==========>...................] - ETA: 1:07 - loss: 0.7629 - acc: 0.4777
 512/1202 [===========>..................] - ETA: 58s - loss: 0.7632 - acc: 0.4824 
 576/1202 [=============>................] - ETA: 50s - loss: 0.7615 - acc: 0.4913
 640/1202 [==============>...............] - ETA: 43s - loss: 0.7567 - acc: 0.4984
 704/1202 [================>.............] - ETA: 37s - loss: 0.7542 - acc: 0.4957
 768/1202 [==================>...........] - ETA: 31s - loss: 0.7502 - acc: 0.4987
 832/1202 [===================>..........] - ETA: 26s - loss: 0.7438 - acc: 0.5048
 896/1202 [=====================>........] - ETA: 21s - loss: 0.7401 - acc: 0.5100
 960/1202 [======================>.......] - ETA: 16s - loss: 0.7342 - acc: 0.5198
1024/1202 [========================>.....] - ETA: 11s - loss: 0.7344 - acc: 0.5244
1088/1202 [==========================>...] - ETA: 7s - loss: 0.7359 - acc: 0.5211 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7307 - acc: 0.5286
1202/1202 [==============================] - 83s 69ms/step - loss: 0.7322 - acc: 0.5283 - val_loss: 0.7047 - val_acc: 0.5224

Epoch 00001: val_acc improved from -inf to 0.52239, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window10/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:19 - loss: 0.7138 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:07 - loss: 0.7247 - acc: 0.5391
 192/1202 [===>..........................] - ETA: 58s - loss: 0.7553 - acc: 0.5052 
 256/1202 [=====>........................] - ETA: 53s - loss: 0.7432 - acc: 0.5156
 320/1202 [======>.......................] - ETA: 47s - loss: 0.7405 - acc: 0.5062
 384/1202 [========>.....................] - ETA: 44s - loss: 0.7287 - acc: 0.5156
 448/1202 [==========>...................] - ETA: 40s - loss: 0.7308 - acc: 0.5201
 512/1202 [===========>..................] - ETA: 36s - loss: 0.7302 - acc: 0.5273
 576/1202 [=============>................] - ETA: 33s - loss: 0.7296 - acc: 0.5278
 640/1202 [==============>...............] - ETA: 29s - loss: 0.7266 - acc: 0.5281
 704/1202 [================>.............] - ETA: 26s - loss: 0.7255 - acc: 0.5298
 768/1202 [==================>...........] - ETA: 23s - loss: 0.7207 - acc: 0.5326
 832/1202 [===================>..........] - ETA: 19s - loss: 0.7150 - acc: 0.5385
 896/1202 [=====================>........] - ETA: 16s - loss: 0.7181 - acc: 0.5346
 960/1202 [======================>.......] - ETA: 12s - loss: 0.7156 - acc: 0.5375
1024/1202 [========================>.....] - ETA: 9s - loss: 0.7200 - acc: 0.5332 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.7201 - acc: 0.5322
1152/1202 [===========================>..] - ETA: 2s - loss: 0.7204 - acc: 0.5295
1202/1202 [==============================] - 69s 58ms/step - loss: 0.7214 - acc: 0.5275 - val_loss: 0.7018 - val_acc: 0.5149

Epoch 00002: val_acc did not improve from 0.52239
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:15 - loss: 0.7834 - acc: 0.4219
 128/1202 [==>...........................] - ETA: 1:03 - loss: 0.7607 - acc: 0.4766
 192/1202 [===>..........................] - ETA: 57s - loss: 0.7569 - acc: 0.4740 
 256/1202 [=====>........................] - ETA: 53s - loss: 0.7312 - acc: 0.5273
 320/1202 [======>.......................] - ETA: 52s - loss: 0.7234 - acc: 0.5344
 384/1202 [========>.....................] - ETA: 49s - loss: 0.7228 - acc: 0.5339
 448/1202 [==========>...................] - ETA: 46s - loss: 0.7189 - acc: 0.5379
 512/1202 [===========>..................] - ETA: 42s - loss: 0.7188 - acc: 0.5293
 576/1202 [=============>................] - ETA: 38s - loss: 0.7136 - acc: 0.5295
 640/1202 [==============>...............] - ETA: 34s - loss: 0.7205 - acc: 0.5188
 704/1202 [================>.............] - ETA: 30s - loss: 0.7227 - acc: 0.5170
 768/1202 [==================>...........] - ETA: 26s - loss: 0.7220 - acc: 0.5221
 832/1202 [===================>..........] - ETA: 22s - loss: 0.7199 - acc: 0.5252
 896/1202 [=====================>........] - ETA: 18s - loss: 0.7204 - acc: 0.5234
 960/1202 [======================>.......] - ETA: 14s - loss: 0.7181 - acc: 0.5323
1024/1202 [========================>.....] - ETA: 10s - loss: 0.7188 - acc: 0.5283
1088/1202 [==========================>...] - ETA: 6s - loss: 0.7190 - acc: 0.5267 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7169 - acc: 0.5269
1202/1202 [==============================] - 76s 63ms/step - loss: 0.7162 - acc: 0.5275 - val_loss: 0.7788 - val_acc: 0.4478

Epoch 00003: val_acc did not improve from 0.52239
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:13 - loss: 0.7198 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:09 - loss: 0.7197 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:02 - loss: 0.7163 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 57s - loss: 0.7106 - acc: 0.5586 
 320/1202 [======>.......................] - ETA: 52s - loss: 0.7287 - acc: 0.5406
 384/1202 [========>.....................] - ETA: 48s - loss: 0.7352 - acc: 0.5208
 448/1202 [==========>...................] - ETA: 45s - loss: 0.7307 - acc: 0.5134
 512/1202 [===========>..................] - ETA: 41s - loss: 0.7248 - acc: 0.5195
 576/1202 [=============>................] - ETA: 37s - loss: 0.7175 - acc: 0.5347
 640/1202 [==============>...............] - ETA: 33s - loss: 0.7098 - acc: 0.5453
 704/1202 [================>.............] - ETA: 29s - loss: 0.7084 - acc: 0.5483
 768/1202 [==================>...........] - ETA: 25s - loss: 0.7054 - acc: 0.5521
 832/1202 [===================>..........] - ETA: 22s - loss: 0.7040 - acc: 0.5505
 896/1202 [=====================>........] - ETA: 18s - loss: 0.7046 - acc: 0.5458
 960/1202 [======================>.......] - ETA: 14s - loss: 0.7036 - acc: 0.5458
1024/1202 [========================>.....] - ETA: 10s - loss: 0.7029 - acc: 0.5479
1088/1202 [==========================>...] - ETA: 6s - loss: 0.7043 - acc: 0.5441 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6992 - acc: 0.5521
1202/1202 [==============================] - 75s 62ms/step - loss: 0.6988 - acc: 0.5516 - val_loss: 0.7001 - val_acc: 0.4851

Epoch 00004: val_acc did not improve from 0.52239
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:06 - loss: 0.6828 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:03 - loss: 0.6909 - acc: 0.5156
 192/1202 [===>..........................] - ETA: 56s - loss: 0.6993 - acc: 0.5052 
 256/1202 [=====>........................] - ETA: 51s - loss: 0.6974 - acc: 0.5156
 320/1202 [======>.......................] - ETA: 52s - loss: 0.6992 - acc: 0.5188
 384/1202 [========>.....................] - ETA: 48s - loss: 0.7001 - acc: 0.5208
 448/1202 [==========>...................] - ETA: 44s - loss: 0.7034 - acc: 0.5156
 512/1202 [===========>..................] - ETA: 40s - loss: 0.7070 - acc: 0.5098
 576/1202 [=============>................] - ETA: 36s - loss: 0.7091 - acc: 0.5087
 640/1202 [==============>...............] - ETA: 32s - loss: 0.7022 - acc: 0.5234
 704/1202 [================>.............] - ETA: 28s - loss: 0.7040 - acc: 0.5213
 768/1202 [==================>...........] - ETA: 24s - loss: 0.7039 - acc: 0.5182
 832/1202 [===================>..........] - ETA: 20s - loss: 0.7000 - acc: 0.5252
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6960 - acc: 0.5335
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6957 - acc: 0.5365
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6957 - acc: 0.5410
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6958 - acc: 0.5450 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6975 - acc: 0.5451
1202/1202 [==============================] - 73s 61ms/step - loss: 0.7006 - acc: 0.5441 - val_loss: 0.6961 - val_acc: 0.5522

Epoch 00005: val_acc improved from 0.52239 to 0.55224, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window10/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:07 - loss: 0.7064 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:01 - loss: 0.6815 - acc: 0.6016
 192/1202 [===>..........................] - ETA: 56s - loss: 0.6941 - acc: 0.5625 
 256/1202 [=====>........................] - ETA: 54s - loss: 0.7015 - acc: 0.5703
 320/1202 [======>.......................] - ETA: 49s - loss: 0.6939 - acc: 0.5750
 384/1202 [========>.....................] - ETA: 47s - loss: 0.6933 - acc: 0.5781
 448/1202 [==========>...................] - ETA: 44s - loss: 0.6936 - acc: 0.5759
 512/1202 [===========>..................] - ETA: 41s - loss: 0.6985 - acc: 0.5645
 576/1202 [=============>................] - ETA: 38s - loss: 0.6987 - acc: 0.5608
 640/1202 [==============>...............] - ETA: 34s - loss: 0.6980 - acc: 0.5563
 704/1202 [================>.............] - ETA: 31s - loss: 0.6964 - acc: 0.5554
 768/1202 [==================>...........] - ETA: 27s - loss: 0.6949 - acc: 0.5547
 832/1202 [===================>..........] - ETA: 23s - loss: 0.6921 - acc: 0.5613
 896/1202 [=====================>........] - ETA: 19s - loss: 0.6969 - acc: 0.5513
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6984 - acc: 0.5469
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6972 - acc: 0.5479
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6934 - acc: 0.5524 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6948 - acc: 0.5503
1202/1202 [==============================] - 85s 71ms/step - loss: 0.6972 - acc: 0.5466 - val_loss: 0.7054 - val_acc: 0.4478

Epoch 00006: val_acc did not improve from 0.55224
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:25 - loss: 0.7046 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:18 - loss: 0.6695 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:15 - loss: 0.6738 - acc: 0.5521
 256/1202 [=====>........................] - ETA: 1:12 - loss: 0.6713 - acc: 0.5430
 320/1202 [======>.......................] - ETA: 1:07 - loss: 0.6718 - acc: 0.5500
 384/1202 [========>.....................] - ETA: 1:02 - loss: 0.6708 - acc: 0.5599
 448/1202 [==========>...................] - ETA: 57s - loss: 0.6667 - acc: 0.5737 
 512/1202 [===========>..................] - ETA: 51s - loss: 0.6650 - acc: 0.5723
 576/1202 [=============>................] - ETA: 46s - loss: 0.6689 - acc: 0.5694
 640/1202 [==============>...............] - ETA: 41s - loss: 0.6710 - acc: 0.5641
 704/1202 [================>.............] - ETA: 36s - loss: 0.6708 - acc: 0.5653
 768/1202 [==================>...........] - ETA: 32s - loss: 0.6702 - acc: 0.5690
 832/1202 [===================>..........] - ETA: 27s - loss: 0.6687 - acc: 0.5733
 896/1202 [=====================>........] - ETA: 22s - loss: 0.6744 - acc: 0.5681
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6771 - acc: 0.5604
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6809 - acc: 0.5566
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6786 - acc: 0.5588 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6812 - acc: 0.5590
1202/1202 [==============================] - 91s 76ms/step - loss: 0.6831 - acc: 0.5574 - val_loss: 0.7025 - val_acc: 0.5373

Epoch 00007: val_acc did not improve from 0.55224
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:11 - loss: 0.6090 - acc: 0.6875
 128/1202 [==>...........................] - ETA: 1:01 - loss: 0.6506 - acc: 0.6484
 192/1202 [===>..........................] - ETA: 59s - loss: 0.6672 - acc: 0.6302 
 256/1202 [=====>........................] - ETA: 56s - loss: 0.6666 - acc: 0.6250
 320/1202 [======>.......................] - ETA: 52s - loss: 0.6705 - acc: 0.6219
 384/1202 [========>.....................] - ETA: 47s - loss: 0.6718 - acc: 0.6120
 448/1202 [==========>...................] - ETA: 44s - loss: 0.6752 - acc: 0.6071
 512/1202 [===========>..................] - ETA: 40s - loss: 0.6782 - acc: 0.6055
 576/1202 [=============>................] - ETA: 36s - loss: 0.6784 - acc: 0.5972
 640/1202 [==============>...............] - ETA: 32s - loss: 0.6791 - acc: 0.5953
 704/1202 [================>.............] - ETA: 29s - loss: 0.6774 - acc: 0.5966
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6808 - acc: 0.5885
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6833 - acc: 0.5853
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6806 - acc: 0.5859
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6805 - acc: 0.5875
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6799 - acc: 0.5869
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6788 - acc: 0.5864 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6795 - acc: 0.5851
1202/1202 [==============================] - 73s 61ms/step - loss: 0.6807 - acc: 0.5807 - val_loss: 0.6976 - val_acc: 0.5224

Epoch 00008: val_acc did not improve from 0.55224
Epoch 9/10

  64/1202 [>.............................] - ETA: 59s - loss: 0.6449 - acc: 0.6406
 128/1202 [==>...........................] - ETA: 1:02 - loss: 0.6645 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 57s - loss: 0.6613 - acc: 0.5729 
 256/1202 [=====>........................] - ETA: 54s - loss: 0.6623 - acc: 0.5938
 320/1202 [======>.......................] - ETA: 49s - loss: 0.6757 - acc: 0.5687
 384/1202 [========>.....................] - ETA: 47s - loss: 0.6725 - acc: 0.5703
 448/1202 [==========>...................] - ETA: 43s - loss: 0.6705 - acc: 0.5759
 512/1202 [===========>..................] - ETA: 39s - loss: 0.6650 - acc: 0.5859
 576/1202 [=============>................] - ETA: 36s - loss: 0.6635 - acc: 0.5885
 640/1202 [==============>...............] - ETA: 32s - loss: 0.6629 - acc: 0.5875
 704/1202 [================>.............] - ETA: 28s - loss: 0.6654 - acc: 0.5852
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6676 - acc: 0.5833
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6665 - acc: 0.5853
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6688 - acc: 0.5792
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6710 - acc: 0.5771
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6701 - acc: 0.5762
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6694 - acc: 0.5800 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6683 - acc: 0.5833
1202/1202 [==============================] - 74s 62ms/step - loss: 0.6722 - acc: 0.5765 - val_loss: 0.7166 - val_acc: 0.4701

Epoch 00009: val_acc did not improve from 0.55224
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:12 - loss: 0.7179 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:04 - loss: 0.6876 - acc: 0.5469
 192/1202 [===>..........................] - ETA: 1:00 - loss: 0.6884 - acc: 0.5365
 256/1202 [=====>........................] - ETA: 57s - loss: 0.6843 - acc: 0.5352 
 320/1202 [======>.......................] - ETA: 53s - loss: 0.6802 - acc: 0.5406
 384/1202 [========>.....................] - ETA: 49s - loss: 0.6816 - acc: 0.5469
 448/1202 [==========>...................] - ETA: 46s - loss: 0.6855 - acc: 0.5335
 512/1202 [===========>..................] - ETA: 42s - loss: 0.6847 - acc: 0.5352
 576/1202 [=============>................] - ETA: 37s - loss: 0.6854 - acc: 0.5347
 640/1202 [==============>...............] - ETA: 33s - loss: 0.6874 - acc: 0.5312
 704/1202 [================>.............] - ETA: 29s - loss: 0.6840 - acc: 0.5398
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6815 - acc: 0.5469
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6815 - acc: 0.5529
 896/1202 [=====================>........] - ETA: 18s - loss: 0.6841 - acc: 0.5525
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6819 - acc: 0.5583
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6799 - acc: 0.5625
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6786 - acc: 0.5597 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6784 - acc: 0.5634
1202/1202 [==============================] - 75s 62ms/step - loss: 0.6794 - acc: 0.5632 - val_loss: 0.6843 - val_acc: 0.5522

Epoch 00010: val_acc improved from 0.55224 to 0.55224, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window10/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
样本个数 167
样本个数 334
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 17s
128/334 [==========>...................] - ETA: 7s 
192/334 [================>.............] - ETA: 4s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 8s 24ms/step
loss: 0.6990492954225598
acc: 0.5479041917952235
