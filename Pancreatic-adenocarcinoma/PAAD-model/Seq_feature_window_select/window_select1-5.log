nohup: ignoring input
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
样本个数 668
样本个数 1336
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fefb0a1e5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fefb0a1e5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fefd240c910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fefd240c910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefd240cd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefd240cd10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefd23387d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefd23387d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fefb09bc750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fefb09bc750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb076c990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb076c990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefd2338d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefd2338d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb09c0810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb09c0810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefb065e4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefb065e4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fefb0510590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fefb0510590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb0405510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb0405510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefb065e150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefb065e150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb05e8a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb05e8a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefb039f910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefb039f910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fefb03c6a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fefb03c6a10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb02e8f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb02e8f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefb0654450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefb0654450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefa0117e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefa0117e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefb0315250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefb0315250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fefa0265290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fefa0265290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefa00816d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefa00816d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefa0099d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefa0099d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefa0007c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefa0007c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef9fd0f310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef9fd0f310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef9fd5a350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef9fd5a350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef9fe252d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef9fe252d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefa0104d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefa0104d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef9fd29810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef9fd29810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef9fec2d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef9fec2d10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef978fcd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef978fcd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef9fcce250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef9fcce250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef9fd59bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef9fd59bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef979ede90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef979ede90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef976dcd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef976dcd10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef9759a990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef9759a990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef97496850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef97496850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef976dc190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef976dc190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef975dfad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef975dfad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef975d3890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef975d3890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef975e93d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef975e93d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef9fbd9450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef9fbd9450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef978c7ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef978c7ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef9738ca50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef9738ca50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef973a5710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef973a5710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef8f01ba10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef8f01ba10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8f0bd3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8f0bd3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef973a5810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef973a5810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8ef943d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8ef943d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef8ed538d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef8ed538d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef8ef8bf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef8ef8bf90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8eb4a990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8eb4a990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef8ed53310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef8ed53310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8ec42cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8ec42cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef8ea03c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef8ea03c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef8ea65090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef8ea65090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef97386c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef97386c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef8eb5fdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef8eb5fdd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8e9e61d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8e9e61d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef8e90d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fef8e90d990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef8ea65650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fef8ea65650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8e96ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8e96ff90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef8e521410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fef8e521410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8e6036d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8e6036d0>>: AttributeError: module 'gast' has no attribute 'Str'
2023-01-12 11:15:46.492011: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-01-12 11:15:46.524816: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2023-01-12 11:15:46.552184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5589b7e00520 executing computations on platform Host. Devices:
2023-01-12 11:15:46.552246: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-01-12 11:15:46.872557: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 3:43 - loss: 0.8362 - acc: 0.4688
 128/1202 [==>...........................] - ETA: 3:08 - loss: 0.8144 - acc: 0.5156
 192/1202 [===>..........................] - ETA: 2:40 - loss: 0.8156 - acc: 0.5052
 256/1202 [=====>........................] - ETA: 2:16 - loss: 0.7910 - acc: 0.5078
 320/1202 [======>.......................] - ETA: 1:58 - loss: 0.7636 - acc: 0.5219
 384/1202 [========>.....................] - ETA: 1:45 - loss: 0.7572 - acc: 0.5260
 448/1202 [==========>...................] - ETA: 1:32 - loss: 0.7544 - acc: 0.5268
 512/1202 [===========>..................] - ETA: 1:23 - loss: 0.7475 - acc: 0.5371
 576/1202 [=============>................] - ETA: 1:13 - loss: 0.7452 - acc: 0.5330
 640/1202 [==============>...............] - ETA: 1:04 - loss: 0.7446 - acc: 0.5344
 704/1202 [================>.............] - ETA: 56s - loss: 0.7419 - acc: 0.5270 
 768/1202 [==================>...........] - ETA: 48s - loss: 0.7388 - acc: 0.5312
 832/1202 [===================>..........] - ETA: 40s - loss: 0.7323 - acc: 0.5312
 896/1202 [=====================>........] - ETA: 33s - loss: 0.7271 - acc: 0.5391
 960/1202 [======================>.......] - ETA: 25s - loss: 0.7269 - acc: 0.5396
1024/1202 [========================>.....] - ETA: 19s - loss: 0.7285 - acc: 0.5352
1088/1202 [==========================>...] - ETA: 12s - loss: 0.7277 - acc: 0.5331
1152/1202 [===========================>..] - ETA: 5s - loss: 0.7269 - acc: 0.5330 
1202/1202 [==============================] - 132s 110ms/step - loss: 0.7278 - acc: 0.5333 - val_loss: 0.7124 - val_acc: 0.5373

Epoch 00001: val_acc improved from -inf to 0.53731, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window01/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:36 - loss: 0.6613 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:34 - loss: 0.6919 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:33 - loss: 0.6970 - acc: 0.5469
 256/1202 [=====>........................] - ETA: 1:27 - loss: 0.7073 - acc: 0.5352
 320/1202 [======>.......................] - ETA: 1:25 - loss: 0.7121 - acc: 0.5156
 384/1202 [========>.....................] - ETA: 1:17 - loss: 0.7135 - acc: 0.5182
 448/1202 [==========>...................] - ETA: 1:10 - loss: 0.7081 - acc: 0.5246
 512/1202 [===========>..................] - ETA: 1:04 - loss: 0.7087 - acc: 0.5273
 576/1202 [=============>................] - ETA: 58s - loss: 0.7045 - acc: 0.5365 
 640/1202 [==============>...............] - ETA: 52s - loss: 0.7022 - acc: 0.5437
 704/1202 [================>.............] - ETA: 45s - loss: 0.7049 - acc: 0.5455
 768/1202 [==================>...........] - ETA: 39s - loss: 0.7005 - acc: 0.5508
 832/1202 [===================>..........] - ETA: 33s - loss: 0.7005 - acc: 0.5505
 896/1202 [=====================>........] - ETA: 27s - loss: 0.6973 - acc: 0.5536
 960/1202 [======================>.......] - ETA: 21s - loss: 0.6949 - acc: 0.5552
1024/1202 [========================>.....] - ETA: 16s - loss: 0.6956 - acc: 0.5527
1088/1202 [==========================>...] - ETA: 10s - loss: 0.6980 - acc: 0.5496
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6981 - acc: 0.5495 
1202/1202 [==============================] - 113s 94ms/step - loss: 0.6983 - acc: 0.5532 - val_loss: 0.7230 - val_acc: 0.5373

Epoch 00002: val_acc did not improve from 0.53731
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:41 - loss: 0.7040 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:31 - loss: 0.7030 - acc: 0.5234
 192/1202 [===>..........................] - ETA: 1:24 - loss: 0.6974 - acc: 0.5521
 256/1202 [=====>........................] - ETA: 1:20 - loss: 0.6903 - acc: 0.5625
 320/1202 [======>.......................] - ETA: 1:14 - loss: 0.6964 - acc: 0.5437
 384/1202 [========>.....................] - ETA: 1:09 - loss: 0.6891 - acc: 0.5495
 448/1202 [==========>...................] - ETA: 1:04 - loss: 0.6844 - acc: 0.5513
 512/1202 [===========>..................] - ETA: 1:00 - loss: 0.6844 - acc: 0.5547
 576/1202 [=============>................] - ETA: 55s - loss: 0.6897 - acc: 0.5399 
 640/1202 [==============>...............] - ETA: 50s - loss: 0.6866 - acc: 0.5578
 704/1202 [================>.............] - ETA: 44s - loss: 0.6866 - acc: 0.5540
 768/1202 [==================>...........] - ETA: 38s - loss: 0.6943 - acc: 0.5443
 832/1202 [===================>..........] - ETA: 32s - loss: 0.6939 - acc: 0.5445
 896/1202 [=====================>........] - ETA: 27s - loss: 0.6949 - acc: 0.5480
 960/1202 [======================>.......] - ETA: 21s - loss: 0.6946 - acc: 0.5500
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6939 - acc: 0.5479
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6967 - acc: 0.5469 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6968 - acc: 0.5477
1202/1202 [==============================] - 109s 91ms/step - loss: 0.6973 - acc: 0.5507 - val_loss: 0.6949 - val_acc: 0.5597

Epoch 00003: val_acc improved from 0.53731 to 0.55970, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window01/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:28 - loss: 0.6858 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:25 - loss: 0.6932 - acc: 0.5234
 192/1202 [===>..........................] - ETA: 1:21 - loss: 0.7017 - acc: 0.5365
 256/1202 [=====>........................] - ETA: 1:16 - loss: 0.6921 - acc: 0.5664
 320/1202 [======>.......................] - ETA: 1:12 - loss: 0.6910 - acc: 0.5500
 384/1202 [========>.....................] - ETA: 1:07 - loss: 0.6869 - acc: 0.5677
 448/1202 [==========>...................] - ETA: 1:02 - loss: 0.6896 - acc: 0.5580
 512/1202 [===========>..................] - ETA: 57s - loss: 0.6987 - acc: 0.5449 
 576/1202 [=============>................] - ETA: 52s - loss: 0.7058 - acc: 0.5365
 640/1202 [==============>...............] - ETA: 47s - loss: 0.7020 - acc: 0.5437
 704/1202 [================>.............] - ETA: 42s - loss: 0.6977 - acc: 0.5455
 768/1202 [==================>...........] - ETA: 36s - loss: 0.6986 - acc: 0.5430
 832/1202 [===================>..........] - ETA: 31s - loss: 0.7003 - acc: 0.5445
 896/1202 [=====================>........] - ETA: 25s - loss: 0.6992 - acc: 0.5480
 960/1202 [======================>.......] - ETA: 20s - loss: 0.7019 - acc: 0.5469
1024/1202 [========================>.....] - ETA: 14s - loss: 0.7007 - acc: 0.5449
1088/1202 [==========================>...] - ETA: 9s - loss: 0.7003 - acc: 0.5460 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6999 - acc: 0.5477
1202/1202 [==============================] - 106s 88ms/step - loss: 0.7012 - acc: 0.5441 - val_loss: 0.6934 - val_acc: 0.5597

Epoch 00004: val_acc improved from 0.55970 to 0.55970, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window01/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:26 - loss: 0.6622 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:27 - loss: 0.6857 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 1:24 - loss: 0.6885 - acc: 0.5469
 256/1202 [=====>........................] - ETA: 1:18 - loss: 0.6908 - acc: 0.5430
 320/1202 [======>.......................] - ETA: 1:13 - loss: 0.6888 - acc: 0.5531
 384/1202 [========>.....................] - ETA: 1:07 - loss: 0.6861 - acc: 0.5521
 448/1202 [==========>...................] - ETA: 1:01 - loss: 0.6847 - acc: 0.5536
 512/1202 [===========>..................] - ETA: 56s - loss: 0.6847 - acc: 0.5547 
 576/1202 [=============>................] - ETA: 51s - loss: 0.6833 - acc: 0.5625
 640/1202 [==============>...............] - ETA: 46s - loss: 0.6832 - acc: 0.5641
 704/1202 [================>.............] - ETA: 40s - loss: 0.6831 - acc: 0.5611
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6791 - acc: 0.5729
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6772 - acc: 0.5805
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6787 - acc: 0.5792
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6792 - acc: 0.5792
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6792 - acc: 0.5771
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6795 - acc: 0.5800 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6804 - acc: 0.5747
1202/1202 [==============================] - 102s 85ms/step - loss: 0.6840 - acc: 0.5682 - val_loss: 0.7117 - val_acc: 0.5597

Epoch 00005: val_acc did not improve from 0.55970
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:35 - loss: 0.6888 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:27 - loss: 0.6683 - acc: 0.5859
 192/1202 [===>..........................] - ETA: 1:23 - loss: 0.6677 - acc: 0.5938
 256/1202 [=====>........................] - ETA: 1:17 - loss: 0.6748 - acc: 0.5859
 320/1202 [======>.......................] - ETA: 1:12 - loss: 0.6793 - acc: 0.5781
 384/1202 [========>.....................] - ETA: 1:06 - loss: 0.6757 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 1:00 - loss: 0.6780 - acc: 0.5714
 512/1202 [===========>..................] - ETA: 56s - loss: 0.6776 - acc: 0.5703 
 576/1202 [=============>................] - ETA: 51s - loss: 0.6845 - acc: 0.5556
 640/1202 [==============>...............] - ETA: 46s - loss: 0.6845 - acc: 0.5641
 704/1202 [================>.............] - ETA: 40s - loss: 0.6855 - acc: 0.5554
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6854 - acc: 0.5599
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6827 - acc: 0.5685
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6815 - acc: 0.5703
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6820 - acc: 0.5677
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6840 - acc: 0.5625
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6864 - acc: 0.5579 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6865 - acc: 0.5556
1202/1202 [==============================] - 102s 85ms/step - loss: 0.6857 - acc: 0.5516 - val_loss: 0.7081 - val_acc: 0.5522

Epoch 00006: val_acc did not improve from 0.55970
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:32 - loss: 0.6832 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:30 - loss: 0.6636 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 1:23 - loss: 0.6644 - acc: 0.5938
 256/1202 [=====>........................] - ETA: 1:19 - loss: 0.6630 - acc: 0.5820
 320/1202 [======>.......................] - ETA: 1:13 - loss: 0.6816 - acc: 0.5500
 384/1202 [========>.....................] - ETA: 1:08 - loss: 0.6773 - acc: 0.5599
 448/1202 [==========>...................] - ETA: 1:02 - loss: 0.6747 - acc: 0.5647
 512/1202 [===========>..................] - ETA: 56s - loss: 0.6736 - acc: 0.5625 
 576/1202 [=============>................] - ETA: 51s - loss: 0.6761 - acc: 0.5573
 640/1202 [==============>...............] - ETA: 45s - loss: 0.6764 - acc: 0.5594
 704/1202 [================>.............] - ETA: 40s - loss: 0.6795 - acc: 0.5582
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6797 - acc: 0.5586
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6790 - acc: 0.5589
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6789 - acc: 0.5569
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6763 - acc: 0.5635
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6769 - acc: 0.5674
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6757 - acc: 0.5699 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6804 - acc: 0.5616
1202/1202 [==============================] - 102s 85ms/step - loss: 0.6808 - acc: 0.5616 - val_loss: 0.6999 - val_acc: 0.4925

Epoch 00007: val_acc did not improve from 0.55970
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:31 - loss: 0.6457 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 1:26 - loss: 0.6476 - acc: 0.6094
 192/1202 [===>..........................] - ETA: 1:20 - loss: 0.6805 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 1:14 - loss: 0.6877 - acc: 0.5469
 320/1202 [======>.......................] - ETA: 1:08 - loss: 0.6822 - acc: 0.5625
 384/1202 [========>.....................] - ETA: 1:02 - loss: 0.6864 - acc: 0.5443
 448/1202 [==========>...................] - ETA: 57s - loss: 0.6794 - acc: 0.5603 
 512/1202 [===========>..................] - ETA: 52s - loss: 0.6736 - acc: 0.5801
 576/1202 [=============>................] - ETA: 47s - loss: 0.6740 - acc: 0.5764
 640/1202 [==============>...............] - ETA: 42s - loss: 0.6778 - acc: 0.5609
 704/1202 [================>.............] - ETA: 38s - loss: 0.6781 - acc: 0.5597
 768/1202 [==================>...........] - ETA: 33s - loss: 0.6808 - acc: 0.5534
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6783 - acc: 0.5601
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6785 - acc: 0.5625
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6782 - acc: 0.5635
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6809 - acc: 0.5596
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6806 - acc: 0.5616 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6789 - acc: 0.5651
1202/1202 [==============================] - 97s 81ms/step - loss: 0.6788 - acc: 0.5666 - val_loss: 0.6933 - val_acc: 0.5373

Epoch 00008: val_acc did not improve from 0.55970
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:10 - loss: 0.6718 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:06 - loss: 0.6717 - acc: 0.5859
 192/1202 [===>..........................] - ETA: 1:02 - loss: 0.6706 - acc: 0.5990
 256/1202 [=====>........................] - ETA: 1:00 - loss: 0.6628 - acc: 0.6172
 320/1202 [======>.......................] - ETA: 58s - loss: 0.6760 - acc: 0.6000 
 384/1202 [========>.....................] - ETA: 55s - loss: 0.6657 - acc: 0.6172
 448/1202 [==========>...................] - ETA: 51s - loss: 0.6711 - acc: 0.6228
 512/1202 [===========>..................] - ETA: 47s - loss: 0.6745 - acc: 0.6113
 576/1202 [=============>................] - ETA: 44s - loss: 0.6781 - acc: 0.6076
 640/1202 [==============>...............] - ETA: 39s - loss: 0.6798 - acc: 0.6047
 704/1202 [================>.............] - ETA: 35s - loss: 0.6770 - acc: 0.5966
 768/1202 [==================>...........] - ETA: 30s - loss: 0.6776 - acc: 0.5964
 832/1202 [===================>..........] - ETA: 26s - loss: 0.6795 - acc: 0.5889
 896/1202 [=====================>........] - ETA: 21s - loss: 0.6794 - acc: 0.5882
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6774 - acc: 0.5906
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6782 - acc: 0.5869
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6797 - acc: 0.5800 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6782 - acc: 0.5842
1202/1202 [==============================] - 88s 74ms/step - loss: 0.6782 - acc: 0.5865 - val_loss: 0.6936 - val_acc: 0.5299

Epoch 00009: val_acc did not improve from 0.55970
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:25 - loss: 0.6758 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:16 - loss: 0.6972 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 1:10 - loss: 0.6934 - acc: 0.5208
 256/1202 [=====>........................] - ETA: 1:04 - loss: 0.6819 - acc: 0.5391
 320/1202 [======>.......................] - ETA: 1:01 - loss: 0.6691 - acc: 0.5687
 384/1202 [========>.....................] - ETA: 55s - loss: 0.6745 - acc: 0.5625 
 448/1202 [==========>...................] - ETA: 52s - loss: 0.6703 - acc: 0.5714
 512/1202 [===========>..................] - ETA: 47s - loss: 0.6728 - acc: 0.5781
 576/1202 [=============>................] - ETA: 42s - loss: 0.6690 - acc: 0.5851
 640/1202 [==============>...............] - ETA: 37s - loss: 0.6664 - acc: 0.5859
 704/1202 [================>.............] - ETA: 32s - loss: 0.6680 - acc: 0.5838
 768/1202 [==================>...........] - ETA: 28s - loss: 0.6681 - acc: 0.5833
 832/1202 [===================>..........] - ETA: 23s - loss: 0.6677 - acc: 0.5877
 896/1202 [=====================>........] - ETA: 19s - loss: 0.6652 - acc: 0.5938
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6598 - acc: 0.6010
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6598 - acc: 0.6025
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6636 - acc: 0.6011 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6653 - acc: 0.5964
1202/1202 [==============================] - 79s 66ms/step - loss: 0.6685 - acc: 0.5932 - val_loss: 0.6908 - val_acc: 0.5000

Epoch 00010: val_acc did not improve from 0.55970
样本个数 167
样本个数 334
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 9s
128/334 [==========>...................] - ETA: 5s
192/334 [================>.............] - ETA: 3s
256/334 [=====================>........] - ETA: 1s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 8s 23ms/step
loss: 0.69027971293398
acc: 0.5359281433556609
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fe9480a6610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fe9480a6610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fe92c2486d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fe92c2486d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb09e2b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb09e2b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefd243eb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefd243eb50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fefd23f3fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fefd23f3fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe92c7d9250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe92c7d9250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefd2396d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefd2396d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefd2404490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefd2404490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe92c7cea90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe92c7cea90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe948092e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe948092e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe9480e2950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe9480e2950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefd2431f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefd2431f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe92c38cb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe92c38cb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe92c5f52d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe92c5f52d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe92c2bef90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe92c2bef90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe90074a150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe90074a150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe92c7bd410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe92c7bd410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe9080daf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe9080daf10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe90063ce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe90063ce50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe9005aa490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe9005aa490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8ed49f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fef8ed49f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe90063c9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe90063c9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe900539d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe900539d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe90034f950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe90034f950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe9002d1ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe9002d1ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe90037c310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe90037c310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe90034ff50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe90034ff50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe900093990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe900093990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe900068290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe900068290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe900052610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe900052610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe9000a7650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe9000a7650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe9000fbad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe9000fbad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8c86dd150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8c86dd150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8c85de150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8c85de150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8c8382e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8c8382e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8c8464bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8c8464bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8c8563b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8c8563b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8c83b98d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8c83b98d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8c81ce890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8c81ce890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8c809f650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8c809f650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8c8453d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8c8453d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8c81ceb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8c81ceb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8a874a050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8a874a050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8a8667b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8a8667b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8a8689110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8a8689110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8c822a090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8c822a090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8a8667e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8a8667e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8a854cc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8a854cc90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8a8305110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8a8305110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8a8228410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8a8228410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8a816efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8a816efd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8a8576d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8a8576d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8a826fed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8a826fed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8a8260510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8a8260510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8886c2610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8886c2610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8887c0050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8887c0050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8a8218ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8a8218ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe88873e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe88873e350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8884f65d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe8884f65d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8886c2d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe8886c2d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe888545ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe888545ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8884f66d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe8884f66d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8883fcf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe8883fcf50>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 4:09 - loss: 0.7256 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 2:45 - loss: 0.7206 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 2:12 - loss: 0.7348 - acc: 0.5208
 256/1202 [=====>........................] - ETA: 1:54 - loss: 0.7484 - acc: 0.5117
 320/1202 [======>.......................] - ETA: 1:41 - loss: 0.7549 - acc: 0.5156
 384/1202 [========>.....................] - ETA: 1:31 - loss: 0.7515 - acc: 0.5156
 448/1202 [==========>...................] - ETA: 1:22 - loss: 0.7557 - acc: 0.5000
 512/1202 [===========>..................] - ETA: 1:12 - loss: 0.7482 - acc: 0.5020
 576/1202 [=============>................] - ETA: 1:04 - loss: 0.7471 - acc: 0.5017
 640/1202 [==============>...............] - ETA: 57s - loss: 0.7401 - acc: 0.5062 
 704/1202 [================>.............] - ETA: 50s - loss: 0.7387 - acc: 0.5085
 768/1202 [==================>...........] - ETA: 43s - loss: 0.7389 - acc: 0.5026
 832/1202 [===================>..........] - ETA: 36s - loss: 0.7361 - acc: 0.5072
 896/1202 [=====================>........] - ETA: 29s - loss: 0.7349 - acc: 0.5078
 960/1202 [======================>.......] - ETA: 23s - loss: 0.7316 - acc: 0.5115
1024/1202 [========================>.....] - ETA: 17s - loss: 0.7332 - acc: 0.5107
1088/1202 [==========================>...] - ETA: 10s - loss: 0.7320 - acc: 0.5129
1152/1202 [===========================>..] - ETA: 4s - loss: 0.7294 - acc: 0.5139 
1202/1202 [==============================] - 121s 100ms/step - loss: 0.7242 - acc: 0.5208 - val_loss: 0.6895 - val_acc: 0.5597

Epoch 00001: val_acc improved from -inf to 0.55970, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window02/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:47 - loss: 0.7176 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:40 - loss: 0.6818 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:31 - loss: 0.6580 - acc: 0.5938
 256/1202 [=====>........................] - ETA: 1:26 - loss: 0.6670 - acc: 0.5742
 320/1202 [======>.......................] - ETA: 1:19 - loss: 0.6638 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 1:14 - loss: 0.6754 - acc: 0.5729
 448/1202 [==========>...................] - ETA: 1:08 - loss: 0.6809 - acc: 0.5625
 512/1202 [===========>..................] - ETA: 1:02 - loss: 0.6842 - acc: 0.5566
 576/1202 [=============>................] - ETA: 56s - loss: 0.6933 - acc: 0.5486 
 640/1202 [==============>...............] - ETA: 50s - loss: 0.6902 - acc: 0.5516
 704/1202 [================>.............] - ETA: 44s - loss: 0.6944 - acc: 0.5469
 768/1202 [==================>...........] - ETA: 39s - loss: 0.6949 - acc: 0.5482
 832/1202 [===================>..........] - ETA: 33s - loss: 0.6944 - acc: 0.5505
 896/1202 [=====================>........] - ETA: 27s - loss: 0.6974 - acc: 0.5491
 960/1202 [======================>.......] - ETA: 21s - loss: 0.6980 - acc: 0.5469
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6993 - acc: 0.5439
1088/1202 [==========================>...] - ETA: 10s - loss: 0.6989 - acc: 0.5423
1152/1202 [===========================>..] - ETA: 4s - loss: 0.7009 - acc: 0.5434 
1202/1202 [==============================] - 113s 94ms/step - loss: 0.6997 - acc: 0.5449 - val_loss: 0.7110 - val_acc: 0.5373

Epoch 00002: val_acc did not improve from 0.55970
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:40 - loss: 0.6826 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 1:36 - loss: 0.6668 - acc: 0.6094
 192/1202 [===>..........................] - ETA: 1:30 - loss: 0.6894 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 1:23 - loss: 0.6814 - acc: 0.5859
 320/1202 [======>.......................] - ETA: 1:17 - loss: 0.6843 - acc: 0.5875
 384/1202 [========>.....................] - ETA: 1:12 - loss: 0.6793 - acc: 0.5990
 448/1202 [==========>...................] - ETA: 1:05 - loss: 0.6837 - acc: 0.5893
 512/1202 [===========>..................] - ETA: 1:00 - loss: 0.6835 - acc: 0.5898
 576/1202 [=============>................] - ETA: 55s - loss: 0.6926 - acc: 0.5764 
 640/1202 [==============>...............] - ETA: 49s - loss: 0.6927 - acc: 0.5750
 704/1202 [================>.............] - ETA: 43s - loss: 0.6965 - acc: 0.5696
 768/1202 [==================>...........] - ETA: 37s - loss: 0.6924 - acc: 0.5781
 832/1202 [===================>..........] - ETA: 32s - loss: 0.6938 - acc: 0.5745
 896/1202 [=====================>........] - ETA: 26s - loss: 0.6950 - acc: 0.5737
 960/1202 [======================>.......] - ETA: 21s - loss: 0.6964 - acc: 0.5656
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6958 - acc: 0.5664
1088/1202 [==========================>...] - ETA: 10s - loss: 0.7006 - acc: 0.5588
1152/1202 [===========================>..] - ETA: 4s - loss: 0.7007 - acc: 0.5556 
1202/1202 [==============================] - 109s 91ms/step - loss: 0.7018 - acc: 0.5507 - val_loss: 0.6908 - val_acc: 0.5299

Epoch 00003: val_acc did not improve from 0.55970
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:38 - loss: 0.6825 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:25 - loss: 0.6823 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:18 - loss: 0.6947 - acc: 0.5469
 256/1202 [=====>........................] - ETA: 1:14 - loss: 0.7084 - acc: 0.5234
 320/1202 [======>.......................] - ETA: 1:10 - loss: 0.7124 - acc: 0.5250
 384/1202 [========>.....................] - ETA: 1:04 - loss: 0.7022 - acc: 0.5391
 448/1202 [==========>...................] - ETA: 59s - loss: 0.7000 - acc: 0.5491 
 512/1202 [===========>..................] - ETA: 54s - loss: 0.6980 - acc: 0.5527
 576/1202 [=============>................] - ETA: 49s - loss: 0.6943 - acc: 0.5608
 640/1202 [==============>...............] - ETA: 44s - loss: 0.6926 - acc: 0.5594
 704/1202 [================>.............] - ETA: 38s - loss: 0.6931 - acc: 0.5625
 768/1202 [==================>...........] - ETA: 34s - loss: 0.6895 - acc: 0.5677
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6896 - acc: 0.5685
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6861 - acc: 0.5748
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6871 - acc: 0.5823
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6861 - acc: 0.5820
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6837 - acc: 0.5873 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6842 - acc: 0.5859
1202/1202 [==============================] - 99s 82ms/step - loss: 0.6857 - acc: 0.5824 - val_loss: 0.7145 - val_acc: 0.5448

Epoch 00004: val_acc did not improve from 0.55970
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:35 - loss: 0.7177 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:30 - loss: 0.7028 - acc: 0.5469
 192/1202 [===>..........................] - ETA: 1:21 - loss: 0.6963 - acc: 0.5573
 256/1202 [=====>........................] - ETA: 1:17 - loss: 0.6953 - acc: 0.5625
 320/1202 [======>.......................] - ETA: 1:10 - loss: 0.6823 - acc: 0.5906
 384/1202 [========>.....................] - ETA: 1:05 - loss: 0.6897 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 59s - loss: 0.6869 - acc: 0.5759 
 512/1202 [===========>..................] - ETA: 54s - loss: 0.6821 - acc: 0.5840
 576/1202 [=============>................] - ETA: 49s - loss: 0.6804 - acc: 0.5799
 640/1202 [==============>...............] - ETA: 45s - loss: 0.6804 - acc: 0.5875
 704/1202 [================>.............] - ETA: 39s - loss: 0.6896 - acc: 0.5753
 768/1202 [==================>...........] - ETA: 34s - loss: 0.6875 - acc: 0.5807
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6856 - acc: 0.5817
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6892 - acc: 0.5737
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6870 - acc: 0.5740
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6881 - acc: 0.5713
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6874 - acc: 0.5744 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6858 - acc: 0.5790
1202/1202 [==============================] - 99s 82ms/step - loss: 0.6857 - acc: 0.5774 - val_loss: 0.6992 - val_acc: 0.5075

Epoch 00005: val_acc did not improve from 0.55970
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:34 - loss: 0.7067 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:24 - loss: 0.6909 - acc: 0.5391
 192/1202 [===>..........................] - ETA: 1:18 - loss: 0.7084 - acc: 0.5260
 256/1202 [=====>........................] - ETA: 1:13 - loss: 0.6938 - acc: 0.5469
 320/1202 [======>.......................] - ETA: 1:08 - loss: 0.6877 - acc: 0.5594
 384/1202 [========>.....................] - ETA: 1:03 - loss: 0.6876 - acc: 0.5677
 448/1202 [==========>...................] - ETA: 58s - loss: 0.6864 - acc: 0.5670 
 512/1202 [===========>..................] - ETA: 54s - loss: 0.6811 - acc: 0.5703
 576/1202 [=============>................] - ETA: 49s - loss: 0.6737 - acc: 0.5764
 640/1202 [==============>...............] - ETA: 44s - loss: 0.6695 - acc: 0.5859
 704/1202 [================>.............] - ETA: 38s - loss: 0.6708 - acc: 0.5866
 768/1202 [==================>...........] - ETA: 33s - loss: 0.6717 - acc: 0.5911
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6694 - acc: 0.5938
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6708 - acc: 0.5904
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6757 - acc: 0.5854
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6800 - acc: 0.5781
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6788 - acc: 0.5855 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6822 - acc: 0.5816
1202/1202 [==============================] - 102s 85ms/step - loss: 0.6821 - acc: 0.5815 - val_loss: 0.6894 - val_acc: 0.5522

Epoch 00006: val_acc did not improve from 0.55970
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:36 - loss: 0.6653 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:31 - loss: 0.6501 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 1:25 - loss: 0.6663 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 1:20 - loss: 0.6610 - acc: 0.6055
 320/1202 [======>.......................] - ETA: 1:15 - loss: 0.6715 - acc: 0.5781
 384/1202 [========>.....................] - ETA: 1:10 - loss: 0.6812 - acc: 0.5651
 448/1202 [==========>...................] - ETA: 1:04 - loss: 0.6750 - acc: 0.5826
 512/1202 [===========>..................] - ETA: 59s - loss: 0.6798 - acc: 0.5801 
 576/1202 [=============>................] - ETA: 53s - loss: 0.6746 - acc: 0.5938
 640/1202 [==============>...............] - ETA: 48s - loss: 0.6755 - acc: 0.5969
 704/1202 [================>.............] - ETA: 42s - loss: 0.6778 - acc: 0.5895
 768/1202 [==================>...........] - ETA: 37s - loss: 0.6809 - acc: 0.5768
 832/1202 [===================>..........] - ETA: 31s - loss: 0.6808 - acc: 0.5781
 896/1202 [=====================>........] - ETA: 26s - loss: 0.6812 - acc: 0.5770
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6799 - acc: 0.5792
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6805 - acc: 0.5752
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6840 - acc: 0.5699 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6857 - acc: 0.5651
1202/1202 [==============================] - 108s 90ms/step - loss: 0.6852 - acc: 0.5649 - val_loss: 0.6948 - val_acc: 0.5597

Epoch 00007: val_acc improved from 0.55970 to 0.55970, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window02/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:42 - loss: 0.6636 - acc: 0.6406
 128/1202 [==>...........................] - ETA: 1:34 - loss: 0.6603 - acc: 0.6562
 192/1202 [===>..........................] - ETA: 1:28 - loss: 0.6668 - acc: 0.6406
 256/1202 [=====>........................] - ETA: 1:21 - loss: 0.6725 - acc: 0.6289
 320/1202 [======>.......................] - ETA: 1:17 - loss: 0.6640 - acc: 0.6375
 384/1202 [========>.....................] - ETA: 1:11 - loss: 0.6687 - acc: 0.6172
 448/1202 [==========>...................] - ETA: 1:05 - loss: 0.6650 - acc: 0.6183
 512/1202 [===========>..................] - ETA: 59s - loss: 0.6739 - acc: 0.6094 
 576/1202 [=============>................] - ETA: 54s - loss: 0.6691 - acc: 0.6146
 640/1202 [==============>...............] - ETA: 48s - loss: 0.6715 - acc: 0.6094
 704/1202 [================>.............] - ETA: 42s - loss: 0.6731 - acc: 0.6023
 768/1202 [==================>...........] - ETA: 37s - loss: 0.6738 - acc: 0.5964
 832/1202 [===================>..........] - ETA: 31s - loss: 0.6760 - acc: 0.5901
 896/1202 [=====================>........] - ETA: 26s - loss: 0.6780 - acc: 0.5815
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6792 - acc: 0.5792
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6774 - acc: 0.5830
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6772 - acc: 0.5818 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6777 - acc: 0.5773
1202/1202 [==============================] - 108s 90ms/step - loss: 0.6777 - acc: 0.5774 - val_loss: 0.6898 - val_acc: 0.5896

Epoch 00008: val_acc improved from 0.55970 to 0.58955, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window02/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:33 - loss: 0.6703 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:31 - loss: 0.6606 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 1:25 - loss: 0.6688 - acc: 0.5938
 256/1202 [=====>........................] - ETA: 1:20 - loss: 0.6612 - acc: 0.6094
 320/1202 [======>.......................] - ETA: 1:15 - loss: 0.6665 - acc: 0.5938
 384/1202 [========>.....................] - ETA: 1:09 - loss: 0.6680 - acc: 0.5911
 448/1202 [==========>...................] - ETA: 1:03 - loss: 0.6731 - acc: 0.5893
 512/1202 [===========>..................] - ETA: 58s - loss: 0.6696 - acc: 0.5996 
 576/1202 [=============>................] - ETA: 53s - loss: 0.6632 - acc: 0.6163
 640/1202 [==============>...............] - ETA: 48s - loss: 0.6609 - acc: 0.6234
 704/1202 [================>.............] - ETA: 42s - loss: 0.6611 - acc: 0.6250
 768/1202 [==================>...........] - ETA: 37s - loss: 0.6609 - acc: 0.6224
 832/1202 [===================>..........] - ETA: 31s - loss: 0.6597 - acc: 0.6226
 896/1202 [=====================>........] - ETA: 26s - loss: 0.6596 - acc: 0.6217
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6596 - acc: 0.6208
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6633 - acc: 0.6172
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6659 - acc: 0.6112 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6699 - acc: 0.6076
1202/1202 [==============================] - 108s 90ms/step - loss: 0.6704 - acc: 0.6057 - val_loss: 0.7253 - val_acc: 0.5299

Epoch 00009: val_acc did not improve from 0.58955
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:39 - loss: 0.6032 - acc: 0.7031
 128/1202 [==>...........................] - ETA: 1:31 - loss: 0.6398 - acc: 0.6484
 192/1202 [===>..........................] - ETA: 1:25 - loss: 0.6400 - acc: 0.6458
 256/1202 [=====>........................] - ETA: 1:20 - loss: 0.6405 - acc: 0.6406
 320/1202 [======>.......................] - ETA: 1:15 - loss: 0.6573 - acc: 0.6188
 384/1202 [========>.....................] - ETA: 1:10 - loss: 0.6635 - acc: 0.6094
 448/1202 [==========>...................] - ETA: 1:05 - loss: 0.6735 - acc: 0.6027
 512/1202 [===========>..................] - ETA: 1:00 - loss: 0.6793 - acc: 0.5859
 576/1202 [=============>................] - ETA: 54s - loss: 0.6858 - acc: 0.5694 
 640/1202 [==============>...............] - ETA: 48s - loss: 0.6851 - acc: 0.5703
 704/1202 [================>.............] - ETA: 43s - loss: 0.6887 - acc: 0.5653
 768/1202 [==================>...........] - ETA: 37s - loss: 0.6907 - acc: 0.5599
 832/1202 [===================>..........] - ETA: 32s - loss: 0.6882 - acc: 0.5625
 896/1202 [=====================>........] - ETA: 26s - loss: 0.6837 - acc: 0.5703
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6825 - acc: 0.5729
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6836 - acc: 0.5693
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6839 - acc: 0.5671 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6823 - acc: 0.5694
1202/1202 [==============================] - 110s 91ms/step - loss: 0.6835 - acc: 0.5674 - val_loss: 0.7028 - val_acc: 0.5299

Epoch 00010: val_acc did not improve from 0.58955
样本个数 167
样本个数 334
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 15s
128/334 [==========>...................] - ETA: 8s 
192/334 [================>.............] - ETA: 5s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 11s 33ms/step
loss: 0.6842404903765924
acc: 0.5688622756275589
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fe7e85f1850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fe7e85f1850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fefd231b090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fefd231b090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb90af310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb90af310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefc19ce6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fefc19ce6d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7a86cf990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7a86cf990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7c878d350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7c878d350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefc19ce3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fefc19ce3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7e844ea10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7e844ea10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7e8311dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7e8311dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7e82735d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7e82735d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7e82ec410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7e82ec410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe7e850ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe7e850ba50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7e82ebb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7e82ebb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7e806c810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7e806c810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7a857ce90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7a857ce90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7e80c24d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7e80c24d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe7e806c2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe7e806c2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7a85cec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7a85cec50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7a857cc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7a857cc50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7a82d5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7a82d5090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7a8623a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7a8623a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe7a840fe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe7a840fe90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7a82eded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7a82eded0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7e85991d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7e85991d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe788774a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe788774a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7a82e9410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7a82e9410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe7e8599cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe7e8599cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe788741d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe788741d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe78858ced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe78858ced0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe788410a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe788410a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe78865b450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe78865b450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe78858c210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe78858c210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe78840ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe78840ba90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe788452050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe788452050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7881287d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7881287d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7787e90d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7787e90d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe788274950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe788274950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe778708ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe778708ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe788128510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe788128510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe778641b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe778641b10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7786bc450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7786bc450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe7786eaa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe7786eaa10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7785dc7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7785dc7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7785c1d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7785c1d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7782b0c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe7782b0c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7784f78d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7784f78d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe77842f750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe77842f750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe77827bc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe77827bc10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7780c1f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7780c1f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe744714e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe744714e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe77816add0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe77816add0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe77807bf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe77807bf10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe744754790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe744754790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7783822d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7783822d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe744481310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe744481310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe74446e790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe74446e790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe744319310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe744319310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe74451a050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe74451a050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7442ffcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe7442ffcd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe744119210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe744119210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7440c55d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7440c55d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe74424d610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe74424d610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7440d3ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe7440d3ad0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 4:06 - loss: 0.7580 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 2:33 - loss: 0.7396 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:59 - loss: 0.7454 - acc: 0.5417
 256/1202 [=====>........................] - ETA: 1:39 - loss: 0.7556 - acc: 0.5234
 320/1202 [======>.......................] - ETA: 1:26 - loss: 0.7570 - acc: 0.5281
 384/1202 [========>.....................] - ETA: 1:16 - loss: 0.7399 - acc: 0.5365
 448/1202 [==========>...................] - ETA: 1:07 - loss: 0.7434 - acc: 0.5424
 512/1202 [===========>..................] - ETA: 1:00 - loss: 0.7574 - acc: 0.5312
 576/1202 [=============>................] - ETA: 52s - loss: 0.7585 - acc: 0.5260 
 640/1202 [==============>...............] - ETA: 46s - loss: 0.7501 - acc: 0.5281
 704/1202 [================>.............] - ETA: 40s - loss: 0.7442 - acc: 0.5312
 768/1202 [==================>...........] - ETA: 34s - loss: 0.7456 - acc: 0.5208
 832/1202 [===================>..........] - ETA: 29s - loss: 0.7422 - acc: 0.5228
 896/1202 [=====================>........] - ETA: 24s - loss: 0.7380 - acc: 0.5301
 960/1202 [======================>.......] - ETA: 18s - loss: 0.7347 - acc: 0.5333
1024/1202 [========================>.....] - ETA: 13s - loss: 0.7355 - acc: 0.5273
1088/1202 [==========================>...] - ETA: 8s - loss: 0.7362 - acc: 0.5285 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7319 - acc: 0.5339
1202/1202 [==============================] - 100s 83ms/step - loss: 0.7303 - acc: 0.5333 - val_loss: 0.6808 - val_acc: 0.5672

Epoch 00001: val_acc improved from -inf to 0.56716, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window03/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:30 - loss: 0.6831 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 1:23 - loss: 0.7077 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 1:20 - loss: 0.6976 - acc: 0.5677
 256/1202 [=====>........................] - ETA: 1:14 - loss: 0.6924 - acc: 0.5820
 320/1202 [======>.......................] - ETA: 1:09 - loss: 0.6921 - acc: 0.5844
 384/1202 [========>.....................] - ETA: 1:04 - loss: 0.6859 - acc: 0.5859
 448/1202 [==========>...................] - ETA: 59s - loss: 0.6803 - acc: 0.5915 
 512/1202 [===========>..................] - ETA: 54s - loss: 0.6938 - acc: 0.5762
 576/1202 [=============>................] - ETA: 49s - loss: 0.6964 - acc: 0.5781
 640/1202 [==============>...............] - ETA: 44s - loss: 0.6981 - acc: 0.5781
 704/1202 [================>.............] - ETA: 39s - loss: 0.6974 - acc: 0.5824
 768/1202 [==================>...........] - ETA: 34s - loss: 0.7053 - acc: 0.5742
 832/1202 [===================>..........] - ETA: 29s - loss: 0.7104 - acc: 0.5577
 896/1202 [=====================>........] - ETA: 24s - loss: 0.7095 - acc: 0.5536
 960/1202 [======================>.......] - ETA: 19s - loss: 0.7039 - acc: 0.5615
1024/1202 [========================>.....] - ETA: 14s - loss: 0.7004 - acc: 0.5674
1088/1202 [==========================>...] - ETA: 9s - loss: 0.7019 - acc: 0.5607 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7011 - acc: 0.5608
1202/1202 [==============================] - 100s 83ms/step - loss: 0.7034 - acc: 0.5557 - val_loss: 0.6809 - val_acc: 0.5373

Epoch 00002: val_acc did not improve from 0.56716
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:30 - loss: 0.7197 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 1:28 - loss: 0.7326 - acc: 0.4766
 192/1202 [===>..........................] - ETA: 1:24 - loss: 0.7183 - acc: 0.5156
 256/1202 [=====>........................] - ETA: 1:19 - loss: 0.7150 - acc: 0.5156
 320/1202 [======>.......................] - ETA: 1:13 - loss: 0.7119 - acc: 0.5219
 384/1202 [========>.....................] - ETA: 1:08 - loss: 0.7194 - acc: 0.5052
 448/1202 [==========>...................] - ETA: 1:03 - loss: 0.7109 - acc: 0.5268
 512/1202 [===========>..................] - ETA: 57s - loss: 0.7055 - acc: 0.5371 
 576/1202 [=============>................] - ETA: 52s - loss: 0.7107 - acc: 0.5260
 640/1202 [==============>...............] - ETA: 47s - loss: 0.7062 - acc: 0.5375
 704/1202 [================>.............] - ETA: 42s - loss: 0.7007 - acc: 0.5511
 768/1202 [==================>...........] - ETA: 37s - loss: 0.6999 - acc: 0.5482
 832/1202 [===================>..........] - ETA: 31s - loss: 0.6977 - acc: 0.5505
 896/1202 [=====================>........] - ETA: 26s - loss: 0.6961 - acc: 0.5513
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6951 - acc: 0.5531
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6937 - acc: 0.5547
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6950 - acc: 0.5561 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6979 - acc: 0.5538
1202/1202 [==============================] - 109s 91ms/step - loss: 0.7031 - acc: 0.5507 - val_loss: 0.7006 - val_acc: 0.5224

Epoch 00003: val_acc did not improve from 0.56716
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:41 - loss: 0.6431 - acc: 0.7188
 128/1202 [==>...........................] - ETA: 1:31 - loss: 0.6866 - acc: 0.6172
 192/1202 [===>..........................] - ETA: 1:27 - loss: 0.6851 - acc: 0.6042
 256/1202 [=====>........................] - ETA: 1:21 - loss: 0.6925 - acc: 0.5977
 320/1202 [======>.......................] - ETA: 1:15 - loss: 0.6805 - acc: 0.6062
 384/1202 [========>.....................] - ETA: 1:09 - loss: 0.6772 - acc: 0.6172
 448/1202 [==========>...................] - ETA: 1:05 - loss: 0.6796 - acc: 0.6138
 512/1202 [===========>..................] - ETA: 59s - loss: 0.6777 - acc: 0.6094 
 576/1202 [=============>................] - ETA: 53s - loss: 0.6802 - acc: 0.5938
 640/1202 [==============>...............] - ETA: 47s - loss: 0.6801 - acc: 0.5906
 704/1202 [================>.............] - ETA: 42s - loss: 0.6764 - acc: 0.5895
 768/1202 [==================>...........] - ETA: 37s - loss: 0.6780 - acc: 0.5807
 832/1202 [===================>..........] - ETA: 31s - loss: 0.6823 - acc: 0.5769
 896/1202 [=====================>........] - ETA: 25s - loss: 0.6831 - acc: 0.5737
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6835 - acc: 0.5667
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6822 - acc: 0.5703
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6826 - acc: 0.5689 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6824 - acc: 0.5694
1202/1202 [==============================] - 104s 86ms/step - loss: 0.6819 - acc: 0.5691 - val_loss: 0.6926 - val_acc: 0.5597

Epoch 00004: val_acc did not improve from 0.56716
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:29 - loss: 0.7157 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:25 - loss: 0.7185 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 1:21 - loss: 0.7011 - acc: 0.5573
 256/1202 [=====>........................] - ETA: 1:17 - loss: 0.6880 - acc: 0.5703
 320/1202 [======>.......................] - ETA: 1:12 - loss: 0.6810 - acc: 0.5781
 384/1202 [========>.....................] - ETA: 1:06 - loss: 0.6782 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 1:02 - loss: 0.6718 - acc: 0.5804
 512/1202 [===========>..................] - ETA: 56s - loss: 0.6768 - acc: 0.5781 
 576/1202 [=============>................] - ETA: 51s - loss: 0.6816 - acc: 0.5625
 640/1202 [==============>...............] - ETA: 45s - loss: 0.6830 - acc: 0.5641
 704/1202 [================>.............] - ETA: 40s - loss: 0.6823 - acc: 0.5668
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6806 - acc: 0.5703
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6827 - acc: 0.5709
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6884 - acc: 0.5625
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6897 - acc: 0.5594
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6912 - acc: 0.5557
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6892 - acc: 0.5607 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6855 - acc: 0.5677
1202/1202 [==============================] - 102s 85ms/step - loss: 0.6890 - acc: 0.5624 - val_loss: 0.7047 - val_acc: 0.5373

Epoch 00005: val_acc did not improve from 0.56716
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:24 - loss: 0.6967 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:24 - loss: 0.7112 - acc: 0.4844
 192/1202 [===>..........................] - ETA: 1:20 - loss: 0.7331 - acc: 0.4635
 256/1202 [=====>........................] - ETA: 1:17 - loss: 0.7194 - acc: 0.4844
 320/1202 [======>.......................] - ETA: 1:12 - loss: 0.7186 - acc: 0.4844
 384/1202 [========>.....................] - ETA: 1:06 - loss: 0.7096 - acc: 0.5026
 448/1202 [==========>...................] - ETA: 1:01 - loss: 0.7093 - acc: 0.5045
 512/1202 [===========>..................] - ETA: 57s - loss: 0.7081 - acc: 0.5039 
 576/1202 [=============>................] - ETA: 51s - loss: 0.7054 - acc: 0.5139
 640/1202 [==============>...............] - ETA: 46s - loss: 0.7024 - acc: 0.5281
 704/1202 [================>.............] - ETA: 41s - loss: 0.7034 - acc: 0.5270
 768/1202 [==================>...........] - ETA: 36s - loss: 0.7027 - acc: 0.5312
 832/1202 [===================>..........] - ETA: 30s - loss: 0.7011 - acc: 0.5325
 896/1202 [=====================>........] - ETA: 25s - loss: 0.7024 - acc: 0.5268
 960/1202 [======================>.......] - ETA: 20s - loss: 0.7009 - acc: 0.5323
1024/1202 [========================>.....] - ETA: 14s - loss: 0.7003 - acc: 0.5322
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6964 - acc: 0.5395 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6966 - acc: 0.5382
1202/1202 [==============================] - 105s 87ms/step - loss: 0.6953 - acc: 0.5433 - val_loss: 0.7160 - val_acc: 0.5299

Epoch 00006: val_acc did not improve from 0.56716
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:34 - loss: 0.6739 - acc: 0.5938
 128/1202 [==>...........................] - ETA: 1:31 - loss: 0.6756 - acc: 0.6094
 192/1202 [===>..........................] - ETA: 1:25 - loss: 0.6800 - acc: 0.5990
 256/1202 [=====>........................] - ETA: 1:21 - loss: 0.6788 - acc: 0.5859
 320/1202 [======>.......................] - ETA: 1:14 - loss: 0.6825 - acc: 0.5750
 384/1202 [========>.....................] - ETA: 1:10 - loss: 0.6835 - acc: 0.5703
 448/1202 [==========>...................] - ETA: 1:04 - loss: 0.6868 - acc: 0.5737
 512/1202 [===========>..................] - ETA: 58s - loss: 0.6827 - acc: 0.5801 
 576/1202 [=============>................] - ETA: 53s - loss: 0.6796 - acc: 0.5799
 640/1202 [==============>...............] - ETA: 47s - loss: 0.6810 - acc: 0.5781
 704/1202 [================>.............] - ETA: 42s - loss: 0.6825 - acc: 0.5767
 768/1202 [==================>...........] - ETA: 36s - loss: 0.6845 - acc: 0.5729
 832/1202 [===================>..........] - ETA: 31s - loss: 0.6844 - acc: 0.5745
 896/1202 [=====================>........] - ETA: 26s - loss: 0.6880 - acc: 0.5647
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6878 - acc: 0.5656
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6900 - acc: 0.5596
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6891 - acc: 0.5597 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6879 - acc: 0.5625
1202/1202 [==============================] - 106s 88ms/step - loss: 0.6888 - acc: 0.5624 - val_loss: 0.6901 - val_acc: 0.5448

Epoch 00007: val_acc did not improve from 0.56716
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:36 - loss: 0.7073 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:30 - loss: 0.6862 - acc: 0.5469
 192/1202 [===>..........................] - ETA: 1:23 - loss: 0.6809 - acc: 0.5417
 256/1202 [=====>........................] - ETA: 1:16 - loss: 0.6875 - acc: 0.5352
 320/1202 [======>.......................] - ETA: 1:10 - loss: 0.6900 - acc: 0.5500
 384/1202 [========>.....................] - ETA: 1:06 - loss: 0.6866 - acc: 0.5521
 448/1202 [==========>...................] - ETA: 1:00 - loss: 0.6821 - acc: 0.5558
 512/1202 [===========>..................] - ETA: 55s - loss: 0.6839 - acc: 0.5566 
 576/1202 [=============>................] - ETA: 50s - loss: 0.6812 - acc: 0.5538
 640/1202 [==============>...............] - ETA: 45s - loss: 0.6815 - acc: 0.5531
 704/1202 [================>.............] - ETA: 40s - loss: 0.6831 - acc: 0.5554
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6856 - acc: 0.5534
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6860 - acc: 0.5517
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6884 - acc: 0.5536
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6853 - acc: 0.5625
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6894 - acc: 0.5586
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6884 - acc: 0.5597 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6869 - acc: 0.5599
1202/1202 [==============================] - 102s 85ms/step - loss: 0.6835 - acc: 0.5657 - val_loss: 0.6948 - val_acc: 0.5373

Epoch 00008: val_acc did not improve from 0.56716
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:27 - loss: 0.7015 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:26 - loss: 0.6826 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 1:24 - loss: 0.6601 - acc: 0.6146
 256/1202 [=====>........................] - ETA: 1:20 - loss: 0.6590 - acc: 0.6133
 320/1202 [======>.......................] - ETA: 1:13 - loss: 0.6531 - acc: 0.6188
 384/1202 [========>.....................] - ETA: 1:08 - loss: 0.6663 - acc: 0.5990
 448/1202 [==========>...................] - ETA: 1:03 - loss: 0.6608 - acc: 0.6116
 512/1202 [===========>..................] - ETA: 57s - loss: 0.6682 - acc: 0.6094 
 576/1202 [=============>................] - ETA: 52s - loss: 0.6697 - acc: 0.6094
 640/1202 [==============>...............] - ETA: 46s - loss: 0.6711 - acc: 0.6031
 704/1202 [================>.............] - ETA: 40s - loss: 0.6716 - acc: 0.6037
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6735 - acc: 0.5990
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6792 - acc: 0.5938
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6775 - acc: 0.5926
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6807 - acc: 0.5854
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6791 - acc: 0.5918
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6794 - acc: 0.5864 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6793 - acc: 0.5842
1202/1202 [==============================] - 102s 85ms/step - loss: 0.6810 - acc: 0.5790 - val_loss: 0.6751 - val_acc: 0.5746

Epoch 00009: val_acc improved from 0.56716 to 0.57463, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window03/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:30 - loss: 0.7300 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:28 - loss: 0.6991 - acc: 0.5469
 192/1202 [===>..........................] - ETA: 1:21 - loss: 0.6998 - acc: 0.5260
 256/1202 [=====>........................] - ETA: 1:16 - loss: 0.7008 - acc: 0.5312
 320/1202 [======>.......................] - ETA: 1:11 - loss: 0.6924 - acc: 0.5437
 384/1202 [========>.....................] - ETA: 1:05 - loss: 0.6892 - acc: 0.5599
 448/1202 [==========>...................] - ETA: 1:01 - loss: 0.6911 - acc: 0.5536
 512/1202 [===========>..................] - ETA: 56s - loss: 0.6915 - acc: 0.5469 
 576/1202 [=============>................] - ETA: 51s - loss: 0.6944 - acc: 0.5538
 640/1202 [==============>...............] - ETA: 46s - loss: 0.6914 - acc: 0.5563
 704/1202 [================>.............] - ETA: 41s - loss: 0.6877 - acc: 0.5582
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6865 - acc: 0.5612
 832/1202 [===================>..........] - ETA: 31s - loss: 0.6811 - acc: 0.5685
 896/1202 [=====================>........] - ETA: 25s - loss: 0.6778 - acc: 0.5725
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6780 - acc: 0.5740
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6776 - acc: 0.5752
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6771 - acc: 0.5754 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6777 - acc: 0.5773
1202/1202 [==============================] - 108s 90ms/step - loss: 0.6770 - acc: 0.5774 - val_loss: 0.6826 - val_acc: 0.5597

Epoch 00010: val_acc did not improve from 0.57463
样本个数 167
样本个数 334
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 19s
128/334 [==========>...................] - ETA: 9s 
192/334 [================>.............] - ETA: 5s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 11s 34ms/step
loss: 0.6885411136164636
acc: 0.5868263469484751
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fe6a8317b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fe6a8317b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fe6a82c8850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fe6a82c8850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe92c098750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe92c098750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe6a82f07d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe6a82f07d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6a826bdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6a826bdd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6a82c9e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6a82c9e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe6a82f0cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe6a82f0cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb90c32d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefb90c32d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe6a8057f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe6a8057f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6887a9850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6887a9850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6a80e8b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6a80e8b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe6a8057a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe6a8057a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe688719d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe688719d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe668417090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe668417090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe668389ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe668389ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe688779e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe688779e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe668417e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe668417e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe66836e990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe66836e990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe668178d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe668178d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6680bc690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6680bc690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe668131590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe668131590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe668178990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe668178990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe64c614490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe64c614490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe64c58df10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe64c58df10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe64c5e8790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe64c5e8790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe668080a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe668080a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe64c58dc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe64c58dc90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe64c3a6950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe64c3a6950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe64c4f6c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe64c4f6c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe64c199510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe64c199510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe64c36af10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe64c36af10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe64c4f6a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe64c4f6a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe64c060390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe64c060390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe64c2af610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe64c2af610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6287aaf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6287aaf50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6287a7e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6287a7e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe64c2af750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe64c2af750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6284e4fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6284e4fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe6284463d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe6284463d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6283a0050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6283a0050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6281c0fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6281c0fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe628446550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe628446550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6287a8150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6287a8150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe6280cb650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe6280cb650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6087f4910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6087f4910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6a835efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6a835efd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe628369ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe628369ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6281c6750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6281c6750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe60859a5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe60859a5d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe60848ee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe60848ee10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe608392f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe608392f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe628159d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe628159d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6083b3210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6083b3210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe608242cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe608242cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6082a2c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe6082a2c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6082da290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6082da290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe608242a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe608242a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe608510dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe608510dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe608247310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe608247310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe5e86954d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe5e86954d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe608219490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe608219490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe5e87dc910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe5e87dc910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe5e8693dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe5e8693dd0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 4:32 - loss: 0.6733 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 2:39 - loss: 0.6632 - acc: 0.6406
 192/1202 [===>..........................] - ETA: 2:01 - loss: 0.6852 - acc: 0.6302
 256/1202 [=====>........................] - ETA: 1:41 - loss: 0.6945 - acc: 0.6211
 320/1202 [======>.......................] - ETA: 1:26 - loss: 0.7273 - acc: 0.5875
 384/1202 [========>.....................] - ETA: 1:15 - loss: 0.7151 - acc: 0.6016
 448/1202 [==========>...................] - ETA: 1:06 - loss: 0.7154 - acc: 0.5848
 512/1202 [===========>..................] - ETA: 58s - loss: 0.7150 - acc: 0.5742 
 576/1202 [=============>................] - ETA: 52s - loss: 0.7241 - acc: 0.5608
 640/1202 [==============>...............] - ETA: 46s - loss: 0.7279 - acc: 0.5531
 704/1202 [================>.............] - ETA: 39s - loss: 0.7248 - acc: 0.5455
 768/1202 [==================>...........] - ETA: 34s - loss: 0.7161 - acc: 0.5586
 832/1202 [===================>..........] - ETA: 29s - loss: 0.7172 - acc: 0.5553
 896/1202 [=====================>........] - ETA: 24s - loss: 0.7218 - acc: 0.5458
 960/1202 [======================>.......] - ETA: 19s - loss: 0.7222 - acc: 0.5427
1024/1202 [========================>.....] - ETA: 13s - loss: 0.7162 - acc: 0.5498
1088/1202 [==========================>...] - ETA: 8s - loss: 0.7151 - acc: 0.5496 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7120 - acc: 0.5547
1202/1202 [==============================] - 98s 82ms/step - loss: 0.7125 - acc: 0.5516 - val_loss: 0.7476 - val_acc: 0.4925

Epoch 00001: val_acc improved from -inf to 0.49254, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window04/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:20 - loss: 0.7225 - acc: 0.4219
 128/1202 [==>...........................] - ETA: 1:18 - loss: 0.7034 - acc: 0.4922
 192/1202 [===>..........................] - ETA: 1:12 - loss: 0.7089 - acc: 0.5052
 256/1202 [=====>........................] - ETA: 1:10 - loss: 0.7267 - acc: 0.5117
 320/1202 [======>.......................] - ETA: 1:05 - loss: 0.7175 - acc: 0.5188
 384/1202 [========>.....................] - ETA: 59s - loss: 0.7072 - acc: 0.5417 
 448/1202 [==========>...................] - ETA: 55s - loss: 0.7062 - acc: 0.5357
 512/1202 [===========>..................] - ETA: 50s - loss: 0.7010 - acc: 0.5449
 576/1202 [=============>................] - ETA: 45s - loss: 0.6951 - acc: 0.5590
 640/1202 [==============>...............] - ETA: 40s - loss: 0.6949 - acc: 0.5625
 704/1202 [================>.............] - ETA: 35s - loss: 0.6998 - acc: 0.5526
 768/1202 [==================>...........] - ETA: 31s - loss: 0.7056 - acc: 0.5482
 832/1202 [===================>..........] - ETA: 26s - loss: 0.7132 - acc: 0.5349
 896/1202 [=====================>........] - ETA: 22s - loss: 0.7103 - acc: 0.5357
 960/1202 [======================>.......] - ETA: 17s - loss: 0.7086 - acc: 0.5385
1024/1202 [========================>.....] - ETA: 12s - loss: 0.7053 - acc: 0.5410
1088/1202 [==========================>...] - ETA: 7s - loss: 0.7036 - acc: 0.5423 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7021 - acc: 0.5469
1202/1202 [==============================] - 87s 72ms/step - loss: 0.7017 - acc: 0.5483 - val_loss: 0.7237 - val_acc: 0.5075

Epoch 00002: val_acc improved from 0.49254 to 0.50746, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window04/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:03 - loss: 0.7152 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:01 - loss: 0.6935 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 59s - loss: 0.7161 - acc: 0.5312 
 256/1202 [=====>........................] - ETA: 56s - loss: 0.6898 - acc: 0.5664
 320/1202 [======>.......................] - ETA: 51s - loss: 0.7041 - acc: 0.5406
 384/1202 [========>.....................] - ETA: 48s - loss: 0.6984 - acc: 0.5469
 448/1202 [==========>...................] - ETA: 44s - loss: 0.6911 - acc: 0.5491
 512/1202 [===========>..................] - ETA: 40s - loss: 0.6881 - acc: 0.5508
 576/1202 [=============>................] - ETA: 35s - loss: 0.6864 - acc: 0.5573
 640/1202 [==============>...............] - ETA: 31s - loss: 0.6850 - acc: 0.5531
 704/1202 [================>.............] - ETA: 28s - loss: 0.6843 - acc: 0.5611
 768/1202 [==================>...........] - ETA: 24s - loss: 0.6881 - acc: 0.5573
 832/1202 [===================>..........] - ETA: 20s - loss: 0.6883 - acc: 0.5577
 896/1202 [=====================>........] - ETA: 16s - loss: 0.6864 - acc: 0.5592
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6871 - acc: 0.5615
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6859 - acc: 0.5635 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6871 - acc: 0.5662
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6870 - acc: 0.5625
1202/1202 [==============================] - 68s 56ms/step - loss: 0.6882 - acc: 0.5599 - val_loss: 0.6823 - val_acc: 0.5746

Epoch 00003: val_acc improved from 0.50746 to 0.57463, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window04/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:03 - loss: 0.7362 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 57s - loss: 0.6964 - acc: 0.5391 
 192/1202 [===>..........................] - ETA: 53s - loss: 0.7101 - acc: 0.5156
 256/1202 [=====>........................] - ETA: 50s - loss: 0.6904 - acc: 0.5469
 320/1202 [======>.......................] - ETA: 47s - loss: 0.6876 - acc: 0.5531
 384/1202 [========>.....................] - ETA: 45s - loss: 0.6901 - acc: 0.5469
 448/1202 [==========>...................] - ETA: 41s - loss: 0.6977 - acc: 0.5312
 512/1202 [===========>..................] - ETA: 38s - loss: 0.6963 - acc: 0.5273
 576/1202 [=============>................] - ETA: 34s - loss: 0.7008 - acc: 0.5226
 640/1202 [==============>...............] - ETA: 31s - loss: 0.7007 - acc: 0.5281
 704/1202 [================>.............] - ETA: 27s - loss: 0.6933 - acc: 0.5369
 768/1202 [==================>...........] - ETA: 24s - loss: 0.6960 - acc: 0.5365
 832/1202 [===================>..........] - ETA: 20s - loss: 0.6954 - acc: 0.5385
 896/1202 [=====================>........] - ETA: 17s - loss: 0.7014 - acc: 0.5335
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6976 - acc: 0.5385
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6935 - acc: 0.5459
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6947 - acc: 0.5432 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6956 - acc: 0.5451
1202/1202 [==============================] - 72s 60ms/step - loss: 0.6966 - acc: 0.5449 - val_loss: 0.6882 - val_acc: 0.5597

Epoch 00004: val_acc did not improve from 0.57463
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:02 - loss: 0.6187 - acc: 0.7031
 128/1202 [==>...........................] - ETA: 1:02 - loss: 0.6276 - acc: 0.6641
 192/1202 [===>..........................] - ETA: 58s - loss: 0.6508 - acc: 0.6198 
 256/1202 [=====>........................] - ETA: 55s - loss: 0.6388 - acc: 0.6133
 320/1202 [======>.......................] - ETA: 50s - loss: 0.6490 - acc: 0.6000
 384/1202 [========>.....................] - ETA: 47s - loss: 0.6574 - acc: 0.5859
 448/1202 [==========>...................] - ETA: 43s - loss: 0.6577 - acc: 0.5804
 512/1202 [===========>..................] - ETA: 40s - loss: 0.6592 - acc: 0.5840
 576/1202 [=============>................] - ETA: 36s - loss: 0.6631 - acc: 0.5799
 640/1202 [==============>...............] - ETA: 33s - loss: 0.6676 - acc: 0.5781
 704/1202 [================>.............] - ETA: 29s - loss: 0.6712 - acc: 0.5710
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6810 - acc: 0.5677
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6813 - acc: 0.5697
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6837 - acc: 0.5658
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6861 - acc: 0.5625
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6859 - acc: 0.5615
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6864 - acc: 0.5634 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6870 - acc: 0.5616
1202/1202 [==============================] - 73s 61ms/step - loss: 0.6877 - acc: 0.5607 - val_loss: 0.6843 - val_acc: 0.5597

Epoch 00005: val_acc did not improve from 0.57463
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:02 - loss: 0.6950 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:03 - loss: 0.6964 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 58s - loss: 0.6893 - acc: 0.5833 
 256/1202 [=====>........................] - ETA: 55s - loss: 0.6863 - acc: 0.5820
 320/1202 [======>.......................] - ETA: 53s - loss: 0.6888 - acc: 0.5656
 384/1202 [========>.....................] - ETA: 50s - loss: 0.6726 - acc: 0.5938
 448/1202 [==========>...................] - ETA: 46s - loss: 0.6829 - acc: 0.5670
 512/1202 [===========>..................] - ETA: 43s - loss: 0.6817 - acc: 0.5742
 576/1202 [=============>................] - ETA: 39s - loss: 0.6840 - acc: 0.5625
 640/1202 [==============>...............] - ETA: 35s - loss: 0.6858 - acc: 0.5687
 704/1202 [================>.............] - ETA: 31s - loss: 0.6857 - acc: 0.5682
 768/1202 [==================>...........] - ETA: 27s - loss: 0.6842 - acc: 0.5781
 832/1202 [===================>..........] - ETA: 24s - loss: 0.6897 - acc: 0.5661
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6842 - acc: 0.5770
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6803 - acc: 0.5833
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6794 - acc: 0.5830
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6807 - acc: 0.5781 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6797 - acc: 0.5773
1202/1202 [==============================] - 88s 73ms/step - loss: 0.6811 - acc: 0.5749 - val_loss: 0.7010 - val_acc: 0.5672

Epoch 00006: val_acc did not improve from 0.57463
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:21 - loss: 0.6711 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:21 - loss: 0.6886 - acc: 0.6016
 192/1202 [===>..........................] - ETA: 1:16 - loss: 0.6803 - acc: 0.5938
 256/1202 [=====>........................] - ETA: 1:12 - loss: 0.6849 - acc: 0.5703
 320/1202 [======>.......................] - ETA: 1:06 - loss: 0.6793 - acc: 0.5781
 384/1202 [========>.....................] - ETA: 1:01 - loss: 0.6740 - acc: 0.5781
 448/1202 [==========>...................] - ETA: 56s - loss: 0.6799 - acc: 0.5781 
 512/1202 [===========>..................] - ETA: 51s - loss: 0.6731 - acc: 0.5840
 576/1202 [=============>................] - ETA: 47s - loss: 0.6719 - acc: 0.5903
 640/1202 [==============>...............] - ETA: 42s - loss: 0.6711 - acc: 0.5891
 704/1202 [================>.............] - ETA: 37s - loss: 0.6667 - acc: 0.6023
 768/1202 [==================>...........] - ETA: 32s - loss: 0.6712 - acc: 0.5938
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6716 - acc: 0.5950
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6721 - acc: 0.5915
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6749 - acc: 0.5896
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6736 - acc: 0.5898
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6739 - acc: 0.5901 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6741 - acc: 0.5903
1202/1202 [==============================] - 93s 78ms/step - loss: 0.6738 - acc: 0.5915 - val_loss: 0.6941 - val_acc: 0.5522

Epoch 00007: val_acc did not improve from 0.57463
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:14 - loss: 0.6501 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 1:13 - loss: 0.6474 - acc: 0.6172
 192/1202 [===>..........................] - ETA: 1:11 - loss: 0.6610 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 1:05 - loss: 0.6554 - acc: 0.5938
 320/1202 [======>.......................] - ETA: 1:01 - loss: 0.6702 - acc: 0.5687
 384/1202 [========>.....................] - ETA: 58s - loss: 0.6651 - acc: 0.5703 
 448/1202 [==========>...................] - ETA: 52s - loss: 0.6694 - acc: 0.5625
 512/1202 [===========>..................] - ETA: 48s - loss: 0.6665 - acc: 0.5566
 576/1202 [=============>................] - ETA: 43s - loss: 0.6673 - acc: 0.5573
 640/1202 [==============>...............] - ETA: 38s - loss: 0.6632 - acc: 0.5703
 704/1202 [================>.............] - ETA: 34s - loss: 0.6732 - acc: 0.5639
 768/1202 [==================>...........] - ETA: 29s - loss: 0.6710 - acc: 0.5690
 832/1202 [===================>..........] - ETA: 25s - loss: 0.6673 - acc: 0.5721
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6650 - acc: 0.5815
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6665 - acc: 0.5823
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6649 - acc: 0.5869
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6667 - acc: 0.5827 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6684 - acc: 0.5833
1202/1202 [==============================] - 86s 72ms/step - loss: 0.6658 - acc: 0.5882 - val_loss: 0.7206 - val_acc: 0.5448

Epoch 00008: val_acc did not improve from 0.57463
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:13 - loss: 0.6839 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:05 - loss: 0.6706 - acc: 0.6172
 192/1202 [===>..........................] - ETA: 1:05 - loss: 0.6737 - acc: 0.5885
 256/1202 [=====>........................] - ETA: 1:02 - loss: 0.6662 - acc: 0.5898
 320/1202 [======>.......................] - ETA: 59s - loss: 0.6778 - acc: 0.5875 
 384/1202 [========>.....................] - ETA: 57s - loss: 0.6866 - acc: 0.5729
 448/1202 [==========>...................] - ETA: 52s - loss: 0.6801 - acc: 0.5804
 512/1202 [===========>..................] - ETA: 48s - loss: 0.6850 - acc: 0.5703
 576/1202 [=============>................] - ETA: 43s - loss: 0.6848 - acc: 0.5694
 640/1202 [==============>...............] - ETA: 39s - loss: 0.6784 - acc: 0.5797
 704/1202 [================>.............] - ETA: 34s - loss: 0.6715 - acc: 0.5881
 768/1202 [==================>...........] - ETA: 29s - loss: 0.6712 - acc: 0.5885
 832/1202 [===================>..........] - ETA: 25s - loss: 0.6652 - acc: 0.5974
 896/1202 [=====================>........] - ETA: 21s - loss: 0.6637 - acc: 0.6016
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6609 - acc: 0.6083
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6619 - acc: 0.6113
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6604 - acc: 0.6158 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6622 - acc: 0.6128
1202/1202 [==============================] - 87s 72ms/step - loss: 0.6638 - acc: 0.6123 - val_loss: 0.7189 - val_acc: 0.5448

Epoch 00009: val_acc did not improve from 0.57463
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:19 - loss: 0.6802 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:16 - loss: 0.6719 - acc: 0.6016
 192/1202 [===>..........................] - ETA: 1:13 - loss: 0.6633 - acc: 0.5885
 256/1202 [=====>........................] - ETA: 1:07 - loss: 0.6742 - acc: 0.5781
 320/1202 [======>.......................] - ETA: 1:01 - loss: 0.6675 - acc: 0.5938
 384/1202 [========>.....................] - ETA: 58s - loss: 0.6686 - acc: 0.5833 
 448/1202 [==========>...................] - ETA: 53s - loss: 0.6684 - acc: 0.5826
 512/1202 [===========>..................] - ETA: 48s - loss: 0.6697 - acc: 0.5840
 576/1202 [=============>................] - ETA: 44s - loss: 0.6675 - acc: 0.5799
 640/1202 [==============>...............] - ETA: 39s - loss: 0.6682 - acc: 0.5766
 704/1202 [================>.............] - ETA: 35s - loss: 0.6670 - acc: 0.5866
 768/1202 [==================>...........] - ETA: 30s - loss: 0.6695 - acc: 0.5898
 832/1202 [===================>..........] - ETA: 25s - loss: 0.6738 - acc: 0.5865
 896/1202 [=====================>........] - ETA: 21s - loss: 0.6729 - acc: 0.5893
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6748 - acc: 0.5885
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6699 - acc: 0.5967
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6700 - acc: 0.5974 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6719 - acc: 0.5946
1202/1202 [==============================] - 91s 75ms/step - loss: 0.6718 - acc: 0.5965 - val_loss: 0.7339 - val_acc: 0.5075

Epoch 00010: val_acc did not improve from 0.57463
样本个数 167
样本个数 334
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 24s
128/334 [==========>...................] - ETA: 11s
192/334 [================>.............] - ETA: 6s 
256/334 [=====================>........] - ETA: 3s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 13s 39ms/step
loss: 0.6890497585970484
acc: 0.5538922155688623
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fe5487dde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fe5487dde10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fe52814b950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fe52814b950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefd235df10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fefd235df10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe92c0f01d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe92c0f01d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe548707590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe548707590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6287a80d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe6287a80d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe92c0f0b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe92c0f0b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe548701fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe548701fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe5487593d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe5487593d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe548740f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe548740f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe92c054690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe92c054690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe54857e2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe54857e2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe548474d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe548474d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe5482499d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe5482499d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe52803f890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe52803f890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe548274f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe548274f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe548249550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe548249550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe5280dfed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe5280dfed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe548215390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe548215390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe504535710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe504535710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe504526190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe504526190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe50463ca10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe50463ca10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe504530d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe504530d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe5042bf190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe5042bf190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe5487e4dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe5487e4dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe50438bf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe50438bf10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe5042bf990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe5042bf990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe72c601790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe72c601790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4ec77f850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4ec77f850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe5045a6850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe5045a6850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe5041cb190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe5041cb190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4ec77f210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4ec77f210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4ec5a2c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4ec5a2c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4ec4aa9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4ec4aa9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4ec39dd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4ec39dd10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4ec67bc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4ec67bc10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4ec7b2390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4ec7b2390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4ec41ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4ec41ff90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4ec15a110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4ec15a110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4ec06cc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4ec06cc50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4ec195e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4ec195e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4ec4f6fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4ec4f6fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4ec0bc8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4ec0bc8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4ec114590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4ec114590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4ec06c5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4ec06c5d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4c8716610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4c8716610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4ec39de90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4ec39de90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4c860bb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4c860bb10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4c82c4650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4c82c4650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4c850a890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4c850a890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4c860b090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4c860b090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4c82c4850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4c82c4850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4c8237bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4c8237bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4a87f5490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4a87f5490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4a8645b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4a8645b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4a87b18d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4a87b18d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4a87f5390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4a87f5390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4a8696f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4a8696f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4a84c97d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fe4a84c97d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4a8450e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fe4a8450e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4a8645850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4a8645850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4a8798790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fe4a8798790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4a817d050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fe4a817d050>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 3:58 - loss: 0.7703 - acc: 0.4688
 128/1202 [==>...........................] - ETA: 2:15 - loss: 0.8212 - acc: 0.4922
 192/1202 [===>..........................] - ETA: 1:42 - loss: 0.7693 - acc: 0.5312
 256/1202 [=====>........................] - ETA: 1:24 - loss: 0.7646 - acc: 0.5156
 320/1202 [======>.......................] - ETA: 1:12 - loss: 0.7790 - acc: 0.5062
 384/1202 [========>.....................] - ETA: 1:03 - loss: 0.7695 - acc: 0.4948
 448/1202 [==========>...................] - ETA: 55s - loss: 0.7686 - acc: 0.4888 
 512/1202 [===========>..................] - ETA: 48s - loss: 0.7650 - acc: 0.4883
 576/1202 [=============>................] - ETA: 42s - loss: 0.7690 - acc: 0.4792
 640/1202 [==============>...............] - ETA: 38s - loss: 0.7701 - acc: 0.4844
 704/1202 [================>.............] - ETA: 33s - loss: 0.7732 - acc: 0.4759
 768/1202 [==================>...........] - ETA: 27s - loss: 0.7665 - acc: 0.4792
 832/1202 [===================>..........] - ETA: 23s - loss: 0.7597 - acc: 0.4868
 896/1202 [=====================>........] - ETA: 19s - loss: 0.7543 - acc: 0.4955
 960/1202 [======================>.......] - ETA: 15s - loss: 0.7519 - acc: 0.4979
1024/1202 [========================>.....] - ETA: 10s - loss: 0.7510 - acc: 0.5000
1088/1202 [==========================>...] - ETA: 6s - loss: 0.7468 - acc: 0.5055 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.7445 - acc: 0.5078
1202/1202 [==============================] - 76s 63ms/step - loss: 0.7424 - acc: 0.5092 - val_loss: 0.6905 - val_acc: 0.5821

Epoch 00001: val_acc improved from -inf to 0.58209, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window05/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 52s - loss: 0.6989 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 58s - loss: 0.6826 - acc: 0.5859
 192/1202 [===>..........................] - ETA: 52s - loss: 0.6816 - acc: 0.5781
 256/1202 [=====>........................] - ETA: 47s - loss: 0.6865 - acc: 0.5664
 320/1202 [======>.......................] - ETA: 44s - loss: 0.6821 - acc: 0.5750
 384/1202 [========>.....................] - ETA: 41s - loss: 0.6730 - acc: 0.5781
 448/1202 [==========>...................] - ETA: 38s - loss: 0.6788 - acc: 0.5804
 512/1202 [===========>..................] - ETA: 34s - loss: 0.6819 - acc: 0.5801
 576/1202 [=============>................] - ETA: 30s - loss: 0.6819 - acc: 0.5833
 640/1202 [==============>...............] - ETA: 28s - loss: 0.6967 - acc: 0.5734
 704/1202 [================>.............] - ETA: 24s - loss: 0.6956 - acc: 0.5696
 768/1202 [==================>...........] - ETA: 21s - loss: 0.6970 - acc: 0.5664
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6999 - acc: 0.5637
 896/1202 [=====================>........] - ETA: 15s - loss: 0.7033 - acc: 0.5614
 960/1202 [======================>.......] - ETA: 12s - loss: 0.7029 - acc: 0.5604
1024/1202 [========================>.....] - ETA: 8s - loss: 0.7022 - acc: 0.5566 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6993 - acc: 0.5570
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6992 - acc: 0.5564
1202/1202 [==============================] - 63s 53ms/step - loss: 0.6990 - acc: 0.5541 - val_loss: 0.6809 - val_acc: 0.5672

Epoch 00002: val_acc did not improve from 0.58209
Epoch 3/10

  64/1202 [>.............................] - ETA: 47s - loss: 0.7399 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 48s - loss: 0.7196 - acc: 0.5391
 192/1202 [===>..........................] - ETA: 46s - loss: 0.7165 - acc: 0.5521
 256/1202 [=====>........................] - ETA: 43s - loss: 0.7227 - acc: 0.5195
 320/1202 [======>.......................] - ETA: 42s - loss: 0.7162 - acc: 0.5156
 384/1202 [========>.....................] - ETA: 39s - loss: 0.7216 - acc: 0.5078
 448/1202 [==========>...................] - ETA: 37s - loss: 0.7134 - acc: 0.5179
 512/1202 [===========>..................] - ETA: 33s - loss: 0.7107 - acc: 0.5195
 576/1202 [=============>................] - ETA: 31s - loss: 0.7089 - acc: 0.5278
 640/1202 [==============>...............] - ETA: 28s - loss: 0.7002 - acc: 0.5406
 704/1202 [================>.............] - ETA: 25s - loss: 0.6972 - acc: 0.5483
 768/1202 [==================>...........] - ETA: 21s - loss: 0.6953 - acc: 0.5521
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6973 - acc: 0.5517
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6942 - acc: 0.5603
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6952 - acc: 0.5615
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6953 - acc: 0.5625 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6920 - acc: 0.5689
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6939 - acc: 0.5651
1202/1202 [==============================] - 65s 54ms/step - loss: 0.6930 - acc: 0.5691 - val_loss: 0.6755 - val_acc: 0.5896

Epoch 00003: val_acc improved from 0.58209 to 0.58955, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window05/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1202 [>.............................] - ETA: 58s - loss: 0.6905 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 53s - loss: 0.6685 - acc: 0.6172
 192/1202 [===>..........................] - ETA: 50s - loss: 0.6730 - acc: 0.6146
 256/1202 [=====>........................] - ETA: 51s - loss: 0.6829 - acc: 0.5898
 320/1202 [======>.......................] - ETA: 48s - loss: 0.6961 - acc: 0.5531
 384/1202 [========>.....................] - ETA: 44s - loss: 0.6874 - acc: 0.5729
 448/1202 [==========>...................] - ETA: 42s - loss: 0.6932 - acc: 0.5647
 512/1202 [===========>..................] - ETA: 38s - loss: 0.7005 - acc: 0.5449
 576/1202 [=============>................] - ETA: 35s - loss: 0.6972 - acc: 0.5486
 640/1202 [==============>...............] - ETA: 32s - loss: 0.6961 - acc: 0.5500
 704/1202 [================>.............] - ETA: 28s - loss: 0.6974 - acc: 0.5455
 768/1202 [==================>...........] - ETA: 25s - loss: 0.7046 - acc: 0.5365
 832/1202 [===================>..........] - ETA: 21s - loss: 0.7032 - acc: 0.5397
 896/1202 [=====================>........] - ETA: 18s - loss: 0.7058 - acc: 0.5324
 960/1202 [======================>.......] - ETA: 14s - loss: 0.7097 - acc: 0.5292
1024/1202 [========================>.....] - ETA: 10s - loss: 0.7111 - acc: 0.5283
1088/1202 [==========================>...] - ETA: 6s - loss: 0.7102 - acc: 0.5303 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7077 - acc: 0.5373
1202/1202 [==============================] - 77s 64ms/step - loss: 0.7070 - acc: 0.5408 - val_loss: 0.6816 - val_acc: 0.5597

Epoch 00004: val_acc did not improve from 0.58955
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:06 - loss: 0.7229 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:08 - loss: 0.7076 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:04 - loss: 0.6927 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 59s - loss: 0.6861 - acc: 0.5938 
 320/1202 [======>.......................] - ETA: 55s - loss: 0.6890 - acc: 0.5875
 384/1202 [========>.....................] - ETA: 50s - loss: 0.6971 - acc: 0.5807
 448/1202 [==========>...................] - ETA: 47s - loss: 0.6936 - acc: 0.5759
 512/1202 [===========>..................] - ETA: 43s - loss: 0.6973 - acc: 0.5684
 576/1202 [=============>................] - ETA: 39s - loss: 0.6942 - acc: 0.5712
 640/1202 [==============>...............] - ETA: 35s - loss: 0.6954 - acc: 0.5672
 704/1202 [================>.............] - ETA: 31s - loss: 0.7014 - acc: 0.5554
 768/1202 [==================>...........] - ETA: 27s - loss: 0.7044 - acc: 0.5521
 832/1202 [===================>..........] - ETA: 23s - loss: 0.7051 - acc: 0.5505
 896/1202 [=====================>........] - ETA: 19s - loss: 0.7045 - acc: 0.5536
 960/1202 [======================>.......] - ETA: 15s - loss: 0.7078 - acc: 0.5479
1024/1202 [========================>.....] - ETA: 11s - loss: 0.7081 - acc: 0.5508
1088/1202 [==========================>...] - ETA: 7s - loss: 0.7044 - acc: 0.5551 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7048 - acc: 0.5564
1202/1202 [==============================] - 80s 66ms/step - loss: 0.7072 - acc: 0.5524 - val_loss: 0.6735 - val_acc: 0.5896

Epoch 00005: val_acc did not improve from 0.58955
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:15 - loss: 0.6818 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:08 - loss: 0.6915 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 1:04 - loss: 0.6801 - acc: 0.5990
 256/1202 [=====>........................] - ETA: 59s - loss: 0.6916 - acc: 0.5742 
 320/1202 [======>.......................] - ETA: 55s - loss: 0.6977 - acc: 0.5563
 384/1202 [========>.....................] - ETA: 52s - loss: 0.6976 - acc: 0.5521
 448/1202 [==========>...................] - ETA: 48s - loss: 0.6945 - acc: 0.5558
 512/1202 [===========>..................] - ETA: 44s - loss: 0.6940 - acc: 0.5566
 576/1202 [=============>................] - ETA: 40s - loss: 0.6933 - acc: 0.5608
 640/1202 [==============>...............] - ETA: 36s - loss: 0.6915 - acc: 0.5625
 704/1202 [================>.............] - ETA: 31s - loss: 0.6919 - acc: 0.5582
 768/1202 [==================>...........] - ETA: 27s - loss: 0.6903 - acc: 0.5651
 832/1202 [===================>..........] - ETA: 23s - loss: 0.6915 - acc: 0.5613
 896/1202 [=====================>........] - ETA: 19s - loss: 0.6862 - acc: 0.5658
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6861 - acc: 0.5646
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6864 - acc: 0.5674
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6889 - acc: 0.5625 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6876 - acc: 0.5651
1202/1202 [==============================] - 82s 68ms/step - loss: 0.6870 - acc: 0.5682 - val_loss: 0.6908 - val_acc: 0.5970

Epoch 00006: val_acc improved from 0.58955 to 0.59701, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window05/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:18 - loss: 0.6769 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:13 - loss: 0.7043 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:09 - loss: 0.6891 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 1:04 - loss: 0.6828 - acc: 0.5820
 320/1202 [======>.......................] - ETA: 59s - loss: 0.6880 - acc: 0.5531 
 384/1202 [========>.....................] - ETA: 55s - loss: 0.6883 - acc: 0.5573
 448/1202 [==========>...................] - ETA: 51s - loss: 0.6845 - acc: 0.5647
 512/1202 [===========>..................] - ETA: 47s - loss: 0.6786 - acc: 0.5781
 576/1202 [=============>................] - ETA: 42s - loss: 0.6769 - acc: 0.5885
 640/1202 [==============>...............] - ETA: 38s - loss: 0.6733 - acc: 0.5922
 704/1202 [================>.............] - ETA: 34s - loss: 0.6732 - acc: 0.5938
 768/1202 [==================>...........] - ETA: 29s - loss: 0.6760 - acc: 0.5846
 832/1202 [===================>..........] - ETA: 25s - loss: 0.6794 - acc: 0.5793
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6786 - acc: 0.5759
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6804 - acc: 0.5781
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6829 - acc: 0.5723
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6800 - acc: 0.5790 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6776 - acc: 0.5833
1202/1202 [==============================] - 85s 71ms/step - loss: 0.6786 - acc: 0.5807 - val_loss: 0.6663 - val_acc: 0.5597

Epoch 00007: val_acc did not improve from 0.59701
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:25 - loss: 0.6473 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:10 - loss: 0.6549 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 1:08 - loss: 0.6749 - acc: 0.5677
 256/1202 [=====>........................] - ETA: 1:03 - loss: 0.6589 - acc: 0.5938
 320/1202 [======>.......................] - ETA: 58s - loss: 0.6619 - acc: 0.5844 
 384/1202 [========>.....................] - ETA: 54s - loss: 0.6638 - acc: 0.5833
 448/1202 [==========>...................] - ETA: 50s - loss: 0.6691 - acc: 0.5781
 512/1202 [===========>..................] - ETA: 46s - loss: 0.6663 - acc: 0.5781
 576/1202 [=============>................] - ETA: 41s - loss: 0.6743 - acc: 0.5642
 640/1202 [==============>...............] - ETA: 37s - loss: 0.6770 - acc: 0.5578
 704/1202 [================>.............] - ETA: 32s - loss: 0.6720 - acc: 0.5682
 768/1202 [==================>...........] - ETA: 28s - loss: 0.6731 - acc: 0.5651
 832/1202 [===================>..........] - ETA: 24s - loss: 0.6768 - acc: 0.5601
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6786 - acc: 0.5625
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6801 - acc: 0.5615
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6787 - acc: 0.5674
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6813 - acc: 0.5662 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6840 - acc: 0.5625
1202/1202 [==============================] - 83s 69ms/step - loss: 0.6846 - acc: 0.5632 - val_loss: 0.6646 - val_acc: 0.5896

Epoch 00008: val_acc did not improve from 0.59701
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:24 - loss: 0.7063 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:15 - loss: 0.6778 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:10 - loss: 0.6644 - acc: 0.5885
 256/1202 [=====>........................] - ETA: 1:04 - loss: 0.6585 - acc: 0.6016
 320/1202 [======>.......................] - ETA: 59s - loss: 0.6637 - acc: 0.5969 
 384/1202 [========>.....................] - ETA: 55s - loss: 0.6725 - acc: 0.5911
 448/1202 [==========>...................] - ETA: 51s - loss: 0.6763 - acc: 0.5781
 512/1202 [===========>..................] - ETA: 47s - loss: 0.6725 - acc: 0.5801
 576/1202 [=============>................] - ETA: 43s - loss: 0.6735 - acc: 0.5781
 640/1202 [==============>...............] - ETA: 39s - loss: 0.6823 - acc: 0.5641
 704/1202 [================>.............] - ETA: 34s - loss: 0.6828 - acc: 0.5682
 768/1202 [==================>...........] - ETA: 30s - loss: 0.6823 - acc: 0.5664
 832/1202 [===================>..........] - ETA: 25s - loss: 0.6867 - acc: 0.5577
 896/1202 [=====================>........] - ETA: 21s - loss: 0.6875 - acc: 0.5558
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6840 - acc: 0.5604
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6863 - acc: 0.5605
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6823 - acc: 0.5689 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6815 - acc: 0.5694
1202/1202 [==============================] - 88s 73ms/step - loss: 0.6846 - acc: 0.5649 - val_loss: 0.6761 - val_acc: 0.5746

Epoch 00009: val_acc did not improve from 0.59701
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:18 - loss: 0.7134 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 1:11 - loss: 0.6896 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:09 - loss: 0.6743 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 1:04 - loss: 0.6613 - acc: 0.6094
 320/1202 [======>.......................] - ETA: 1:01 - loss: 0.6610 - acc: 0.6094
 384/1202 [========>.....................] - ETA: 57s - loss: 0.6619 - acc: 0.6224 
 448/1202 [==========>...................] - ETA: 51s - loss: 0.6679 - acc: 0.6071
 512/1202 [===========>..................] - ETA: 47s - loss: 0.6657 - acc: 0.6172
 576/1202 [=============>................] - ETA: 43s - loss: 0.6727 - acc: 0.6059
 640/1202 [==============>...............] - ETA: 38s - loss: 0.6783 - acc: 0.5906
 704/1202 [================>.............] - ETA: 33s - loss: 0.6819 - acc: 0.5810
 768/1202 [==================>...........] - ETA: 29s - loss: 0.6837 - acc: 0.5729
 832/1202 [===================>..........] - ETA: 24s - loss: 0.6851 - acc: 0.5721
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6859 - acc: 0.5703
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6843 - acc: 0.5719
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6821 - acc: 0.5771
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6817 - acc: 0.5754 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6834 - acc: 0.5686
1202/1202 [==============================] - 80s 67ms/step - loss: 0.6821 - acc: 0.5707 - val_loss: 0.6836 - val_acc: 0.5448

Epoch 00010: val_acc did not improve from 0.59701
样本个数 167
样本个数 334
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 24s
128/334 [==========>...................] - ETA: 11s
192/334 [================>.............] - ETA: 6s 
256/334 [=====================>........] - ETA: 3s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 12s 36ms/step
loss: 0.6880090540040753
acc: 0.5898203594598942
