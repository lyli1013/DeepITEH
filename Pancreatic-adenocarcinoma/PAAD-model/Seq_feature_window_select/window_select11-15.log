nohup: ignoring input
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
样本个数 668
样本个数 1336
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f8ebc053310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f8ebc053310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f8ebc026c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f8ebc026c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebc022ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebc022ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ebbf73310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ebbf73310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ebbea00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ebbea00d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebbf8f790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebbf8f790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ebbef1c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ebbef1c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebbeee650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebbeee650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ebbca3e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ebbca3e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ebbb45450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ebbb45450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebbf74710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebbf74710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ebbbf70d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ebbbf70d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebbe9d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebbe9d6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ebbc1b450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ebbc1b450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ebb9da6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ebb9da6d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebb944cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ebb944cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ebbc723d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ebbc723d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eb38a6190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eb38a6190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eb370db50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eb370db50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8eb3743950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8eb3743950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eb35d33d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eb35d33d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eb3852dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eb3852dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eb33f8d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eb33f8d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eb338f850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eb338f850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8eb32f1250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8eb32f1250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eb3358790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eb3358790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eb3427cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eb3427cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eb3344210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eb3344210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eb3307090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eb3307090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8eb3258590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8eb3258590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eab016dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eab016dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eb320f3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eb320f3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eab006650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eab006650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eaada4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eaada4e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8eaacae990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8eaacae990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eaac79710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eaac79710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eab063290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eab063290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eaaacd190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eaaacd190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eaa9db310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eaa9db310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8eaabcab90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8eaabcab90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eaabfb910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eaabfb910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eaad3ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eaad3ee90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eaa8b6810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eaa8b6810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eaaad46d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8eaaad46d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ea2584750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ea2584750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ea2486990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ea2486990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ea270c190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ea270c190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ea248b210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ea248b210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ea24afa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ea24afa10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ea22b4790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ea22b4790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ea2655c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ea2655c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eaac1c150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8eaac1c150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ea2423750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ea2423750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ea20c8c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ea20c8c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8e9a01fe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8e9a01fe50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eaac1cf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8eaac1cf90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ea219cc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ea219cc10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8e9a01a890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8e9a01a890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8e99d47a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8e99d47a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8e99d8f9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8e99d8f9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8e9a008690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8e9a008690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8e99d474d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8e99d474d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8e9a022f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8e9a022f90>>: AttributeError: module 'gast' has no attribute 'Str'
2023-01-12 00:43:08.035420: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-01-12 00:43:08.073933: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2023-01-12 00:43:08.103843: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c91d040a00 executing computations on platform Host. Devices:
2023-01-12 00:43:08.103918: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-01-12 00:43:08.513494: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
window_select11-15.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 3:31 - loss: 0.8101 - acc: 0.4375
 128/1202 [==>...........................] - ETA: 2:30 - loss: 0.8041 - acc: 0.4453
 192/1202 [===>..........................] - ETA: 2:24 - loss: 0.7717 - acc: 0.4896
 256/1202 [=====>........................] - ETA: 2:04 - loss: 0.7570 - acc: 0.4961
 320/1202 [======>.......................] - ETA: 1:51 - loss: 0.7593 - acc: 0.4906
 384/1202 [========>.....................] - ETA: 1:39 - loss: 0.7442 - acc: 0.5026
 448/1202 [==========>...................] - ETA: 1:26 - loss: 0.7345 - acc: 0.5179
 512/1202 [===========>..................] - ETA: 1:16 - loss: 0.7265 - acc: 0.5273
 576/1202 [=============>................] - ETA: 1:07 - loss: 0.7283 - acc: 0.5278
 640/1202 [==============>...............] - ETA: 59s - loss: 0.7292 - acc: 0.5281 
 704/1202 [================>.............] - ETA: 51s - loss: 0.7297 - acc: 0.5284
 768/1202 [==================>...........] - ETA: 45s - loss: 0.7250 - acc: 0.5326
 832/1202 [===================>..........] - ETA: 38s - loss: 0.7248 - acc: 0.5325
 896/1202 [=====================>........] - ETA: 30s - loss: 0.7211 - acc: 0.5346
 960/1202 [======================>.......] - ETA: 24s - loss: 0.7203 - acc: 0.5292
1024/1202 [========================>.....] - ETA: 17s - loss: 0.7210 - acc: 0.5303
1088/1202 [==========================>...] - ETA: 11s - loss: 0.7228 - acc: 0.5285
1152/1202 [===========================>..] - ETA: 4s - loss: 0.7238 - acc: 0.5260 
1202/1202 [==============================] - 121s 100ms/step - loss: 0.7231 - acc: 0.5275 - val_loss: 0.7433 - val_acc: 0.4552

Epoch 00001: val_acc improved from -inf to 0.45522, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window11/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:31 - loss: 0.7724 - acc: 0.4844
 128/1202 [==>...........................] - ETA: 1:27 - loss: 0.7185 - acc: 0.5391
 192/1202 [===>..........................] - ETA: 1:27 - loss: 0.7113 - acc: 0.5729
 256/1202 [=====>........................] - ETA: 1:22 - loss: 0.7064 - acc: 0.5742
 320/1202 [======>.......................] - ETA: 1:14 - loss: 0.7025 - acc: 0.5719
 384/1202 [========>.....................] - ETA: 1:08 - loss: 0.6944 - acc: 0.5729
 448/1202 [==========>...................] - ETA: 1:01 - loss: 0.6953 - acc: 0.5670
 512/1202 [===========>..................] - ETA: 56s - loss: 0.6996 - acc: 0.5645 
 576/1202 [=============>................] - ETA: 51s - loss: 0.7027 - acc: 0.5625
 640/1202 [==============>...............] - ETA: 45s - loss: 0.7073 - acc: 0.5516
 704/1202 [================>.............] - ETA: 40s - loss: 0.7016 - acc: 0.5625
 768/1202 [==================>...........] - ETA: 35s - loss: 0.7017 - acc: 0.5612
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6981 - acc: 0.5685
 896/1202 [=====================>........] - ETA: 24s - loss: 0.7026 - acc: 0.5603
 960/1202 [======================>.......] - ETA: 19s - loss: 0.7022 - acc: 0.5583
1024/1202 [========================>.....] - ETA: 14s - loss: 0.7017 - acc: 0.5605
1088/1202 [==========================>...] - ETA: 9s - loss: 0.7016 - acc: 0.5597 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7015 - acc: 0.5582
1202/1202 [==============================] - 100s 84ms/step - loss: 0.7022 - acc: 0.5582 - val_loss: 0.7236 - val_acc: 0.5075

Epoch 00002: val_acc improved from 0.45522 to 0.50746, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window11/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:29 - loss: 0.6784 - acc: 0.5938
 128/1202 [==>...........................] - ETA: 1:28 - loss: 0.6757 - acc: 0.6016
 192/1202 [===>..........................] - ETA: 1:22 - loss: 0.7009 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 1:15 - loss: 0.6919 - acc: 0.5586
 320/1202 [======>.......................] - ETA: 1:11 - loss: 0.7087 - acc: 0.5375
 384/1202 [========>.....................] - ETA: 1:06 - loss: 0.6977 - acc: 0.5521
 448/1202 [==========>...................] - ETA: 1:00 - loss: 0.7032 - acc: 0.5402
 512/1202 [===========>..................] - ETA: 55s - loss: 0.7050 - acc: 0.5352 
 576/1202 [=============>................] - ETA: 49s - loss: 0.7012 - acc: 0.5399
 640/1202 [==============>...............] - ETA: 44s - loss: 0.6970 - acc: 0.5500
 704/1202 [================>.............] - ETA: 39s - loss: 0.6945 - acc: 0.5554
 768/1202 [==================>...........] - ETA: 34s - loss: 0.6920 - acc: 0.5625
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6906 - acc: 0.5673
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6911 - acc: 0.5647
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6904 - acc: 0.5656
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6943 - acc: 0.5605
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6961 - acc: 0.5570 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6981 - acc: 0.5530
1202/1202 [==============================] - 101s 84ms/step - loss: 0.6988 - acc: 0.5516 - val_loss: 0.6650 - val_acc: 0.6194

Epoch 00003: val_acc improved from 0.50746 to 0.61940, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window11/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:40 - loss: 0.7292 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:33 - loss: 0.7044 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:31 - loss: 0.6901 - acc: 0.5677
 256/1202 [=====>........................] - ETA: 1:37 - loss: 0.6839 - acc: 0.5664
 320/1202 [======>.......................] - ETA: 1:29 - loss: 0.6828 - acc: 0.5719
 384/1202 [========>.....................] - ETA: 1:19 - loss: 0.6881 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 1:12 - loss: 0.6835 - acc: 0.5871
 512/1202 [===========>..................] - ETA: 1:06 - loss: 0.6827 - acc: 0.5840
 576/1202 [=============>................] - ETA: 58s - loss: 0.6886 - acc: 0.5660 
 640/1202 [==============>...............] - ETA: 52s - loss: 0.6898 - acc: 0.5594
 704/1202 [================>.............] - ETA: 45s - loss: 0.6831 - acc: 0.5710
 768/1202 [==================>...........] - ETA: 39s - loss: 0.6755 - acc: 0.5794
 832/1202 [===================>..........] - ETA: 33s - loss: 0.6797 - acc: 0.5733
 896/1202 [=====================>........] - ETA: 27s - loss: 0.6815 - acc: 0.5770
 960/1202 [======================>.......] - ETA: 21s - loss: 0.6884 - acc: 0.5698
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6923 - acc: 0.5703
1088/1202 [==========================>...] - ETA: 10s - loss: 0.6991 - acc: 0.5616
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6969 - acc: 0.5582 
1202/1202 [==============================] - 109s 91ms/step - loss: 0.6961 - acc: 0.5557 - val_loss: 0.6850 - val_acc: 0.5746

Epoch 00004: val_acc did not improve from 0.61940
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:34 - loss: 0.6495 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:24 - loss: 0.6653 - acc: 0.5625
 192/1202 [===>..........................] - ETA: 1:15 - loss: 0.6554 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 1:08 - loss: 0.6758 - acc: 0.5664
 320/1202 [======>.......................] - ETA: 1:06 - loss: 0.6833 - acc: 0.5594
 384/1202 [========>.....................] - ETA: 1:02 - loss: 0.7048 - acc: 0.5339
 448/1202 [==========>...................] - ETA: 57s - loss: 0.7099 - acc: 0.5223 
 512/1202 [===========>..................] - ETA: 52s - loss: 0.7088 - acc: 0.5215
 576/1202 [=============>................] - ETA: 48s - loss: 0.7063 - acc: 0.5312
 640/1202 [==============>...............] - ETA: 43s - loss: 0.7033 - acc: 0.5359
 704/1202 [================>.............] - ETA: 38s - loss: 0.6992 - acc: 0.5412
 768/1202 [==================>...........] - ETA: 33s - loss: 0.7010 - acc: 0.5417
 832/1202 [===================>..........] - ETA: 28s - loss: 0.7002 - acc: 0.5421
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6984 - acc: 0.5458
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6930 - acc: 0.5531
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6931 - acc: 0.5518
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6924 - acc: 0.5460 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6919 - acc: 0.5469
1202/1202 [==============================] - 99s 83ms/step - loss: 0.6898 - acc: 0.5516 - val_loss: 0.6762 - val_acc: 0.5821

Epoch 00005: val_acc did not improve from 0.61940
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:28 - loss: 0.7240 - acc: 0.4531
 128/1202 [==>...........................] - ETA: 1:26 - loss: 0.6963 - acc: 0.5156
 192/1202 [===>..........................] - ETA: 1:19 - loss: 0.6929 - acc: 0.5208
 256/1202 [=====>........................] - ETA: 1:13 - loss: 0.6829 - acc: 0.5508
 320/1202 [======>.......................] - ETA: 1:09 - loss: 0.6945 - acc: 0.5344
 384/1202 [========>.....................] - ETA: 1:03 - loss: 0.6920 - acc: 0.5365
 448/1202 [==========>...................] - ETA: 58s - loss: 0.6854 - acc: 0.5424 
 512/1202 [===========>..................] - ETA: 54s - loss: 0.6835 - acc: 0.5508
 576/1202 [=============>................] - ETA: 49s - loss: 0.6743 - acc: 0.5729
 640/1202 [==============>...............] - ETA: 44s - loss: 0.6702 - acc: 0.5813
 704/1202 [================>.............] - ETA: 39s - loss: 0.6715 - acc: 0.5838
 768/1202 [==================>...........] - ETA: 33s - loss: 0.6704 - acc: 0.5820
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6662 - acc: 0.5877
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6714 - acc: 0.5792
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6712 - acc: 0.5833
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6705 - acc: 0.5869
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6697 - acc: 0.5864 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6682 - acc: 0.5920
1202/1202 [==============================] - 97s 80ms/step - loss: 0.6674 - acc: 0.5915 - val_loss: 0.6733 - val_acc: 0.5896

Epoch 00006: val_acc did not improve from 0.61940
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:31 - loss: 0.6207 - acc: 0.6875
 128/1202 [==>...........................] - ETA: 1:22 - loss: 0.6309 - acc: 0.7031
 192/1202 [===>..........................] - ETA: 1:18 - loss: 0.6626 - acc: 0.6562
 256/1202 [=====>........................] - ETA: 1:15 - loss: 0.6685 - acc: 0.6406
 320/1202 [======>.......................] - ETA: 1:09 - loss: 0.6625 - acc: 0.6344
 384/1202 [========>.....................] - ETA: 1:04 - loss: 0.6726 - acc: 0.6146
 448/1202 [==========>...................] - ETA: 59s - loss: 0.6626 - acc: 0.6317 
 512/1202 [===========>..................] - ETA: 54s - loss: 0.6588 - acc: 0.6289
 576/1202 [=============>................] - ETA: 49s - loss: 0.6627 - acc: 0.6181
 640/1202 [==============>...............] - ETA: 44s - loss: 0.6625 - acc: 0.6188
 704/1202 [================>.............] - ETA: 39s - loss: 0.6656 - acc: 0.6094
 768/1202 [==================>...........] - ETA: 34s - loss: 0.6616 - acc: 0.6172
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6610 - acc: 0.6178
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6669 - acc: 0.6105
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6645 - acc: 0.6104
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6592 - acc: 0.6162
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6615 - acc: 0.6131 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6613 - acc: 0.6155
1202/1202 [==============================] - 97s 81ms/step - loss: 0.6597 - acc: 0.6181 - val_loss: 0.6605 - val_acc: 0.6045

Epoch 00007: val_acc did not improve from 0.61940
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:24 - loss: 0.5923 - acc: 0.7031
 128/1202 [==>...........................] - ETA: 1:23 - loss: 0.6298 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 1:20 - loss: 0.6370 - acc: 0.6146
 256/1202 [=====>........................] - ETA: 1:12 - loss: 0.6285 - acc: 0.6367
 320/1202 [======>.......................] - ETA: 1:07 - loss: 0.6480 - acc: 0.6125
 384/1202 [========>.....................] - ETA: 1:02 - loss: 0.6717 - acc: 0.5859
 448/1202 [==========>...................] - ETA: 57s - loss: 0.6687 - acc: 0.5938 
 512/1202 [===========>..................] - ETA: 52s - loss: 0.6639 - acc: 0.5996
 576/1202 [=============>................] - ETA: 47s - loss: 0.6617 - acc: 0.6007
 640/1202 [==============>...............] - ETA: 43s - loss: 0.6592 - acc: 0.6125
 704/1202 [================>.............] - ETA: 38s - loss: 0.6569 - acc: 0.6165
 768/1202 [==================>...........] - ETA: 33s - loss: 0.6623 - acc: 0.6055
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6660 - acc: 0.5998
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6606 - acc: 0.6027
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6655 - acc: 0.5990
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6693 - acc: 0.5977
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6667 - acc: 0.6011 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6666 - acc: 0.6016
1202/1202 [==============================] - 97s 80ms/step - loss: 0.6703 - acc: 0.5965 - val_loss: 0.6794 - val_acc: 0.5896

Epoch 00008: val_acc did not improve from 0.61940
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:28 - loss: 0.6275 - acc: 0.6406
 128/1202 [==>...........................] - ETA: 1:22 - loss: 0.6664 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 1:15 - loss: 0.6507 - acc: 0.6250
 256/1202 [=====>........................] - ETA: 1:08 - loss: 0.6673 - acc: 0.5859
 320/1202 [======>.......................] - ETA: 1:03 - loss: 0.6616 - acc: 0.5969
 384/1202 [========>.....................] - ETA: 1:00 - loss: 0.6687 - acc: 0.5859
 448/1202 [==========>...................] - ETA: 55s - loss: 0.6670 - acc: 0.5848 
 512/1202 [===========>..................] - ETA: 51s - loss: 0.6685 - acc: 0.5898
 576/1202 [=============>................] - ETA: 47s - loss: 0.6678 - acc: 0.5903
 640/1202 [==============>...............] - ETA: 42s - loss: 0.6670 - acc: 0.5969
 704/1202 [================>.............] - ETA: 37s - loss: 0.6699 - acc: 0.5881
 768/1202 [==================>...........] - ETA: 32s - loss: 0.6693 - acc: 0.5885
 832/1202 [===================>..........] - ETA: 27s - loss: 0.6669 - acc: 0.5938
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6621 - acc: 0.6038
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6649 - acc: 0.6000
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6625 - acc: 0.6006
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6619 - acc: 0.6066 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6576 - acc: 0.6128
1202/1202 [==============================] - 98s 81ms/step - loss: 0.6591 - acc: 0.6115 - val_loss: 0.7042 - val_acc: 0.5224

Epoch 00009: val_acc did not improve from 0.61940
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:24 - loss: 0.6429 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 1:20 - loss: 0.6387 - acc: 0.6484
 192/1202 [===>..........................] - ETA: 1:15 - loss: 0.6414 - acc: 0.6354
 256/1202 [=====>........................] - ETA: 1:10 - loss: 0.6344 - acc: 0.6406
 320/1202 [======>.......................] - ETA: 1:05 - loss: 0.6437 - acc: 0.6375
 384/1202 [========>.....................] - ETA: 1:00 - loss: 0.6503 - acc: 0.6302
 448/1202 [==========>...................] - ETA: 54s - loss: 0.6429 - acc: 0.6384 
 512/1202 [===========>..................] - ETA: 51s - loss: 0.6432 - acc: 0.6367
 576/1202 [=============>................] - ETA: 47s - loss: 0.6364 - acc: 0.6458
 640/1202 [==============>...............] - ETA: 42s - loss: 0.6305 - acc: 0.6531
 704/1202 [================>.............] - ETA: 38s - loss: 0.6379 - acc: 0.6463
 768/1202 [==================>...........] - ETA: 33s - loss: 0.6446 - acc: 0.6328
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6488 - acc: 0.6334
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6492 - acc: 0.6328
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6496 - acc: 0.6344
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6534 - acc: 0.6328
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6540 - acc: 0.6287 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6548 - acc: 0.6233
1202/1202 [==============================] - 98s 81ms/step - loss: 0.6550 - acc: 0.6231 - val_loss: 0.7249 - val_acc: 0.5075

Epoch 00010: val_acc did not improve from 0.61940
样本个数 167
样本个数 334
window_select11-15.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 7s
128/334 [==========>...................] - ETA: 4s
192/334 [================>.............] - ETA: 3s
256/334 [=====================>........] - ETA: 1s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 7s 21ms/step
loss: 0.6794982595358067
acc: 0.5928143714359421
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f8840723e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f8840723e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f88406aa310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f88406aa310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8edd99d810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8edd99d810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8edda74410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8edda74410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88405d3b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88405d3b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f884061e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f884061e350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8edda74610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8edda74610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f88404ec350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f88404ec350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f884049bdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f884049bdd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88407342d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88407342d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f884049bd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f884049bd50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f88404339d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f88404339d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f884018f750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f884018f750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8840135bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8840135bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88006cad10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88006cad10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f88401072d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f88401072d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8840135c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8840135c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f88006d8e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f88006d8e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f88004845d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f88004845d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88004d2c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88004d2c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f880048ef90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f880048ef90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8800484450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8800484450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8800264bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8800264bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f88001b2d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f88001b2d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88004f8610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88004f8610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f880028eb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f880028eb90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8800264c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8800264c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f880011a410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f880011a410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f880007c190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f880007c190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87e0527f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87e0527f90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87e03fa710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87e03fa710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87e06a9f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87e06a9f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87e05f6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87e05f6a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87e033af10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87e033af10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87e01c2f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87e01c2f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87e00b9d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87e00b9d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87e0572150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87e0572150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87e0215e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87e0215e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87c0789890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87c0789890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87c0791190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87c0791190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87c0702c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87c0702c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87c0702250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87c0702250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f88402e3350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f88402e3350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87c0791a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87c0791a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87c0348ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87c0348ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87c02b02d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87c02b02d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f884039ead0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f884039ead0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87c03b8c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87c03b8c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87c014e190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87c014e190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87c00637d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87c00637d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87a0775d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87a0775d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87c02b5e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87c02b5e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87c005be50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87c005be50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87a0709510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87a0709510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87a050f3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87a050f3d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87a05013d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87a05013d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87a0737ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87a0737ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87c00a76d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87c00a76d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87a02ce050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f87a02ce050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87a021f290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f87a021f290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87a03b3cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87a03b3cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87a0428ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f87a0428ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87a0227b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87a0227b90>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 3:36 - loss: 0.7553 - acc: 0.4688
 128/1202 [==>...........................] - ETA: 2:21 - loss: 0.7814 - acc: 0.4375
 192/1202 [===>..........................] - ETA: 1:54 - loss: 0.7966 - acc: 0.4375
 256/1202 [=====>........................] - ETA: 1:37 - loss: 0.7817 - acc: 0.4570
 320/1202 [======>.......................] - ETA: 1:25 - loss: 0.7607 - acc: 0.4906
 384/1202 [========>.....................] - ETA: 1:17 - loss: 0.7591 - acc: 0.4844
 448/1202 [==========>...................] - ETA: 1:09 - loss: 0.7464 - acc: 0.4955
 512/1202 [===========>..................] - ETA: 1:01 - loss: 0.7391 - acc: 0.5078
 576/1202 [=============>................] - ETA: 55s - loss: 0.7381 - acc: 0.5087 
 640/1202 [==============>...............] - ETA: 48s - loss: 0.7337 - acc: 0.5125
 704/1202 [================>.............] - ETA: 42s - loss: 0.7296 - acc: 0.5241
 768/1202 [==================>...........] - ETA: 36s - loss: 0.7263 - acc: 0.5286
 832/1202 [===================>..........] - ETA: 31s - loss: 0.7241 - acc: 0.5276
 896/1202 [=====================>........] - ETA: 25s - loss: 0.7264 - acc: 0.5324
 960/1202 [======================>.......] - ETA: 20s - loss: 0.7297 - acc: 0.5312
1024/1202 [========================>.....] - ETA: 14s - loss: 0.7302 - acc: 0.5332
1088/1202 [==========================>...] - ETA: 9s - loss: 0.7312 - acc: 0.5303 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.7361 - acc: 0.5226
1202/1202 [==============================] - 104s 87ms/step - loss: 0.7336 - acc: 0.5250 - val_loss: 0.6766 - val_acc: 0.5746

Epoch 00001: val_acc improved from -inf to 0.57463, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window12/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:34 - loss: 0.7311 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 1:28 - loss: 0.7380 - acc: 0.4844
 192/1202 [===>..........................] - ETA: 1:21 - loss: 0.7249 - acc: 0.4896
 256/1202 [=====>........................] - ETA: 1:14 - loss: 0.7222 - acc: 0.5117
 320/1202 [======>.......................] - ETA: 1:09 - loss: 0.7238 - acc: 0.5188
 384/1202 [========>.....................] - ETA: 1:03 - loss: 0.7207 - acc: 0.5312
 448/1202 [==========>...................] - ETA: 58s - loss: 0.7101 - acc: 0.5290 
 512/1202 [===========>..................] - ETA: 53s - loss: 0.7069 - acc: 0.5312
 576/1202 [=============>................] - ETA: 47s - loss: 0.7071 - acc: 0.5347
 640/1202 [==============>...............] - ETA: 43s - loss: 0.7027 - acc: 0.5391
 704/1202 [================>.............] - ETA: 38s - loss: 0.7082 - acc: 0.5270
 768/1202 [==================>...........] - ETA: 33s - loss: 0.7012 - acc: 0.5404
 832/1202 [===================>..........] - ETA: 28s - loss: 0.7007 - acc: 0.5397
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6985 - acc: 0.5413
 960/1202 [======================>.......] - ETA: 18s - loss: 0.7000 - acc: 0.5396
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6999 - acc: 0.5391
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6928 - acc: 0.5506 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6920 - acc: 0.5521
1202/1202 [==============================] - 94s 78ms/step - loss: 0.6914 - acc: 0.5516 - val_loss: 0.6703 - val_acc: 0.6045

Epoch 00002: val_acc improved from 0.57463 to 0.60448, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window12/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:04 - loss: 0.6503 - acc: 0.6406
 128/1202 [==>...........................] - ETA: 59s - loss: 0.6554 - acc: 0.6172 
 192/1202 [===>..........................] - ETA: 58s - loss: 0.6611 - acc: 0.6146
 256/1202 [=====>........................] - ETA: 54s - loss: 0.6790 - acc: 0.5859
 320/1202 [======>.......................] - ETA: 53s - loss: 0.6858 - acc: 0.5781
 384/1202 [========>.....................] - ETA: 49s - loss: 0.6890 - acc: 0.5781
 448/1202 [==========>...................] - ETA: 44s - loss: 0.6973 - acc: 0.5714
 512/1202 [===========>..................] - ETA: 40s - loss: 0.6919 - acc: 0.5762
 576/1202 [=============>................] - ETA: 37s - loss: 0.6976 - acc: 0.5712
 640/1202 [==============>...............] - ETA: 33s - loss: 0.7028 - acc: 0.5687
 704/1202 [================>.............] - ETA: 29s - loss: 0.6986 - acc: 0.5753
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6994 - acc: 0.5677
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6964 - acc: 0.5697
 896/1202 [=====================>........] - ETA: 18s - loss: 0.6950 - acc: 0.5692
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6976 - acc: 0.5646
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6957 - acc: 0.5654
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6926 - acc: 0.5717 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6961 - acc: 0.5677
1202/1202 [==============================] - 73s 61ms/step - loss: 0.6960 - acc: 0.5666 - val_loss: 0.6648 - val_acc: 0.5970

Epoch 00003: val_acc did not improve from 0.60448
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:10 - loss: 0.7264 - acc: 0.4844
 128/1202 [==>...........................] - ETA: 1:02 - loss: 0.7016 - acc: 0.5625
 192/1202 [===>..........................] - ETA: 59s - loss: 0.6851 - acc: 0.5677 
 256/1202 [=====>........................] - ETA: 54s - loss: 0.6866 - acc: 0.5664
 320/1202 [======>.......................] - ETA: 50s - loss: 0.6764 - acc: 0.5687
 384/1202 [========>.....................] - ETA: 48s - loss: 0.6731 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 44s - loss: 0.6712 - acc: 0.5848
 512/1202 [===========>..................] - ETA: 40s - loss: 0.6799 - acc: 0.5781
 576/1202 [=============>................] - ETA: 36s - loss: 0.6767 - acc: 0.5833
 640/1202 [==============>...............] - ETA: 33s - loss: 0.6735 - acc: 0.5891
 704/1202 [================>.............] - ETA: 29s - loss: 0.6733 - acc: 0.5909
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6710 - acc: 0.5924
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6736 - acc: 0.5913
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6780 - acc: 0.5871
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6812 - acc: 0.5823
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6829 - acc: 0.5762
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6814 - acc: 0.5827 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6845 - acc: 0.5755
1202/1202 [==============================] - 68s 57ms/step - loss: 0.6868 - acc: 0.5691 - val_loss: 0.6596 - val_acc: 0.5746

Epoch 00004: val_acc did not improve from 0.60448
Epoch 5/10

  64/1202 [>.............................] - ETA: 45s - loss: 0.6713 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 49s - loss: 0.6703 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 46s - loss: 0.6723 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 43s - loss: 0.6759 - acc: 0.5625
 320/1202 [======>.......................] - ETA: 39s - loss: 0.6795 - acc: 0.5500
 384/1202 [========>.....................] - ETA: 36s - loss: 0.6876 - acc: 0.5443
 448/1202 [==========>...................] - ETA: 34s - loss: 0.6920 - acc: 0.5424
 512/1202 [===========>..................] - ETA: 31s - loss: 0.6910 - acc: 0.5469
 576/1202 [=============>................] - ETA: 28s - loss: 0.6902 - acc: 0.5399
 640/1202 [==============>...............] - ETA: 25s - loss: 0.6913 - acc: 0.5391
 704/1202 [================>.............] - ETA: 22s - loss: 0.6932 - acc: 0.5355
 768/1202 [==================>...........] - ETA: 19s - loss: 0.6912 - acc: 0.5352
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6887 - acc: 0.5409
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6886 - acc: 0.5424
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6897 - acc: 0.5448
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6883 - acc: 0.5449 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6873 - acc: 0.5487
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6868 - acc: 0.5495
1202/1202 [==============================] - 56s 47ms/step - loss: 0.6862 - acc: 0.5491 - val_loss: 0.6760 - val_acc: 0.5896

Epoch 00005: val_acc did not improve from 0.60448
Epoch 6/10

  64/1202 [>.............................] - ETA: 51s - loss: 0.6195 - acc: 0.6719
 128/1202 [==>...........................] - ETA: 48s - loss: 0.6250 - acc: 0.6641
 192/1202 [===>..........................] - ETA: 46s - loss: 0.6437 - acc: 0.6354
 256/1202 [=====>........................] - ETA: 44s - loss: 0.6647 - acc: 0.5898
 320/1202 [======>.......................] - ETA: 41s - loss: 0.6639 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 37s - loss: 0.6649 - acc: 0.5833
 448/1202 [==========>...................] - ETA: 34s - loss: 0.6749 - acc: 0.5759
 512/1202 [===========>..................] - ETA: 31s - loss: 0.6723 - acc: 0.5762
 576/1202 [=============>................] - ETA: 28s - loss: 0.6693 - acc: 0.5833
 640/1202 [==============>...............] - ETA: 26s - loss: 0.6666 - acc: 0.5891
 704/1202 [================>.............] - ETA: 24s - loss: 0.6644 - acc: 0.5923
 768/1202 [==================>...........] - ETA: 21s - loss: 0.6669 - acc: 0.5872
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6662 - acc: 0.5877
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6709 - acc: 0.5804
 960/1202 [======================>.......] - ETA: 11s - loss: 0.6694 - acc: 0.5833
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6721 - acc: 0.5820 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6706 - acc: 0.5836
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6721 - acc: 0.5825
1202/1202 [==============================] - 63s 53ms/step - loss: 0.6718 - acc: 0.5815 - val_loss: 0.6803 - val_acc: 0.5821

Epoch 00006: val_acc did not improve from 0.60448
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:00 - loss: 0.6590 - acc: 0.5938
 128/1202 [==>...........................] - ETA: 1:00 - loss: 0.6725 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 58s - loss: 0.6859 - acc: 0.5260 
 256/1202 [=====>........................] - ETA: 54s - loss: 0.6702 - acc: 0.5547
 320/1202 [======>.......................] - ETA: 50s - loss: 0.6723 - acc: 0.5563
 384/1202 [========>.....................] - ETA: 47s - loss: 0.6659 - acc: 0.5703
 448/1202 [==========>...................] - ETA: 44s - loss: 0.6670 - acc: 0.5737
 512/1202 [===========>..................] - ETA: 40s - loss: 0.6725 - acc: 0.5684
 576/1202 [=============>................] - ETA: 36s - loss: 0.6666 - acc: 0.5816
 640/1202 [==============>...............] - ETA: 32s - loss: 0.6687 - acc: 0.5781
 704/1202 [================>.............] - ETA: 28s - loss: 0.6691 - acc: 0.5753
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6727 - acc: 0.5677
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6761 - acc: 0.5721
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6772 - acc: 0.5681
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6718 - acc: 0.5802
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6717 - acc: 0.5840
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6718 - acc: 0.5800 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6703 - acc: 0.5851
1202/1202 [==============================] - 73s 61ms/step - loss: 0.6699 - acc: 0.5857 - val_loss: 0.6629 - val_acc: 0.5821

Epoch 00007: val_acc did not improve from 0.60448
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:01 - loss: 0.6369 - acc: 0.6719
 128/1202 [==>...........................] - ETA: 54s - loss: 0.6855 - acc: 0.5938 
 192/1202 [===>..........................] - ETA: 53s - loss: 0.6760 - acc: 0.5938
 256/1202 [=====>........................] - ETA: 50s - loss: 0.6660 - acc: 0.5977
 320/1202 [======>.......................] - ETA: 50s - loss: 0.6641 - acc: 0.5969
 384/1202 [========>.....................] - ETA: 47s - loss: 0.6669 - acc: 0.5859
 448/1202 [==========>...................] - ETA: 46s - loss: 0.6658 - acc: 0.5960
 512/1202 [===========>..................] - ETA: 42s - loss: 0.6667 - acc: 0.6035
 576/1202 [=============>................] - ETA: 39s - loss: 0.6669 - acc: 0.6111
 640/1202 [==============>...............] - ETA: 35s - loss: 0.6613 - acc: 0.6172
 704/1202 [================>.............] - ETA: 31s - loss: 0.6614 - acc: 0.6179
 768/1202 [==================>...........] - ETA: 27s - loss: 0.6580 - acc: 0.6250
 832/1202 [===================>..........] - ETA: 23s - loss: 0.6559 - acc: 0.6262
 896/1202 [=====================>........] - ETA: 19s - loss: 0.6546 - acc: 0.6250
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6543 - acc: 0.6250
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6519 - acc: 0.6279
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6551 - acc: 0.6213 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6614 - acc: 0.6172
1202/1202 [==============================] - 84s 70ms/step - loss: 0.6603 - acc: 0.6165 - val_loss: 0.6737 - val_acc: 0.5821

Epoch 00008: val_acc did not improve from 0.60448
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:29 - loss: 0.7037 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 1:19 - loss: 0.6689 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 1:14 - loss: 0.6340 - acc: 0.6302
 256/1202 [=====>........................] - ETA: 1:09 - loss: 0.6380 - acc: 0.6367
 320/1202 [======>.......................] - ETA: 1:04 - loss: 0.6450 - acc: 0.6312
 384/1202 [========>.....................] - ETA: 1:00 - loss: 0.6507 - acc: 0.6250
 448/1202 [==========>...................] - ETA: 55s - loss: 0.6539 - acc: 0.6250 
 512/1202 [===========>..................] - ETA: 50s - loss: 0.6626 - acc: 0.6191
 576/1202 [=============>................] - ETA: 45s - loss: 0.6602 - acc: 0.6250
 640/1202 [==============>...............] - ETA: 41s - loss: 0.6610 - acc: 0.6250
 704/1202 [================>.............] - ETA: 36s - loss: 0.6636 - acc: 0.6165
 768/1202 [==================>...........] - ETA: 31s - loss: 0.6593 - acc: 0.6211
 832/1202 [===================>..........] - ETA: 26s - loss: 0.6642 - acc: 0.6130
 896/1202 [=====================>........] - ETA: 22s - loss: 0.6642 - acc: 0.6127
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6650 - acc: 0.6094
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6702 - acc: 0.6035
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6684 - acc: 0.6029 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6699 - acc: 0.6016
1202/1202 [==============================] - 90s 75ms/step - loss: 0.6681 - acc: 0.6048 - val_loss: 0.6816 - val_acc: 0.5970

Epoch 00009: val_acc did not improve from 0.60448
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:12 - loss: 0.6315 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 1:14 - loss: 0.6361 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 1:10 - loss: 0.6319 - acc: 0.6562
 256/1202 [=====>........................] - ETA: 1:04 - loss: 0.6272 - acc: 0.6719
 320/1202 [======>.......................] - ETA: 59s - loss: 0.6291 - acc: 0.6594 
 384/1202 [========>.....................] - ETA: 56s - loss: 0.6296 - acc: 0.6562
 448/1202 [==========>...................] - ETA: 52s - loss: 0.6395 - acc: 0.6562
 512/1202 [===========>..................] - ETA: 49s - loss: 0.6523 - acc: 0.6309
 576/1202 [=============>................] - ETA: 44s - loss: 0.6553 - acc: 0.6215
 640/1202 [==============>...............] - ETA: 40s - loss: 0.6638 - acc: 0.6094
 704/1202 [================>.............] - ETA: 35s - loss: 0.6640 - acc: 0.6122
 768/1202 [==================>...........] - ETA: 31s - loss: 0.6661 - acc: 0.6081
 832/1202 [===================>..........] - ETA: 26s - loss: 0.6678 - acc: 0.6046
 896/1202 [=====================>........] - ETA: 21s - loss: 0.6692 - acc: 0.6016
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6690 - acc: 0.6000
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6708 - acc: 0.5967
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6723 - acc: 0.5956 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6717 - acc: 0.5964
1202/1202 [==============================] - 92s 76ms/step - loss: 0.6720 - acc: 0.5957 - val_loss: 0.6760 - val_acc: 0.5448

Epoch 00010: val_acc did not improve from 0.60448
样本个数 167
样本个数 334
window_select11-15.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 16s
128/334 [==========>...................] - ETA: 8s 
192/334 [================>.............] - ETA: 5s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 12s 36ms/step
loss: 0.6775314900689496
acc: 0.5778443115557025
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f8700414750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f8700414750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f87003ddcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f87003ddcd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c04ffc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c04ffc10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ecd013390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8ecd013390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f870033b390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f870033b390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ecd0a1990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8ecd0a1990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ecd013490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8ecd013490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c0506d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c0506d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86e05e7510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86e05e7510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86e05f3950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86e05f3950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8700106f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8700106f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f870029ae90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f870029ae90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86e0774d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86e0774d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86e061e810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86e061e810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8700046990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8700046990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c0337ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c0337ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f870018dd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f870018dd90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86e05f4350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86e05f4350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c01c1310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c01c1310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c00dbbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c00dbbd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c049f650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c049f650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c01c1ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c01c1ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c012c910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c012c910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c011ce90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c011ce90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86a4665910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86a4665910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87e0211c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f87e0211c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c049b610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c049b610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86a45f3410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86a45f3410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86a459d210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86a459d210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86a44f2990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86a44f2990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86a413a090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86a413a090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86a4601390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86a4601390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c0252f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c0252f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86a4050750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86a4050750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8680732cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8680732cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86a424ea10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86a424ea10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86a4604390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86a4604390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86a472e110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86a472e110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f868054c290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f868054c290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8680549d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8680549d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8680527f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8680527f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86807822d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86807822d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f868041cb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f868041cb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f868022c190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f868022c190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8680403bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8680403bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8680244fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8680244fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f868022ca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f868022ca90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86800e7190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86800e7190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8680217750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8680217750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86800bc9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86800bc9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8680143f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8680143f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8660744090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8660744090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86605990d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86605990d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86603952d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86603952d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86603b03d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86603b03d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f866035b350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f866035b350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f866044b390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f866044b390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86600815d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86600815d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86600787d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86600787d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8644719890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8644719890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86a4332d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86a4332d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f866016c750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f866016c750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8644713c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8644713c10>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 4:35 - loss: 0.7640 - acc: 0.4375
 128/1202 [==>...........................] - ETA: 2:49 - loss: 0.7277 - acc: 0.5000
 192/1202 [===>..........................] - ETA: 2:13 - loss: 0.7284 - acc: 0.5208
 256/1202 [=====>........................] - ETA: 1:54 - loss: 0.7497 - acc: 0.5273
 320/1202 [======>.......................] - ETA: 1:39 - loss: 0.7544 - acc: 0.5188
 384/1202 [========>.....................] - ETA: 1:28 - loss: 0.7524 - acc: 0.5182
 448/1202 [==========>...................] - ETA: 1:18 - loss: 0.7552 - acc: 0.5067
 512/1202 [===========>..................] - ETA: 1:09 - loss: 0.7458 - acc: 0.5098
 576/1202 [=============>................] - ETA: 1:01 - loss: 0.7317 - acc: 0.5260
 640/1202 [==============>...............] - ETA: 54s - loss: 0.7384 - acc: 0.5297 
 704/1202 [================>.............] - ETA: 47s - loss: 0.7348 - acc: 0.5327
 768/1202 [==================>...........] - ETA: 41s - loss: 0.7385 - acc: 0.5286
 832/1202 [===================>..........] - ETA: 34s - loss: 0.7319 - acc: 0.5337
 896/1202 [=====================>........] - ETA: 28s - loss: 0.7301 - acc: 0.5335
 960/1202 [======================>.......] - ETA: 22s - loss: 0.7298 - acc: 0.5312
1024/1202 [========================>.....] - ETA: 16s - loss: 0.7320 - acc: 0.5312
1088/1202 [==========================>...] - ETA: 10s - loss: 0.7296 - acc: 0.5340
1152/1202 [===========================>..] - ETA: 4s - loss: 0.7293 - acc: 0.5356 
1202/1202 [==============================] - 113s 94ms/step - loss: 0.7307 - acc: 0.5349 - val_loss: 0.7816 - val_acc: 0.4552

Epoch 00001: val_acc improved from -inf to 0.45522, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window13/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:31 - loss: 0.7107 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:22 - loss: 0.6825 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:18 - loss: 0.6774 - acc: 0.5729
 256/1202 [=====>........................] - ETA: 1:11 - loss: 0.6867 - acc: 0.5703
 320/1202 [======>.......................] - ETA: 1:06 - loss: 0.6805 - acc: 0.5844
 384/1202 [========>.....................] - ETA: 1:02 - loss: 0.6897 - acc: 0.5651
 448/1202 [==========>...................] - ETA: 57s - loss: 0.6892 - acc: 0.5580 
 512/1202 [===========>..................] - ETA: 52s - loss: 0.6876 - acc: 0.5605
 576/1202 [=============>................] - ETA: 47s - loss: 0.6884 - acc: 0.5590
 640/1202 [==============>...............] - ETA: 43s - loss: 0.6883 - acc: 0.5594
 704/1202 [================>.............] - ETA: 38s - loss: 0.6921 - acc: 0.5540
 768/1202 [==================>...........] - ETA: 33s - loss: 0.6875 - acc: 0.5625
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6886 - acc: 0.5601
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6867 - acc: 0.5614
 960/1202 [======================>.......] - ETA: 18s - loss: 0.6870 - acc: 0.5615
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6868 - acc: 0.5625
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6878 - acc: 0.5588 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6865 - acc: 0.5599
1202/1202 [==============================] - 97s 81ms/step - loss: 0.6860 - acc: 0.5599 - val_loss: 0.7169 - val_acc: 0.5000

Epoch 00002: val_acc improved from 0.45522 to 0.50000, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window13/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:17 - loss: 0.6635 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 1:11 - loss: 0.6999 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:08 - loss: 0.6657 - acc: 0.5938
 256/1202 [=====>........................] - ETA: 1:05 - loss: 0.6707 - acc: 0.5859
 320/1202 [======>.......................] - ETA: 1:02 - loss: 0.6727 - acc: 0.5969
 384/1202 [========>.....................] - ETA: 59s - loss: 0.6742 - acc: 0.5938 
 448/1202 [==========>...................] - ETA: 53s - loss: 0.6749 - acc: 0.5915
 512/1202 [===========>..................] - ETA: 49s - loss: 0.6762 - acc: 0.5840
 576/1202 [=============>................] - ETA: 44s - loss: 0.6751 - acc: 0.5868
 640/1202 [==============>...............] - ETA: 40s - loss: 0.6813 - acc: 0.5813
 704/1202 [================>.............] - ETA: 35s - loss: 0.6831 - acc: 0.5795
 768/1202 [==================>...........] - ETA: 30s - loss: 0.6868 - acc: 0.5742
 832/1202 [===================>..........] - ETA: 26s - loss: 0.6943 - acc: 0.5673
 896/1202 [=====================>........] - ETA: 21s - loss: 0.6893 - acc: 0.5748
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6902 - acc: 0.5750
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6938 - acc: 0.5762
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6923 - acc: 0.5790 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6905 - acc: 0.5781
1202/1202 [==============================] - 87s 73ms/step - loss: 0.6910 - acc: 0.5765 - val_loss: 0.6828 - val_acc: 0.5672

Epoch 00003: val_acc improved from 0.50000 to 0.56716, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window13/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:07 - loss: 0.6651 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:08 - loss: 0.7034 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 1:05 - loss: 0.6991 - acc: 0.5521
 256/1202 [=====>........................] - ETA: 1:02 - loss: 0.6895 - acc: 0.5586
 320/1202 [======>.......................] - ETA: 59s - loss: 0.6910 - acc: 0.5500 
 384/1202 [========>.....................] - ETA: 55s - loss: 0.6930 - acc: 0.5469
 448/1202 [==========>...................] - ETA: 51s - loss: 0.6994 - acc: 0.5469
 512/1202 [===========>..................] - ETA: 46s - loss: 0.7046 - acc: 0.5508
 576/1202 [=============>................] - ETA: 41s - loss: 0.7023 - acc: 0.5538
 640/1202 [==============>...............] - ETA: 37s - loss: 0.7074 - acc: 0.5437
 704/1202 [================>.............] - ETA: 32s - loss: 0.7078 - acc: 0.5398
 768/1202 [==================>...........] - ETA: 28s - loss: 0.7115 - acc: 0.5339
 832/1202 [===================>..........] - ETA: 24s - loss: 0.7091 - acc: 0.5397
 896/1202 [=====================>........] - ETA: 20s - loss: 0.7042 - acc: 0.5458
 960/1202 [======================>.......] - ETA: 15s - loss: 0.7048 - acc: 0.5448
1024/1202 [========================>.....] - ETA: 11s - loss: 0.7076 - acc: 0.5430
1088/1202 [==========================>...] - ETA: 7s - loss: 0.7090 - acc: 0.5404 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7073 - acc: 0.5434
1202/1202 [==============================] - 82s 69ms/step - loss: 0.7058 - acc: 0.5433 - val_loss: 0.7332 - val_acc: 0.4925

Epoch 00004: val_acc did not improve from 0.56716
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:16 - loss: 0.6742 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:04 - loss: 0.6615 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 59s - loss: 0.6705 - acc: 0.5729 
 256/1202 [=====>........................] - ETA: 53s - loss: 0.6711 - acc: 0.5703
 320/1202 [======>.......................] - ETA: 49s - loss: 0.6613 - acc: 0.5906
 384/1202 [========>.....................] - ETA: 45s - loss: 0.6663 - acc: 0.5885
 448/1202 [==========>...................] - ETA: 40s - loss: 0.6847 - acc: 0.5603
 512/1202 [===========>..................] - ETA: 37s - loss: 0.6819 - acc: 0.5684
 576/1202 [=============>................] - ETA: 34s - loss: 0.6767 - acc: 0.5799
 640/1202 [==============>...............] - ETA: 31s - loss: 0.6716 - acc: 0.5813
 704/1202 [================>.............] - ETA: 27s - loss: 0.6730 - acc: 0.5810
 768/1202 [==================>...........] - ETA: 23s - loss: 0.6762 - acc: 0.5742
 832/1202 [===================>..........] - ETA: 20s - loss: 0.6733 - acc: 0.5793
 896/1202 [=====================>........] - ETA: 16s - loss: 0.6792 - acc: 0.5725
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6851 - acc: 0.5677
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6851 - acc: 0.5674 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6832 - acc: 0.5717
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6802 - acc: 0.5764
1202/1202 [==============================] - 66s 55ms/step - loss: 0.6823 - acc: 0.5715 - val_loss: 0.6890 - val_acc: 0.5373

Epoch 00005: val_acc did not improve from 0.56716
Epoch 6/10

  64/1202 [>.............................] - ETA: 49s - loss: 0.6147 - acc: 0.6406
 128/1202 [==>...........................] - ETA: 50s - loss: 0.6438 - acc: 0.6016
 192/1202 [===>..........................] - ETA: 45s - loss: 0.6277 - acc: 0.6302
 256/1202 [=====>........................] - ETA: 45s - loss: 0.6316 - acc: 0.6211
 320/1202 [======>.......................] - ETA: 44s - loss: 0.6419 - acc: 0.6219
 384/1202 [========>.....................] - ETA: 40s - loss: 0.6470 - acc: 0.6302
 448/1202 [==========>...................] - ETA: 37s - loss: 0.6522 - acc: 0.6228
 512/1202 [===========>..................] - ETA: 34s - loss: 0.6556 - acc: 0.6133
 576/1202 [=============>................] - ETA: 30s - loss: 0.6571 - acc: 0.6076
 640/1202 [==============>...............] - ETA: 27s - loss: 0.6641 - acc: 0.6016
 704/1202 [================>.............] - ETA: 24s - loss: 0.6706 - acc: 0.5938
 768/1202 [==================>...........] - ETA: 21s - loss: 0.6699 - acc: 0.5951
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6727 - acc: 0.5877
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6736 - acc: 0.5882
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6737 - acc: 0.5906
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6746 - acc: 0.5889 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6719 - acc: 0.5928
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6726 - acc: 0.5920
1202/1202 [==============================] - 62s 52ms/step - loss: 0.6716 - acc: 0.5957 - val_loss: 0.6777 - val_acc: 0.5821

Epoch 00006: val_acc improved from 0.56716 to 0.58209, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window13/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 7/10

  64/1202 [>.............................] - ETA: 57s - loss: 0.6139 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 50s - loss: 0.6130 - acc: 0.6641
 192/1202 [===>..........................] - ETA: 47s - loss: 0.6478 - acc: 0.6302
 256/1202 [=====>........................] - ETA: 45s - loss: 0.6558 - acc: 0.6016
 320/1202 [======>.......................] - ETA: 42s - loss: 0.6537 - acc: 0.6094
 384/1202 [========>.....................] - ETA: 40s - loss: 0.6557 - acc: 0.6068
 448/1202 [==========>...................] - ETA: 36s - loss: 0.6571 - acc: 0.6116
 512/1202 [===========>..................] - ETA: 34s - loss: 0.6567 - acc: 0.6035
 576/1202 [=============>................] - ETA: 30s - loss: 0.6606 - acc: 0.5955
 640/1202 [==============>...............] - ETA: 27s - loss: 0.6643 - acc: 0.5844
 704/1202 [================>.............] - ETA: 24s - loss: 0.6638 - acc: 0.5881
 768/1202 [==================>...........] - ETA: 21s - loss: 0.6698 - acc: 0.5794
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6691 - acc: 0.5829
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6703 - acc: 0.5804
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6674 - acc: 0.5833
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6644 - acc: 0.5869 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6658 - acc: 0.5892
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6669 - acc: 0.5929
1202/1202 [==============================] - 64s 54ms/step - loss: 0.6675 - acc: 0.5915 - val_loss: 0.7163 - val_acc: 0.5000

Epoch 00007: val_acc did not improve from 0.58209
Epoch 8/10

  64/1202 [>.............................] - ETA: 57s - loss: 0.6524 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 53s - loss: 0.6484 - acc: 0.6172
 192/1202 [===>..........................] - ETA: 49s - loss: 0.6519 - acc: 0.6146
 256/1202 [=====>........................] - ETA: 45s - loss: 0.6616 - acc: 0.5859
 320/1202 [======>.......................] - ETA: 43s - loss: 0.6708 - acc: 0.5750
 384/1202 [========>.....................] - ETA: 40s - loss: 0.6723 - acc: 0.5703
 448/1202 [==========>...................] - ETA: 37s - loss: 0.6738 - acc: 0.5670
 512/1202 [===========>..................] - ETA: 35s - loss: 0.6788 - acc: 0.5664
 576/1202 [=============>................] - ETA: 32s - loss: 0.6708 - acc: 0.5764
 640/1202 [==============>...............] - ETA: 28s - loss: 0.6719 - acc: 0.5734
 704/1202 [================>.............] - ETA: 25s - loss: 0.6762 - acc: 0.5767
 768/1202 [==================>...........] - ETA: 21s - loss: 0.6755 - acc: 0.5768
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6759 - acc: 0.5709
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6763 - acc: 0.5714
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6759 - acc: 0.5719
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6736 - acc: 0.5742 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6749 - acc: 0.5763
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6713 - acc: 0.5825
1202/1202 [==============================] - 67s 56ms/step - loss: 0.6687 - acc: 0.5874 - val_loss: 0.7310 - val_acc: 0.4925

Epoch 00008: val_acc did not improve from 0.58209
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:05 - loss: 0.6580 - acc: 0.6719
 128/1202 [==>...........................] - ETA: 59s - loss: 0.6882 - acc: 0.5938 
 192/1202 [===>..........................] - ETA: 58s - loss: 0.6734 - acc: 0.6042
 256/1202 [=====>........................] - ETA: 53s - loss: 0.6774 - acc: 0.5938
 320/1202 [======>.......................] - ETA: 49s - loss: 0.6861 - acc: 0.5906
 384/1202 [========>.....................] - ETA: 47s - loss: 0.6821 - acc: 0.5964
 448/1202 [==========>...................] - ETA: 44s - loss: 0.6675 - acc: 0.6071
 512/1202 [===========>..................] - ETA: 40s - loss: 0.6625 - acc: 0.6152
 576/1202 [=============>................] - ETA: 37s - loss: 0.6589 - acc: 0.6198
 640/1202 [==============>...............] - ETA: 32s - loss: 0.6619 - acc: 0.6172
 704/1202 [================>.............] - ETA: 29s - loss: 0.6666 - acc: 0.6094
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6647 - acc: 0.6094
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6663 - acc: 0.6118
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6692 - acc: 0.6094
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6709 - acc: 0.6062
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6705 - acc: 0.6035
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6727 - acc: 0.5993 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6731 - acc: 0.5964
1202/1202 [==============================] - 74s 61ms/step - loss: 0.6733 - acc: 0.5948 - val_loss: 0.6836 - val_acc: 0.5597

Epoch 00009: val_acc did not improve from 0.58209
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:06 - loss: 0.6439 - acc: 0.6406
 128/1202 [==>...........................] - ETA: 1:05 - loss: 0.6393 - acc: 0.6328
 192/1202 [===>..........................] - ETA: 59s - loss: 0.6604 - acc: 0.6198 
 256/1202 [=====>........................] - ETA: 56s - loss: 0.6588 - acc: 0.6250
 320/1202 [======>.......................] - ETA: 53s - loss: 0.6629 - acc: 0.6062
 384/1202 [========>.....................] - ETA: 49s - loss: 0.6668 - acc: 0.5990
 448/1202 [==========>...................] - ETA: 45s - loss: 0.6755 - acc: 0.5893
 512/1202 [===========>..................] - ETA: 41s - loss: 0.6778 - acc: 0.5879
 576/1202 [=============>................] - ETA: 37s - loss: 0.6706 - acc: 0.6024
 640/1202 [==============>...............] - ETA: 33s - loss: 0.6666 - acc: 0.6078
 704/1202 [================>.............] - ETA: 29s - loss: 0.6624 - acc: 0.6094
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6642 - acc: 0.6081
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6658 - acc: 0.6010
 896/1202 [=====================>........] - ETA: 18s - loss: 0.6652 - acc: 0.6038
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6691 - acc: 0.5990
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6681 - acc: 0.5996
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6684 - acc: 0.5993 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6695 - acc: 0.5964
1202/1202 [==============================] - 75s 63ms/step - loss: 0.6667 - acc: 0.6015 - val_loss: 0.6942 - val_acc: 0.5821

Epoch 00010: val_acc did not improve from 0.58209
样本个数 167
样本个数 334
window_select11-15.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 14s
128/334 [==========>...................] - ETA: 7s 
192/334 [================>.............] - ETA: 4s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 9s 26ms/step
loss: 0.6810222189583465
acc: 0.5508982035928144
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f85c41a0990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f85c41a0990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f85c410cad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f85c410cad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f88246cd750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f88246cd750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f85c411fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f85c411fd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ec4713f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8ec4713f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85a0771bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85a0771bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85c40af810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85c40af810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85c4127150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85c4127150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f85a0656810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f85a0656810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f85a075d110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f85a075d110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85a0468c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85a0468c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85a0684250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85a0684250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85a05645d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85a05645d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8580258310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8580258310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8580170090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8580170090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f858006fad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f858006fad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8580258450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8580258450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85801d0f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85801d0f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f856072f710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f856072f710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f85605d0fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f85605d0fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85604ccd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85604ccd10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8560745050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8560745050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f856061f290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f856061f290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8560451910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8560451910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8560288610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8560288610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85603c32d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85603c32d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8560730410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8560730410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8560606fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8560606fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8560741310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8560741310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8560063590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8560063590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8560109890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8560109890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85602ed5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85602ed5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f856006fc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f856006fc10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f85585b3b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f85585b3b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f855854fc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f855854fc90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f855855c550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f855855c550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85585b3cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85585b3cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f855854fd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f855854fd90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f855846ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f855846ba50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8558116b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8558116b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f855843bd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f855843bd10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f855827b8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f855827b8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85581fc250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85581fc250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f855076ba10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f855076ba10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f85506d6850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f85506d6850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85506d9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85506d9050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85581df090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85581df090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85506918d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85506918d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8550428110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8550428110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8550354510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8550354510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85507299d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85507299d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85c4146cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85c4146cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85502bfbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85502bfbd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f855843e510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f855843e510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8500783790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8500783790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8500652410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8500652410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8550112f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8550112f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8500657b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8500657b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8500546910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8500546910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f85004456d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f85004456d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85004d8890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f85004d8890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85503a0b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f85503a0b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f850078dd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f850078dd10>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 4:37 - loss: 0.7905 - acc: 0.3906
 128/1202 [==>...........................] - ETA: 2:43 - loss: 0.8143 - acc: 0.4688
 192/1202 [===>..........................] - ETA: 2:03 - loss: 0.7876 - acc: 0.4948
 256/1202 [=====>........................] - ETA: 1:41 - loss: 0.7867 - acc: 0.4961
 320/1202 [======>.......................] - ETA: 1:27 - loss: 0.7799 - acc: 0.4813
 384/1202 [========>.....................] - ETA: 1:15 - loss: 0.7819 - acc: 0.4688
 448/1202 [==========>...................] - ETA: 1:06 - loss: 0.7689 - acc: 0.4799
 512/1202 [===========>..................] - ETA: 58s - loss: 0.7600 - acc: 0.4902 
 576/1202 [=============>................] - ETA: 51s - loss: 0.7526 - acc: 0.5017
 640/1202 [==============>...............] - ETA: 45s - loss: 0.7546 - acc: 0.4969
 704/1202 [================>.............] - ETA: 39s - loss: 0.7444 - acc: 0.5114
 768/1202 [==================>...........] - ETA: 33s - loss: 0.7382 - acc: 0.5182
 832/1202 [===================>..........] - ETA: 28s - loss: 0.7342 - acc: 0.5264
 896/1202 [=====================>........] - ETA: 23s - loss: 0.7302 - acc: 0.5335
 960/1202 [======================>.......] - ETA: 18s - loss: 0.7285 - acc: 0.5333
1024/1202 [========================>.....] - ETA: 13s - loss: 0.7248 - acc: 0.5410
1088/1202 [==========================>...] - ETA: 8s - loss: 0.7238 - acc: 0.5423 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7195 - acc: 0.5486
1202/1202 [==============================] - 92s 76ms/step - loss: 0.7164 - acc: 0.5516 - val_loss: 0.7093 - val_acc: 0.5149

Epoch 00001: val_acc improved from -inf to 0.51493, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window14/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 56s - loss: 0.7698 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 59s - loss: 0.7221 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:00 - loss: 0.7467 - acc: 0.5260
 256/1202 [=====>........................] - ETA: 59s - loss: 0.7427 - acc: 0.5117 
 320/1202 [======>.......................] - ETA: 53s - loss: 0.7215 - acc: 0.5375
 384/1202 [========>.....................] - ETA: 52s - loss: 0.7329 - acc: 0.5391
 448/1202 [==========>...................] - ETA: 48s - loss: 0.7252 - acc: 0.5379
 512/1202 [===========>..................] - ETA: 45s - loss: 0.7163 - acc: 0.5449
 576/1202 [=============>................] - ETA: 40s - loss: 0.7125 - acc: 0.5399
 640/1202 [==============>...............] - ETA: 36s - loss: 0.7105 - acc: 0.5422
 704/1202 [================>.............] - ETA: 32s - loss: 0.7015 - acc: 0.5540
 768/1202 [==================>...........] - ETA: 27s - loss: 0.7043 - acc: 0.5495
 832/1202 [===================>..........] - ETA: 23s - loss: 0.7052 - acc: 0.5445
 896/1202 [=====================>........] - ETA: 19s - loss: 0.7005 - acc: 0.5547
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6997 - acc: 0.5552
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6978 - acc: 0.5557
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6930 - acc: 0.5653 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6945 - acc: 0.5651
1202/1202 [==============================] - 79s 66ms/step - loss: 0.6930 - acc: 0.5657 - val_loss: 0.6895 - val_acc: 0.5821

Epoch 00002: val_acc improved from 0.51493 to 0.58209, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window14/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:16 - loss: 0.6917 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:11 - loss: 0.6940 - acc: 0.5469
 192/1202 [===>..........................] - ETA: 1:04 - loss: 0.6885 - acc: 0.5573
 256/1202 [=====>........................] - ETA: 1:00 - loss: 0.6986 - acc: 0.5234
 320/1202 [======>.......................] - ETA: 54s - loss: 0.6930 - acc: 0.5406 
 384/1202 [========>.....................] - ETA: 50s - loss: 0.6981 - acc: 0.5286
 448/1202 [==========>...................] - ETA: 45s - loss: 0.6885 - acc: 0.5536
 512/1202 [===========>..................] - ETA: 42s - loss: 0.6939 - acc: 0.5488
 576/1202 [=============>................] - ETA: 38s - loss: 0.6949 - acc: 0.5538
 640/1202 [==============>...............] - ETA: 34s - loss: 0.6925 - acc: 0.5578
 704/1202 [================>.............] - ETA: 30s - loss: 0.6926 - acc: 0.5597
 768/1202 [==================>...........] - ETA: 26s - loss: 0.6919 - acc: 0.5586
 832/1202 [===================>..........] - ETA: 22s - loss: 0.6932 - acc: 0.5577
 896/1202 [=====================>........] - ETA: 18s - loss: 0.6930 - acc: 0.5592
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6919 - acc: 0.5583
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6901 - acc: 0.5615
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6897 - acc: 0.5616 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6916 - acc: 0.5590
1202/1202 [==============================] - 77s 64ms/step - loss: 0.6893 - acc: 0.5641 - val_loss: 0.7047 - val_acc: 0.5522

Epoch 00003: val_acc did not improve from 0.58209
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:04 - loss: 0.6743 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:05 - loss: 0.6829 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 1:00 - loss: 0.6775 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 57s - loss: 0.6719 - acc: 0.5859 
 320/1202 [======>.......................] - ETA: 52s - loss: 0.6796 - acc: 0.5750
 384/1202 [========>.....................] - ETA: 48s - loss: 0.6889 - acc: 0.5729
 448/1202 [==========>...................] - ETA: 44s - loss: 0.6865 - acc: 0.5759
 512/1202 [===========>..................] - ETA: 40s - loss: 0.6760 - acc: 0.5938
 576/1202 [=============>................] - ETA: 36s - loss: 0.6820 - acc: 0.5885
 640/1202 [==============>...............] - ETA: 33s - loss: 0.6809 - acc: 0.5953
 704/1202 [================>.............] - ETA: 29s - loss: 0.6836 - acc: 0.5938
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6822 - acc: 0.5911
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6788 - acc: 0.5986
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6835 - acc: 0.5926
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6870 - acc: 0.5865
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6890 - acc: 0.5820
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6917 - acc: 0.5754 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6892 - acc: 0.5807
1202/1202 [==============================] - 69s 58ms/step - loss: 0.6883 - acc: 0.5807 - val_loss: 0.6833 - val_acc: 0.6119

Epoch 00004: val_acc improved from 0.58209 to 0.61194, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window14/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:03 - loss: 0.7053 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 59s - loss: 0.7201 - acc: 0.5234 
 192/1202 [===>..........................] - ETA: 56s - loss: 0.7043 - acc: 0.5469
 256/1202 [=====>........................] - ETA: 51s - loss: 0.7111 - acc: 0.5273
 320/1202 [======>.......................] - ETA: 48s - loss: 0.7111 - acc: 0.5250
 384/1202 [========>.....................] - ETA: 44s - loss: 0.7122 - acc: 0.5286
 448/1202 [==========>...................] - ETA: 39s - loss: 0.7075 - acc: 0.5379
 512/1202 [===========>..................] - ETA: 36s - loss: 0.7046 - acc: 0.5488
 576/1202 [=============>................] - ETA: 32s - loss: 0.7030 - acc: 0.5538
 640/1202 [==============>...............] - ETA: 29s - loss: 0.7032 - acc: 0.5500
 704/1202 [================>.............] - ETA: 25s - loss: 0.6976 - acc: 0.5625
 768/1202 [==================>...........] - ETA: 22s - loss: 0.6919 - acc: 0.5716
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6903 - acc: 0.5745
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6858 - acc: 0.5837
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6859 - acc: 0.5833
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6861 - acc: 0.5859 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6862 - acc: 0.5864
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6911 - acc: 0.5833
1202/1202 [==============================] - 63s 52ms/step - loss: 0.6881 - acc: 0.5857 - val_loss: 0.6939 - val_acc: 0.5746

Epoch 00005: val_acc did not improve from 0.61194
Epoch 6/10

  64/1202 [>.............................] - ETA: 42s - loss: 0.6206 - acc: 0.6875
 128/1202 [==>...........................] - ETA: 40s - loss: 0.6833 - acc: 0.6094
 192/1202 [===>..........................] - ETA: 39s - loss: 0.6913 - acc: 0.5885
 256/1202 [=====>........................] - ETA: 36s - loss: 0.6816 - acc: 0.5898
 320/1202 [======>.......................] - ETA: 34s - loss: 0.6959 - acc: 0.5625
 384/1202 [========>.....................] - ETA: 32s - loss: 0.6898 - acc: 0.5651
 448/1202 [==========>...................] - ETA: 29s - loss: 0.6877 - acc: 0.5714
 512/1202 [===========>..................] - ETA: 28s - loss: 0.6932 - acc: 0.5605
 576/1202 [=============>................] - ETA: 26s - loss: 0.6886 - acc: 0.5642
 640/1202 [==============>...............] - ETA: 23s - loss: 0.6872 - acc: 0.5656
 704/1202 [================>.............] - ETA: 20s - loss: 0.6893 - acc: 0.5682
 768/1202 [==================>...........] - ETA: 18s - loss: 0.6856 - acc: 0.5729
 832/1202 [===================>..........] - ETA: 15s - loss: 0.6849 - acc: 0.5709
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6843 - acc: 0.5670
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6844 - acc: 0.5698
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6852 - acc: 0.5713 
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6867 - acc: 0.5643
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6836 - acc: 0.5694
1202/1202 [==============================] - 54s 45ms/step - loss: 0.6826 - acc: 0.5732 - val_loss: 0.6737 - val_acc: 0.5672

Epoch 00006: val_acc did not improve from 0.61194
Epoch 7/10

  64/1202 [>.............................] - ETA: 46s - loss: 0.6728 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 44s - loss: 0.6453 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 40s - loss: 0.6478 - acc: 0.6354
 256/1202 [=====>........................] - ETA: 40s - loss: 0.6583 - acc: 0.6250
 320/1202 [======>.......................] - ETA: 38s - loss: 0.6525 - acc: 0.6344
 384/1202 [========>.....................] - ETA: 35s - loss: 0.6582 - acc: 0.6328
 448/1202 [==========>...................] - ETA: 32s - loss: 0.6526 - acc: 0.6406
 512/1202 [===========>..................] - ETA: 30s - loss: 0.6643 - acc: 0.6270
 576/1202 [=============>................] - ETA: 27s - loss: 0.6659 - acc: 0.6285
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6685 - acc: 0.6188
 704/1202 [================>.............] - ETA: 21s - loss: 0.6694 - acc: 0.6136
 768/1202 [==================>...........] - ETA: 18s - loss: 0.6709 - acc: 0.6120
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6729 - acc: 0.6070
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6707 - acc: 0.6049
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6724 - acc: 0.5990
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6704 - acc: 0.5996 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6735 - acc: 0.5919
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6738 - acc: 0.5885
1202/1202 [==============================] - 57s 47ms/step - loss: 0.6724 - acc: 0.5882 - val_loss: 0.6744 - val_acc: 0.5672

Epoch 00007: val_acc did not improve from 0.61194
Epoch 8/10

  64/1202 [>.............................] - ETA: 56s - loss: 0.6851 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 49s - loss: 0.6692 - acc: 0.6172
 192/1202 [===>..........................] - ETA: 44s - loss: 0.6817 - acc: 0.5885
 256/1202 [=====>........................] - ETA: 43s - loss: 0.6740 - acc: 0.6016
 320/1202 [======>.......................] - ETA: 39s - loss: 0.6754 - acc: 0.6031
 384/1202 [========>.....................] - ETA: 36s - loss: 0.6781 - acc: 0.5990
 448/1202 [==========>...................] - ETA: 33s - loss: 0.6795 - acc: 0.5848
 512/1202 [===========>..................] - ETA: 31s - loss: 0.6799 - acc: 0.5898
 576/1202 [=============>................] - ETA: 28s - loss: 0.6744 - acc: 0.5920
 640/1202 [==============>...............] - ETA: 26s - loss: 0.6664 - acc: 0.6000
 704/1202 [================>.............] - ETA: 23s - loss: 0.6708 - acc: 0.5980
 768/1202 [==================>...........] - ETA: 20s - loss: 0.6719 - acc: 0.5924
 832/1202 [===================>..........] - ETA: 17s - loss: 0.6726 - acc: 0.5865
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6701 - acc: 0.5882
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6711 - acc: 0.5927
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6693 - acc: 0.5928 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6684 - acc: 0.5938
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6681 - acc: 0.5929
1202/1202 [==============================] - 56s 47ms/step - loss: 0.6695 - acc: 0.5957 - val_loss: 0.6792 - val_acc: 0.5597

Epoch 00008: val_acc did not improve from 0.61194
Epoch 9/10

  64/1202 [>.............................] - ETA: 50s - loss: 0.7138 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 46s - loss: 0.7026 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 43s - loss: 0.6916 - acc: 0.5573
 256/1202 [=====>........................] - ETA: 39s - loss: 0.6838 - acc: 0.5664
 320/1202 [======>.......................] - ETA: 38s - loss: 0.6717 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 35s - loss: 0.6742 - acc: 0.5807
 448/1202 [==========>...................] - ETA: 32s - loss: 0.6732 - acc: 0.5848
 512/1202 [===========>..................] - ETA: 29s - loss: 0.6712 - acc: 0.5879
 576/1202 [=============>................] - ETA: 27s - loss: 0.6659 - acc: 0.5990
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6586 - acc: 0.6172
 704/1202 [================>.............] - ETA: 21s - loss: 0.6628 - acc: 0.6136
 768/1202 [==================>...........] - ETA: 19s - loss: 0.6634 - acc: 0.6172
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6657 - acc: 0.6202
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6650 - acc: 0.6228
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6626 - acc: 0.6240
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6642 - acc: 0.6191 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6652 - acc: 0.6176
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6691 - acc: 0.6102
1202/1202 [==============================] - 57s 48ms/step - loss: 0.6700 - acc: 0.6082 - val_loss: 0.6790 - val_acc: 0.5672

Epoch 00009: val_acc did not improve from 0.61194
Epoch 10/10

  64/1202 [>.............................] - ETA: 49s - loss: 0.6670 - acc: 0.5938
 128/1202 [==>...........................] - ETA: 44s - loss: 0.6653 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 42s - loss: 0.6628 - acc: 0.6042
 256/1202 [=====>........................] - ETA: 39s - loss: 0.6437 - acc: 0.6289
 320/1202 [======>.......................] - ETA: 38s - loss: 0.6417 - acc: 0.6438
 384/1202 [========>.....................] - ETA: 35s - loss: 0.6554 - acc: 0.6224
 448/1202 [==========>...................] - ETA: 32s - loss: 0.6609 - acc: 0.6049
 512/1202 [===========>..................] - ETA: 29s - loss: 0.6612 - acc: 0.6113
 576/1202 [=============>................] - ETA: 26s - loss: 0.6608 - acc: 0.6076
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6622 - acc: 0.6047
 704/1202 [================>.............] - ETA: 21s - loss: 0.6638 - acc: 0.6009
 768/1202 [==================>...........] - ETA: 19s - loss: 0.6636 - acc: 0.5977
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6634 - acc: 0.6070
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6630 - acc: 0.6016
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6617 - acc: 0.6052
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6619 - acc: 0.6064 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6620 - acc: 0.6075
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6623 - acc: 0.6042
1202/1202 [==============================] - 57s 47ms/step - loss: 0.6618 - acc: 0.6048 - val_loss: 0.6681 - val_acc: 0.5821

Epoch 00010: val_acc did not improve from 0.61194
样本个数 167
样本个数 334
window_select11-15.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 31s
128/334 [==========>...................] - ETA: 13s
192/334 [================>.............] - ETA: 7s 
256/334 [=====================>........] - ETA: 3s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 13s 40ms/step
loss: 0.676787600188912
acc: 0.562874251497006
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f8460667690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f8460667690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f846061e050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f846061e050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86e0400190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86e0400190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f842074dc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f842074dc10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f846057f350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f846057f350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86e046ab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86e046ab10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f842074d610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f842074d610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f846058a490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f846058a490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f846044a710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f846044a710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88246bbf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f88246bbf90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f846015a910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f846015a910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f88246e5450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f88246e5450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84605ab250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84605ab250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f846006c590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f846006c590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8420607950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8420607950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84600b5b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84600b5b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f846006c190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f846006c190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8420534690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8420534690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8420600e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8420600e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8420463d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8420463d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f842021b350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f842021b350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8420552ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8420552ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8420373810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8420373810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8700477150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8700477150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8460673350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8460673350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84201e1bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84201e1bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8644523fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8644523fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8420051410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8420051410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f84045dd0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f84045dd0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f84045c6990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f84045c6990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84043c5bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84043c5bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f84045dd210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f84045dd210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84200524d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84200524d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f84045cd890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f84045cd890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f84041e0e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f84041e0e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84042bc090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84042bc090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f840430cf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f840430cf10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84040ec7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84040ec7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f84041c5f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f84041c5f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f83e07bd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f83e07bd050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83e07efe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83e07efe50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8404265dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8404265dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84041e0210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f84041e0210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f83e0439510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f83e0439510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f83e033e990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f83e033e990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f846058e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f846058e350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f83e0451810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f83e0451810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83e06397d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83e06397d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f83e01ad910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f83e01ad910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f83c07ea8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f83c07ea8d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c06815d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c06815d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f83e010b090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f83e010b090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c0729f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c0729f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f83c05e6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f83c05e6910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f83c05c5c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f83c05c5c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c037c790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c037c790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f83e01a76d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f83e01a76d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c0482f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c0482f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f83c0485650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f83c0485650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f83c01a6f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f83c01a6f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c009f290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c009f290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f83c037cc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f83c037cc90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c04f64d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f83c04f64d0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 5:00 - loss: 0.7610 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 2:58 - loss: 0.7556 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 2:12 - loss: 0.7375 - acc: 0.5469
 256/1202 [=====>........................] - ETA: 1:49 - loss: 0.7365 - acc: 0.5352
 320/1202 [======>.......................] - ETA: 1:32 - loss: 0.7545 - acc: 0.5344
 384/1202 [========>.....................] - ETA: 1:21 - loss: 0.7576 - acc: 0.5391
 448/1202 [==========>...................] - ETA: 1:10 - loss: 0.7549 - acc: 0.5357
 512/1202 [===========>..................] - ETA: 1:01 - loss: 0.7538 - acc: 0.5312
 576/1202 [=============>................] - ETA: 54s - loss: 0.7541 - acc: 0.5260 
 640/1202 [==============>...............] - ETA: 47s - loss: 0.7504 - acc: 0.5297
 704/1202 [================>.............] - ETA: 40s - loss: 0.7488 - acc: 0.5256
 768/1202 [==================>...........] - ETA: 35s - loss: 0.7475 - acc: 0.5260
 832/1202 [===================>..........] - ETA: 29s - loss: 0.7489 - acc: 0.5264
 896/1202 [=====================>........] - ETA: 23s - loss: 0.7412 - acc: 0.5335
 960/1202 [======================>.......] - ETA: 18s - loss: 0.7408 - acc: 0.5302
1024/1202 [========================>.....] - ETA: 13s - loss: 0.7354 - acc: 0.5352
1088/1202 [==========================>...] - ETA: 8s - loss: 0.7337 - acc: 0.5331 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7313 - acc: 0.5347
1202/1202 [==============================] - 95s 79ms/step - loss: 0.7305 - acc: 0.5349 - val_loss: 0.6851 - val_acc: 0.5746

Epoch 00001: val_acc improved from -inf to 0.57463, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window15/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:08 - loss: 0.6728 - acc: 0.5938
 128/1202 [==>...........................] - ETA: 1:00 - loss: 0.6884 - acc: 0.5625
 192/1202 [===>..........................] - ETA: 55s - loss: 0.6951 - acc: 0.5625 
 256/1202 [=====>........................] - ETA: 54s - loss: 0.6870 - acc: 0.5703
 320/1202 [======>.......................] - ETA: 50s - loss: 0.6884 - acc: 0.5719
 384/1202 [========>.....................] - ETA: 48s - loss: 0.6904 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 44s - loss: 0.6912 - acc: 0.5692
 512/1202 [===========>..................] - ETA: 40s - loss: 0.6896 - acc: 0.5703
 576/1202 [=============>................] - ETA: 37s - loss: 0.6900 - acc: 0.5712
 640/1202 [==============>...............] - ETA: 33s - loss: 0.6928 - acc: 0.5687
 704/1202 [================>.............] - ETA: 29s - loss: 0.6951 - acc: 0.5668
 768/1202 [==================>...........] - ETA: 25s - loss: 0.6916 - acc: 0.5638
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6955 - acc: 0.5589
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6947 - acc: 0.5636
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6966 - acc: 0.5583
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6944 - acc: 0.5596
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6925 - acc: 0.5643 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6948 - acc: 0.5625
1202/1202 [==============================] - 74s 61ms/step - loss: 0.6960 - acc: 0.5607 - val_loss: 0.7484 - val_acc: 0.5000

Epoch 00002: val_acc did not improve from 0.57463
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:14 - loss: 0.6761 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 1:10 - loss: 0.6502 - acc: 0.6562
 192/1202 [===>..........................] - ETA: 1:02 - loss: 0.6467 - acc: 0.6510
 256/1202 [=====>........................] - ETA: 59s - loss: 0.6631 - acc: 0.6055 
 320/1202 [======>.......................] - ETA: 55s - loss: 0.6717 - acc: 0.6062
 384/1202 [========>.....................] - ETA: 50s - loss: 0.6781 - acc: 0.5885
 448/1202 [==========>...................] - ETA: 47s - loss: 0.6795 - acc: 0.5893
 512/1202 [===========>..................] - ETA: 42s - loss: 0.6778 - acc: 0.5898
 576/1202 [=============>................] - ETA: 38s - loss: 0.6750 - acc: 0.5920
 640/1202 [==============>...............] - ETA: 34s - loss: 0.6772 - acc: 0.5906
 704/1202 [================>.............] - ETA: 30s - loss: 0.6764 - acc: 0.5895
 768/1202 [==================>...........] - ETA: 26s - loss: 0.6730 - acc: 0.5964
 832/1202 [===================>..........] - ETA: 22s - loss: 0.6754 - acc: 0.5962
 896/1202 [=====================>........] - ETA: 18s - loss: 0.6778 - acc: 0.5949
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6752 - acc: 0.5969
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6748 - acc: 0.5996
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6775 - acc: 0.5956 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6832 - acc: 0.5911
1202/1202 [==============================] - 76s 64ms/step - loss: 0.6819 - acc: 0.5882 - val_loss: 0.6832 - val_acc: 0.5597

Epoch 00003: val_acc did not improve from 0.57463
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:02 - loss: 0.6479 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 1:04 - loss: 0.6617 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 57s - loss: 0.6874 - acc: 0.5990 
 256/1202 [=====>........................] - ETA: 51s - loss: 0.6766 - acc: 0.6055
 320/1202 [======>.......................] - ETA: 46s - loss: 0.6744 - acc: 0.6156
 384/1202 [========>.....................] - ETA: 42s - loss: 0.6749 - acc: 0.6068
 448/1202 [==========>...................] - ETA: 37s - loss: 0.6725 - acc: 0.6161
 512/1202 [===========>..................] - ETA: 34s - loss: 0.6783 - acc: 0.6055
 576/1202 [=============>................] - ETA: 30s - loss: 0.6785 - acc: 0.6042
 640/1202 [==============>...............] - ETA: 27s - loss: 0.6775 - acc: 0.6078
 704/1202 [================>.............] - ETA: 24s - loss: 0.6772 - acc: 0.6065
 768/1202 [==================>...........] - ETA: 21s - loss: 0.6822 - acc: 0.5990
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6825 - acc: 0.5962
 896/1202 [=====================>........] - ETA: 14s - loss: 0.6855 - acc: 0.5882
 960/1202 [======================>.......] - ETA: 11s - loss: 0.6831 - acc: 0.5875
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6823 - acc: 0.5850 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6840 - acc: 0.5836
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6843 - acc: 0.5790
1202/1202 [==============================] - 62s 52ms/step - loss: 0.6834 - acc: 0.5782 - val_loss: 0.6761 - val_acc: 0.5597

Epoch 00004: val_acc did not improve from 0.57463
Epoch 5/10

  64/1202 [>.............................] - ETA: 53s - loss: 0.7373 - acc: 0.4844
 128/1202 [==>...........................] - ETA: 55s - loss: 0.7056 - acc: 0.5078
 192/1202 [===>..........................] - ETA: 52s - loss: 0.7146 - acc: 0.5000
 256/1202 [=====>........................] - ETA: 47s - loss: 0.7174 - acc: 0.5078
 320/1202 [======>.......................] - ETA: 44s - loss: 0.7108 - acc: 0.5250
 384/1202 [========>.....................] - ETA: 41s - loss: 0.7052 - acc: 0.5260
 448/1202 [==========>...................] - ETA: 37s - loss: 0.7045 - acc: 0.5290
 512/1202 [===========>..................] - ETA: 34s - loss: 0.7011 - acc: 0.5391
 576/1202 [=============>................] - ETA: 31s - loss: 0.6998 - acc: 0.5417
 640/1202 [==============>...............] - ETA: 28s - loss: 0.6994 - acc: 0.5422
 704/1202 [================>.............] - ETA: 24s - loss: 0.6949 - acc: 0.5554
 768/1202 [==================>...........] - ETA: 21s - loss: 0.6939 - acc: 0.5534
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6911 - acc: 0.5577
 896/1202 [=====================>........] - ETA: 14s - loss: 0.6891 - acc: 0.5592
 960/1202 [======================>.......] - ETA: 11s - loss: 0.6871 - acc: 0.5625
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6876 - acc: 0.5635 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6846 - acc: 0.5671
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6849 - acc: 0.5677
1202/1202 [==============================] - 58s 49ms/step - loss: 0.6890 - acc: 0.5616 - val_loss: 0.6817 - val_acc: 0.5896

Epoch 00005: val_acc improved from 0.57463 to 0.58955, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window15/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1202 [>.............................] - ETA: 50s - loss: 0.6628 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 49s - loss: 0.6632 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 44s - loss: 0.7016 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 43s - loss: 0.6922 - acc: 0.5820
 320/1202 [======>.......................] - ETA: 40s - loss: 0.7064 - acc: 0.5563
 384/1202 [========>.....................] - ETA: 36s - loss: 0.6929 - acc: 0.5729
 448/1202 [==========>...................] - ETA: 33s - loss: 0.6884 - acc: 0.5781
 512/1202 [===========>..................] - ETA: 30s - loss: 0.6930 - acc: 0.5645
 576/1202 [=============>................] - ETA: 27s - loss: 0.6917 - acc: 0.5660
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6898 - acc: 0.5687
 704/1202 [================>.............] - ETA: 21s - loss: 0.6896 - acc: 0.5710
 768/1202 [==================>...........] - ETA: 19s - loss: 0.6886 - acc: 0.5677
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6848 - acc: 0.5733
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6816 - acc: 0.5770
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6792 - acc: 0.5813
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6793 - acc: 0.5840 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6804 - acc: 0.5827
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6794 - acc: 0.5877
1202/1202 [==============================] - 56s 47ms/step - loss: 0.6795 - acc: 0.5899 - val_loss: 0.6856 - val_acc: 0.5746

Epoch 00006: val_acc did not improve from 0.58955
Epoch 7/10

  64/1202 [>.............................] - ETA: 43s - loss: 0.6334 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 41s - loss: 0.6514 - acc: 0.6016
 192/1202 [===>..........................] - ETA: 39s - loss: 0.6779 - acc: 0.5781
 256/1202 [=====>........................] - ETA: 36s - loss: 0.6697 - acc: 0.6016
 320/1202 [======>.......................] - ETA: 38s - loss: 0.6694 - acc: 0.5969
 384/1202 [========>.....................] - ETA: 36s - loss: 0.6718 - acc: 0.5833
 448/1202 [==========>...................] - ETA: 33s - loss: 0.6655 - acc: 0.5915
 512/1202 [===========>..................] - ETA: 30s - loss: 0.6723 - acc: 0.5840
 576/1202 [=============>................] - ETA: 27s - loss: 0.6717 - acc: 0.5885
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6682 - acc: 0.5922
 704/1202 [================>.............] - ETA: 21s - loss: 0.6689 - acc: 0.5938
 768/1202 [==================>...........] - ETA: 18s - loss: 0.6683 - acc: 0.5990
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6665 - acc: 0.6010
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6655 - acc: 0.6027
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6641 - acc: 0.6042
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6634 - acc: 0.6016 
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6649 - acc: 0.6011
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6678 - acc: 0.5981
1202/1202 [==============================] - 55s 46ms/step - loss: 0.6680 - acc: 0.5998 - val_loss: 0.6850 - val_acc: 0.5821

Epoch 00007: val_acc did not improve from 0.58955
Epoch 8/10

  64/1202 [>.............................] - ETA: 43s - loss: 0.6985 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 45s - loss: 0.6956 - acc: 0.5234
 192/1202 [===>..........................] - ETA: 42s - loss: 0.7046 - acc: 0.5208
 256/1202 [=====>........................] - ETA: 39s - loss: 0.6908 - acc: 0.5430
 320/1202 [======>.......................] - ETA: 37s - loss: 0.6813 - acc: 0.5531
 384/1202 [========>.....................] - ETA: 35s - loss: 0.6876 - acc: 0.5469
 448/1202 [==========>...................] - ETA: 32s - loss: 0.6928 - acc: 0.5379
 512/1202 [===========>..................] - ETA: 29s - loss: 0.6893 - acc: 0.5469
 576/1202 [=============>................] - ETA: 26s - loss: 0.6814 - acc: 0.5608
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6890 - acc: 0.5563
 704/1202 [================>.............] - ETA: 21s - loss: 0.6871 - acc: 0.5639
 768/1202 [==================>...........] - ETA: 19s - loss: 0.6865 - acc: 0.5651
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6879 - acc: 0.5661
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6867 - acc: 0.5647
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6880 - acc: 0.5583
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6833 - acc: 0.5664 
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6802 - acc: 0.5726
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6800 - acc: 0.5720
1202/1202 [==============================] - 54s 45ms/step - loss: 0.6779 - acc: 0.5765 - val_loss: 0.6895 - val_acc: 0.5821

Epoch 00008: val_acc did not improve from 0.58955
Epoch 9/10

  64/1202 [>.............................] - ETA: 47s - loss: 0.7030 - acc: 0.5938
 128/1202 [==>...........................] - ETA: 43s - loss: 0.6733 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 41s - loss: 0.6716 - acc: 0.6198
 256/1202 [=====>........................] - ETA: 38s - loss: 0.6779 - acc: 0.6133
 320/1202 [======>.......................] - ETA: 35s - loss: 0.6726 - acc: 0.6156
 384/1202 [========>.....................] - ETA: 32s - loss: 0.6775 - acc: 0.5990
 448/1202 [==========>...................] - ETA: 30s - loss: 0.6710 - acc: 0.6116
 512/1202 [===========>..................] - ETA: 28s - loss: 0.6823 - acc: 0.5977
 576/1202 [=============>................] - ETA: 25s - loss: 0.6809 - acc: 0.5972
 640/1202 [==============>...............] - ETA: 22s - loss: 0.6799 - acc: 0.6016
 704/1202 [================>.............] - ETA: 20s - loss: 0.6758 - acc: 0.6037
 768/1202 [==================>...........] - ETA: 18s - loss: 0.6734 - acc: 0.6081
 832/1202 [===================>..........] - ETA: 15s - loss: 0.6724 - acc: 0.6094
 896/1202 [=====================>........] - ETA: 12s - loss: 0.6699 - acc: 0.6105
 960/1202 [======================>.......] - ETA: 9s - loss: 0.6675 - acc: 0.6115 
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6693 - acc: 0.6064
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6678 - acc: 0.6094
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6673 - acc: 0.6085
1202/1202 [==============================] - 53s 44ms/step - loss: 0.6666 - acc: 0.6048 - val_loss: 0.6978 - val_acc: 0.5522

Epoch 00009: val_acc did not improve from 0.58955
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:00 - loss: 0.6660 - acc: 0.5938
 128/1202 [==>...........................] - ETA: 53s - loss: 0.6526 - acc: 0.6328 
 192/1202 [===>..........................] - ETA: 47s - loss: 0.6543 - acc: 0.6042
 256/1202 [=====>........................] - ETA: 43s - loss: 0.6612 - acc: 0.5977
 320/1202 [======>.......................] - ETA: 41s - loss: 0.6622 - acc: 0.6031
 384/1202 [========>.....................] - ETA: 37s - loss: 0.6687 - acc: 0.5885
 448/1202 [==========>...................] - ETA: 34s - loss: 0.6711 - acc: 0.5871
 512/1202 [===========>..................] - ETA: 31s - loss: 0.6657 - acc: 0.5996
 576/1202 [=============>................] - ETA: 28s - loss: 0.6725 - acc: 0.5833
 640/1202 [==============>...............] - ETA: 25s - loss: 0.6728 - acc: 0.5859
 704/1202 [================>.............] - ETA: 22s - loss: 0.6707 - acc: 0.5952
 768/1202 [==================>...........] - ETA: 19s - loss: 0.6697 - acc: 0.5964
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6694 - acc: 0.5974
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6670 - acc: 0.5993
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6692 - acc: 0.6000
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6671 - acc: 0.6055 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6640 - acc: 0.6131
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6642 - acc: 0.6128
1202/1202 [==============================] - 56s 47ms/step - loss: 0.6646 - acc: 0.6148 - val_loss: 0.6880 - val_acc: 0.5597

Epoch 00010: val_acc did not improve from 0.58955
样本个数 167
样本个数 334
window_select11-15.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 22s
128/334 [==========>...................] - ETA: 10s
192/334 [================>.............] - ETA: 5s 
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 11s 32ms/step
loss: 0.7011894316016557
acc: 0.5538922152119482
