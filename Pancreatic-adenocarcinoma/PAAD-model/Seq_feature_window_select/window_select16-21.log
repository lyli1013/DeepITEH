nohup: ignoring input
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
样本个数 668
样本个数 1336
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f30adb58350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f30adb58350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f30adb1f590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f30adb1f590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30adaf28d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30adaf28d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f30adaef090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f30adaef090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f30ad9e36d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f30ad9e36d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30ad9a4490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30ad9a4490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f30ad9a1810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f30ad9a1810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30adaef310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30adaef310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f30ad7ce9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f30ad7ce9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f30ad6f3250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f30ad6f3250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30ad6ba450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30ad6ba450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f30ad6ba850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f30ad6ba850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30ad6872d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30ad6872d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f30ad798cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f30ad798cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f30ad42d590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f30ad42d590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f309d3a0710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f309d3a0710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f30ad4b3d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f30ad4b3d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30ad4bc410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30ad4bc410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f309d1fbd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f309d1fbd10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f309d049850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f309d049850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f309d1228d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f309d1228d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f309d1fb1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f309d1fb1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f309d395e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f309d395e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f309cf53d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f309cf53d10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f309ce67910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f309ce67910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f309ce5db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f309ce5db10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f309cf33750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f309cf33750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f309ce96910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f309ce96910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f309cd16690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f309cd16690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3094a08150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3094a08150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3094b155d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3094b155d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3094b3bdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3094b3bdd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3094910490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3094910490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f309491f310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f309491f310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f30948ba510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f30948ba510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30945d9750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30945d9750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3094726dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3094726dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30947b9950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30947b9950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f30944e38d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f30944e38d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3094520d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3094520d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30946cf4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30946cf4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f30944e3ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f30944e3ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30946cf2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30946cf2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3094422d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3094422d10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f308c099f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f308c099f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3094520e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3094520e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f308c2df590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f308c2df590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308c0da9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308c0da9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f308be85590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f308be85590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f308bd800d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f308bd800d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308bedd890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308bedd890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f308be852d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f308be852d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308bde42d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308bde42d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f308be952d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f308be952d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f308ba93290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f308ba93290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308bde8910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308bde8910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f308bc952d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f308bc952d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308b93d810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308b93d810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f308ba80e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f308ba80e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f308b8a3dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f308b8a3dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308baa60d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308baa60d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f308ba93650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f308ba93650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308b7b5ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f308b7b5ad0>>: AttributeError: module 'gast' has no attribute 'Str'
2023-01-12 00:43:01.016038: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-01-12 00:43:01.052938: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2023-01-12 00:43:01.085150: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e0c2cfc220 executing computations on platform Host. Devices:
2023-01-12 00:43:01.085231: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-01-12 00:43:01.467636: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 2:37 - loss: 0.7053 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:56 - loss: 0.7042 - acc: 0.5469
 192/1202 [===>..........................] - ETA: 1:33 - loss: 0.7253 - acc: 0.5469
 256/1202 [=====>........................] - ETA: 1:22 - loss: 0.7475 - acc: 0.5234
 320/1202 [======>.......................] - ETA: 1:14 - loss: 0.7272 - acc: 0.5312
 384/1202 [========>.....................] - ETA: 1:07 - loss: 0.7204 - acc: 0.5417
 448/1202 [==========>...................] - ETA: 1:02 - loss: 0.7094 - acc: 0.5536
 512/1202 [===========>..................] - ETA: 56s - loss: 0.7160 - acc: 0.5410 
 576/1202 [=============>................] - ETA: 51s - loss: 0.7270 - acc: 0.5330
 640/1202 [==============>...............] - ETA: 45s - loss: 0.7239 - acc: 0.5375
 704/1202 [================>.............] - ETA: 39s - loss: 0.7231 - acc: 0.5369
 768/1202 [==================>...........] - ETA: 35s - loss: 0.7153 - acc: 0.5482
 832/1202 [===================>..........] - ETA: 30s - loss: 0.7135 - acc: 0.5517
 896/1202 [=====================>........] - ETA: 24s - loss: 0.7076 - acc: 0.5547
 960/1202 [======================>.......] - ETA: 19s - loss: 0.7035 - acc: 0.5604
1024/1202 [========================>.....] - ETA: 14s - loss: 0.7021 - acc: 0.5615
1088/1202 [==========================>...] - ETA: 9s - loss: 0.7052 - acc: 0.5607 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6990 - acc: 0.5677
1202/1202 [==============================] - 104s 86ms/step - loss: 0.7002 - acc: 0.5657 - val_loss: 0.7942 - val_acc: 0.4627

Epoch 00001: val_acc improved from -inf to 0.46269, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window16/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:25 - loss: 0.7143 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:23 - loss: 0.6726 - acc: 0.5859
 192/1202 [===>..........................] - ETA: 1:19 - loss: 0.6953 - acc: 0.5417
 256/1202 [=====>........................] - ETA: 1:15 - loss: 0.7082 - acc: 0.5312
 320/1202 [======>.......................] - ETA: 1:11 - loss: 0.7193 - acc: 0.5312
 384/1202 [========>.....................] - ETA: 1:06 - loss: 0.7213 - acc: 0.5312
 448/1202 [==========>...................] - ETA: 1:00 - loss: 0.7186 - acc: 0.5335
 512/1202 [===========>..................] - ETA: 55s - loss: 0.7098 - acc: 0.5430 
 576/1202 [=============>................] - ETA: 50s - loss: 0.7021 - acc: 0.5521
 640/1202 [==============>...............] - ETA: 45s - loss: 0.6996 - acc: 0.5578
 704/1202 [================>.............] - ETA: 39s - loss: 0.6962 - acc: 0.5625
 768/1202 [==================>...........] - ETA: 34s - loss: 0.6910 - acc: 0.5677
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6945 - acc: 0.5673
 896/1202 [=====================>........] - ETA: 24s - loss: 0.7005 - acc: 0.5580
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6971 - acc: 0.5646
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6947 - acc: 0.5654
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6937 - acc: 0.5653 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6965 - acc: 0.5642
1202/1202 [==============================] - 101s 84ms/step - loss: 0.6983 - acc: 0.5607 - val_loss: 0.7208 - val_acc: 0.5821

Epoch 00002: val_acc improved from 0.46269 to 0.58209, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window16/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:34 - loss: 0.6827 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:26 - loss: 0.7054 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:24 - loss: 0.7142 - acc: 0.5365
 256/1202 [=====>........................] - ETA: 1:17 - loss: 0.6997 - acc: 0.5742
 320/1202 [======>.......................] - ETA: 1:12 - loss: 0.7003 - acc: 0.5719
 384/1202 [========>.....................] - ETA: 1:07 - loss: 0.6954 - acc: 0.5781
 448/1202 [==========>...................] - ETA: 1:01 - loss: 0.6997 - acc: 0.5670
 512/1202 [===========>..................] - ETA: 56s - loss: 0.7013 - acc: 0.5684 
 576/1202 [=============>................] - ETA: 50s - loss: 0.7024 - acc: 0.5625
 640/1202 [==============>...............] - ETA: 44s - loss: 0.6991 - acc: 0.5578
 704/1202 [================>.............] - ETA: 39s - loss: 0.6952 - acc: 0.5568
 768/1202 [==================>...........] - ETA: 34s - loss: 0.6957 - acc: 0.5599
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6936 - acc: 0.5601
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6882 - acc: 0.5714
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6892 - acc: 0.5708
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6879 - acc: 0.5723
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6871 - acc: 0.5717 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6854 - acc: 0.5729
1202/1202 [==============================] - 99s 83ms/step - loss: 0.6851 - acc: 0.5691 - val_loss: 0.7128 - val_acc: 0.4925

Epoch 00003: val_acc did not improve from 0.58209
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:28 - loss: 0.6903 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:28 - loss: 0.7012 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:23 - loss: 0.7062 - acc: 0.5312
 256/1202 [=====>........................] - ETA: 1:19 - loss: 0.6946 - acc: 0.5586
 320/1202 [======>.......................] - ETA: 1:13 - loss: 0.6974 - acc: 0.5594
 384/1202 [========>.....................] - ETA: 1:07 - loss: 0.6894 - acc: 0.5625
 448/1202 [==========>...................] - ETA: 1:01 - loss: 0.6898 - acc: 0.5603
 512/1202 [===========>..................] - ETA: 55s - loss: 0.6903 - acc: 0.5566 
 576/1202 [=============>................] - ETA: 49s - loss: 0.6838 - acc: 0.5538
 640/1202 [==============>...............] - ETA: 45s - loss: 0.6812 - acc: 0.5594
 704/1202 [================>.............] - ETA: 40s - loss: 0.6817 - acc: 0.5597
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6787 - acc: 0.5625
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6775 - acc: 0.5685
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6777 - acc: 0.5714
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6758 - acc: 0.5760
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6738 - acc: 0.5742
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6719 - acc: 0.5763 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6736 - acc: 0.5738
1202/1202 [==============================] - 103s 86ms/step - loss: 0.6702 - acc: 0.5799 - val_loss: 0.7251 - val_acc: 0.4851

Epoch 00004: val_acc did not improve from 0.58209
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:36 - loss: 0.6592 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 1:28 - loss: 0.6470 - acc: 0.6484
 192/1202 [===>..........................] - ETA: 1:26 - loss: 0.6693 - acc: 0.6042
 256/1202 [=====>........................] - ETA: 1:18 - loss: 0.6809 - acc: 0.6016
 320/1202 [======>.......................] - ETA: 1:14 - loss: 0.6865 - acc: 0.5938
 384/1202 [========>.....................] - ETA: 1:07 - loss: 0.6856 - acc: 0.5911
 448/1202 [==========>...................] - ETA: 1:02 - loss: 0.6731 - acc: 0.6116
 512/1202 [===========>..................] - ETA: 57s - loss: 0.6781 - acc: 0.5977 
 576/1202 [=============>................] - ETA: 51s - loss: 0.6753 - acc: 0.6024
 640/1202 [==============>...............] - ETA: 46s - loss: 0.6706 - acc: 0.6047
 704/1202 [================>.............] - ETA: 41s - loss: 0.6752 - acc: 0.5966
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6742 - acc: 0.5964
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6720 - acc: 0.6010
 896/1202 [=====================>........] - ETA: 25s - loss: 0.6736 - acc: 0.5938
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6780 - acc: 0.5885
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6805 - acc: 0.5850
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6790 - acc: 0.5882 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6759 - acc: 0.5929
1202/1202 [==============================] - 104s 86ms/step - loss: 0.6759 - acc: 0.5907 - val_loss: 0.7153 - val_acc: 0.5000

Epoch 00005: val_acc did not improve from 0.58209
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:24 - loss: 0.6401 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:23 - loss: 0.6500 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 1:20 - loss: 0.6546 - acc: 0.6094
 256/1202 [=====>........................] - ETA: 1:16 - loss: 0.6613 - acc: 0.6133
 320/1202 [======>.......................] - ETA: 1:10 - loss: 0.6732 - acc: 0.6000
 384/1202 [========>.....................] - ETA: 1:07 - loss: 0.6759 - acc: 0.5964
 448/1202 [==========>...................] - ETA: 1:02 - loss: 0.6778 - acc: 0.6004
 512/1202 [===========>..................] - ETA: 56s - loss: 0.6843 - acc: 0.5898 
 576/1202 [=============>................] - ETA: 51s - loss: 0.6783 - acc: 0.6007
 640/1202 [==============>...............] - ETA: 46s - loss: 0.6751 - acc: 0.5984
 704/1202 [================>.............] - ETA: 40s - loss: 0.6722 - acc: 0.6051
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6690 - acc: 0.6055
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6691 - acc: 0.6034
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6699 - acc: 0.6004
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6696 - acc: 0.5969
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6729 - acc: 0.5918
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6714 - acc: 0.5965 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6707 - acc: 0.5972
1202/1202 [==============================] - 102s 85ms/step - loss: 0.6678 - acc: 0.5998 - val_loss: 0.7345 - val_acc: 0.4627

Epoch 00006: val_acc did not improve from 0.58209
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:29 - loss: 0.6650 - acc: 0.5938
 128/1202 [==>...........................] - ETA: 1:31 - loss: 0.6352 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 1:26 - loss: 0.6487 - acc: 0.6094
 256/1202 [=====>........................] - ETA: 1:19 - loss: 0.6685 - acc: 0.5820
 320/1202 [======>.......................] - ETA: 1:12 - loss: 0.6700 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 1:06 - loss: 0.6631 - acc: 0.5938
 448/1202 [==========>...................] - ETA: 1:01 - loss: 0.6688 - acc: 0.5915
 512/1202 [===========>..................] - ETA: 57s - loss: 0.6686 - acc: 0.5938 
 576/1202 [=============>................] - ETA: 51s - loss: 0.6723 - acc: 0.5938
 640/1202 [==============>...............] - ETA: 46s - loss: 0.6737 - acc: 0.5938
 704/1202 [================>.............] - ETA: 40s - loss: 0.6774 - acc: 0.5838
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6740 - acc: 0.5911
 832/1202 [===================>..........] - ETA: 30s - loss: 0.6765 - acc: 0.5925
 896/1202 [=====================>........] - ETA: 25s - loss: 0.6752 - acc: 0.5938
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6799 - acc: 0.5865
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6856 - acc: 0.5781
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6822 - acc: 0.5836 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6856 - acc: 0.5807
1202/1202 [==============================] - 104s 86ms/step - loss: 0.6873 - acc: 0.5815 - val_loss: 0.7298 - val_acc: 0.5075

Epoch 00007: val_acc did not improve from 0.58209
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:33 - loss: 0.6638 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:40 - loss: 0.6367 - acc: 0.6172
 192/1202 [===>..........................] - ETA: 1:29 - loss: 0.6467 - acc: 0.6042
 256/1202 [=====>........................] - ETA: 1:20 - loss: 0.6606 - acc: 0.5820
 320/1202 [======>.......................] - ETA: 1:14 - loss: 0.6536 - acc: 0.5906
 384/1202 [========>.....................] - ETA: 1:08 - loss: 0.6658 - acc: 0.5833
 448/1202 [==========>...................] - ETA: 1:02 - loss: 0.6724 - acc: 0.5781
 512/1202 [===========>..................] - ETA: 56s - loss: 0.6743 - acc: 0.5781 
 576/1202 [=============>................] - ETA: 51s - loss: 0.6732 - acc: 0.5747
 640/1202 [==============>...............] - ETA: 45s - loss: 0.6689 - acc: 0.5813
 704/1202 [================>.............] - ETA: 40s - loss: 0.6738 - acc: 0.5767
 768/1202 [==================>...........] - ETA: 34s - loss: 0.6698 - acc: 0.5872
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6736 - acc: 0.5865
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6747 - acc: 0.5882
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6749 - acc: 0.5885
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6741 - acc: 0.5879
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6763 - acc: 0.5818 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6746 - acc: 0.5859
1202/1202 [==============================] - 99s 82ms/step - loss: 0.6736 - acc: 0.5899 - val_loss: 0.7084 - val_acc: 0.5224

Epoch 00008: val_acc did not improve from 0.58209
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:32 - loss: 0.7083 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 1:28 - loss: 0.7203 - acc: 0.5391
 192/1202 [===>..........................] - ETA: 1:22 - loss: 0.6853 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 1:15 - loss: 0.6768 - acc: 0.6016
 320/1202 [======>.......................] - ETA: 1:09 - loss: 0.6686 - acc: 0.6094
 384/1202 [========>.....................] - ETA: 1:04 - loss: 0.6667 - acc: 0.6068
 448/1202 [==========>...................] - ETA: 59s - loss: 0.6662 - acc: 0.6071 
 512/1202 [===========>..................] - ETA: 53s - loss: 0.6618 - acc: 0.6152
 576/1202 [=============>................] - ETA: 48s - loss: 0.6603 - acc: 0.6128
 640/1202 [==============>...............] - ETA: 43s - loss: 0.6571 - acc: 0.6219
 704/1202 [================>.............] - ETA: 39s - loss: 0.6577 - acc: 0.6222
 768/1202 [==================>...........] - ETA: 34s - loss: 0.6680 - acc: 0.6055
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6674 - acc: 0.6070
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6679 - acc: 0.6071
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6673 - acc: 0.6042
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6653 - acc: 0.6035
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6682 - acc: 0.5993 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6671 - acc: 0.6024
1202/1202 [==============================] - 99s 82ms/step - loss: 0.6648 - acc: 0.6040 - val_loss: 0.7070 - val_acc: 0.5299

Epoch 00009: val_acc did not improve from 0.58209
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:28 - loss: 0.6473 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:25 - loss: 0.6302 - acc: 0.6172
 192/1202 [===>..........................] - ETA: 1:20 - loss: 0.6326 - acc: 0.6406
 256/1202 [=====>........................] - ETA: 1:16 - loss: 0.6377 - acc: 0.6211
 320/1202 [======>.......................] - ETA: 1:10 - loss: 0.6350 - acc: 0.6156
 384/1202 [========>.....................] - ETA: 1:05 - loss: 0.6403 - acc: 0.6120
 448/1202 [==========>...................] - ETA: 1:00 - loss: 0.6412 - acc: 0.6161
 512/1202 [===========>..................] - ETA: 55s - loss: 0.6434 - acc: 0.6152 
 576/1202 [=============>................] - ETA: 50s - loss: 0.6448 - acc: 0.6163
 640/1202 [==============>...............] - ETA: 45s - loss: 0.6493 - acc: 0.6141
 704/1202 [================>.............] - ETA: 40s - loss: 0.6536 - acc: 0.6037
 768/1202 [==================>...........] - ETA: 35s - loss: 0.6521 - acc: 0.6042
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6501 - acc: 0.6106
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6509 - acc: 0.6083
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6500 - acc: 0.6073
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6525 - acc: 0.6025
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6521 - acc: 0.6039 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6547 - acc: 0.6007
1202/1202 [==============================] - 102s 85ms/step - loss: 0.6563 - acc: 0.5982 - val_loss: 0.7056 - val_acc: 0.5746

Epoch 00010: val_acc did not improve from 0.58209
样本个数 167
样本个数 334
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 9s
128/334 [==========>...................] - ETA: 6s
192/334 [================>.............] - ETA: 3s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 9s 26ms/step
loss: 0.6958880310287019
acc: 0.5688622754491018
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f2a60237790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f2a60237790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f2a58384050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f2a58384050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30adb69b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30adb69b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a2030e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a2030e550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a6015a990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a6015a990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a6006c610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a6006c610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a2030e810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a2030e810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30947b52d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30947b52d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a587ca810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a587ca810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a5861b990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a5861b990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a601e6750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a601e6750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f30c750ed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f30c750ed90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a585e9f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a585e9f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a585e4610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a585e4610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a201ff450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a201ff450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a201c3550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a201c3550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a5871a590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a5871a590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a2021bd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a2021bd90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a007d41d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a007d41d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a006c29d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a006c29d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a00787b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a00787b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a007d42d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a007d42d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a2021d350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a2021d350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a0058f850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a0058f850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a003439d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a003439d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a0042bf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a0042bf10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a0049c050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a0049c050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a007e94d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a007e94d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a004b1fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a004b1fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a0006fa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a0006fa10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a00388dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a00388dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a002496d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a002496d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e0710ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e0710ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29e061e790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29e061e790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29e0583710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29e0583710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e0671910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e0671910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29e061e8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29e061e8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e0423ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e0423ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29e0328c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29e0328c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29e01de090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29e01de090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e0356590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e0356590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29e0367cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29e0367cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e02344d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e02344d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29c07ee750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29c07ee750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29c0706590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29c0706590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e01de950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29e01de950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29e00aae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29e00aae10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29c068df10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29c068df10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29c067bc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29c067bc10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29c0408650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29c0408650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29c03bd550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29c03bd550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29c04a04d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29c04a04d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29c03b28d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29c03b28d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29c0275950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29c0275950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29c0171a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29c0171a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29c04326d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29c04326d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29c02257d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29c02257d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29a47bb050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29a47bb050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29a45cd990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29a45cd990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29a4584cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29a4584cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29a461c110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29a461c110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29a45cdf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29a45cdf50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29a453c350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29a453c350>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 3:00 - loss: 0.8928 - acc: 0.4375
 128/1202 [==>...........................] - ETA: 1:50 - loss: 0.8287 - acc: 0.5234
 192/1202 [===>..........................] - ETA: 1:32 - loss: 0.8425 - acc: 0.4948
 256/1202 [=====>........................] - ETA: 1:18 - loss: 0.8061 - acc: 0.5234
 320/1202 [======>.......................] - ETA: 1:09 - loss: 0.8033 - acc: 0.5188
 384/1202 [========>.....................] - ETA: 1:01 - loss: 0.7926 - acc: 0.5208
 448/1202 [==========>...................] - ETA: 55s - loss: 0.7894 - acc: 0.5156 
 512/1202 [===========>..................] - ETA: 48s - loss: 0.7781 - acc: 0.5234
 576/1202 [=============>................] - ETA: 42s - loss: 0.7677 - acc: 0.5312
 640/1202 [==============>...............] - ETA: 37s - loss: 0.7619 - acc: 0.5250
 704/1202 [================>.............] - ETA: 33s - loss: 0.7498 - acc: 0.5384
 768/1202 [==================>...........] - ETA: 28s - loss: 0.7499 - acc: 0.5299
 832/1202 [===================>..........] - ETA: 23s - loss: 0.7471 - acc: 0.5312
 896/1202 [=====================>........] - ETA: 19s - loss: 0.7425 - acc: 0.5357
 960/1202 [======================>.......] - ETA: 15s - loss: 0.7421 - acc: 0.5365
1024/1202 [========================>.....] - ETA: 11s - loss: 0.7384 - acc: 0.5410
1088/1202 [==========================>...] - ETA: 7s - loss: 0.7389 - acc: 0.5368 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7377 - acc: 0.5347
1202/1202 [==============================] - 80s 67ms/step - loss: 0.7337 - acc: 0.5391 - val_loss: 0.7701 - val_acc: 0.4701

Epoch 00001: val_acc improved from -inf to 0.47015, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window17/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:05 - loss: 0.6720 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 1:05 - loss: 0.6813 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 1:00 - loss: 0.6849 - acc: 0.5885
 256/1202 [=====>........................] - ETA: 57s - loss: 0.6944 - acc: 0.5742 
 320/1202 [======>.......................] - ETA: 54s - loss: 0.7129 - acc: 0.5594
 384/1202 [========>.....................] - ETA: 51s - loss: 0.7068 - acc: 0.5703
 448/1202 [==========>...................] - ETA: 46s - loss: 0.7206 - acc: 0.5536
 512/1202 [===========>..................] - ETA: 43s - loss: 0.7156 - acc: 0.5547
 576/1202 [=============>................] - ETA: 40s - loss: 0.7098 - acc: 0.5590
 640/1202 [==============>...............] - ETA: 36s - loss: 0.7138 - acc: 0.5594
 704/1202 [================>.............] - ETA: 31s - loss: 0.7130 - acc: 0.5554
 768/1202 [==================>...........] - ETA: 27s - loss: 0.7078 - acc: 0.5599
 832/1202 [===================>..........] - ETA: 22s - loss: 0.7075 - acc: 0.5577
 896/1202 [=====================>........] - ETA: 18s - loss: 0.7119 - acc: 0.5446
 960/1202 [======================>.......] - ETA: 14s - loss: 0.7100 - acc: 0.5479
1024/1202 [========================>.....] - ETA: 10s - loss: 0.7066 - acc: 0.5537
1088/1202 [==========================>...] - ETA: 6s - loss: 0.7084 - acc: 0.5524 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.7108 - acc: 0.5547
1202/1202 [==============================] - 72s 60ms/step - loss: 0.7117 - acc: 0.5516 - val_loss: 0.7084 - val_acc: 0.5224

Epoch 00002: val_acc improved from 0.47015 to 0.52239, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window17/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:07 - loss: 0.6864 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 54s - loss: 0.6634 - acc: 0.5547 
 192/1202 [===>..........................] - ETA: 48s - loss: 0.6800 - acc: 0.5365
 256/1202 [=====>........................] - ETA: 46s - loss: 0.6900 - acc: 0.5312
 320/1202 [======>.......................] - ETA: 43s - loss: 0.6885 - acc: 0.5594
 384/1202 [========>.....................] - ETA: 39s - loss: 0.6924 - acc: 0.5495
 448/1202 [==========>...................] - ETA: 35s - loss: 0.6861 - acc: 0.5647
 512/1202 [===========>..................] - ETA: 32s - loss: 0.6819 - acc: 0.5723
 576/1202 [=============>................] - ETA: 29s - loss: 0.6821 - acc: 0.5747
 640/1202 [==============>...............] - ETA: 26s - loss: 0.6823 - acc: 0.5719
 704/1202 [================>.............] - ETA: 23s - loss: 0.6770 - acc: 0.5767
 768/1202 [==================>...........] - ETA: 20s - loss: 0.6749 - acc: 0.5794
 832/1202 [===================>..........] - ETA: 17s - loss: 0.6761 - acc: 0.5781
 896/1202 [=====================>........] - ETA: 14s - loss: 0.6789 - acc: 0.5748
 960/1202 [======================>.......] - ETA: 11s - loss: 0.6809 - acc: 0.5750
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6832 - acc: 0.5703 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6859 - acc: 0.5634
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6881 - acc: 0.5608
1202/1202 [==============================] - 59s 49ms/step - loss: 0.6903 - acc: 0.5574 - val_loss: 0.7094 - val_acc: 0.5000

Epoch 00003: val_acc did not improve from 0.52239
Epoch 4/10

  64/1202 [>.............................] - ETA: 50s - loss: 0.7606 - acc: 0.4375
 128/1202 [==>...........................] - ETA: 48s - loss: 0.7124 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 49s - loss: 0.7125 - acc: 0.5417
 256/1202 [=====>........................] - ETA: 50s - loss: 0.7023 - acc: 0.5625
 320/1202 [======>.......................] - ETA: 48s - loss: 0.6952 - acc: 0.5719
 384/1202 [========>.....................] - ETA: 44s - loss: 0.6954 - acc: 0.5625
 448/1202 [==========>...................] - ETA: 42s - loss: 0.6879 - acc: 0.5603
 512/1202 [===========>..................] - ETA: 38s - loss: 0.6805 - acc: 0.5723
 576/1202 [=============>................] - ETA: 35s - loss: 0.6826 - acc: 0.5694
 640/1202 [==============>...............] - ETA: 31s - loss: 0.6765 - acc: 0.5766
 704/1202 [================>.............] - ETA: 28s - loss: 0.6754 - acc: 0.5767
 768/1202 [==================>...........] - ETA: 24s - loss: 0.6744 - acc: 0.5781
 832/1202 [===================>..........] - ETA: 21s - loss: 0.6782 - acc: 0.5721
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6755 - acc: 0.5770
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6770 - acc: 0.5750
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6790 - acc: 0.5732
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6792 - acc: 0.5781 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6787 - acc: 0.5816
1202/1202 [==============================] - 75s 62ms/step - loss: 0.6797 - acc: 0.5807 - val_loss: 0.6989 - val_acc: 0.5224

Epoch 00004: val_acc did not improve from 0.52239
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:12 - loss: 0.6532 - acc: 0.5938
 128/1202 [==>...........................] - ETA: 1:08 - loss: 0.6674 - acc: 0.6094
 192/1202 [===>..........................] - ETA: 1:05 - loss: 0.6662 - acc: 0.5990
 256/1202 [=====>........................] - ETA: 1:00 - loss: 0.6730 - acc: 0.5898
 320/1202 [======>.......................] - ETA: 55s - loss: 0.6842 - acc: 0.5844 
 384/1202 [========>.....................] - ETA: 50s - loss: 0.6840 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 46s - loss: 0.6927 - acc: 0.5625
 512/1202 [===========>..................] - ETA: 42s - loss: 0.6923 - acc: 0.5605
 576/1202 [=============>................] - ETA: 38s - loss: 0.6933 - acc: 0.5642
 640/1202 [==============>...............] - ETA: 34s - loss: 0.6944 - acc: 0.5594
 704/1202 [================>.............] - ETA: 30s - loss: 0.6930 - acc: 0.5625
 768/1202 [==================>...........] - ETA: 26s - loss: 0.6884 - acc: 0.5677
 832/1202 [===================>..........] - ETA: 22s - loss: 0.6913 - acc: 0.5565
 896/1202 [=====================>........] - ETA: 18s - loss: 0.6843 - acc: 0.5658
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6831 - acc: 0.5677
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6870 - acc: 0.5664
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6893 - acc: 0.5653 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6874 - acc: 0.5703
1202/1202 [==============================] - 81s 67ms/step - loss: 0.6859 - acc: 0.5691 - val_loss: 0.7226 - val_acc: 0.5224

Epoch 00005: val_acc did not improve from 0.52239
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:21 - loss: 0.7189 - acc: 0.5938
 128/1202 [==>...........................] - ETA: 1:15 - loss: 0.6685 - acc: 0.6562
 192/1202 [===>..........................] - ETA: 1:12 - loss: 0.6775 - acc: 0.6406
 256/1202 [=====>........................] - ETA: 1:07 - loss: 0.6816 - acc: 0.6172
 320/1202 [======>.......................] - ETA: 1:03 - loss: 0.6924 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 58s - loss: 0.6838 - acc: 0.5911 
 448/1202 [==========>...................] - ETA: 54s - loss: 0.6792 - acc: 0.6004
 512/1202 [===========>..................] - ETA: 49s - loss: 0.6776 - acc: 0.5938
 576/1202 [=============>................] - ETA: 45s - loss: 0.6741 - acc: 0.5920
 640/1202 [==============>...............] - ETA: 40s - loss: 0.6764 - acc: 0.5875
 704/1202 [================>.............] - ETA: 36s - loss: 0.6768 - acc: 0.5881
 768/1202 [==================>...........] - ETA: 32s - loss: 0.6757 - acc: 0.5820
 832/1202 [===================>..........] - ETA: 27s - loss: 0.6800 - acc: 0.5781
 896/1202 [=====================>........] - ETA: 22s - loss: 0.6831 - acc: 0.5725
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6836 - acc: 0.5750
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6823 - acc: 0.5752
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6816 - acc: 0.5772 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6780 - acc: 0.5825
1202/1202 [==============================] - 94s 78ms/step - loss: 0.6777 - acc: 0.5840 - val_loss: 0.7165 - val_acc: 0.5149

Epoch 00006: val_acc did not improve from 0.52239
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:17 - loss: 0.7361 - acc: 0.4688
 128/1202 [==>...........................] - ETA: 1:14 - loss: 0.6979 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 1:12 - loss: 0.6791 - acc: 0.5677
 256/1202 [=====>........................] - ETA: 1:09 - loss: 0.6835 - acc: 0.5586
 320/1202 [======>.......................] - ETA: 1:05 - loss: 0.6781 - acc: 0.5750
 384/1202 [========>.....................] - ETA: 1:01 - loss: 0.6738 - acc: 0.5885
 448/1202 [==========>...................] - ETA: 56s - loss: 0.6788 - acc: 0.5871 
 512/1202 [===========>..................] - ETA: 51s - loss: 0.6799 - acc: 0.5859
 576/1202 [=============>................] - ETA: 46s - loss: 0.6773 - acc: 0.5799
 640/1202 [==============>...............] - ETA: 42s - loss: 0.6768 - acc: 0.5813
 704/1202 [================>.............] - ETA: 37s - loss: 0.6893 - acc: 0.5639
 768/1202 [==================>...........] - ETA: 32s - loss: 0.6951 - acc: 0.5560
 832/1202 [===================>..........] - ETA: 27s - loss: 0.6941 - acc: 0.5529
 896/1202 [=====================>........] - ETA: 22s - loss: 0.6902 - acc: 0.5592
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6880 - acc: 0.5625
1024/1202 [========================>.....] - ETA: 13s - loss: 0.6848 - acc: 0.5693
1088/1202 [==========================>...] - ETA: 8s - loss: 0.6854 - acc: 0.5680 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6847 - acc: 0.5651
1202/1202 [==============================] - 93s 77ms/step - loss: 0.6859 - acc: 0.5632 - val_loss: 0.7276 - val_acc: 0.4851

Epoch 00007: val_acc did not improve from 0.52239
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:32 - loss: 0.6821 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:23 - loss: 0.7201 - acc: 0.5156
 192/1202 [===>..........................] - ETA: 1:18 - loss: 0.6851 - acc: 0.5781
 256/1202 [=====>........................] - ETA: 1:14 - loss: 0.6957 - acc: 0.5703
 320/1202 [======>.......................] - ETA: 1:10 - loss: 0.6883 - acc: 0.5625
 384/1202 [========>.....................] - ETA: 1:04 - loss: 0.6867 - acc: 0.5521
 448/1202 [==========>...................] - ETA: 58s - loss: 0.6953 - acc: 0.5513 
 512/1202 [===========>..................] - ETA: 53s - loss: 0.6930 - acc: 0.5547
 576/1202 [=============>................] - ETA: 48s - loss: 0.6891 - acc: 0.5677
 640/1202 [==============>...............] - ETA: 43s - loss: 0.6846 - acc: 0.5766
 704/1202 [================>.............] - ETA: 38s - loss: 0.6829 - acc: 0.5824
 768/1202 [==================>...........] - ETA: 33s - loss: 0.6761 - acc: 0.5911
 832/1202 [===================>..........] - ETA: 28s - loss: 0.6750 - acc: 0.5913
 896/1202 [=====================>........] - ETA: 23s - loss: 0.6791 - acc: 0.5882
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6808 - acc: 0.5865
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6787 - acc: 0.5908
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6743 - acc: 0.5983 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6735 - acc: 0.5972
1202/1202 [==============================] - 101s 84ms/step - loss: 0.6753 - acc: 0.5923 - val_loss: 0.6856 - val_acc: 0.5075

Epoch 00008: val_acc did not improve from 0.52239
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:26 - loss: 0.7170 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 1:18 - loss: 0.6961 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 1:17 - loss: 0.6921 - acc: 0.5729
 256/1202 [=====>........................] - ETA: 1:13 - loss: 0.6760 - acc: 0.5977
 320/1202 [======>.......................] - ETA: 1:09 - loss: 0.6661 - acc: 0.6000
 384/1202 [========>.....................] - ETA: 1:05 - loss: 0.6631 - acc: 0.6042
 448/1202 [==========>...................] - ETA: 59s - loss: 0.6633 - acc: 0.6027 
 512/1202 [===========>..................] - ETA: 54s - loss: 0.6605 - acc: 0.6094
 576/1202 [=============>................] - ETA: 48s - loss: 0.6563 - acc: 0.6128
 640/1202 [==============>...............] - ETA: 44s - loss: 0.6621 - acc: 0.6016
 704/1202 [================>.............] - ETA: 39s - loss: 0.6700 - acc: 0.5866
 768/1202 [==================>...........] - ETA: 34s - loss: 0.6650 - acc: 0.5990
 832/1202 [===================>..........] - ETA: 29s - loss: 0.6658 - acc: 0.5974
 896/1202 [=====================>........] - ETA: 24s - loss: 0.6651 - acc: 0.5971
 960/1202 [======================>.......] - ETA: 19s - loss: 0.6653 - acc: 0.5969
1024/1202 [========================>.....] - ETA: 14s - loss: 0.6610 - acc: 0.6016
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6642 - acc: 0.6011 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6660 - acc: 0.5981
1202/1202 [==============================] - 101s 84ms/step - loss: 0.6657 - acc: 0.5973 - val_loss: 0.7069 - val_acc: 0.5000

Epoch 00009: val_acc did not improve from 0.52239
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:32 - loss: 0.6090 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 1:26 - loss: 0.6003 - acc: 0.6797
 192/1202 [===>..........................] - ETA: 1:21 - loss: 0.6305 - acc: 0.6458
 256/1202 [=====>........................] - ETA: 1:17 - loss: 0.6212 - acc: 0.6562
 320/1202 [======>.......................] - ETA: 1:12 - loss: 0.6296 - acc: 0.6375
 384/1202 [========>.....................] - ETA: 1:07 - loss: 0.6368 - acc: 0.6380
 448/1202 [==========>...................] - ETA: 1:01 - loss: 0.6461 - acc: 0.6250
 512/1202 [===========>..................] - ETA: 56s - loss: 0.6476 - acc: 0.6230 
 576/1202 [=============>................] - ETA: 52s - loss: 0.6571 - acc: 0.6094
 640/1202 [==============>...............] - ETA: 47s - loss: 0.6616 - acc: 0.6000
 704/1202 [================>.............] - ETA: 42s - loss: 0.6626 - acc: 0.5994
 768/1202 [==================>...........] - ETA: 36s - loss: 0.6619 - acc: 0.5977
 832/1202 [===================>..........] - ETA: 31s - loss: 0.6615 - acc: 0.5998
 896/1202 [=====================>........] - ETA: 25s - loss: 0.6645 - acc: 0.5960
 960/1202 [======================>.......] - ETA: 20s - loss: 0.6622 - acc: 0.5979
1024/1202 [========================>.....] - ETA: 15s - loss: 0.6643 - acc: 0.5986
1088/1202 [==========================>...] - ETA: 9s - loss: 0.6647 - acc: 0.6011 
1152/1202 [===========================>..] - ETA: 4s - loss: 0.6665 - acc: 0.5972
1202/1202 [==============================] - 108s 90ms/step - loss: 0.6653 - acc: 0.5998 - val_loss: 0.6905 - val_acc: 0.5373

Epoch 00010: val_acc improved from 0.52239 to 0.53731, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window17/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
样本个数 167
样本个数 334
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 11s
128/334 [==========>...................] - ETA: 6s 
192/334 [================>.............] - ETA: 3s
256/334 [=====================>........] - ETA: 1s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 8s 24ms/step
loss: 0.685015874708484
acc: 0.532934132093441
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f290071ec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f290071ec50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f28e00437d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f28e00437d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30adb69e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30adb69e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28e0053d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28e0053d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2900659d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2900659d10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2900540510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2900540510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2900109cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2900109cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29c006ebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29c006ebd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f290044f3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f290044f3d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29004271d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f29004271d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f290043d290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f290043d290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29004e6dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29004e6dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29003a45d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29003a45d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29001461d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f29001461d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28c06bf790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28c06bf790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2900184d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2900184d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29c00b7850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f29c00b7850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c062a290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c062a290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28c050b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28c050b7d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28c04cf550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28c04cf550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c0705050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c0705050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f28c050b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f28c050b550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c042c890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c042c890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a60289f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a60289f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28c0417610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28c0417610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c01cee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c01cee90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f28c04ba210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f28c04ba210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c013d250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c013d250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28a067ff50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28a067ff50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28a054ef90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28a054ef90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28a06d7ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28a06d7ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f28a067f1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f28a067f1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c012a5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c012a5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28a03f2e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28a03f2e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28a02a7150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28a02a7150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28a0361510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28a0361510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f28a0470490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f28a0470490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28a0342050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28a0342050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28a016f910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28a016f910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28a004c150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28a004c150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2880711690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2880711690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f28a0063cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f28a0063cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28a0087d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28a0087d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2880542f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2880542f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f288044e5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f288044e5d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f288044c350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f288044c350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2880542e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2880542e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c078ac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28c078ac50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28801dbb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28801dbb10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2880096e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2880096e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28607b71d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28607b71d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2880440690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2880440690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28606b9750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28606b9750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28800d5f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28800d5f90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2880083810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2880083810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28605b45d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28605b45d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2860644090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2860644090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f286063b990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f286063b990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2860429e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2860429e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2860207d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2860207d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f286037f390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f286037f390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f286036c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f286036c7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28602dd250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28602dd250>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 3:21 - loss: 0.7653 - acc: 0.4375
 128/1202 [==>...........................] - ETA: 2:03 - loss: 0.8449 - acc: 0.4688
 192/1202 [===>..........................] - ETA: 1:32 - loss: 0.8083 - acc: 0.4792
 256/1202 [=====>........................] - ETA: 1:16 - loss: 0.7945 - acc: 0.4961
 320/1202 [======>.......................] - ETA: 1:07 - loss: 0.7881 - acc: 0.4875
 384/1202 [========>.....................] - ETA: 58s - loss: 0.7742 - acc: 0.4948 
 448/1202 [==========>...................] - ETA: 51s - loss: 0.7690 - acc: 0.4911
 512/1202 [===========>..................] - ETA: 46s - loss: 0.7651 - acc: 0.4961
 576/1202 [=============>................] - ETA: 41s - loss: 0.7544 - acc: 0.5035
 640/1202 [==============>...............] - ETA: 36s - loss: 0.7432 - acc: 0.5141
 704/1202 [================>.............] - ETA: 31s - loss: 0.7361 - acc: 0.5213
 768/1202 [==================>...........] - ETA: 27s - loss: 0.7325 - acc: 0.5234
 832/1202 [===================>..........] - ETA: 23s - loss: 0.7326 - acc: 0.5264
 896/1202 [=====================>........] - ETA: 18s - loss: 0.7292 - acc: 0.5279
 960/1202 [======================>.......] - ETA: 14s - loss: 0.7245 - acc: 0.5323
1024/1202 [========================>.....] - ETA: 10s - loss: 0.7228 - acc: 0.5322
1088/1202 [==========================>...] - ETA: 6s - loss: 0.7208 - acc: 0.5358 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7212 - acc: 0.5365
1202/1202 [==============================] - 77s 64ms/step - loss: 0.7194 - acc: 0.5383 - val_loss: 0.7726 - val_acc: 0.4925

Epoch 00001: val_acc improved from -inf to 0.49254, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window18/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 1:04 - loss: 0.7476 - acc: 0.4375
 128/1202 [==>...........................] - ETA: 57s - loss: 0.7081 - acc: 0.5312 
 192/1202 [===>..........................] - ETA: 53s - loss: 0.7239 - acc: 0.5000
 256/1202 [=====>........................] - ETA: 51s - loss: 0.7048 - acc: 0.5195
 320/1202 [======>.......................] - ETA: 47s - loss: 0.6976 - acc: 0.5250
 384/1202 [========>.....................] - ETA: 44s - loss: 0.6988 - acc: 0.5234
 448/1202 [==========>...................] - ETA: 41s - loss: 0.6843 - acc: 0.5536
 512/1202 [===========>..................] - ETA: 38s - loss: 0.6892 - acc: 0.5527
 576/1202 [=============>................] - ETA: 34s - loss: 0.6883 - acc: 0.5573
 640/1202 [==============>...............] - ETA: 31s - loss: 0.6910 - acc: 0.5547
 704/1202 [================>.............] - ETA: 27s - loss: 0.6905 - acc: 0.5625
 768/1202 [==================>...........] - ETA: 24s - loss: 0.6868 - acc: 0.5703
 832/1202 [===================>..........] - ETA: 20s - loss: 0.6848 - acc: 0.5769
 896/1202 [=====================>........] - ETA: 17s - loss: 0.6847 - acc: 0.5804
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6863 - acc: 0.5781
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6864 - acc: 0.5762 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6877 - acc: 0.5781
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6870 - acc: 0.5790
1202/1202 [==============================] - 71s 59ms/step - loss: 0.6892 - acc: 0.5774 - val_loss: 0.6884 - val_acc: 0.5821

Epoch 00002: val_acc improved from 0.49254 to 0.58209, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window18/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 1:00 - loss: 0.7450 - acc: 0.4688
 128/1202 [==>...........................] - ETA: 59s - loss: 0.7337 - acc: 0.4453 
 192/1202 [===>..........................] - ETA: 56s - loss: 0.7098 - acc: 0.5052
 256/1202 [=====>........................] - ETA: 52s - loss: 0.7072 - acc: 0.5234
 320/1202 [======>.......................] - ETA: 48s - loss: 0.7090 - acc: 0.5219
 384/1202 [========>.....................] - ETA: 45s - loss: 0.7052 - acc: 0.5078
 448/1202 [==========>...................] - ETA: 41s - loss: 0.7002 - acc: 0.5223
 512/1202 [===========>..................] - ETA: 38s - loss: 0.7023 - acc: 0.5156
 576/1202 [=============>................] - ETA: 34s - loss: 0.6975 - acc: 0.5226
 640/1202 [==============>...............] - ETA: 30s - loss: 0.6974 - acc: 0.5281
 704/1202 [================>.............] - ETA: 27s - loss: 0.6933 - acc: 0.5369
 768/1202 [==================>...........] - ETA: 23s - loss: 0.6930 - acc: 0.5391
 832/1202 [===================>..........] - ETA: 20s - loss: 0.6882 - acc: 0.5505
 896/1202 [=====================>........] - ETA: 16s - loss: 0.6925 - acc: 0.5413
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6888 - acc: 0.5479
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6886 - acc: 0.5488
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6879 - acc: 0.5533 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6872 - acc: 0.5556
1202/1202 [==============================] - 74s 61ms/step - loss: 0.6895 - acc: 0.5491 - val_loss: 0.7118 - val_acc: 0.5597

Epoch 00003: val_acc did not improve from 0.58209
Epoch 4/10

  64/1202 [>.............................] - ETA: 1:12 - loss: 0.7851 - acc: 0.4531
 128/1202 [==>...........................] - ETA: 1:09 - loss: 0.7370 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 1:06 - loss: 0.7186 - acc: 0.5365
 256/1202 [=====>........................] - ETA: 1:01 - loss: 0.7040 - acc: 0.5508
 320/1202 [======>.......................] - ETA: 57s - loss: 0.7005 - acc: 0.5531 
 384/1202 [========>.....................] - ETA: 53s - loss: 0.6953 - acc: 0.5703
 448/1202 [==========>...................] - ETA: 49s - loss: 0.6944 - acc: 0.5692
 512/1202 [===========>..................] - ETA: 45s - loss: 0.6878 - acc: 0.5859
 576/1202 [=============>................] - ETA: 41s - loss: 0.6897 - acc: 0.5799
 640/1202 [==============>...............] - ETA: 37s - loss: 0.6855 - acc: 0.5797
 704/1202 [================>.............] - ETA: 32s - loss: 0.6863 - acc: 0.5781
 768/1202 [==================>...........] - ETA: 28s - loss: 0.6901 - acc: 0.5703
 832/1202 [===================>..........] - ETA: 24s - loss: 0.6909 - acc: 0.5685
 896/1202 [=====================>........] - ETA: 19s - loss: 0.6897 - acc: 0.5692
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6922 - acc: 0.5604
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6886 - acc: 0.5654
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6904 - acc: 0.5616 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6893 - acc: 0.5642
1202/1202 [==============================] - 83s 69ms/step - loss: 0.6891 - acc: 0.5657 - val_loss: 0.6858 - val_acc: 0.5597

Epoch 00004: val_acc did not improve from 0.58209
Epoch 5/10

  64/1202 [>.............................] - ETA: 1:11 - loss: 0.7284 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:09 - loss: 0.7033 - acc: 0.5547
 192/1202 [===>..........................] - ETA: 1:04 - loss: 0.7196 - acc: 0.5573
 256/1202 [=====>........................] - ETA: 59s - loss: 0.7045 - acc: 0.5664 
 320/1202 [======>.......................] - ETA: 55s - loss: 0.6992 - acc: 0.5719
 384/1202 [========>.....................] - ETA: 52s - loss: 0.6909 - acc: 0.5807
 448/1202 [==========>...................] - ETA: 48s - loss: 0.6896 - acc: 0.5826
 512/1202 [===========>..................] - ETA: 44s - loss: 0.6896 - acc: 0.5820
 576/1202 [=============>................] - ETA: 40s - loss: 0.6902 - acc: 0.5712
 640/1202 [==============>...............] - ETA: 36s - loss: 0.6881 - acc: 0.5687
 704/1202 [================>.............] - ETA: 32s - loss: 0.6852 - acc: 0.5724
 768/1202 [==================>...........] - ETA: 28s - loss: 0.6866 - acc: 0.5703
 832/1202 [===================>..........] - ETA: 24s - loss: 0.6810 - acc: 0.5793
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6826 - acc: 0.5815
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6820 - acc: 0.5813
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6809 - acc: 0.5850
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6813 - acc: 0.5827 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6819 - acc: 0.5799
1202/1202 [==============================] - 86s 71ms/step - loss: 0.6813 - acc: 0.5807 - val_loss: 0.6869 - val_acc: 0.5672

Epoch 00005: val_acc did not improve from 0.58209
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:26 - loss: 0.6625 - acc: 0.6719
 128/1202 [==>...........................] - ETA: 1:22 - loss: 0.6554 - acc: 0.6484
 192/1202 [===>..........................] - ETA: 1:18 - loss: 0.6469 - acc: 0.6354
 256/1202 [=====>........................] - ETA: 1:12 - loss: 0.6578 - acc: 0.6094
 320/1202 [======>.......................] - ETA: 1:05 - loss: 0.6638 - acc: 0.5844
 384/1202 [========>.....................] - ETA: 59s - loss: 0.6743 - acc: 0.5755 
 448/1202 [==========>...................] - ETA: 54s - loss: 0.6732 - acc: 0.5714
 512/1202 [===========>..................] - ETA: 50s - loss: 0.6766 - acc: 0.5684
 576/1202 [=============>................] - ETA: 45s - loss: 0.6763 - acc: 0.5764
 640/1202 [==============>...............] - ETA: 40s - loss: 0.6862 - acc: 0.5578
 704/1202 [================>.............] - ETA: 35s - loss: 0.6844 - acc: 0.5568
 768/1202 [==================>...........] - ETA: 30s - loss: 0.6830 - acc: 0.5573
 832/1202 [===================>..........] - ETA: 26s - loss: 0.6836 - acc: 0.5577
 896/1202 [=====================>........] - ETA: 21s - loss: 0.6796 - acc: 0.5670
 960/1202 [======================>.......] - ETA: 17s - loss: 0.6787 - acc: 0.5646
1024/1202 [========================>.....] - ETA: 12s - loss: 0.6780 - acc: 0.5664
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6758 - acc: 0.5708 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6765 - acc: 0.5694
1202/1202 [==============================] - 87s 73ms/step - loss: 0.6748 - acc: 0.5732 - val_loss: 0.7044 - val_acc: 0.5896

Epoch 00006: val_acc improved from 0.58209 to 0.58955, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window18/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 7/10

  64/1202 [>.............................] - ETA: 1:19 - loss: 0.7042 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:13 - loss: 0.7038 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 1:06 - loss: 0.6962 - acc: 0.5729
 256/1202 [=====>........................] - ETA: 1:01 - loss: 0.6763 - acc: 0.5977
 320/1202 [======>.......................] - ETA: 57s - loss: 0.6759 - acc: 0.5969 
 384/1202 [========>.....................] - ETA: 53s - loss: 0.6777 - acc: 0.5938
 448/1202 [==========>...................] - ETA: 50s - loss: 0.6831 - acc: 0.5893
 512/1202 [===========>..................] - ETA: 45s - loss: 0.6757 - acc: 0.6016
 576/1202 [=============>................] - ETA: 41s - loss: 0.6764 - acc: 0.5920
 640/1202 [==============>...............] - ETA: 37s - loss: 0.6771 - acc: 0.5906
 704/1202 [================>.............] - ETA: 33s - loss: 0.6809 - acc: 0.5895
 768/1202 [==================>...........] - ETA: 29s - loss: 0.6837 - acc: 0.5898
 832/1202 [===================>..........] - ETA: 24s - loss: 0.6811 - acc: 0.5889
 896/1202 [=====================>........] - ETA: 20s - loss: 0.6821 - acc: 0.5871
 960/1202 [======================>.......] - ETA: 16s - loss: 0.6817 - acc: 0.5917
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6809 - acc: 0.5908
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6794 - acc: 0.5928 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6779 - acc: 0.5929
1202/1202 [==============================] - 85s 71ms/step - loss: 0.6747 - acc: 0.5973 - val_loss: 0.6872 - val_acc: 0.5597

Epoch 00007: val_acc did not improve from 0.58955
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:18 - loss: 0.6438 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:15 - loss: 0.6399 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 1:07 - loss: 0.6665 - acc: 0.5573
 256/1202 [=====>........................] - ETA: 1:03 - loss: 0.6629 - acc: 0.5742
 320/1202 [======>.......................] - ETA: 59s - loss: 0.6866 - acc: 0.5500 
 384/1202 [========>.....................] - ETA: 54s - loss: 0.6762 - acc: 0.5703
 448/1202 [==========>...................] - ETA: 51s - loss: 0.6711 - acc: 0.5804
 512/1202 [===========>..................] - ETA: 46s - loss: 0.6699 - acc: 0.5859
 576/1202 [=============>................] - ETA: 42s - loss: 0.6656 - acc: 0.5920
 640/1202 [==============>...............] - ETA: 38s - loss: 0.6681 - acc: 0.5875
 704/1202 [================>.............] - ETA: 33s - loss: 0.6701 - acc: 0.5838
 768/1202 [==================>...........] - ETA: 28s - loss: 0.6704 - acc: 0.5833
 832/1202 [===================>..........] - ETA: 23s - loss: 0.6691 - acc: 0.5901
 896/1202 [=====================>........] - ETA: 19s - loss: 0.6678 - acc: 0.5938
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6676 - acc: 0.5917
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6674 - acc: 0.5918
1088/1202 [==========================>...] - ETA: 7s - loss: 0.6693 - acc: 0.5882 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6688 - acc: 0.5877
1202/1202 [==============================] - 76s 63ms/step - loss: 0.6719 - acc: 0.5840 - val_loss: 0.6927 - val_acc: 0.5672

Epoch 00008: val_acc did not improve from 0.58955
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:05 - loss: 0.6543 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 59s - loss: 0.6568 - acc: 0.6328 
 192/1202 [===>..........................] - ETA: 55s - loss: 0.6744 - acc: 0.6042
 256/1202 [=====>........................] - ETA: 51s - loss: 0.6669 - acc: 0.6289
 320/1202 [======>.......................] - ETA: 48s - loss: 0.6741 - acc: 0.6281
 384/1202 [========>.....................] - ETA: 43s - loss: 0.6727 - acc: 0.6120
 448/1202 [==========>...................] - ETA: 41s - loss: 0.6767 - acc: 0.5982
 512/1202 [===========>..................] - ETA: 37s - loss: 0.6755 - acc: 0.5957
 576/1202 [=============>................] - ETA: 34s - loss: 0.6823 - acc: 0.5799
 640/1202 [==============>...............] - ETA: 30s - loss: 0.6794 - acc: 0.5828
 704/1202 [================>.............] - ETA: 27s - loss: 0.6765 - acc: 0.5881
 768/1202 [==================>...........] - ETA: 23s - loss: 0.6765 - acc: 0.5885
 832/1202 [===================>..........] - ETA: 20s - loss: 0.6759 - acc: 0.5950
 896/1202 [=====================>........] - ETA: 16s - loss: 0.6782 - acc: 0.5893
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6748 - acc: 0.5917
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6759 - acc: 0.5918 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6752 - acc: 0.5910
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6748 - acc: 0.5920
1202/1202 [==============================] - 70s 58ms/step - loss: 0.6727 - acc: 0.5948 - val_loss: 0.7107 - val_acc: 0.5522

Epoch 00009: val_acc did not improve from 0.58955
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:10 - loss: 0.6738 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 1:05 - loss: 0.6846 - acc: 0.5625
 192/1202 [===>..........................] - ETA: 1:00 - loss: 0.6670 - acc: 0.5781
 256/1202 [=====>........................] - ETA: 57s - loss: 0.6728 - acc: 0.5703 
 320/1202 [======>.......................] - ETA: 53s - loss: 0.6697 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 49s - loss: 0.6698 - acc: 0.5781
 448/1202 [==========>...................] - ETA: 45s - loss: 0.6726 - acc: 0.5781
 512/1202 [===========>..................] - ETA: 42s - loss: 0.6673 - acc: 0.5879
 576/1202 [=============>................] - ETA: 38s - loss: 0.6678 - acc: 0.5920
 640/1202 [==============>...............] - ETA: 34s - loss: 0.6710 - acc: 0.5906
 704/1202 [================>.............] - ETA: 30s - loss: 0.6666 - acc: 0.5966
 768/1202 [==================>...........] - ETA: 26s - loss: 0.6653 - acc: 0.6003
 832/1202 [===================>..........] - ETA: 22s - loss: 0.6608 - acc: 0.6082
 896/1202 [=====================>........] - ETA: 18s - loss: 0.6626 - acc: 0.6060
 960/1202 [======================>.......] - ETA: 14s - loss: 0.6602 - acc: 0.6073
1024/1202 [========================>.....] - ETA: 10s - loss: 0.6623 - acc: 0.6064
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6615 - acc: 0.6075 
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6646 - acc: 0.6042
1202/1202 [==============================] - 73s 61ms/step - loss: 0.6696 - acc: 0.5965 - val_loss: 0.6950 - val_acc: 0.5597

Epoch 00010: val_acc did not improve from 0.58955
样本个数 167
样本个数 334
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 14s
128/334 [==========>...................] - ETA: 7s 
192/334 [================>.............] - ETA: 4s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 8s 24ms/step
loss: 0.7122187296787422
acc: 0.5598802405917002
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f27c045ab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f27c045ab10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f27c040cf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f27c040cf50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a581e7b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a581e7b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27c0427250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27c0427250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27c034aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27c034aa90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27c037f690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27c037f690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27c037f710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27c037f710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27c02f66d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27c02f66d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27c028fbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27c028fbd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27c01926d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27c01926d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27c03f2150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27c03f2150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27c017e050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27c017e050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27c0140c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27c0140c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27c009ab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27c009ab10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f279851a9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f279851a9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27c00b7710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27c00b7710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27c008f290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27c008f290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2798440cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2798440cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f279826b710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f279826b710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27981c4810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27981c4810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27984a77d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27984a77d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f279826b650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f279826b650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27607c6590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27607c6590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f279804de90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f279804de90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27606becd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27606becd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2760631210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2760631210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27981ea790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27981ea790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27606e6350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27606e6350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27603ec190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27603ec190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27602c28d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27602c28d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27603b9ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27603b9ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27603ecf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27603ecf50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27602dd650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27602dd650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2760097850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2760097850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2760126e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2760126e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f276012a490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f276012a490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27600973d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27600973d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2760090690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2760090690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f274056a6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f274056a6d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2740406ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2740406ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f274056a210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f274056a210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f274056a110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f274056a110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2740406750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2740406750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f274044b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f274044b550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27c040a050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27c040a050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f274026afd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f274026afd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f274029ad90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f274029ad90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27401883d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27401883d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27206e9a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27206e9a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27205c8ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27205c8ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27204e59d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27204e59d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27c040a050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27c040a050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2720441e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2720441e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2720414e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2720414e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27203e7490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27203e7490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2720376d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2720376d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27206d0c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27206d0c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f272057c410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f272057c410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27202dc190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27202dc190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27200e5890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f27200e5890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27007463d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27007463d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27202ccd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27202ccd50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27007d73d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f27007d73d0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 3:11 - loss: 0.6976 - acc: 0.5781
 128/1202 [==>...........................] - ETA: 1:52 - loss: 0.7379 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 1:24 - loss: 0.7262 - acc: 0.5469
 256/1202 [=====>........................] - ETA: 1:09 - loss: 0.7328 - acc: 0.5391
 320/1202 [======>.......................] - ETA: 1:00 - loss: 0.7441 - acc: 0.5125
 384/1202 [========>.....................] - ETA: 52s - loss: 0.7444 - acc: 0.5104 
 448/1202 [==========>...................] - ETA: 46s - loss: 0.7440 - acc: 0.5089
 512/1202 [===========>..................] - ETA: 41s - loss: 0.7424 - acc: 0.5137
 576/1202 [=============>................] - ETA: 36s - loss: 0.7358 - acc: 0.5295
 640/1202 [==============>...............] - ETA: 31s - loss: 0.7320 - acc: 0.5344
 704/1202 [================>.............] - ETA: 27s - loss: 0.7292 - acc: 0.5312
 768/1202 [==================>...........] - ETA: 23s - loss: 0.7266 - acc: 0.5339
 832/1202 [===================>..........] - ETA: 19s - loss: 0.7216 - acc: 0.5373
 896/1202 [=====================>........] - ETA: 16s - loss: 0.7227 - acc: 0.5335
 960/1202 [======================>.......] - ETA: 12s - loss: 0.7208 - acc: 0.5375
1024/1202 [========================>.....] - ETA: 9s - loss: 0.7165 - acc: 0.5420 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.7117 - acc: 0.5478
1152/1202 [===========================>..] - ETA: 2s - loss: 0.7111 - acc: 0.5495
1202/1202 [==============================] - 65s 54ms/step - loss: 0.7097 - acc: 0.5499 - val_loss: 0.6794 - val_acc: 0.5597

Epoch 00001: val_acc improved from -inf to 0.55970, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window19/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 53s - loss: 0.7955 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 49s - loss: 0.7204 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 46s - loss: 0.6988 - acc: 0.5938
 256/1202 [=====>........................] - ETA: 42s - loss: 0.7205 - acc: 0.5742
 320/1202 [======>.......................] - ETA: 39s - loss: 0.7128 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 36s - loss: 0.7185 - acc: 0.5703
 448/1202 [==========>...................] - ETA: 34s - loss: 0.7187 - acc: 0.5603
 512/1202 [===========>..................] - ETA: 31s - loss: 0.7227 - acc: 0.5488
 576/1202 [=============>................] - ETA: 28s - loss: 0.7244 - acc: 0.5451
 640/1202 [==============>...............] - ETA: 25s - loss: 0.7252 - acc: 0.5359
 704/1202 [================>.............] - ETA: 22s - loss: 0.7160 - acc: 0.5497
 768/1202 [==================>...........] - ETA: 19s - loss: 0.7164 - acc: 0.5482
 832/1202 [===================>..........] - ETA: 16s - loss: 0.7132 - acc: 0.5457
 896/1202 [=====================>........] - ETA: 13s - loss: 0.7106 - acc: 0.5502
 960/1202 [======================>.......] - ETA: 10s - loss: 0.7098 - acc: 0.5563
1024/1202 [========================>.....] - ETA: 8s - loss: 0.7059 - acc: 0.5635 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.7068 - acc: 0.5643
1152/1202 [===========================>..] - ETA: 2s - loss: 0.7082 - acc: 0.5651
1202/1202 [==============================] - 57s 48ms/step - loss: 0.7092 - acc: 0.5649 - val_loss: 0.6799 - val_acc: 0.5672

Epoch 00002: val_acc improved from 0.55970 to 0.56716, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window19/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 58s - loss: 0.7379 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 52s - loss: 0.6835 - acc: 0.5859
 192/1202 [===>..........................] - ETA: 49s - loss: 0.6827 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 47s - loss: 0.6779 - acc: 0.5820
 320/1202 [======>.......................] - ETA: 44s - loss: 0.6757 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 39s - loss: 0.6846 - acc: 0.5807
 448/1202 [==========>...................] - ETA: 36s - loss: 0.6806 - acc: 0.5960
 512/1202 [===========>..................] - ETA: 32s - loss: 0.6737 - acc: 0.6016
 576/1202 [=============>................] - ETA: 29s - loss: 0.6756 - acc: 0.6007
 640/1202 [==============>...............] - ETA: 26s - loss: 0.6757 - acc: 0.6000
 704/1202 [================>.............] - ETA: 23s - loss: 0.6834 - acc: 0.5952
 768/1202 [==================>...........] - ETA: 20s - loss: 0.6863 - acc: 0.5885
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6831 - acc: 0.5901
 896/1202 [=====================>........] - ETA: 14s - loss: 0.6838 - acc: 0.5871
 960/1202 [======================>.......] - ETA: 11s - loss: 0.6816 - acc: 0.5865
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6837 - acc: 0.5801 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6884 - acc: 0.5726
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6859 - acc: 0.5738
1202/1202 [==============================] - 57s 48ms/step - loss: 0.6893 - acc: 0.5715 - val_loss: 0.6754 - val_acc: 0.5448

Epoch 00003: val_acc did not improve from 0.56716
Epoch 4/10

  64/1202 [>.............................] - ETA: 52s - loss: 0.7192 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 50s - loss: 0.7136 - acc: 0.5391
 192/1202 [===>..........................] - ETA: 46s - loss: 0.6770 - acc: 0.5729
 256/1202 [=====>........................] - ETA: 41s - loss: 0.6782 - acc: 0.5703
 320/1202 [======>.......................] - ETA: 40s - loss: 0.7016 - acc: 0.5312
 384/1202 [========>.....................] - ETA: 37s - loss: 0.6939 - acc: 0.5417
 448/1202 [==========>...................] - ETA: 34s - loss: 0.6945 - acc: 0.5536
 512/1202 [===========>..................] - ETA: 31s - loss: 0.6925 - acc: 0.5605
 576/1202 [=============>................] - ETA: 29s - loss: 0.6871 - acc: 0.5660
 640/1202 [==============>...............] - ETA: 26s - loss: 0.6855 - acc: 0.5625
 704/1202 [================>.............] - ETA: 23s - loss: 0.6812 - acc: 0.5682
 768/1202 [==================>...........] - ETA: 20s - loss: 0.6812 - acc: 0.5651
 832/1202 [===================>..........] - ETA: 17s - loss: 0.6841 - acc: 0.5601
 896/1202 [=====================>........] - ETA: 14s - loss: 0.6886 - acc: 0.5547
 960/1202 [======================>.......] - ETA: 11s - loss: 0.6886 - acc: 0.5563
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6871 - acc: 0.5625 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6858 - acc: 0.5625
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6850 - acc: 0.5616
1202/1202 [==============================] - 58s 48ms/step - loss: 0.6836 - acc: 0.5632 - val_loss: 0.7103 - val_acc: 0.5597

Epoch 00004: val_acc did not improve from 0.56716
Epoch 5/10

  64/1202 [>.............................] - ETA: 46s - loss: 0.7334 - acc: 0.4531
 128/1202 [==>...........................] - ETA: 46s - loss: 0.7010 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 46s - loss: 0.7028 - acc: 0.5365
 256/1202 [=====>........................] - ETA: 42s - loss: 0.7011 - acc: 0.5312
 320/1202 [======>.......................] - ETA: 39s - loss: 0.6896 - acc: 0.5375
 384/1202 [========>.....................] - ETA: 37s - loss: 0.6808 - acc: 0.5547
 448/1202 [==========>...................] - ETA: 34s - loss: 0.6869 - acc: 0.5603
 512/1202 [===========>..................] - ETA: 31s - loss: 0.6824 - acc: 0.5625
 576/1202 [=============>................] - ETA: 28s - loss: 0.6837 - acc: 0.5590
 640/1202 [==============>...............] - ETA: 26s - loss: 0.6807 - acc: 0.5703
 704/1202 [================>.............] - ETA: 23s - loss: 0.6827 - acc: 0.5625
 768/1202 [==================>...........] - ETA: 20s - loss: 0.6835 - acc: 0.5599
 832/1202 [===================>..........] - ETA: 17s - loss: 0.6806 - acc: 0.5637
 896/1202 [=====================>........] - ETA: 14s - loss: 0.6817 - acc: 0.5625
 960/1202 [======================>.......] - ETA: 11s - loss: 0.6799 - acc: 0.5625
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6764 - acc: 0.5703 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6739 - acc: 0.5735
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6768 - acc: 0.5712
1202/1202 [==============================] - 60s 50ms/step - loss: 0.6786 - acc: 0.5674 - val_loss: 0.7055 - val_acc: 0.5597

Epoch 00005: val_acc did not improve from 0.56716
Epoch 6/10

  64/1202 [>.............................] - ETA: 1:02 - loss: 0.7062 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 56s - loss: 0.6812 - acc: 0.5781 
 192/1202 [===>..........................] - ETA: 53s - loss: 0.6715 - acc: 0.5885
 256/1202 [=====>........................] - ETA: 50s - loss: 0.6772 - acc: 0.5898
 320/1202 [======>.......................] - ETA: 46s - loss: 0.6787 - acc: 0.5906
 384/1202 [========>.....................] - ETA: 43s - loss: 0.6702 - acc: 0.6042
 448/1202 [==========>...................] - ETA: 40s - loss: 0.6671 - acc: 0.6071
 512/1202 [===========>..................] - ETA: 37s - loss: 0.6635 - acc: 0.6074
 576/1202 [=============>................] - ETA: 33s - loss: 0.6685 - acc: 0.5990
 640/1202 [==============>...............] - ETA: 29s - loss: 0.6709 - acc: 0.5984
 704/1202 [================>.............] - ETA: 26s - loss: 0.6683 - acc: 0.6037
 768/1202 [==================>...........] - ETA: 22s - loss: 0.6693 - acc: 0.6042
 832/1202 [===================>..........] - ETA: 19s - loss: 0.6682 - acc: 0.6070
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6684 - acc: 0.6105
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6692 - acc: 0.6115
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6684 - acc: 0.6104 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6696 - acc: 0.6048
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6686 - acc: 0.6059
1202/1202 [==============================] - 65s 54ms/step - loss: 0.6666 - acc: 0.6073 - val_loss: 0.7647 - val_acc: 0.4478

Epoch 00006: val_acc did not improve from 0.56716
Epoch 7/10

  64/1202 [>.............................] - ETA: 53s - loss: 0.6453 - acc: 0.6406
 128/1202 [==>...........................] - ETA: 52s - loss: 0.6437 - acc: 0.6484
 192/1202 [===>..........................] - ETA: 50s - loss: 0.6577 - acc: 0.6146
 256/1202 [=====>........................] - ETA: 48s - loss: 0.6666 - acc: 0.6016
 320/1202 [======>.......................] - ETA: 46s - loss: 0.6614 - acc: 0.6062
 384/1202 [========>.....................] - ETA: 42s - loss: 0.6546 - acc: 0.6172
 448/1202 [==========>...................] - ETA: 38s - loss: 0.6434 - acc: 0.6339
 512/1202 [===========>..................] - ETA: 35s - loss: 0.6449 - acc: 0.6348
 576/1202 [=============>................] - ETA: 32s - loss: 0.6395 - acc: 0.6372
 640/1202 [==============>...............] - ETA: 28s - loss: 0.6450 - acc: 0.6297
 704/1202 [================>.............] - ETA: 25s - loss: 0.6444 - acc: 0.6321
 768/1202 [==================>...........] - ETA: 22s - loss: 0.6472 - acc: 0.6328
 832/1202 [===================>..........] - ETA: 19s - loss: 0.6487 - acc: 0.6334
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6500 - acc: 0.6295
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6528 - acc: 0.6198
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6544 - acc: 0.6201 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6549 - acc: 0.6167
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6546 - acc: 0.6207
1202/1202 [==============================] - 67s 56ms/step - loss: 0.6567 - acc: 0.6173 - val_loss: 0.7236 - val_acc: 0.4925

Epoch 00007: val_acc did not improve from 0.56716
Epoch 8/10

  64/1202 [>.............................] - ETA: 1:00 - loss: 0.6426 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 1:02 - loss: 0.6524 - acc: 0.6016
 192/1202 [===>..........................] - ETA: 56s - loss: 0.6709 - acc: 0.5729 
 256/1202 [=====>........................] - ETA: 52s - loss: 0.6611 - acc: 0.5938
 320/1202 [======>.......................] - ETA: 49s - loss: 0.6798 - acc: 0.5687
 384/1202 [========>.....................] - ETA: 45s - loss: 0.6899 - acc: 0.5495
 448/1202 [==========>...................] - ETA: 41s - loss: 0.6839 - acc: 0.5558
 512/1202 [===========>..................] - ETA: 37s - loss: 0.6808 - acc: 0.5605
 576/1202 [=============>................] - ETA: 33s - loss: 0.6782 - acc: 0.5608
 640/1202 [==============>...............] - ETA: 30s - loss: 0.6676 - acc: 0.5813
 704/1202 [================>.............] - ETA: 26s - loss: 0.6634 - acc: 0.5938
 768/1202 [==================>...........] - ETA: 23s - loss: 0.6649 - acc: 0.5938
 832/1202 [===================>..........] - ETA: 20s - loss: 0.6681 - acc: 0.5925
 896/1202 [=====================>........] - ETA: 16s - loss: 0.6671 - acc: 0.5938
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6656 - acc: 0.5969
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6683 - acc: 0.5967 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6689 - acc: 0.5956
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6662 - acc: 0.5998
1202/1202 [==============================] - 69s 58ms/step - loss: 0.6653 - acc: 0.6007 - val_loss: 0.7192 - val_acc: 0.5522

Epoch 00008: val_acc did not improve from 0.56716
Epoch 9/10

  64/1202 [>.............................] - ETA: 54s - loss: 0.7080 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 58s - loss: 0.6863 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 55s - loss: 0.6935 - acc: 0.5677
 256/1202 [=====>........................] - ETA: 50s - loss: 0.6856 - acc: 0.5625
 320/1202 [======>.......................] - ETA: 48s - loss: 0.6715 - acc: 0.5813
 384/1202 [========>.....................] - ETA: 44s - loss: 0.6728 - acc: 0.5807
 448/1202 [==========>...................] - ETA: 41s - loss: 0.6684 - acc: 0.5871
 512/1202 [===========>..................] - ETA: 37s - loss: 0.6709 - acc: 0.5859
 576/1202 [=============>................] - ETA: 34s - loss: 0.6639 - acc: 0.5990
 640/1202 [==============>...............] - ETA: 30s - loss: 0.6620 - acc: 0.5984
 704/1202 [================>.............] - ETA: 27s - loss: 0.6604 - acc: 0.6051
 768/1202 [==================>...........] - ETA: 23s - loss: 0.6664 - acc: 0.6029
 832/1202 [===================>..........] - ETA: 20s - loss: 0.6657 - acc: 0.6010
 896/1202 [=====================>........] - ETA: 16s - loss: 0.6647 - acc: 0.6016
 960/1202 [======================>.......] - ETA: 13s - loss: 0.6614 - acc: 0.6042
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6617 - acc: 0.6045 
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6606 - acc: 0.6057
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6582 - acc: 0.6111
1202/1202 [==============================] - 70s 58ms/step - loss: 0.6575 - acc: 0.6115 - val_loss: 0.7221 - val_acc: 0.5373

Epoch 00009: val_acc did not improve from 0.56716
Epoch 10/10

  64/1202 [>.............................] - ETA: 1:12 - loss: 0.6346 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 1:11 - loss: 0.6568 - acc: 0.6172
 192/1202 [===>..........................] - ETA: 1:04 - loss: 0.6380 - acc: 0.6458
 256/1202 [=====>........................] - ETA: 1:01 - loss: 0.6447 - acc: 0.6484
 320/1202 [======>.......................] - ETA: 56s - loss: 0.6411 - acc: 0.6344 
 384/1202 [========>.....................] - ETA: 53s - loss: 0.6374 - acc: 0.6406
 448/1202 [==========>...................] - ETA: 48s - loss: 0.6452 - acc: 0.6362
 512/1202 [===========>..................] - ETA: 44s - loss: 0.6526 - acc: 0.6426
 576/1202 [=============>................] - ETA: 40s - loss: 0.6480 - acc: 0.6493
 640/1202 [==============>...............] - ETA: 35s - loss: 0.6522 - acc: 0.6469
 704/1202 [================>.............] - ETA: 31s - loss: 0.6496 - acc: 0.6506
 768/1202 [==================>...........] - ETA: 27s - loss: 0.6457 - acc: 0.6549
 832/1202 [===================>..........] - ETA: 23s - loss: 0.6475 - acc: 0.6526
 896/1202 [=====================>........] - ETA: 19s - loss: 0.6498 - acc: 0.6473
 960/1202 [======================>.......] - ETA: 15s - loss: 0.6488 - acc: 0.6458
1024/1202 [========================>.....] - ETA: 11s - loss: 0.6488 - acc: 0.6426
1088/1202 [==========================>...] - ETA: 6s - loss: 0.6495 - acc: 0.6369 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.6505 - acc: 0.6337
1202/1202 [==============================] - 75s 63ms/step - loss: 0.6526 - acc: 0.6281 - val_loss: 0.7788 - val_acc: 0.5075

Epoch 00010: val_acc did not improve from 0.56716
样本个数 167
样本个数 334
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 16s
128/334 [==========>...................] - ETA: 7s 
192/334 [================>.............] - ETA: 4s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 8s 25ms/step
loss: 0.7160041407196821
acc: 0.5449101796407185
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f26801a8790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f26801a8790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f2680163e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f2680163e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30adb69e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30adb69e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a581d0f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2a581d0f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a581d2f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2a581d2f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26607612d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26607612d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a581d0490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2a581d0490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26402b4c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26402b4c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2720297310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2720297310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2660566cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2660566cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a581d2ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2a581d2ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f26800ca490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f26800ca490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2660425f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2660425f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f26605a7e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f26605a7e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2640220450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2640220450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26605add10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26605add10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f26606b6090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f26606b6090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2640225b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2640225b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f26206f9bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f26206f9bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f262061e090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f262061e090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2620767e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2620767e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2640220e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2640220e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26205677d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26205677d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28407dc150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f28407dc150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2620474550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2620474550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29006e2050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f29006e2050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2680155a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2680155a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f262030a390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f262030a390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f262015c990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f262015c990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2620068490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2620068490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2620344310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2620344310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f262015c090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f262015c090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26006ec710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26006ec710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2600609e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2600609e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f26004986d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f26004986d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26005f7e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26005f7e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2600609050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2600609050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2600358d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2600358d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2600310d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2600310d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2600256d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2600256d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f260008e5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f260008e5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f26005eea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f26005eea50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f260017cc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f260017cc50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2600200490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2600200490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f25e4658f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f25e4658f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26001f2050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f26001f2050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f26002003d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f26002003d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25e46fda90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25e46fda90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f25e44ac990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f25e44ac990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f25e4418cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f25e4418cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25e43d1e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25e43d1e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f25e44ac0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f25e44ac0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25e41d8090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25e41d8090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f25e412a7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f25e412a7d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f25e437d9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f25e437d9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2680155c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2680155c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f25e412aa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f25e412aa10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25c067a4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25c067a4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f25c07cac10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f25c07cac10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f25c0687750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f25c0687750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25c04f8d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25c04f8d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f25c04f8390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f25c04f8390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25c0584ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25c0584ed0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 4:16 - loss: 0.7664 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 2:27 - loss: 0.8474 - acc: 0.5078
 192/1202 [===>..........................] - ETA: 1:51 - loss: 0.8197 - acc: 0.4896
 256/1202 [=====>........................] - ETA: 1:30 - loss: 0.8031 - acc: 0.4805
 320/1202 [======>.......................] - ETA: 1:16 - loss: 0.7760 - acc: 0.5156
 384/1202 [========>.....................] - ETA: 1:06 - loss: 0.7414 - acc: 0.5469
 448/1202 [==========>...................] - ETA: 57s - loss: 0.7272 - acc: 0.5469 
 512/1202 [===========>..................] - ETA: 51s - loss: 0.7226 - acc: 0.5469
 576/1202 [=============>................] - ETA: 45s - loss: 0.7151 - acc: 0.5608
 640/1202 [==============>...............] - ETA: 39s - loss: 0.7090 - acc: 0.5703
 704/1202 [================>.............] - ETA: 33s - loss: 0.7076 - acc: 0.5724
 768/1202 [==================>...........] - ETA: 29s - loss: 0.7023 - acc: 0.5729
 832/1202 [===================>..........] - ETA: 24s - loss: 0.7046 - acc: 0.5697
 896/1202 [=====================>........] - ETA: 19s - loss: 0.7048 - acc: 0.5703
 960/1202 [======================>.......] - ETA: 15s - loss: 0.7098 - acc: 0.5687
1024/1202 [========================>.....] - ETA: 11s - loss: 0.7065 - acc: 0.5684
1088/1202 [==========================>...] - ETA: 7s - loss: 0.7068 - acc: 0.5699 
1152/1202 [===========================>..] - ETA: 3s - loss: 0.7062 - acc: 0.5729
1202/1202 [==============================] - 79s 66ms/step - loss: 0.7065 - acc: 0.5732 - val_loss: 0.7654 - val_acc: 0.5224

Epoch 00001: val_acc improved from -inf to 0.52239, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window20/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 49s - loss: 0.6426 - acc: 0.6719
 128/1202 [==>...........................] - ETA: 44s - loss: 0.6891 - acc: 0.5859
 192/1202 [===>..........................] - ETA: 41s - loss: 0.6837 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 39s - loss: 0.6959 - acc: 0.5859
 320/1202 [======>.......................] - ETA: 36s - loss: 0.6899 - acc: 0.5906
 384/1202 [========>.....................] - ETA: 34s - loss: 0.6932 - acc: 0.6016
 448/1202 [==========>...................] - ETA: 32s - loss: 0.6899 - acc: 0.6049
 512/1202 [===========>..................] - ETA: 29s - loss: 0.6922 - acc: 0.5977
 576/1202 [=============>................] - ETA: 26s - loss: 0.6999 - acc: 0.5833
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6999 - acc: 0.5875
 704/1202 [================>.............] - ETA: 21s - loss: 0.6973 - acc: 0.5881
 768/1202 [==================>...........] - ETA: 18s - loss: 0.6959 - acc: 0.5846
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6897 - acc: 0.5950
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6906 - acc: 0.5949
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6918 - acc: 0.5958
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6933 - acc: 0.5908 
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6951 - acc: 0.5910
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6973 - acc: 0.5877
1202/1202 [==============================] - 55s 46ms/step - loss: 0.6978 - acc: 0.5849 - val_loss: 0.7071 - val_acc: 0.5224

Epoch 00002: val_acc improved from 0.52239 to 0.52239, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window20/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1202 [>.............................] - ETA: 54s - loss: 0.6462 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 48s - loss: 0.6569 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 44s - loss: 0.6546 - acc: 0.6042
 256/1202 [=====>........................] - ETA: 41s - loss: 0.6715 - acc: 0.5742
 320/1202 [======>.......................] - ETA: 39s - loss: 0.6731 - acc: 0.5719
 384/1202 [========>.....................] - ETA: 35s - loss: 0.6758 - acc: 0.5625
 448/1202 [==========>...................] - ETA: 32s - loss: 0.6802 - acc: 0.5558
 512/1202 [===========>..................] - ETA: 29s - loss: 0.6844 - acc: 0.5586
 576/1202 [=============>................] - ETA: 27s - loss: 0.6840 - acc: 0.5573
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6848 - acc: 0.5484
 704/1202 [================>.............] - ETA: 21s - loss: 0.6843 - acc: 0.5540
 768/1202 [==================>...........] - ETA: 18s - loss: 0.6906 - acc: 0.5495
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6892 - acc: 0.5541
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6893 - acc: 0.5580
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6889 - acc: 0.5594
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6893 - acc: 0.5596 
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6913 - acc: 0.5579
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6946 - acc: 0.5556
1202/1202 [==============================] - 56s 46ms/step - loss: 0.6949 - acc: 0.5549 - val_loss: 0.6641 - val_acc: 0.5896

Epoch 00003: val_acc improved from 0.52239 to 0.58955, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window20/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1202 [>.............................] - ETA: 50s - loss: 0.5859 - acc: 0.7031
 128/1202 [==>...........................] - ETA: 45s - loss: 0.7034 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 42s - loss: 0.7125 - acc: 0.5625
 256/1202 [=====>........................] - ETA: 41s - loss: 0.7224 - acc: 0.5586
 320/1202 [======>.......................] - ETA: 38s - loss: 0.7145 - acc: 0.5625
 384/1202 [========>.....................] - ETA: 36s - loss: 0.7008 - acc: 0.5807
 448/1202 [==========>...................] - ETA: 32s - loss: 0.6939 - acc: 0.5915
 512/1202 [===========>..................] - ETA: 29s - loss: 0.6885 - acc: 0.5977
 576/1202 [=============>................] - ETA: 27s - loss: 0.6860 - acc: 0.5990
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6922 - acc: 0.5891
 704/1202 [================>.............] - ETA: 21s - loss: 0.6893 - acc: 0.5895
 768/1202 [==================>...........] - ETA: 18s - loss: 0.6858 - acc: 0.5938
 832/1202 [===================>..........] - ETA: 15s - loss: 0.6864 - acc: 0.5853
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6878 - acc: 0.5848
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6865 - acc: 0.5844
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6876 - acc: 0.5850 
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6889 - acc: 0.5827
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6945 - acc: 0.5738
1202/1202 [==============================] - 55s 46ms/step - loss: 0.6953 - acc: 0.5682 - val_loss: 0.7019 - val_acc: 0.5149

Epoch 00004: val_acc did not improve from 0.58955
Epoch 5/10

  64/1202 [>.............................] - ETA: 47s - loss: 0.6619 - acc: 0.5625
 128/1202 [==>...........................] - ETA: 45s - loss: 0.6708 - acc: 0.5234
 192/1202 [===>..........................] - ETA: 43s - loss: 0.6791 - acc: 0.5312
 256/1202 [=====>........................] - ETA: 40s - loss: 0.6859 - acc: 0.5234
 320/1202 [======>.......................] - ETA: 37s - loss: 0.6913 - acc: 0.5219
 384/1202 [========>.....................] - ETA: 34s - loss: 0.6943 - acc: 0.5234
 448/1202 [==========>...................] - ETA: 32s - loss: 0.6859 - acc: 0.5446
 512/1202 [===========>..................] - ETA: 29s - loss: 0.6820 - acc: 0.5645
 576/1202 [=============>................] - ETA: 27s - loss: 0.6826 - acc: 0.5590
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6805 - acc: 0.5609
 704/1202 [================>.............] - ETA: 21s - loss: 0.6821 - acc: 0.5582
 768/1202 [==================>...........] - ETA: 18s - loss: 0.6887 - acc: 0.5443
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6880 - acc: 0.5457
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6842 - acc: 0.5513
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6835 - acc: 0.5563
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6857 - acc: 0.5498 
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6862 - acc: 0.5496
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6834 - acc: 0.5564
1202/1202 [==============================] - 55s 46ms/step - loss: 0.6829 - acc: 0.5582 - val_loss: 0.6758 - val_acc: 0.5821

Epoch 00005: val_acc did not improve from 0.58955
Epoch 6/10

  64/1202 [>.............................] - ETA: 52s - loss: 0.7202 - acc: 0.6094
 128/1202 [==>...........................] - ETA: 47s - loss: 0.7247 - acc: 0.5703
 192/1202 [===>..........................] - ETA: 45s - loss: 0.7016 - acc: 0.5729
 256/1202 [=====>........................] - ETA: 43s - loss: 0.6921 - acc: 0.5742
 320/1202 [======>.......................] - ETA: 41s - loss: 0.6962 - acc: 0.5719
 384/1202 [========>.....................] - ETA: 37s - loss: 0.7026 - acc: 0.5599
 448/1202 [==========>...................] - ETA: 33s - loss: 0.6993 - acc: 0.5625
 512/1202 [===========>..................] - ETA: 31s - loss: 0.6938 - acc: 0.5645
 576/1202 [=============>................] - ETA: 27s - loss: 0.6958 - acc: 0.5625
 640/1202 [==============>...............] - ETA: 24s - loss: 0.6907 - acc: 0.5734
 704/1202 [================>.............] - ETA: 22s - loss: 0.6940 - acc: 0.5639
 768/1202 [==================>...........] - ETA: 19s - loss: 0.6907 - acc: 0.5664
 832/1202 [===================>..........] - ETA: 16s - loss: 0.6884 - acc: 0.5733
 896/1202 [=====================>........] - ETA: 13s - loss: 0.6879 - acc: 0.5714
 960/1202 [======================>.......] - ETA: 10s - loss: 0.6884 - acc: 0.5677
1024/1202 [========================>.....] - ETA: 7s - loss: 0.6856 - acc: 0.5742 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6851 - acc: 0.5744
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6878 - acc: 0.5712
1202/1202 [==============================] - 56s 46ms/step - loss: 0.6878 - acc: 0.5691 - val_loss: 0.6828 - val_acc: 0.5746

Epoch 00006: val_acc did not improve from 0.58955
Epoch 7/10

  64/1202 [>.............................] - ETA: 49s - loss: 0.7012 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 46s - loss: 0.7082 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 41s - loss: 0.6972 - acc: 0.5521
 256/1202 [=====>........................] - ETA: 40s - loss: 0.6991 - acc: 0.5586
 320/1202 [======>.......................] - ETA: 39s - loss: 0.6941 - acc: 0.5656
 384/1202 [========>.....................] - ETA: 38s - loss: 0.6882 - acc: 0.5755
 448/1202 [==========>...................] - ETA: 36s - loss: 0.6857 - acc: 0.5692
 512/1202 [===========>..................] - ETA: 33s - loss: 0.6886 - acc: 0.5625
 576/1202 [=============>................] - ETA: 30s - loss: 0.6828 - acc: 0.5729
 640/1202 [==============>...............] - ETA: 27s - loss: 0.6871 - acc: 0.5625
 704/1202 [================>.............] - ETA: 24s - loss: 0.6854 - acc: 0.5625
 768/1202 [==================>...........] - ETA: 21s - loss: 0.6866 - acc: 0.5625
 832/1202 [===================>..........] - ETA: 18s - loss: 0.6840 - acc: 0.5709
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6815 - acc: 0.5703
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6823 - acc: 0.5698
1024/1202 [========================>.....] - ETA: 8s - loss: 0.6791 - acc: 0.5752 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6773 - acc: 0.5763
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6776 - acc: 0.5747
1202/1202 [==============================] - 64s 53ms/step - loss: 0.6803 - acc: 0.5707 - val_loss: 0.6811 - val_acc: 0.5373

Epoch 00007: val_acc did not improve from 0.58955
Epoch 8/10

  64/1202 [>.............................] - ETA: 58s - loss: 0.5937 - acc: 0.7031
 128/1202 [==>...........................] - ETA: 53s - loss: 0.6286 - acc: 0.6719
 192/1202 [===>..........................] - ETA: 52s - loss: 0.6436 - acc: 0.6354
 256/1202 [=====>........................] - ETA: 48s - loss: 0.6470 - acc: 0.6289
 320/1202 [======>.......................] - ETA: 45s - loss: 0.6384 - acc: 0.6500
 384/1202 [========>.....................] - ETA: 41s - loss: 0.6629 - acc: 0.6094
 448/1202 [==========>...................] - ETA: 38s - loss: 0.6658 - acc: 0.6049
 512/1202 [===========>..................] - ETA: 34s - loss: 0.6661 - acc: 0.6094
 576/1202 [=============>................] - ETA: 31s - loss: 0.6640 - acc: 0.6076
 640/1202 [==============>...............] - ETA: 28s - loss: 0.6649 - acc: 0.6047
 704/1202 [================>.............] - ETA: 25s - loss: 0.6629 - acc: 0.6094
 768/1202 [==================>...........] - ETA: 22s - loss: 0.6598 - acc: 0.6107
 832/1202 [===================>..........] - ETA: 19s - loss: 0.6599 - acc: 0.6130
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6624 - acc: 0.6049
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6617 - acc: 0.6073
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6626 - acc: 0.6035 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6629 - acc: 0.6039
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6622 - acc: 0.6076
1202/1202 [==============================] - 66s 55ms/step - loss: 0.6624 - acc: 0.6073 - val_loss: 0.6718 - val_acc: 0.6045

Epoch 00008: val_acc improved from 0.58955 to 0.60448, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window20/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 9/10

  64/1202 [>.............................] - ETA: 1:03 - loss: 0.6927 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 57s - loss: 0.6890 - acc: 0.5625 
 192/1202 [===>..........................] - ETA: 55s - loss: 0.6852 - acc: 0.5677
 256/1202 [=====>........................] - ETA: 50s - loss: 0.6732 - acc: 0.5820
 320/1202 [======>.......................] - ETA: 46s - loss: 0.6702 - acc: 0.5906
 384/1202 [========>.....................] - ETA: 42s - loss: 0.6739 - acc: 0.5807
 448/1202 [==========>...................] - ETA: 39s - loss: 0.6736 - acc: 0.5826
 512/1202 [===========>..................] - ETA: 35s - loss: 0.6717 - acc: 0.5859
 576/1202 [=============>................] - ETA: 32s - loss: 0.6749 - acc: 0.5764
 640/1202 [==============>...............] - ETA: 29s - loss: 0.6719 - acc: 0.5813
 704/1202 [================>.............] - ETA: 25s - loss: 0.6735 - acc: 0.5795
 768/1202 [==================>...........] - ETA: 22s - loss: 0.6769 - acc: 0.5768
 832/1202 [===================>..........] - ETA: 19s - loss: 0.6718 - acc: 0.5841
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6733 - acc: 0.5804
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6721 - acc: 0.5844
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6748 - acc: 0.5801 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6766 - acc: 0.5735
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6738 - acc: 0.5773
1202/1202 [==============================] - 65s 54ms/step - loss: 0.6736 - acc: 0.5790 - val_loss: 0.6784 - val_acc: 0.5597

Epoch 00009: val_acc did not improve from 0.60448
Epoch 10/10

  64/1202 [>.............................] - ETA: 56s - loss: 0.6467 - acc: 0.5469
 128/1202 [==>...........................] - ETA: 57s - loss: 0.6629 - acc: 0.5625
 192/1202 [===>..........................] - ETA: 53s - loss: 0.6626 - acc: 0.5729
 256/1202 [=====>........................] - ETA: 49s - loss: 0.6788 - acc: 0.5664
 320/1202 [======>.......................] - ETA: 45s - loss: 0.6849 - acc: 0.5625
 384/1202 [========>.....................] - ETA: 41s - loss: 0.6846 - acc: 0.5625
 448/1202 [==========>...................] - ETA: 38s - loss: 0.6814 - acc: 0.5714
 512/1202 [===========>..................] - ETA: 35s - loss: 0.6815 - acc: 0.5703
 576/1202 [=============>................] - ETA: 32s - loss: 0.6772 - acc: 0.5764
 640/1202 [==============>...............] - ETA: 28s - loss: 0.6705 - acc: 0.5875
 704/1202 [================>.............] - ETA: 25s - loss: 0.6672 - acc: 0.5909
 768/1202 [==================>...........] - ETA: 22s - loss: 0.6674 - acc: 0.5872
 832/1202 [===================>..........] - ETA: 19s - loss: 0.6684 - acc: 0.5913
 896/1202 [=====================>........] - ETA: 15s - loss: 0.6679 - acc: 0.5915
 960/1202 [======================>.......] - ETA: 12s - loss: 0.6694 - acc: 0.5885
1024/1202 [========================>.....] - ETA: 9s - loss: 0.6709 - acc: 0.5850 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.6732 - acc: 0.5836
1152/1202 [===========================>..] - ETA: 2s - loss: 0.6721 - acc: 0.5868
1202/1202 [==============================] - 66s 55ms/step - loss: 0.6724 - acc: 0.5857 - val_loss: 0.6848 - val_acc: 0.5597

Epoch 00010: val_acc did not improve from 0.60448
样本个数 167
样本个数 334
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 19s
128/334 [==========>...................] - ETA: 9s 
192/334 [================>.............] - ETA: 5s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 10s 29ms/step
loss: 0.6874648857259464
acc: 0.5568862275449101
样本个数 668
样本个数 1336
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f252064ee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f252064ee50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f2520653410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f2520653410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30b6af4e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f30b6af4e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27a03fb1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f27a03fb1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28e06fa490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f28e06fa490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28e0772a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f28e0772a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27a03fba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f27a03fba50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2520534a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2520534a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f252041acd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f252041acd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2520418490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f2520418490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25201da990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f25201da990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f25204eeb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f25204eeb90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2520327790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2520327790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f25200d2390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f25200d2390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24e0641f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24e0641f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f252030f390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f252030f390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f252033e390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f252033e390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f252030b510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f252030b510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24e04e00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24e04e00d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24e0401110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24e0401110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24e03a4210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24e03a4210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24e0641f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24e0641f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24e03a7e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24e03a7e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24e0197610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24e0197610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24e0093850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24e0093850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24e0266790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24e0266790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24e0356790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24e0356790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24e0385d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24e0385d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24c060eb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24c060eb50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24c05c7690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24c05c7690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24e003f150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24e003f150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24e0188690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24e0188690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24c051d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24c051d3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24c040f090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24c040f090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24c02e8a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24c02e8a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24c0300690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24c0300690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24c064b590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24c064b590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24c0349b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24c0349b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24c0212d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24c0212d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24a07e7b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24a07e7b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a0783d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a0783d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24c02e8a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24c02e8a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a07e2ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a07e2ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24a049c050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24a049c050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24a0484e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24a0484e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a04a6a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a04a6a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24a049ce90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24a049ce90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a04935d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a04935d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24a0141390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24a0141390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24a033a990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24a033a990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a01dc8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a01dc8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24a069f390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f24a069f390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a0105fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a0105fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24a0110f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f24a0110f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24a00a9650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f24a00a9650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a0146190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a0146190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2484669f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2484669f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a0130610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f24a0130610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2484309050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f2484309050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f248432b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f248432b050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2484362190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f2484362190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2484385a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f2484385a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f248431cf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f248431cf90>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1202 samples, validate on 134 samples
Epoch 1/10

  64/1202 [>.............................] - ETA: 3:32 - loss: 0.7696 - acc: 0.4531
 128/1202 [==>...........................] - ETA: 1:58 - loss: 0.8951 - acc: 0.4062
 192/1202 [===>..........................] - ETA: 1:25 - loss: 0.8389 - acc: 0.4375
 256/1202 [=====>........................] - ETA: 1:08 - loss: 0.8036 - acc: 0.4648
 320/1202 [======>.......................] - ETA: 57s - loss: 0.7895 - acc: 0.4719 
 384/1202 [========>.....................] - ETA: 49s - loss: 0.7743 - acc: 0.4922
 448/1202 [==========>...................] - ETA: 42s - loss: 0.7620 - acc: 0.4933
 512/1202 [===========>..................] - ETA: 36s - loss: 0.7551 - acc: 0.5098
 576/1202 [=============>................] - ETA: 32s - loss: 0.7517 - acc: 0.5087
 640/1202 [==============>...............] - ETA: 27s - loss: 0.7480 - acc: 0.5109
 704/1202 [================>.............] - ETA: 24s - loss: 0.7477 - acc: 0.5170
 768/1202 [==================>...........] - ETA: 20s - loss: 0.7491 - acc: 0.5195
 832/1202 [===================>..........] - ETA: 17s - loss: 0.7419 - acc: 0.5240
 896/1202 [=====================>........] - ETA: 14s - loss: 0.7409 - acc: 0.5234
 960/1202 [======================>.......] - ETA: 10s - loss: 0.7382 - acc: 0.5229
1024/1202 [========================>.....] - ETA: 7s - loss: 0.7385 - acc: 0.5166 
1088/1202 [==========================>...] - ETA: 5s - loss: 0.7371 - acc: 0.5175
1152/1202 [===========================>..] - ETA: 2s - loss: 0.7360 - acc: 0.5148
1202/1202 [==============================] - 56s 47ms/step - loss: 0.7337 - acc: 0.5166 - val_loss: 0.7035 - val_acc: 0.5522

Epoch 00001: val_acc improved from -inf to 0.55224, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window21/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1202 [>.............................] - ETA: 45s - loss: 0.6554 - acc: 0.6719
 128/1202 [==>...........................] - ETA: 42s - loss: 0.6797 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 39s - loss: 0.7022 - acc: 0.5208
 256/1202 [=====>........................] - ETA: 35s - loss: 0.6898 - acc: 0.5391
 320/1202 [======>.......................] - ETA: 33s - loss: 0.6882 - acc: 0.5250
 384/1202 [========>.....................] - ETA: 30s - loss: 0.6899 - acc: 0.5312
 448/1202 [==========>...................] - ETA: 27s - loss: 0.6876 - acc: 0.5357
 512/1202 [===========>..................] - ETA: 25s - loss: 0.6868 - acc: 0.5430
 576/1202 [=============>................] - ETA: 23s - loss: 0.6845 - acc: 0.5451
 640/1202 [==============>...............] - ETA: 20s - loss: 0.6843 - acc: 0.5484
 704/1202 [================>.............] - ETA: 18s - loss: 0.6882 - acc: 0.5511
 768/1202 [==================>...........] - ETA: 16s - loss: 0.6894 - acc: 0.5508
 832/1202 [===================>..........] - ETA: 13s - loss: 0.6962 - acc: 0.5373
 896/1202 [=====================>........] - ETA: 11s - loss: 0.6955 - acc: 0.5446
 960/1202 [======================>.......] - ETA: 8s - loss: 0.6947 - acc: 0.5479 
1024/1202 [========================>.....] - ETA: 6s - loss: 0.6926 - acc: 0.5508
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6918 - acc: 0.5506
1152/1202 [===========================>..] - ETA: 1s - loss: 0.6939 - acc: 0.5469
1202/1202 [==============================] - 47s 39ms/step - loss: 0.6933 - acc: 0.5483 - val_loss: 0.7562 - val_acc: 0.4925

Epoch 00002: val_acc did not improve from 0.55224
Epoch 3/10

  64/1202 [>.............................] - ETA: 45s - loss: 0.7324 - acc: 0.4531
 128/1202 [==>...........................] - ETA: 40s - loss: 0.6994 - acc: 0.5312
 192/1202 [===>..........................] - ETA: 38s - loss: 0.6877 - acc: 0.5573
 256/1202 [=====>........................] - ETA: 36s - loss: 0.6868 - acc: 0.5664
 320/1202 [======>.......................] - ETA: 33s - loss: 0.6790 - acc: 0.5687
 384/1202 [========>.....................] - ETA: 31s - loss: 0.6708 - acc: 0.5885
 448/1202 [==========>...................] - ETA: 28s - loss: 0.6748 - acc: 0.5871
 512/1202 [===========>..................] - ETA: 26s - loss: 0.6739 - acc: 0.5859
 576/1202 [=============>................] - ETA: 23s - loss: 0.6706 - acc: 0.5920
 640/1202 [==============>...............] - ETA: 21s - loss: 0.6739 - acc: 0.5906
 704/1202 [================>.............] - ETA: 18s - loss: 0.6754 - acc: 0.5909
 768/1202 [==================>...........] - ETA: 16s - loss: 0.6749 - acc: 0.5990
 832/1202 [===================>..........] - ETA: 13s - loss: 0.6792 - acc: 0.5925
 896/1202 [=====================>........] - ETA: 11s - loss: 0.6792 - acc: 0.5938
 960/1202 [======================>.......] - ETA: 9s - loss: 0.6788 - acc: 0.5927 
1024/1202 [========================>.....] - ETA: 6s - loss: 0.6767 - acc: 0.5928
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6762 - acc: 0.5928
1152/1202 [===========================>..] - ETA: 1s - loss: 0.6784 - acc: 0.5894
1202/1202 [==============================] - 47s 39ms/step - loss: 0.6790 - acc: 0.5865 - val_loss: 0.7179 - val_acc: 0.5000

Epoch 00003: val_acc did not improve from 0.55224
Epoch 4/10

  64/1202 [>.............................] - ETA: 41s - loss: 0.6822 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 40s - loss: 0.6733 - acc: 0.5469
 192/1202 [===>..........................] - ETA: 37s - loss: 0.6683 - acc: 0.5521
 256/1202 [=====>........................] - ETA: 34s - loss: 0.6743 - acc: 0.5352
 320/1202 [======>.......................] - ETA: 32s - loss: 0.6711 - acc: 0.5563
 384/1202 [========>.....................] - ETA: 30s - loss: 0.6768 - acc: 0.5547
 448/1202 [==========>...................] - ETA: 27s - loss: 0.6722 - acc: 0.5670
 512/1202 [===========>..................] - ETA: 25s - loss: 0.6733 - acc: 0.5684
 576/1202 [=============>................] - ETA: 22s - loss: 0.6733 - acc: 0.5694
 640/1202 [==============>...............] - ETA: 20s - loss: 0.6691 - acc: 0.5781
 704/1202 [================>.............] - ETA: 18s - loss: 0.6710 - acc: 0.5795
 768/1202 [==================>...........] - ETA: 15s - loss: 0.6719 - acc: 0.5781
 832/1202 [===================>..........] - ETA: 13s - loss: 0.6702 - acc: 0.5817
 896/1202 [=====================>........] - ETA: 11s - loss: 0.6695 - acc: 0.5826
 960/1202 [======================>.......] - ETA: 8s - loss: 0.6674 - acc: 0.5865 
1024/1202 [========================>.....] - ETA: 6s - loss: 0.6680 - acc: 0.5869
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6693 - acc: 0.5864
1152/1202 [===========================>..] - ETA: 1s - loss: 0.6696 - acc: 0.5868
1202/1202 [==============================] - 46s 38ms/step - loss: 0.6711 - acc: 0.5857 - val_loss: 0.6973 - val_acc: 0.5373

Epoch 00004: val_acc did not improve from 0.55224
Epoch 5/10

  64/1202 [>.............................] - ETA: 39s - loss: 0.6349 - acc: 0.6250
 128/1202 [==>...........................] - ETA: 39s - loss: 0.6581 - acc: 0.6250
 192/1202 [===>..........................] - ETA: 37s - loss: 0.6800 - acc: 0.5990
 256/1202 [=====>........................] - ETA: 34s - loss: 0.6931 - acc: 0.5938
 320/1202 [======>.......................] - ETA: 32s - loss: 0.6931 - acc: 0.5938
 384/1202 [========>.....................] - ETA: 29s - loss: 0.6828 - acc: 0.5990
 448/1202 [==========>...................] - ETA: 28s - loss: 0.6866 - acc: 0.5938
 512/1202 [===========>..................] - ETA: 25s - loss: 0.6875 - acc: 0.5918
 576/1202 [=============>................] - ETA: 23s - loss: 0.6882 - acc: 0.5903
 640/1202 [==============>...............] - ETA: 20s - loss: 0.6874 - acc: 0.5906
 704/1202 [================>.............] - ETA: 18s - loss: 0.6864 - acc: 0.5909
 768/1202 [==================>...........] - ETA: 15s - loss: 0.6847 - acc: 0.5859
 832/1202 [===================>..........] - ETA: 13s - loss: 0.6869 - acc: 0.5817
 896/1202 [=====================>........] - ETA: 11s - loss: 0.6872 - acc: 0.5815
 960/1202 [======================>.......] - ETA: 8s - loss: 0.6844 - acc: 0.5844 
1024/1202 [========================>.....] - ETA: 6s - loss: 0.6818 - acc: 0.5869
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6798 - acc: 0.5901
1152/1202 [===========================>..] - ETA: 1s - loss: 0.6809 - acc: 0.5894
1202/1202 [==============================] - 47s 39ms/step - loss: 0.6796 - acc: 0.5907 - val_loss: 0.7112 - val_acc: 0.5448

Epoch 00005: val_acc did not improve from 0.55224
Epoch 6/10

  64/1202 [>.............................] - ETA: 41s - loss: 0.6955 - acc: 0.4844
 128/1202 [==>...........................] - ETA: 38s - loss: 0.7001 - acc: 0.5078
 192/1202 [===>..........................] - ETA: 36s - loss: 0.6866 - acc: 0.5365
 256/1202 [=====>........................] - ETA: 34s - loss: 0.6862 - acc: 0.5469
 320/1202 [======>.......................] - ETA: 31s - loss: 0.6781 - acc: 0.5719
 384/1202 [========>.....................] - ETA: 29s - loss: 0.6780 - acc: 0.5651
 448/1202 [==========>...................] - ETA: 27s - loss: 0.6710 - acc: 0.5714
 512/1202 [===========>..................] - ETA: 24s - loss: 0.6744 - acc: 0.5762
 576/1202 [=============>................] - ETA: 22s - loss: 0.6818 - acc: 0.5625
 640/1202 [==============>...............] - ETA: 20s - loss: 0.6800 - acc: 0.5672
 704/1202 [================>.............] - ETA: 18s - loss: 0.6832 - acc: 0.5625
 768/1202 [==================>...........] - ETA: 15s - loss: 0.6871 - acc: 0.5547
 832/1202 [===================>..........] - ETA: 13s - loss: 0.6863 - acc: 0.5625
 896/1202 [=====================>........] - ETA: 11s - loss: 0.6875 - acc: 0.5580
 960/1202 [======================>.......] - ETA: 8s - loss: 0.6892 - acc: 0.5521 
1024/1202 [========================>.....] - ETA: 6s - loss: 0.6915 - acc: 0.5498
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6917 - acc: 0.5524
1152/1202 [===========================>..] - ETA: 1s - loss: 0.6898 - acc: 0.5556
1202/1202 [==============================] - 46s 38ms/step - loss: 0.6905 - acc: 0.5557 - val_loss: 0.7138 - val_acc: 0.5373

Epoch 00006: val_acc did not improve from 0.55224
Epoch 7/10

  64/1202 [>.............................] - ETA: 40s - loss: 0.6772 - acc: 0.5156
 128/1202 [==>...........................] - ETA: 38s - loss: 0.6672 - acc: 0.5781
 192/1202 [===>..........................] - ETA: 36s - loss: 0.6527 - acc: 0.5990
 256/1202 [=====>........................] - ETA: 33s - loss: 0.6616 - acc: 0.6016
 320/1202 [======>.......................] - ETA: 31s - loss: 0.6673 - acc: 0.5938
 384/1202 [========>.....................] - ETA: 29s - loss: 0.6683 - acc: 0.5911
 448/1202 [==========>...................] - ETA: 27s - loss: 0.6714 - acc: 0.5826
 512/1202 [===========>..................] - ETA: 25s - loss: 0.6684 - acc: 0.5879
 576/1202 [=============>................] - ETA: 22s - loss: 0.6771 - acc: 0.5851
 640/1202 [==============>...............] - ETA: 20s - loss: 0.6798 - acc: 0.5844
 704/1202 [================>.............] - ETA: 18s - loss: 0.6789 - acc: 0.5838
 768/1202 [==================>...........] - ETA: 15s - loss: 0.6765 - acc: 0.5820
 832/1202 [===================>..........] - ETA: 13s - loss: 0.6735 - acc: 0.5841
 896/1202 [=====================>........] - ETA: 11s - loss: 0.6727 - acc: 0.5848
 960/1202 [======================>.......] - ETA: 8s - loss: 0.6713 - acc: 0.5906 
1024/1202 [========================>.....] - ETA: 6s - loss: 0.6701 - acc: 0.5938
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6698 - acc: 0.5965
1152/1202 [===========================>..] - ETA: 1s - loss: 0.6698 - acc: 0.5972
1202/1202 [==============================] - 46s 38ms/step - loss: 0.6714 - acc: 0.5915 - val_loss: 0.7255 - val_acc: 0.5448

Epoch 00007: val_acc did not improve from 0.55224
Epoch 8/10

  64/1202 [>.............................] - ETA: 41s - loss: 0.6853 - acc: 0.6562
 128/1202 [==>...........................] - ETA: 41s - loss: 0.6764 - acc: 0.6562
 192/1202 [===>..........................] - ETA: 37s - loss: 0.6716 - acc: 0.6458
 256/1202 [=====>........................] - ETA: 34s - loss: 0.6753 - acc: 0.6250
 320/1202 [======>.......................] - ETA: 32s - loss: 0.6729 - acc: 0.6250
 384/1202 [========>.....................] - ETA: 29s - loss: 0.6803 - acc: 0.6094
 448/1202 [==========>...................] - ETA: 27s - loss: 0.6802 - acc: 0.6027
 512/1202 [===========>..................] - ETA: 25s - loss: 0.6792 - acc: 0.5918
 576/1202 [=============>................] - ETA: 22s - loss: 0.6778 - acc: 0.5903
 640/1202 [==============>...............] - ETA: 20s - loss: 0.6756 - acc: 0.5859
 704/1202 [================>.............] - ETA: 18s - loss: 0.6732 - acc: 0.5866
 768/1202 [==================>...........] - ETA: 15s - loss: 0.6742 - acc: 0.5833
 832/1202 [===================>..........] - ETA: 13s - loss: 0.6734 - acc: 0.5841
 896/1202 [=====================>........] - ETA: 11s - loss: 0.6742 - acc: 0.5826
 960/1202 [======================>.......] - ETA: 8s - loss: 0.6691 - acc: 0.5906 
1024/1202 [========================>.....] - ETA: 6s - loss: 0.6696 - acc: 0.5889
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6726 - acc: 0.5910
1152/1202 [===========================>..] - ETA: 1s - loss: 0.6722 - acc: 0.5938
1202/1202 [==============================] - 46s 38ms/step - loss: 0.6738 - acc: 0.5907 - val_loss: 0.6994 - val_acc: 0.5522

Epoch 00008: val_acc did not improve from 0.55224
Epoch 9/10

  64/1202 [>.............................] - ETA: 42s - loss: 0.7247 - acc: 0.5000
 128/1202 [==>...........................] - ETA: 38s - loss: 0.6801 - acc: 0.5938
 192/1202 [===>..........................] - ETA: 36s - loss: 0.6837 - acc: 0.5833
 256/1202 [=====>........................] - ETA: 34s - loss: 0.6927 - acc: 0.5938
 320/1202 [======>.......................] - ETA: 31s - loss: 0.6797 - acc: 0.6031
 384/1202 [========>.....................] - ETA: 29s - loss: 0.6788 - acc: 0.6146
 448/1202 [==========>...................] - ETA: 27s - loss: 0.6811 - acc: 0.6027
 512/1202 [===========>..................] - ETA: 24s - loss: 0.6862 - acc: 0.5977
 576/1202 [=============>................] - ETA: 22s - loss: 0.6921 - acc: 0.5868
 640/1202 [==============>...............] - ETA: 20s - loss: 0.6941 - acc: 0.5828
 704/1202 [================>.............] - ETA: 18s - loss: 0.6959 - acc: 0.5810
 768/1202 [==================>...........] - ETA: 15s - loss: 0.6910 - acc: 0.5846
 832/1202 [===================>..........] - ETA: 13s - loss: 0.6866 - acc: 0.5889
 896/1202 [=====================>........] - ETA: 11s - loss: 0.6808 - acc: 0.5971
 960/1202 [======================>.......] - ETA: 8s - loss: 0.6836 - acc: 0.5948 
1024/1202 [========================>.....] - ETA: 6s - loss: 0.6877 - acc: 0.5869
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6869 - acc: 0.5846
1152/1202 [===========================>..] - ETA: 1s - loss: 0.6841 - acc: 0.5929
1202/1202 [==============================] - 46s 38ms/step - loss: 0.6829 - acc: 0.5973 - val_loss: 0.7090 - val_acc: 0.5522

Epoch 00009: val_acc improved from 0.55224 to 0.55224, saving model to /data/lyli/Pancreatic-adenocarcinoma/PAAD-model/Seq_feature_exact/window21/checkpoints/final_seq_model/PAAD_seq_model_2_mer.hdf5
Epoch 10/10

  64/1202 [>.............................] - ETA: 40s - loss: 0.7378 - acc: 0.5312
 128/1202 [==>...........................] - ETA: 38s - loss: 0.6935 - acc: 0.5625
 192/1202 [===>..........................] - ETA: 35s - loss: 0.6901 - acc: 0.5885
 256/1202 [=====>........................] - ETA: 33s - loss: 0.6815 - acc: 0.6055
 320/1202 [======>.......................] - ETA: 31s - loss: 0.6871 - acc: 0.5844
 384/1202 [========>.....................] - ETA: 28s - loss: 0.6916 - acc: 0.5807
 448/1202 [==========>...................] - ETA: 26s - loss: 0.6897 - acc: 0.5737
 512/1202 [===========>..................] - ETA: 24s - loss: 0.6867 - acc: 0.5723
 576/1202 [=============>................] - ETA: 22s - loss: 0.6821 - acc: 0.5764
 640/1202 [==============>...............] - ETA: 20s - loss: 0.6775 - acc: 0.5875
 704/1202 [================>.............] - ETA: 17s - loss: 0.6754 - acc: 0.5895
 768/1202 [==================>...........] - ETA: 15s - loss: 0.6734 - acc: 0.5924
 832/1202 [===================>..........] - ETA: 13s - loss: 0.6717 - acc: 0.5962
 896/1202 [=====================>........] - ETA: 11s - loss: 0.6723 - acc: 0.5960
 960/1202 [======================>.......] - ETA: 8s - loss: 0.6738 - acc: 0.5927 
1024/1202 [========================>.....] - ETA: 6s - loss: 0.6740 - acc: 0.5898
1088/1202 [==========================>...] - ETA: 4s - loss: 0.6731 - acc: 0.5901
1152/1202 [===========================>..] - ETA: 1s - loss: 0.6738 - acc: 0.5903
1202/1202 [==============================] - 46s 38ms/step - loss: 0.6720 - acc: 0.5932 - val_loss: 0.7457 - val_acc: 0.5000

Epoch 00010: val_acc did not improve from 0.55224
样本个数 167
样本个数 334
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/334 [====>.........................] - ETA: 18s
128/334 [==========>...................] - ETA: 8s 
192/334 [================>.............] - ETA: 4s
256/334 [=====================>........] - ETA: 2s
320/334 [===========================>..] - ETA: 0s
334/334 [==============================] - 8s 24ms/step
loss: 0.70359266089822
acc: 0.5508982046635565
