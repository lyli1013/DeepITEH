nohup: ignoring input
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
样本个数 5185
样本个数 10370
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4ec4546310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4ec4546310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f4f98ccf750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f4f98ccf750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4fa965d790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4fa965d790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f98c65e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f98c65e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4fa0f54210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4fa0f54210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f986ea690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f986ea690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f986eab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f986eab50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98d39310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98d39310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ec44c83d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ec44c83d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ec4319250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ec4319250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec415dd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec415dd10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f98c33210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f98c33210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec411b690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec411b690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ec4079c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ec4079c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ec3f63910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ec3f63910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec3e6e5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec3e6e5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ec4071b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ec4071b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec3ff4b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec3ff4b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ec3fe5cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ec3fe5cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ebbc7f610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ebbc7f610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec3d6ee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec3d6ee50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ec3fe5d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ec3fe5d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ebbc28450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ebbc28450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ebbb14bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ebbb14bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ebbb14190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ebbb14190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ebbc82dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ebbc82dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ebb8367d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ebb8367d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec3d83fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec3d83fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ebb735a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ebb735a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ebb63c210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ebb63c210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ebb994550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ebb994550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ebb748c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ebb748c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ebb637b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ebb637b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ebb648310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ebb648310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eb32d8790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eb32d8790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ebb5e8f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ebb5e8f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ebb6480d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ebb6480d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb3365cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb3365cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eb3356910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eb3356910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eb2ff3e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eb2ff3e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb30849d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb30849d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eb30d5710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eb30d5710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb3202050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb3202050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eb2dee290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eb2dee290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eaac924d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eaac924d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb2df2d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb2df2d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eb2dee5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eb2dee5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec3ff2d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ec3ff2d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eaaaa02d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eaaaa02d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eaaa328d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eaaa328d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eaaab8c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eaaab8c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eb2e3a490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eb2e3a490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eaacbf650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eaacbf650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eaa995c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eaa995c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eaa650190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eaa650190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eaa7ac7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eaa7ac7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eaa995390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eaa995390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eaaa8c350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eaaa8c350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ea248fe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ea248fe10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ea236be50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ea236be50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eaa802f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eaa802f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eaa569250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eaa569250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ea246e2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ea246e2d0>>: AttributeError: module 'gast' has no attribute 'Str'
2022-11-25 21:06:03.175608: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2022-11-25 21:06:03.212727: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2022-11-25 21:06:03.261106: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5581fc55f270 executing computations on platform Host. Devices:
2022-11-25 21:06:03.261215: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2022-11-25 21:06:03.732407: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 15:14 - loss: 0.8632 - acc: 0.4531
 128/9333 [..............................] - ETA: 10:38 - loss: 0.8348 - acc: 0.4766
 192/9333 [..............................] - ETA: 9:17 - loss: 0.7996 - acc: 0.4740 
 256/9333 [..............................] - ETA: 8:57 - loss: 0.7794 - acc: 0.4922
 320/9333 [>.............................] - ETA: 8:25 - loss: 0.7628 - acc: 0.5000
 384/9333 [>.............................] - ETA: 8:06 - loss: 0.7613 - acc: 0.5026
 448/9333 [>.............................] - ETA: 7:50 - loss: 0.7559 - acc: 0.5022
 512/9333 [>.............................] - ETA: 7:45 - loss: 0.7524 - acc: 0.5078
 576/9333 [>.............................] - ETA: 7:31 - loss: 0.7445 - acc: 0.5122
 640/9333 [=>............................] - ETA: 7:23 - loss: 0.7427 - acc: 0.5156
 704/9333 [=>............................] - ETA: 7:17 - loss: 0.7439 - acc: 0.5156
 768/9333 [=>............................] - ETA: 7:12 - loss: 0.7432 - acc: 0.5156
 832/9333 [=>............................] - ETA: 7:05 - loss: 0.7416 - acc: 0.5204
 896/9333 [=>............................] - ETA: 6:55 - loss: 0.7414 - acc: 0.5179
 960/9333 [==>...........................] - ETA: 6:45 - loss: 0.7407 - acc: 0.5167
1024/9333 [==>...........................] - ETA: 6:37 - loss: 0.7385 - acc: 0.5166
1088/9333 [==>...........................] - ETA: 6:32 - loss: 0.7382 - acc: 0.5156
1152/9333 [==>...........................] - ETA: 6:30 - loss: 0.7367 - acc: 0.5165
1216/9333 [==>...........................] - ETA: 6:25 - loss: 0.7364 - acc: 0.5123
1280/9333 [===>..........................] - ETA: 6:18 - loss: 0.7387 - acc: 0.5078
1344/9333 [===>..........................] - ETA: 6:13 - loss: 0.7391 - acc: 0.5037
1408/9333 [===>..........................] - ETA: 6:09 - loss: 0.7374 - acc: 0.5036
1472/9333 [===>..........................] - ETA: 6:05 - loss: 0.7380 - acc: 0.5027
1536/9333 [===>..........................] - ETA: 5:59 - loss: 0.7375 - acc: 0.5046
1600/9333 [====>.........................] - ETA: 5:52 - loss: 0.7361 - acc: 0.5044
1664/9333 [====>.........................] - ETA: 5:48 - loss: 0.7352 - acc: 0.5036
1728/9333 [====>.........................] - ETA: 5:50 - loss: 0.7356 - acc: 0.5017
1792/9333 [====>.........................] - ETA: 5:48 - loss: 0.7352 - acc: 0.5033
1856/9333 [====>.........................] - ETA: 5:43 - loss: 0.7335 - acc: 0.5043
1920/9333 [=====>........................] - ETA: 5:38 - loss: 0.7335 - acc: 0.5052
1984/9333 [=====>........................] - ETA: 5:34 - loss: 0.7320 - acc: 0.5050
2048/9333 [=====>........................] - ETA: 5:36 - loss: 0.7319 - acc: 0.5034
2112/9333 [=====>........................] - ETA: 5:31 - loss: 0.7309 - acc: 0.5043
2176/9333 [=====>........................] - ETA: 5:27 - loss: 0.7305 - acc: 0.5060
2240/9333 [======>.......................] - ETA: 5:24 - loss: 0.7298 - acc: 0.5058
2304/9333 [======>.......................] - ETA: 5:22 - loss: 0.7286 - acc: 0.5074
2368/9333 [======>.......................] - ETA: 5:18 - loss: 0.7270 - acc: 0.5101
2432/9333 [======>.......................] - ETA: 5:14 - loss: 0.7278 - acc: 0.5123
2496/9333 [=======>......................] - ETA: 5:09 - loss: 0.7273 - acc: 0.5128
2560/9333 [=======>......................] - ETA: 5:05 - loss: 0.7282 - acc: 0.5125
2624/9333 [=======>......................] - ETA: 5:01 - loss: 0.7277 - acc: 0.5118
2688/9333 [=======>......................] - ETA: 4:57 - loss: 0.7272 - acc: 0.5126
2752/9333 [=======>......................] - ETA: 4:54 - loss: 0.7261 - acc: 0.5138
2816/9333 [========>.....................] - ETA: 4:51 - loss: 0.7248 - acc: 0.5163
2880/9333 [========>.....................] - ETA: 4:48 - loss: 0.7250 - acc: 0.5160
2944/9333 [========>.....................] - ETA: 4:44 - loss: 0.7248 - acc: 0.5136
3008/9333 [========>.....................] - ETA: 4:41 - loss: 0.7251 - acc: 0.5136
3072/9333 [========>.....................] - ETA: 4:37 - loss: 0.7248 - acc: 0.5117
3136/9333 [=========>....................] - ETA: 4:34 - loss: 0.7237 - acc: 0.5128
3200/9333 [=========>....................] - ETA: 4:31 - loss: 0.7228 - acc: 0.5134
3264/9333 [=========>....................] - ETA: 4:27 - loss: 0.7229 - acc: 0.5123
3328/9333 [=========>....................] - ETA: 4:24 - loss: 0.7224 - acc: 0.5135
3392/9333 [=========>....................] - ETA: 4:21 - loss: 0.7219 - acc: 0.5121
3456/9333 [==========>...................] - ETA: 4:18 - loss: 0.7210 - acc: 0.5136
3520/9333 [==========>...................] - ETA: 4:14 - loss: 0.7206 - acc: 0.5142
3584/9333 [==========>...................] - ETA: 4:11 - loss: 0.7202 - acc: 0.5134
3648/9333 [==========>...................] - ETA: 4:08 - loss: 0.7197 - acc: 0.5148
3712/9333 [==========>...................] - ETA: 4:04 - loss: 0.7193 - acc: 0.5145
3776/9333 [===========>..................] - ETA: 4:02 - loss: 0.7193 - acc: 0.5138
3840/9333 [===========>..................] - ETA: 3:59 - loss: 0.7196 - acc: 0.5125
3904/9333 [===========>..................] - ETA: 3:56 - loss: 0.7195 - acc: 0.5115
3968/9333 [===========>..................] - ETA: 3:53 - loss: 0.7190 - acc: 0.5134
4032/9333 [===========>..................] - ETA: 3:50 - loss: 0.7187 - acc: 0.5129
4096/9333 [============>.................] - ETA: 3:47 - loss: 0.7178 - acc: 0.5151
4160/9333 [============>.................] - ETA: 3:44 - loss: 0.7174 - acc: 0.5156
4224/9333 [============>.................] - ETA: 3:42 - loss: 0.7167 - acc: 0.5166
4288/9333 [============>.................] - ETA: 3:39 - loss: 0.7164 - acc: 0.5156
4352/9333 [============>.................] - ETA: 3:36 - loss: 0.7159 - acc: 0.5168
4416/9333 [=============>................] - ETA: 3:33 - loss: 0.7156 - acc: 0.5172
4480/9333 [=============>................] - ETA: 3:30 - loss: 0.7158 - acc: 0.5163
4544/9333 [=============>................] - ETA: 3:27 - loss: 0.7160 - acc: 0.5154
4608/9333 [=============>................] - ETA: 3:24 - loss: 0.7160 - acc: 0.5156
4672/9333 [==============>...............] - ETA: 3:21 - loss: 0.7155 - acc: 0.5158
4736/9333 [==============>...............] - ETA: 3:18 - loss: 0.7153 - acc: 0.5160
4800/9333 [==============>...............] - ETA: 3:15 - loss: 0.7158 - acc: 0.5146
4864/9333 [==============>...............] - ETA: 3:12 - loss: 0.7158 - acc: 0.5140
4928/9333 [==============>...............] - ETA: 3:10 - loss: 0.7157 - acc: 0.5132
4992/9333 [===============>..............] - ETA: 3:07 - loss: 0.7159 - acc: 0.5132
5056/9333 [===============>..............] - ETA: 3:05 - loss: 0.7156 - acc: 0.5134
5120/9333 [===============>..............] - ETA: 3:02 - loss: 0.7153 - acc: 0.5133
5184/9333 [===============>..............] - ETA: 2:59 - loss: 0.7157 - acc: 0.5120
5248/9333 [===============>..............] - ETA: 2:56 - loss: 0.7155 - acc: 0.5124
5312/9333 [================>.............] - ETA: 2:53 - loss: 0.7152 - acc: 0.5119
5376/9333 [================>.............] - ETA: 2:50 - loss: 0.7151 - acc: 0.5119
5440/9333 [================>.............] - ETA: 2:48 - loss: 0.7151 - acc: 0.5118
5504/9333 [================>.............] - ETA: 2:45 - loss: 0.7155 - acc: 0.5107
5568/9333 [================>.............] - ETA: 2:42 - loss: 0.7148 - acc: 0.5122
5632/9333 [=================>............] - ETA: 2:39 - loss: 0.7146 - acc: 0.5117
5696/9333 [=================>............] - ETA: 2:36 - loss: 0.7145 - acc: 0.5119
5760/9333 [=================>............] - ETA: 2:33 - loss: 0.7140 - acc: 0.5130
5824/9333 [=================>............] - ETA: 2:30 - loss: 0.7135 - acc: 0.5146
5888/9333 [=================>............] - ETA: 2:27 - loss: 0.7135 - acc: 0.5149
5952/9333 [==================>...........] - ETA: 2:24 - loss: 0.7135 - acc: 0.5150
6016/9333 [==================>...........] - ETA: 2:22 - loss: 0.7130 - acc: 0.5153
6080/9333 [==================>...........] - ETA: 2:19 - loss: 0.7133 - acc: 0.5140
6144/9333 [==================>...........] - ETA: 2:16 - loss: 0.7133 - acc: 0.5133
6208/9333 [==================>...........] - ETA: 2:13 - loss: 0.7131 - acc: 0.5135
6272/9333 [===================>..........] - ETA: 2:11 - loss: 0.7125 - acc: 0.5147
6336/9333 [===================>..........] - ETA: 2:08 - loss: 0.7124 - acc: 0.5150
6400/9333 [===================>..........] - ETA: 2:05 - loss: 0.7126 - acc: 0.5142
6464/9333 [===================>..........] - ETA: 2:02 - loss: 0.7126 - acc: 0.5135
6528/9333 [===================>..........] - ETA: 1:59 - loss: 0.7122 - acc: 0.5139
6592/9333 [====================>.........] - ETA: 1:57 - loss: 0.7120 - acc: 0.5143
6656/9333 [====================>.........] - ETA: 1:54 - loss: 0.7117 - acc: 0.5149
6720/9333 [====================>.........] - ETA: 1:51 - loss: 0.7117 - acc: 0.5143
6784/9333 [====================>.........] - ETA: 1:49 - loss: 0.7113 - acc: 0.5149
6848/9333 [=====================>........] - ETA: 1:46 - loss: 0.7109 - acc: 0.5158
6912/9333 [=====================>........] - ETA: 1:43 - loss: 0.7108 - acc: 0.5152
6976/9333 [=====================>........] - ETA: 1:40 - loss: 0.7108 - acc: 0.5161
7040/9333 [=====================>........] - ETA: 1:37 - loss: 0.7103 - acc: 0.5168
7104/9333 [=====================>........] - ETA: 1:34 - loss: 0.7102 - acc: 0.5176
7168/9333 [======================>.......] - ETA: 1:32 - loss: 0.7100 - acc: 0.5183
7232/9333 [======================>.......] - ETA: 1:29 - loss: 0.7103 - acc: 0.5173
7296/9333 [======================>.......] - ETA: 1:26 - loss: 0.7105 - acc: 0.5163
7360/9333 [======================>.......] - ETA: 1:24 - loss: 0.7103 - acc: 0.5167
7424/9333 [======================>.......] - ETA: 1:21 - loss: 0.7105 - acc: 0.5166
7488/9333 [=======================>......] - ETA: 1:18 - loss: 0.7104 - acc: 0.5163
7552/9333 [=======================>......] - ETA: 1:15 - loss: 0.7103 - acc: 0.5159
7616/9333 [=======================>......] - ETA: 1:12 - loss: 0.7101 - acc: 0.5165
7680/9333 [=======================>......] - ETA: 1:10 - loss: 0.7100 - acc: 0.5165
7744/9333 [=======================>......] - ETA: 1:07 - loss: 0.7101 - acc: 0.5161
7808/9333 [========================>.....] - ETA: 1:04 - loss: 0.7102 - acc: 0.5163
7872/9333 [========================>.....] - ETA: 1:02 - loss: 0.7103 - acc: 0.5160
7936/9333 [========================>.....] - ETA: 59s - loss: 0.7107 - acc: 0.5145 
8000/9333 [========================>.....] - ETA: 56s - loss: 0.7108 - acc: 0.5141
8064/9333 [========================>.....] - ETA: 53s - loss: 0.7110 - acc: 0.5135
8128/9333 [=========================>....] - ETA: 51s - loss: 0.7112 - acc: 0.5123
8192/9333 [=========================>....] - ETA: 48s - loss: 0.7111 - acc: 0.5127
8256/9333 [=========================>....] - ETA: 45s - loss: 0.7108 - acc: 0.5134
8320/9333 [=========================>....] - ETA: 42s - loss: 0.7106 - acc: 0.5141
8384/9333 [=========================>....] - ETA: 40s - loss: 0.7105 - acc: 0.5137
8448/9333 [==========================>...] - ETA: 37s - loss: 0.7102 - acc: 0.5143
8512/9333 [==========================>...] - ETA: 34s - loss: 0.7100 - acc: 0.5149
8576/9333 [==========================>...] - ETA: 32s - loss: 0.7099 - acc: 0.5152
8640/9333 [==========================>...] - ETA: 29s - loss: 0.7098 - acc: 0.5157
8704/9333 [==========================>...] - ETA: 26s - loss: 0.7098 - acc: 0.5159
8768/9333 [===========================>..] - ETA: 23s - loss: 0.7097 - acc: 0.5159
8832/9333 [===========================>..] - ETA: 21s - loss: 0.7096 - acc: 0.5161
8896/9333 [===========================>..] - ETA: 18s - loss: 0.7096 - acc: 0.5160
8960/9333 [===========================>..] - ETA: 15s - loss: 0.7096 - acc: 0.5155
9024/9333 [============================>.] - ETA: 13s - loss: 0.7093 - acc: 0.5164
9088/9333 [============================>.] - ETA: 10s - loss: 0.7093 - acc: 0.5162
9152/9333 [============================>.] - ETA: 7s - loss: 0.7094 - acc: 0.5153 
9216/9333 [============================>.] - ETA: 4s - loss: 0.7096 - acc: 0.5144
9280/9333 [============================>.] - ETA: 2s - loss: 0.7095 - acc: 0.5148
9333/9333 [==============================] - 410s 44ms/step - loss: 0.7094 - acc: 0.5151 - val_loss: 0.6967 - val_acc: 0.5034

Epoch 00001: val_acc improved from -inf to 0.50338, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window01/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 5:53 - loss: 0.7121 - acc: 0.4062
 128/9333 [..............................] - ETA: 6:00 - loss: 0.7149 - acc: 0.4453
 192/9333 [..............................] - ETA: 6:03 - loss: 0.7084 - acc: 0.4583
 256/9333 [..............................] - ETA: 6:07 - loss: 0.7040 - acc: 0.4844
 320/9333 [>.............................] - ETA: 6:05 - loss: 0.7030 - acc: 0.5000
 384/9333 [>.............................] - ETA: 5:53 - loss: 0.7021 - acc: 0.4974
 448/9333 [>.............................] - ETA: 5:53 - loss: 0.7004 - acc: 0.5000
 512/9333 [>.............................] - ETA: 5:50 - loss: 0.6966 - acc: 0.5117
 576/9333 [>.............................] - ETA: 5:44 - loss: 0.6988 - acc: 0.5052
 640/9333 [=>............................] - ETA: 5:39 - loss: 0.6989 - acc: 0.5062
 704/9333 [=>............................] - ETA: 5:40 - loss: 0.6978 - acc: 0.5071
 768/9333 [=>............................] - ETA: 5:38 - loss: 0.6963 - acc: 0.5156
 832/9333 [=>............................] - ETA: 5:37 - loss: 0.6963 - acc: 0.5132
 896/9333 [=>............................] - ETA: 5:34 - loss: 0.6967 - acc: 0.5112
 960/9333 [==>...........................] - ETA: 5:31 - loss: 0.6970 - acc: 0.5083
1024/9333 [==>...........................] - ETA: 5:26 - loss: 0.6972 - acc: 0.5088
1088/9333 [==>...........................] - ETA: 5:24 - loss: 0.6977 - acc: 0.5037
1152/9333 [==>...........................] - ETA: 5:21 - loss: 0.6982 - acc: 0.5052
1216/9333 [==>...........................] - ETA: 5:22 - loss: 0.6972 - acc: 0.5090
1280/9333 [===>..........................] - ETA: 5:24 - loss: 0.6976 - acc: 0.5070
1344/9333 [===>..........................] - ETA: 5:21 - loss: 0.6969 - acc: 0.5134
1408/9333 [===>..........................] - ETA: 5:17 - loss: 0.6980 - acc: 0.5128
1472/9333 [===>..........................] - ETA: 5:14 - loss: 0.6983 - acc: 0.5115
1536/9333 [===>..........................] - ETA: 5:11 - loss: 0.6981 - acc: 0.5130
1600/9333 [====>.........................] - ETA: 5:08 - loss: 0.6988 - acc: 0.5144
1664/9333 [====>.........................] - ETA: 5:06 - loss: 0.6988 - acc: 0.5150
1728/9333 [====>.........................] - ETA: 5:04 - loss: 0.6996 - acc: 0.5122
1792/9333 [====>.........................] - ETA: 5:00 - loss: 0.6999 - acc: 0.5112
1856/9333 [====>.........................] - ETA: 4:57 - loss: 0.6992 - acc: 0.5113
1920/9333 [=====>........................] - ETA: 4:55 - loss: 0.7001 - acc: 0.5073
1984/9333 [=====>........................] - ETA: 4:54 - loss: 0.7000 - acc: 0.5076
2048/9333 [=====>........................] - ETA: 4:51 - loss: 0.7003 - acc: 0.5054
2112/9333 [=====>........................] - ETA: 4:49 - loss: 0.6995 - acc: 0.5076
2176/9333 [=====>........................] - ETA: 4:46 - loss: 0.6992 - acc: 0.5092
2240/9333 [======>.......................] - ETA: 4:43 - loss: 0.6979 - acc: 0.5125
2304/9333 [======>.......................] - ETA: 4:40 - loss: 0.6978 - acc: 0.5135
2368/9333 [======>.......................] - ETA: 4:39 - loss: 0.6975 - acc: 0.5144
2432/9333 [======>.......................] - ETA: 4:36 - loss: 0.6970 - acc: 0.5152
2496/9333 [=======>......................] - ETA: 4:35 - loss: 0.6967 - acc: 0.5160
2560/9333 [=======>......................] - ETA: 4:33 - loss: 0.6965 - acc: 0.5156
2624/9333 [=======>......................] - ETA: 4:29 - loss: 0.6972 - acc: 0.5141
2688/9333 [=======>......................] - ETA: 4:26 - loss: 0.6970 - acc: 0.5149
2752/9333 [=======>......................] - ETA: 4:23 - loss: 0.6966 - acc: 0.5160
2816/9333 [========>.....................] - ETA: 4:20 - loss: 0.6962 - acc: 0.5167
2880/9333 [========>.....................] - ETA: 4:17 - loss: 0.6960 - acc: 0.5181
2944/9333 [========>.....................] - ETA: 4:14 - loss: 0.6967 - acc: 0.5163
3008/9333 [========>.....................] - ETA: 4:12 - loss: 0.6959 - acc: 0.5203
3072/9333 [========>.....................] - ETA: 4:09 - loss: 0.6965 - acc: 0.5192
3136/9333 [=========>....................] - ETA: 4:07 - loss: 0.6966 - acc: 0.5188
3200/9333 [=========>....................] - ETA: 4:04 - loss: 0.6966 - acc: 0.5197
3264/9333 [=========>....................] - ETA: 4:02 - loss: 0.6970 - acc: 0.5187
3328/9333 [=========>....................] - ETA: 3:59 - loss: 0.6969 - acc: 0.5195
3392/9333 [=========>....................] - ETA: 3:56 - loss: 0.6971 - acc: 0.5195
3456/9333 [==========>...................] - ETA: 3:54 - loss: 0.6969 - acc: 0.5208
3520/9333 [==========>...................] - ETA: 3:51 - loss: 0.6970 - acc: 0.5207
3584/9333 [==========>...................] - ETA: 3:48 - loss: 0.6973 - acc: 0.5193
3648/9333 [==========>...................] - ETA: 3:45 - loss: 0.6976 - acc: 0.5175
3712/9333 [==========>...................] - ETA: 3:43 - loss: 0.6978 - acc: 0.5180
3776/9333 [===========>..................] - ETA: 3:41 - loss: 0.6970 - acc: 0.5207
3840/9333 [===========>..................] - ETA: 3:38 - loss: 0.6969 - acc: 0.5206
3904/9333 [===========>..................] - ETA: 3:36 - loss: 0.6972 - acc: 0.5187
3968/9333 [===========>..................] - ETA: 3:33 - loss: 0.6971 - acc: 0.5194
4032/9333 [===========>..................] - ETA: 3:30 - loss: 0.6972 - acc: 0.5196
4096/9333 [============>.................] - ETA: 3:28 - loss: 0.6969 - acc: 0.5210
4160/9333 [============>.................] - ETA: 3:25 - loss: 0.6976 - acc: 0.5202
4224/9333 [============>.................] - ETA: 3:22 - loss: 0.6974 - acc: 0.5206
4288/9333 [============>.................] - ETA: 3:20 - loss: 0.6976 - acc: 0.5201
4352/9333 [============>.................] - ETA: 3:17 - loss: 0.6976 - acc: 0.5191
4416/9333 [=============>................] - ETA: 3:15 - loss: 0.6973 - acc: 0.5186
4480/9333 [=============>................] - ETA: 3:12 - loss: 0.6973 - acc: 0.5176
4544/9333 [=============>................] - ETA: 3:10 - loss: 0.6974 - acc: 0.5169
4608/9333 [=============>................] - ETA: 3:07 - loss: 0.6975 - acc: 0.5163
4672/9333 [==============>...............] - ETA: 3:04 - loss: 0.6975 - acc: 0.5161
4736/9333 [==============>...............] - ETA: 3:01 - loss: 0.6975 - acc: 0.5160
4800/9333 [==============>...............] - ETA: 2:58 - loss: 0.6973 - acc: 0.5175
4864/9333 [==============>...............] - ETA: 2:56 - loss: 0.6974 - acc: 0.5179
4928/9333 [==============>...............] - ETA: 2:53 - loss: 0.6976 - acc: 0.5177
4992/9333 [===============>..............] - ETA: 2:50 - loss: 0.6978 - acc: 0.5174
5056/9333 [===============>..............] - ETA: 2:48 - loss: 0.6980 - acc: 0.5168
5120/9333 [===============>..............] - ETA: 2:46 - loss: 0.6978 - acc: 0.5168
5184/9333 [===============>..............] - ETA: 2:43 - loss: 0.6977 - acc: 0.5170
5248/9333 [===============>..............] - ETA: 2:41 - loss: 0.6977 - acc: 0.5171
5312/9333 [================>.............] - ETA: 2:38 - loss: 0.6976 - acc: 0.5175
5376/9333 [================>.............] - ETA: 2:36 - loss: 0.6976 - acc: 0.5166
5440/9333 [================>.............] - ETA: 2:33 - loss: 0.6974 - acc: 0.5165
5504/9333 [================>.............] - ETA: 2:31 - loss: 0.6971 - acc: 0.5176
5568/9333 [================>.............] - ETA: 2:28 - loss: 0.6970 - acc: 0.5181
5632/9333 [=================>............] - ETA: 2:26 - loss: 0.6969 - acc: 0.5188
5696/9333 [=================>............] - ETA: 2:23 - loss: 0.6966 - acc: 0.5200
5760/9333 [=================>............] - ETA: 2:21 - loss: 0.6963 - acc: 0.5207
5824/9333 [=================>............] - ETA: 2:19 - loss: 0.6962 - acc: 0.5208
5888/9333 [=================>............] - ETA: 2:16 - loss: 0.6958 - acc: 0.5219
5952/9333 [==================>...........] - ETA: 2:13 - loss: 0.6964 - acc: 0.5210
6016/9333 [==================>...........] - ETA: 2:11 - loss: 0.6966 - acc: 0.5206
6080/9333 [==================>...........] - ETA: 2:08 - loss: 0.6966 - acc: 0.5212
6144/9333 [==================>...........] - ETA: 2:06 - loss: 0.6969 - acc: 0.5203
6208/9333 [==================>...........] - ETA: 2:03 - loss: 0.6971 - acc: 0.5208
6272/9333 [===================>..........] - ETA: 2:01 - loss: 0.6969 - acc: 0.5209
6336/9333 [===================>..........] - ETA: 1:59 - loss: 0.6967 - acc: 0.5216
6400/9333 [===================>..........] - ETA: 1:56 - loss: 0.6965 - acc: 0.5222
6464/9333 [===================>..........] - ETA: 1:53 - loss: 0.6964 - acc: 0.5223
6528/9333 [===================>..........] - ETA: 1:51 - loss: 0.6966 - acc: 0.5214
6592/9333 [====================>.........] - ETA: 1:48 - loss: 0.6968 - acc: 0.5215
6656/9333 [====================>.........] - ETA: 1:45 - loss: 0.6970 - acc: 0.5207
6720/9333 [====================>.........] - ETA: 1:43 - loss: 0.6970 - acc: 0.5216
6784/9333 [====================>.........] - ETA: 1:40 - loss: 0.6970 - acc: 0.5209
6848/9333 [=====================>........] - ETA: 1:38 - loss: 0.6972 - acc: 0.5202
6912/9333 [=====================>........] - ETA: 1:36 - loss: 0.6974 - acc: 0.5198
6976/9333 [=====================>........] - ETA: 1:33 - loss: 0.6972 - acc: 0.5201
7040/9333 [=====================>........] - ETA: 1:30 - loss: 0.6969 - acc: 0.5209
7104/9333 [=====================>........] - ETA: 1:28 - loss: 0.6970 - acc: 0.5207
7168/9333 [======================>.......] - ETA: 1:25 - loss: 0.6970 - acc: 0.5211
7232/9333 [======================>.......] - ETA: 1:23 - loss: 0.6970 - acc: 0.5216
7296/9333 [======================>.......] - ETA: 1:20 - loss: 0.6970 - acc: 0.5217
7360/9333 [======================>.......] - ETA: 1:18 - loss: 0.6973 - acc: 0.5205
7424/9333 [======================>.......] - ETA: 1:15 - loss: 0.6973 - acc: 0.5206
7488/9333 [=======================>......] - ETA: 1:13 - loss: 0.6972 - acc: 0.5204
7552/9333 [=======================>......] - ETA: 1:10 - loss: 0.6971 - acc: 0.5211
7616/9333 [=======================>......] - ETA: 1:08 - loss: 0.6971 - acc: 0.5209
7680/9333 [=======================>......] - ETA: 1:05 - loss: 0.6970 - acc: 0.5214
7744/9333 [=======================>......] - ETA: 1:02 - loss: 0.6971 - acc: 0.5205
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6970 - acc: 0.5210
7872/9333 [========================>.....] - ETA: 57s - loss: 0.6969 - acc: 0.5208 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6969 - acc: 0.5212
8000/9333 [========================>.....] - ETA: 52s - loss: 0.6966 - acc: 0.5219
8064/9333 [========================>.....] - ETA: 50s - loss: 0.6968 - acc: 0.5211
8128/9333 [=========================>....] - ETA: 47s - loss: 0.6969 - acc: 0.5214
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6969 - acc: 0.5209
8256/9333 [=========================>....] - ETA: 42s - loss: 0.6972 - acc: 0.5197
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6971 - acc: 0.5197
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6971 - acc: 0.5194
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6971 - acc: 0.5196
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6969 - acc: 0.5202
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6968 - acc: 0.5204
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6969 - acc: 0.5204
8704/9333 [==========================>...] - ETA: 24s - loss: 0.6969 - acc: 0.5201
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6967 - acc: 0.5204
8832/9333 [===========================>..] - ETA: 19s - loss: 0.6969 - acc: 0.5198
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6969 - acc: 0.5198
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6968 - acc: 0.5204
9024/9333 [============================>.] - ETA: 12s - loss: 0.6967 - acc: 0.5211
9088/9333 [============================>.] - ETA: 9s - loss: 0.6967 - acc: 0.5209 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6966 - acc: 0.5211
9216/9333 [============================>.] - ETA: 4s - loss: 0.6966 - acc: 0.5214
9280/9333 [============================>.] - ETA: 2s - loss: 0.6965 - acc: 0.5217
9333/9333 [==============================] - 386s 41ms/step - loss: 0.6964 - acc: 0.5219 - val_loss: 0.6919 - val_acc: 0.5111

Epoch 00002: val_acc improved from 0.50338 to 0.51109, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window01/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 3/10

  64/9333 [..............................] - ETA: 6:52 - loss: 0.7139 - acc: 0.5625
 128/9333 [..............................] - ETA: 6:22 - loss: 0.6988 - acc: 0.5781
 192/9333 [..............................] - ETA: 6:08 - loss: 0.6908 - acc: 0.5938
 256/9333 [..............................] - ETA: 6:04 - loss: 0.6821 - acc: 0.6211
 320/9333 [>.............................] - ETA: 6:03 - loss: 0.6767 - acc: 0.6250
 384/9333 [>.............................] - ETA: 5:58 - loss: 0.6787 - acc: 0.6042
 448/9333 [>.............................] - ETA: 5:48 - loss: 0.6766 - acc: 0.6049
 512/9333 [>.............................] - ETA: 5:42 - loss: 0.6809 - acc: 0.5918
 576/9333 [>.............................] - ETA: 5:44 - loss: 0.6794 - acc: 0.5938
 640/9333 [=>............................] - ETA: 5:42 - loss: 0.6845 - acc: 0.5781
 704/9333 [=>............................] - ETA: 5:38 - loss: 0.6828 - acc: 0.5810
 768/9333 [=>............................] - ETA: 5:33 - loss: 0.6820 - acc: 0.5833
 832/9333 [=>............................] - ETA: 5:32 - loss: 0.6839 - acc: 0.5757
 896/9333 [=>............................] - ETA: 5:36 - loss: 0.6844 - acc: 0.5725
 960/9333 [==>...........................] - ETA: 5:34 - loss: 0.6836 - acc: 0.5750
1024/9333 [==>...........................] - ETA: 5:32 - loss: 0.6836 - acc: 0.5723
1088/9333 [==>...........................] - ETA: 5:28 - loss: 0.6835 - acc: 0.5708
1152/9333 [==>...........................] - ETA: 5:23 - loss: 0.6857 - acc: 0.5642
1216/9333 [==>...........................] - ETA: 5:20 - loss: 0.6841 - acc: 0.5683
1280/9333 [===>..........................] - ETA: 5:17 - loss: 0.6859 - acc: 0.5672
1344/9333 [===>..........................] - ETA: 5:14 - loss: 0.6867 - acc: 0.5647
1408/9333 [===>..........................] - ETA: 5:12 - loss: 0.6860 - acc: 0.5668
1472/9333 [===>..........................] - ETA: 5:12 - loss: 0.6868 - acc: 0.5659
1536/9333 [===>..........................] - ETA: 5:09 - loss: 0.6871 - acc: 0.5658
1600/9333 [====>.........................] - ETA: 5:06 - loss: 0.6881 - acc: 0.5656
1664/9333 [====>.........................] - ETA: 5:03 - loss: 0.6895 - acc: 0.5625
1728/9333 [====>.........................] - ETA: 5:00 - loss: 0.6889 - acc: 0.5637
1792/9333 [====>.........................] - ETA: 4:58 - loss: 0.6888 - acc: 0.5664
1856/9333 [====>.........................] - ETA: 4:57 - loss: 0.6889 - acc: 0.5668
1920/9333 [=====>........................] - ETA: 4:55 - loss: 0.6874 - acc: 0.5693
1984/9333 [=====>........................] - ETA: 4:52 - loss: 0.6877 - acc: 0.5691
2048/9333 [=====>........................] - ETA: 4:49 - loss: 0.6877 - acc: 0.5664
2112/9333 [=====>........................] - ETA: 4:46 - loss: 0.6889 - acc: 0.5625
2176/9333 [=====>........................] - ETA: 4:43 - loss: 0.6891 - acc: 0.5611
2240/9333 [======>.......................] - ETA: 4:41 - loss: 0.6887 - acc: 0.5621
2304/9333 [======>.......................] - ETA: 4:38 - loss: 0.6890 - acc: 0.5608
2368/9333 [======>.......................] - ETA: 4:35 - loss: 0.6891 - acc: 0.5587
2432/9333 [======>.......................] - ETA: 4:32 - loss: 0.6897 - acc: 0.5596
2496/9333 [=======>......................] - ETA: 4:29 - loss: 0.6898 - acc: 0.5577
2560/9333 [=======>......................] - ETA: 4:27 - loss: 0.6895 - acc: 0.5570
2624/9333 [=======>......................] - ETA: 4:26 - loss: 0.6897 - acc: 0.5564
2688/9333 [=======>......................] - ETA: 4:23 - loss: 0.6897 - acc: 0.5554
2752/9333 [=======>......................] - ETA: 4:20 - loss: 0.6899 - acc: 0.5560
2816/9333 [========>.....................] - ETA: 4:17 - loss: 0.6898 - acc: 0.5540
2880/9333 [========>.....................] - ETA: 4:14 - loss: 0.6903 - acc: 0.5535
2944/9333 [========>.....................] - ETA: 4:11 - loss: 0.6900 - acc: 0.5543
3008/9333 [========>.....................] - ETA: 4:08 - loss: 0.6896 - acc: 0.5559
3072/9333 [========>.....................] - ETA: 4:05 - loss: 0.6905 - acc: 0.5527
3136/9333 [=========>....................] - ETA: 4:02 - loss: 0.6906 - acc: 0.5510
3200/9333 [=========>....................] - ETA: 4:00 - loss: 0.6906 - acc: 0.5500
3264/9333 [=========>....................] - ETA: 3:58 - loss: 0.6901 - acc: 0.5524
3328/9333 [=========>....................] - ETA: 3:55 - loss: 0.6904 - acc: 0.5520
3392/9333 [=========>....................] - ETA: 3:53 - loss: 0.6901 - acc: 0.5522
3456/9333 [==========>...................] - ETA: 3:51 - loss: 0.6909 - acc: 0.5486
3520/9333 [==========>...................] - ETA: 3:49 - loss: 0.6915 - acc: 0.5463
3584/9333 [==========>...................] - ETA: 3:47 - loss: 0.6916 - acc: 0.5452
3648/9333 [==========>...................] - ETA: 3:45 - loss: 0.6918 - acc: 0.5436
3712/9333 [==========>...................] - ETA: 3:42 - loss: 0.6923 - acc: 0.5420
3776/9333 [===========>..................] - ETA: 3:40 - loss: 0.6930 - acc: 0.5395
3840/9333 [===========>..................] - ETA: 3:37 - loss: 0.6931 - acc: 0.5396
3904/9333 [===========>..................] - ETA: 3:35 - loss: 0.6932 - acc: 0.5387
3968/9333 [===========>..................] - ETA: 3:32 - loss: 0.6932 - acc: 0.5386
4032/9333 [===========>..................] - ETA: 3:29 - loss: 0.6934 - acc: 0.5365
4096/9333 [============>.................] - ETA: 3:27 - loss: 0.6936 - acc: 0.5344
4160/9333 [============>.................] - ETA: 3:24 - loss: 0.6938 - acc: 0.5339
4224/9333 [============>.................] - ETA: 3:21 - loss: 0.6938 - acc: 0.5339
4288/9333 [============>.................] - ETA: 3:18 - loss: 0.6935 - acc: 0.5345
4352/9333 [============>.................] - ETA: 3:16 - loss: 0.6938 - acc: 0.5338
4416/9333 [=============>................] - ETA: 3:14 - loss: 0.6939 - acc: 0.5331
4480/9333 [=============>................] - ETA: 3:12 - loss: 0.6936 - acc: 0.5333
4544/9333 [=============>................] - ETA: 3:09 - loss: 0.6939 - acc: 0.5317
4608/9333 [=============>................] - ETA: 3:06 - loss: 0.6941 - acc: 0.5308
4672/9333 [==============>...............] - ETA: 3:04 - loss: 0.6942 - acc: 0.5306
4736/9333 [==============>...............] - ETA: 3:01 - loss: 0.6947 - acc: 0.5296
4800/9333 [==============>...............] - ETA: 2:58 - loss: 0.6949 - acc: 0.5283
4864/9333 [==============>...............] - ETA: 2:56 - loss: 0.6948 - acc: 0.5290
4928/9333 [==============>...............] - ETA: 2:53 - loss: 0.6949 - acc: 0.5286
4992/9333 [===============>..............] - ETA: 2:51 - loss: 0.6946 - acc: 0.5300
5056/9333 [===============>..............] - ETA: 2:48 - loss: 0.6946 - acc: 0.5299
5120/9333 [===============>..............] - ETA: 2:46 - loss: 0.6945 - acc: 0.5301
5184/9333 [===============>..............] - ETA: 2:44 - loss: 0.6944 - acc: 0.5303
5248/9333 [===============>..............] - ETA: 2:41 - loss: 0.6944 - acc: 0.5297
5312/9333 [================>.............] - ETA: 2:39 - loss: 0.6944 - acc: 0.5296
5376/9333 [================>.............] - ETA: 2:36 - loss: 0.6945 - acc: 0.5292
5440/9333 [================>.............] - ETA: 2:33 - loss: 0.6946 - acc: 0.5296
5504/9333 [================>.............] - ETA: 2:31 - loss: 0.6946 - acc: 0.5298
5568/9333 [================>.............] - ETA: 2:28 - loss: 0.6944 - acc: 0.5305
5632/9333 [=================>............] - ETA: 2:26 - loss: 0.6943 - acc: 0.5312
5696/9333 [=================>............] - ETA: 2:23 - loss: 0.6944 - acc: 0.5314
5760/9333 [=================>............] - ETA: 2:21 - loss: 0.6945 - acc: 0.5314
5824/9333 [=================>............] - ETA: 2:18 - loss: 0.6943 - acc: 0.5325
5888/9333 [=================>............] - ETA: 2:16 - loss: 0.6943 - acc: 0.5328
5952/9333 [==================>...........] - ETA: 2:13 - loss: 0.6945 - acc: 0.5321
6016/9333 [==================>...........] - ETA: 2:10 - loss: 0.6942 - acc: 0.5331
6080/9333 [==================>...........] - ETA: 2:08 - loss: 0.6942 - acc: 0.5334
6144/9333 [==================>...........] - ETA: 2:05 - loss: 0.6942 - acc: 0.5329
6208/9333 [==================>...........] - ETA: 2:03 - loss: 0.6943 - acc: 0.5327
6272/9333 [===================>..........] - ETA: 2:00 - loss: 0.6943 - acc: 0.5328
6336/9333 [===================>..........] - ETA: 1:58 - loss: 0.6943 - acc: 0.5336
6400/9333 [===================>..........] - ETA: 1:55 - loss: 0.6941 - acc: 0.5342
6464/9333 [===================>..........] - ETA: 1:53 - loss: 0.6940 - acc: 0.5345
6528/9333 [===================>..........] - ETA: 1:50 - loss: 0.6940 - acc: 0.5339
6592/9333 [====================>.........] - ETA: 1:47 - loss: 0.6941 - acc: 0.5334
6656/9333 [====================>.........] - ETA: 1:45 - loss: 0.6942 - acc: 0.5325
6720/9333 [====================>.........] - ETA: 1:42 - loss: 0.6943 - acc: 0.5318
6784/9333 [====================>.........] - ETA: 1:40 - loss: 0.6943 - acc: 0.5310
6848/9333 [=====================>........] - ETA: 1:37 - loss: 0.6943 - acc: 0.5302
6912/9333 [=====================>........] - ETA: 1:35 - loss: 0.6942 - acc: 0.5304
6976/9333 [=====================>........] - ETA: 1:32 - loss: 0.6942 - acc: 0.5302
7040/9333 [=====================>........] - ETA: 1:30 - loss: 0.6943 - acc: 0.5297
7104/9333 [=====================>........] - ETA: 1:27 - loss: 0.6943 - acc: 0.5297
7168/9333 [======================>.......] - ETA: 1:25 - loss: 0.6944 - acc: 0.5290
7232/9333 [======================>.......] - ETA: 1:22 - loss: 0.6944 - acc: 0.5292
7296/9333 [======================>.......] - ETA: 1:20 - loss: 0.6944 - acc: 0.5295
7360/9333 [======================>.......] - ETA: 1:17 - loss: 0.6943 - acc: 0.5295
7424/9333 [======================>.......] - ETA: 1:15 - loss: 0.6944 - acc: 0.5290
7488/9333 [=======================>......] - ETA: 1:12 - loss: 0.6944 - acc: 0.5294
7552/9333 [=======================>......] - ETA: 1:10 - loss: 0.6944 - acc: 0.5291
7616/9333 [=======================>......] - ETA: 1:07 - loss: 0.6943 - acc: 0.5295
7680/9333 [=======================>......] - ETA: 1:05 - loss: 0.6944 - acc: 0.5284
7744/9333 [=======================>......] - ETA: 1:02 - loss: 0.6945 - acc: 0.5276
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6943 - acc: 0.5284
7872/9333 [========================>.....] - ETA: 57s - loss: 0.6943 - acc: 0.5281 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6943 - acc: 0.5285
8000/9333 [========================>.....] - ETA: 52s - loss: 0.6942 - acc: 0.5284
8064/9333 [========================>.....] - ETA: 50s - loss: 0.6942 - acc: 0.5280
8128/9333 [=========================>....] - ETA: 47s - loss: 0.6942 - acc: 0.5278
8192/9333 [=========================>....] - ETA: 44s - loss: 0.6942 - acc: 0.5271
8256/9333 [=========================>....] - ETA: 42s - loss: 0.6943 - acc: 0.5270
8320/9333 [=========================>....] - ETA: 39s - loss: 0.6943 - acc: 0.5273
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6942 - acc: 0.5274
8448/9333 [==========================>...] - ETA: 34s - loss: 0.6942 - acc: 0.5275
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6943 - acc: 0.5264
8576/9333 [==========================>...] - ETA: 29s - loss: 0.6943 - acc: 0.5259
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6941 - acc: 0.5264
8704/9333 [==========================>...] - ETA: 24s - loss: 0.6941 - acc: 0.5267
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6940 - acc: 0.5273
8832/9333 [===========================>..] - ETA: 19s - loss: 0.6938 - acc: 0.5272
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6938 - acc: 0.5278
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6938 - acc: 0.5279
9024/9333 [============================>.] - ETA: 12s - loss: 0.6938 - acc: 0.5279
9088/9333 [============================>.] - ETA: 9s - loss: 0.6939 - acc: 0.5274 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6938 - acc: 0.5278
9216/9333 [============================>.] - ETA: 4s - loss: 0.6939 - acc: 0.5272
9280/9333 [============================>.] - ETA: 2s - loss: 0.6938 - acc: 0.5275
9333/9333 [==============================] - 383s 41ms/step - loss: 0.6939 - acc: 0.5268 - val_loss: 0.6888 - val_acc: 0.5381

Epoch 00003: val_acc improved from 0.51109 to 0.53809, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window01/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 4/10

  64/9333 [..............................] - ETA: 6:42 - loss: 0.6812 - acc: 0.5938
 128/9333 [..............................] - ETA: 6:22 - loss: 0.6888 - acc: 0.5547
 192/9333 [..............................] - ETA: 6:11 - loss: 0.6883 - acc: 0.5469
 256/9333 [..............................] - ETA: 5:59 - loss: 0.6872 - acc: 0.5547
 320/9333 [>.............................] - ETA: 5:55 - loss: 0.6828 - acc: 0.5844
 384/9333 [>.............................] - ETA: 5:48 - loss: 0.6819 - acc: 0.5885
 448/9333 [>.............................] - ETA: 5:43 - loss: 0.6823 - acc: 0.5848
 512/9333 [>.............................] - ETA: 5:42 - loss: 0.6844 - acc: 0.5781
 576/9333 [>.............................] - ETA: 5:43 - loss: 0.6853 - acc: 0.5799
 640/9333 [=>............................] - ETA: 5:45 - loss: 0.6860 - acc: 0.5766
 704/9333 [=>............................] - ETA: 5:44 - loss: 0.6862 - acc: 0.5781
 768/9333 [=>............................] - ETA: 5:41 - loss: 0.6864 - acc: 0.5729
 832/9333 [=>............................] - ETA: 5:35 - loss: 0.6864 - acc: 0.5697
 896/9333 [=>............................] - ETA: 5:30 - loss: 0.6872 - acc: 0.5692
 960/9333 [==>...........................] - ETA: 5:28 - loss: 0.6865 - acc: 0.5719
1024/9333 [==>...........................] - ETA: 5:24 - loss: 0.6861 - acc: 0.5752
1088/9333 [==>...........................] - ETA: 5:24 - loss: 0.6870 - acc: 0.5708
1152/9333 [==>...........................] - ETA: 5:25 - loss: 0.6872 - acc: 0.5660
1216/9333 [==>...........................] - ETA: 5:22 - loss: 0.6871 - acc: 0.5650
1280/9333 [===>..........................] - ETA: 5:17 - loss: 0.6872 - acc: 0.5594
1344/9333 [===>..........................] - ETA: 5:15 - loss: 0.6880 - acc: 0.5558
1408/9333 [===>..........................] - ETA: 5:11 - loss: 0.6888 - acc: 0.5511
1472/9333 [===>..........................] - ETA: 5:07 - loss: 0.6883 - acc: 0.5510
1536/9333 [===>..........................] - ETA: 5:04 - loss: 0.6896 - acc: 0.5475
1600/9333 [====>.........................] - ETA: 5:00 - loss: 0.6892 - acc: 0.5481
1664/9333 [====>.........................] - ETA: 5:00 - loss: 0.6887 - acc: 0.5481
1728/9333 [====>.........................] - ETA: 4:59 - loss: 0.6882 - acc: 0.5492
1792/9333 [====>.........................] - ETA: 4:56 - loss: 0.6882 - acc: 0.5441
1856/9333 [====>.........................] - ETA: 4:53 - loss: 0.6882 - acc: 0.5409
1920/9333 [=====>........................] - ETA: 4:51 - loss: 0.6891 - acc: 0.5380
1984/9333 [=====>........................] - ETA: 4:50 - loss: 0.6890 - acc: 0.5358
2048/9333 [=====>........................] - ETA: 4:49 - loss: 0.6888 - acc: 0.5352
2112/9333 [=====>........................] - ETA: 4:46 - loss: 0.6891 - acc: 0.5331
2176/9333 [=====>........................] - ETA: 4:43 - loss: 0.6895 - acc: 0.5317
2240/9333 [======>.......................] - ETA: 4:39 - loss: 0.6909 - acc: 0.5290
2304/9333 [======>.......................] - ETA: 4:36 - loss: 0.6907 - acc: 0.5321
2368/9333 [======>.......................] - ETA: 4:33 - loss: 0.6906 - acc: 0.5321
2432/9333 [======>.......................] - ETA: 4:30 - loss: 0.6909 - acc: 0.5308
2496/9333 [=======>......................] - ETA: 4:28 - loss: 0.6911 - acc: 0.5312
2560/9333 [=======>......................] - ETA: 4:27 - loss: 0.6913 - acc: 0.5316
2624/9333 [=======>......................] - ETA: 4:25 - loss: 0.6921 - acc: 0.5290
2688/9333 [=======>......................] - ETA: 4:22 - loss: 0.6924 - acc: 0.5286
2752/9333 [=======>......................] - ETA: 4:19 - loss: 0.6929 - acc: 0.5283
2816/9333 [========>.....................] - ETA: 4:16 - loss: 0.6934 - acc: 0.5256
2880/9333 [========>.....................] - ETA: 4:14 - loss: 0.6939 - acc: 0.5247
2944/9333 [========>.....................] - ETA: 4:12 - loss: 0.6938 - acc: 0.5248
3008/9333 [========>.....................] - ETA: 4:09 - loss: 0.6938 - acc: 0.5233
3072/9333 [========>.....................] - ETA: 4:07 - loss: 0.6936 - acc: 0.5247
3136/9333 [=========>....................] - ETA: 4:05 - loss: 0.6936 - acc: 0.5239
3200/9333 [=========>....................] - ETA: 4:03 - loss: 0.6936 - acc: 0.5238
3264/9333 [=========>....................] - ETA: 4:00 - loss: 0.6939 - acc: 0.5214
3328/9333 [=========>....................] - ETA: 3:57 - loss: 0.6939 - acc: 0.5216
3392/9333 [=========>....................] - ETA: 3:54 - loss: 0.6938 - acc: 0.5218
3456/9333 [==========>...................] - ETA: 3:51 - loss: 0.6939 - acc: 0.5226
3520/9333 [==========>...................] - ETA: 3:49 - loss: 0.6940 - acc: 0.5227
3584/9333 [==========>...................] - ETA: 3:46 - loss: 0.6940 - acc: 0.5220
3648/9333 [==========>...................] - ETA: 3:44 - loss: 0.6941 - acc: 0.5203
3712/9333 [==========>...................] - ETA: 3:42 - loss: 0.6940 - acc: 0.5207
3776/9333 [===========>..................] - ETA: 3:39 - loss: 0.6938 - acc: 0.5217
3840/9333 [===========>..................] - ETA: 3:37 - loss: 0.6936 - acc: 0.5227
3904/9333 [===========>..................] - ETA: 3:34 - loss: 0.6939 - acc: 0.5218
3968/9333 [===========>..................] - ETA: 3:31 - loss: 0.6939 - acc: 0.5214
4032/9333 [===========>..................] - ETA: 3:29 - loss: 0.6941 - acc: 0.5201
4096/9333 [============>.................] - ETA: 3:26 - loss: 0.6940 - acc: 0.5203
4160/9333 [============>.................] - ETA: 3:23 - loss: 0.6941 - acc: 0.5183
4224/9333 [============>.................] - ETA: 3:22 - loss: 0.6939 - acc: 0.5187
4288/9333 [============>.................] - ETA: 3:19 - loss: 0.6939 - acc: 0.5175
4352/9333 [============>.................] - ETA: 3:16 - loss: 0.6938 - acc: 0.5191
4416/9333 [=============>................] - ETA: 3:13 - loss: 0.6936 - acc: 0.5195
4480/9333 [=============>................] - ETA: 3:11 - loss: 0.6935 - acc: 0.5201
4544/9333 [=============>................] - ETA: 3:08 - loss: 0.6937 - acc: 0.5187
4608/9333 [=============>................] - ETA: 3:05 - loss: 0.6936 - acc: 0.5191
4672/9333 [==============>...............] - ETA: 3:03 - loss: 0.6936 - acc: 0.5195
4736/9333 [==============>...............] - ETA: 3:01 - loss: 0.6938 - acc: 0.5184
4800/9333 [==============>...............] - ETA: 2:58 - loss: 0.6936 - acc: 0.5185
4864/9333 [==============>...............] - ETA: 2:56 - loss: 0.6938 - acc: 0.5177
4928/9333 [==============>...............] - ETA: 2:54 - loss: 0.6938 - acc: 0.5183
4992/9333 [===============>..............] - ETA: 2:51 - loss: 0.6936 - acc: 0.5194
5056/9333 [===============>..............] - ETA: 2:49 - loss: 0.6935 - acc: 0.5194
5120/9333 [===============>..............] - ETA: 2:46 - loss: 0.6935 - acc: 0.5201
5184/9333 [===============>..............] - ETA: 2:44 - loss: 0.6936 - acc: 0.5193
5248/9333 [===============>..............] - ETA: 2:41 - loss: 0.6936 - acc: 0.5192
5312/9333 [================>.............] - ETA: 2:38 - loss: 0.6935 - acc: 0.5192
5376/9333 [================>.............] - ETA: 2:36 - loss: 0.6934 - acc: 0.5193
5440/9333 [================>.............] - ETA: 2:33 - loss: 0.6933 - acc: 0.5200
5504/9333 [================>.............] - ETA: 2:31 - loss: 0.6934 - acc: 0.5189
5568/9333 [================>.............] - ETA: 2:28 - loss: 0.6933 - acc: 0.5198
5632/9333 [=================>............] - ETA: 2:26 - loss: 0.6931 - acc: 0.5206
5696/9333 [=================>............] - ETA: 2:23 - loss: 0.6931 - acc: 0.5205
5760/9333 [=================>............] - ETA: 2:21 - loss: 0.6933 - acc: 0.5207
5824/9333 [=================>............] - ETA: 2:18 - loss: 0.6931 - acc: 0.5206
5888/9333 [=================>............] - ETA: 2:15 - loss: 0.6929 - acc: 0.5212
5952/9333 [==================>...........] - ETA: 2:13 - loss: 0.6929 - acc: 0.5215
6016/9333 [==================>...........] - ETA: 2:11 - loss: 0.6928 - acc: 0.5221
6080/9333 [==================>...........] - ETA: 2:08 - loss: 0.6930 - acc: 0.5215
6144/9333 [==================>...........] - ETA: 2:06 - loss: 0.6932 - acc: 0.5208
6208/9333 [==================>...........] - ETA: 2:03 - loss: 0.6931 - acc: 0.5214
6272/9333 [===================>..........] - ETA: 2:01 - loss: 0.6930 - acc: 0.5218
6336/9333 [===================>..........] - ETA: 1:58 - loss: 0.6930 - acc: 0.5208
6400/9333 [===================>..........] - ETA: 1:56 - loss: 0.6930 - acc: 0.5209
6464/9333 [===================>..........] - ETA: 1:53 - loss: 0.6931 - acc: 0.5207
6528/9333 [===================>..........] - ETA: 1:51 - loss: 0.6933 - acc: 0.5201
6592/9333 [====================>.........] - ETA: 1:48 - loss: 0.6930 - acc: 0.5212
6656/9333 [====================>.........] - ETA: 1:46 - loss: 0.6930 - acc: 0.5215
6720/9333 [====================>.........] - ETA: 1:43 - loss: 0.6932 - acc: 0.5213
6784/9333 [====================>.........] - ETA: 1:40 - loss: 0.6932 - acc: 0.5214
6848/9333 [=====================>........] - ETA: 1:38 - loss: 0.6932 - acc: 0.5206
6912/9333 [=====================>........] - ETA: 1:35 - loss: 0.6933 - acc: 0.5204
6976/9333 [=====================>........] - ETA: 1:32 - loss: 0.6933 - acc: 0.5204
7040/9333 [=====================>........] - ETA: 1:30 - loss: 0.6932 - acc: 0.5209
7104/9333 [=====================>........] - ETA: 1:28 - loss: 0.6931 - acc: 0.5208
7168/9333 [======================>.......] - ETA: 1:25 - loss: 0.6932 - acc: 0.5198
7232/9333 [======================>.......] - ETA: 1:22 - loss: 0.6931 - acc: 0.5202
7296/9333 [======================>.......] - ETA: 1:20 - loss: 0.6929 - acc: 0.5210
7360/9333 [======================>.......] - ETA: 1:17 - loss: 0.6929 - acc: 0.5207
7424/9333 [======================>.......] - ETA: 1:15 - loss: 0.6928 - acc: 0.5206
7488/9333 [=======================>......] - ETA: 1:12 - loss: 0.6930 - acc: 0.5202
7552/9333 [=======================>......] - ETA: 1:10 - loss: 0.6933 - acc: 0.5188
7616/9333 [=======================>......] - ETA: 1:07 - loss: 0.6932 - acc: 0.5193
7680/9333 [=======================>......] - ETA: 1:05 - loss: 0.6932 - acc: 0.5190
7744/9333 [=======================>......] - ETA: 1:02 - loss: 0.6933 - acc: 0.5192
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6933 - acc: 0.5188
7872/9333 [========================>.....] - ETA: 57s - loss: 0.6933 - acc: 0.5189 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6934 - acc: 0.5184
8000/9333 [========================>.....] - ETA: 52s - loss: 0.6935 - acc: 0.5180
8064/9333 [========================>.....] - ETA: 49s - loss: 0.6934 - acc: 0.5184
8128/9333 [=========================>....] - ETA: 47s - loss: 0.6934 - acc: 0.5182
8192/9333 [=========================>....] - ETA: 44s - loss: 0.6932 - acc: 0.5187
8256/9333 [=========================>....] - ETA: 42s - loss: 0.6931 - acc: 0.5185
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6932 - acc: 0.5180
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6932 - acc: 0.5180
8448/9333 [==========================>...] - ETA: 34s - loss: 0.6932 - acc: 0.5173
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6933 - acc: 0.5168
8576/9333 [==========================>...] - ETA: 29s - loss: 0.6932 - acc: 0.5173
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6931 - acc: 0.5176
8704/9333 [==========================>...] - ETA: 24s - loss: 0.6931 - acc: 0.5177
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6930 - acc: 0.5181
8832/9333 [===========================>..] - ETA: 19s - loss: 0.6930 - acc: 0.5180
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6930 - acc: 0.5182
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6930 - acc: 0.5182
9024/9333 [============================>.] - ETA: 12s - loss: 0.6928 - acc: 0.5191
9088/9333 [============================>.] - ETA: 9s - loss: 0.6927 - acc: 0.5195 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6927 - acc: 0.5198
9216/9333 [============================>.] - ETA: 4s - loss: 0.6929 - acc: 0.5193
9280/9333 [============================>.] - ETA: 2s - loss: 0.6928 - acc: 0.5198
9333/9333 [==============================] - 385s 41ms/step - loss: 0.6929 - acc: 0.5197 - val_loss: 0.6865 - val_acc: 0.5410

Epoch 00004: val_acc improved from 0.53809 to 0.54098, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window01/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 5/10

  64/9333 [..............................] - ETA: 5:39 - loss: 0.7226 - acc: 0.4531
 128/9333 [..............................] - ETA: 5:41 - loss: 0.7146 - acc: 0.4688
 192/9333 [..............................] - ETA: 5:54 - loss: 0.6973 - acc: 0.5208
 256/9333 [..............................] - ETA: 5:57 - loss: 0.6915 - acc: 0.5234
 320/9333 [>.............................] - ETA: 5:56 - loss: 0.6946 - acc: 0.5219
 384/9333 [>.............................] - ETA: 5:52 - loss: 0.6923 - acc: 0.5234
 448/9333 [>.............................] - ETA: 5:49 - loss: 0.6886 - acc: 0.5268
 512/9333 [>.............................] - ETA: 5:46 - loss: 0.6894 - acc: 0.5273
 576/9333 [>.............................] - ETA: 5:38 - loss: 0.6872 - acc: 0.5330
 640/9333 [=>............................] - ETA: 5:35 - loss: 0.6864 - acc: 0.5344
 704/9333 [=>............................] - ETA: 5:40 - loss: 0.6833 - acc: 0.5483
 768/9333 [=>............................] - ETA: 5:44 - loss: 0.6853 - acc: 0.5417
 832/9333 [=>............................] - ETA: 5:46 - loss: 0.6851 - acc: 0.5409
 896/9333 [=>............................] - ETA: 5:44 - loss: 0.6862 - acc: 0.5368
 960/9333 [==>...........................] - ETA: 5:39 - loss: 0.6874 - acc: 0.5323
1024/9333 [==>...........................] - ETA: 5:34 - loss: 0.6877 - acc: 0.5312
1088/9333 [==>...........................] - ETA: 5:29 - loss: 0.6868 - acc: 0.5340
1152/9333 [==>...........................] - ETA: 5:25 - loss: 0.6861 - acc: 0.5408
1216/9333 [==>...........................] - ETA: 5:22 - loss: 0.6866 - acc: 0.5370
1280/9333 [===>..........................] - ETA: 5:19 - loss: 0.6873 - acc: 0.5344
1344/9333 [===>..........................] - ETA: 5:17 - loss: 0.6862 - acc: 0.5387
1408/9333 [===>..........................] - ETA: 5:16 - loss: 0.6858 - acc: 0.5391
1472/9333 [===>..........................] - ETA: 5:13 - loss: 0.6858 - acc: 0.5374
1536/9333 [===>..........................] - ETA: 5:10 - loss: 0.6862 - acc: 0.5339
1600/9333 [====>.........................] - ETA: 5:10 - loss: 0.6868 - acc: 0.5331
1664/9333 [====>.........................] - ETA: 5:07 - loss: 0.6865 - acc: 0.5349
1728/9333 [====>.........................] - ETA: 5:04 - loss: 0.6867 - acc: 0.5336
1792/9333 [====>.........................] - ETA: 5:00 - loss: 0.6869 - acc: 0.5340
1856/9333 [====>.........................] - ETA: 4:57 - loss: 0.6875 - acc: 0.5312
1920/9333 [=====>........................] - ETA: 4:54 - loss: 0.6878 - acc: 0.5323
1984/9333 [=====>........................] - ETA: 4:51 - loss: 0.6879 - acc: 0.5307
2048/9333 [=====>........................] - ETA: 4:49 - loss: 0.6881 - acc: 0.5293
2112/9333 [=====>........................] - ETA: 4:47 - loss: 0.6883 - acc: 0.5284
2176/9333 [=====>........................] - ETA: 4:43 - loss: 0.6878 - acc: 0.5303
2240/9333 [======>.......................] - ETA: 4:40 - loss: 0.6881 - acc: 0.5286
2304/9333 [======>.......................] - ETA: 4:37 - loss: 0.6878 - acc: 0.5299
2368/9333 [======>.......................] - ETA: 4:34 - loss: 0.6881 - acc: 0.5291
2432/9333 [======>.......................] - ETA: 4:31 - loss: 0.6890 - acc: 0.5280
2496/9333 [=======>......................] - ETA: 4:28 - loss: 0.6889 - acc: 0.5284
2560/9333 [=======>......................] - ETA: 4:25 - loss: 0.6890 - acc: 0.5273
2624/9333 [=======>......................] - ETA: 4:24 - loss: 0.6889 - acc: 0.5263
2688/9333 [=======>......................] - ETA: 4:23 - loss: 0.6889 - acc: 0.5268
2752/9333 [=======>......................] - ETA: 4:20 - loss: 0.6890 - acc: 0.5269
2816/9333 [========>.....................] - ETA: 4:17 - loss: 0.6889 - acc: 0.5277
2880/9333 [========>.....................] - ETA: 4:15 - loss: 0.6890 - acc: 0.5271
2944/9333 [========>.....................] - ETA: 4:13 - loss: 0.6884 - acc: 0.5316
3008/9333 [========>.....................] - ETA: 4:10 - loss: 0.6889 - acc: 0.5303
3072/9333 [========>.....................] - ETA: 4:07 - loss: 0.6886 - acc: 0.5316
3136/9333 [=========>....................] - ETA: 4:04 - loss: 0.6891 - acc: 0.5303
3200/9333 [=========>....................] - ETA: 4:01 - loss: 0.6893 - acc: 0.5312
3264/9333 [=========>....................] - ETA: 3:59 - loss: 0.6888 - acc: 0.5328
3328/9333 [=========>....................] - ETA: 3:57 - loss: 0.6891 - acc: 0.5306
3392/9333 [=========>....................] - ETA: 3:55 - loss: 0.6891 - acc: 0.5301
3456/9333 [==========>...................] - ETA: 3:52 - loss: 0.6895 - acc: 0.5289
3520/9333 [==========>...................] - ETA: 3:50 - loss: 0.6898 - acc: 0.5281
3584/9333 [==========>...................] - ETA: 3:47 - loss: 0.6896 - acc: 0.5290
3648/9333 [==========>...................] - ETA: 3:44 - loss: 0.6895 - acc: 0.5299
3712/9333 [==========>...................] - ETA: 3:42 - loss: 0.6893 - acc: 0.5299
3776/9333 [===========>..................] - ETA: 3:40 - loss: 0.6890 - acc: 0.5310
3840/9333 [===========>..................] - ETA: 3:37 - loss: 0.6885 - acc: 0.5336
3904/9333 [===========>..................] - ETA: 3:34 - loss: 0.6886 - acc: 0.5338
3968/9333 [===========>..................] - ETA: 3:31 - loss: 0.6883 - acc: 0.5338
4032/9333 [===========>..................] - ETA: 3:29 - loss: 0.6884 - acc: 0.5345
4096/9333 [============>.................] - ETA: 3:26 - loss: 0.6881 - acc: 0.5356
4160/9333 [============>.................] - ETA: 3:24 - loss: 0.6881 - acc: 0.5365
4224/9333 [============>.................] - ETA: 3:22 - loss: 0.6880 - acc: 0.5367
4288/9333 [============>.................] - ETA: 3:19 - loss: 0.6884 - acc: 0.5350
4352/9333 [============>.................] - ETA: 3:17 - loss: 0.6886 - acc: 0.5342
4416/9333 [=============>................] - ETA: 3:14 - loss: 0.6886 - acc: 0.5340
4480/9333 [=============>................] - ETA: 3:11 - loss: 0.6886 - acc: 0.5337
4544/9333 [=============>................] - ETA: 3:09 - loss: 0.6890 - acc: 0.5330
4608/9333 [=============>................] - ETA: 3:06 - loss: 0.6892 - acc: 0.5328
4672/9333 [==============>...............] - ETA: 3:04 - loss: 0.6893 - acc: 0.5332
4736/9333 [==============>...............] - ETA: 3:02 - loss: 0.6893 - acc: 0.5325
4800/9333 [==============>...............] - ETA: 2:59 - loss: 0.6894 - acc: 0.5335
4864/9333 [==============>...............] - ETA: 2:56 - loss: 0.6895 - acc: 0.5345
4928/9333 [==============>...............] - ETA: 2:54 - loss: 0.6892 - acc: 0.5365
4992/9333 [===============>..............] - ETA: 2:51 - loss: 0.6893 - acc: 0.5351
5056/9333 [===============>..............] - ETA: 2:48 - loss: 0.6894 - acc: 0.5350
5120/9333 [===============>..............] - ETA: 2:46 - loss: 0.6896 - acc: 0.5338
5184/9333 [===============>..............] - ETA: 2:43 - loss: 0.6896 - acc: 0.5340
5248/9333 [===============>..............] - ETA: 2:40 - loss: 0.6895 - acc: 0.5343
5312/9333 [================>.............] - ETA: 2:38 - loss: 0.6898 - acc: 0.5318
5376/9333 [================>.............] - ETA: 2:35 - loss: 0.6900 - acc: 0.5305
5440/9333 [================>.............] - ETA: 2:33 - loss: 0.6899 - acc: 0.5314
5504/9333 [================>.............] - ETA: 2:30 - loss: 0.6903 - acc: 0.5298
5568/9333 [================>.............] - ETA: 2:28 - loss: 0.6903 - acc: 0.5296
5632/9333 [=================>............] - ETA: 2:25 - loss: 0.6903 - acc: 0.5300
5696/9333 [=================>............] - ETA: 2:22 - loss: 0.6902 - acc: 0.5305
5760/9333 [=================>............] - ETA: 2:20 - loss: 0.6900 - acc: 0.5314
5824/9333 [=================>............] - ETA: 2:17 - loss: 0.6898 - acc: 0.5326
5888/9333 [=================>............] - ETA: 2:15 - loss: 0.6899 - acc: 0.5324
5952/9333 [==================>...........] - ETA: 2:12 - loss: 0.6896 - acc: 0.5331
6016/9333 [==================>...........] - ETA: 2:10 - loss: 0.6897 - acc: 0.5327
6080/9333 [==================>...........] - ETA: 2:07 - loss: 0.6896 - acc: 0.5326
6144/9333 [==================>...........] - ETA: 2:05 - loss: 0.6894 - acc: 0.5332
6208/9333 [==================>...........] - ETA: 2:02 - loss: 0.6894 - acc: 0.5325
6272/9333 [===================>..........] - ETA: 2:00 - loss: 0.6894 - acc: 0.5325
6336/9333 [===================>..........] - ETA: 1:57 - loss: 0.6894 - acc: 0.5328
6400/9333 [===================>..........] - ETA: 1:55 - loss: 0.6891 - acc: 0.5347
6464/9333 [===================>..........] - ETA: 1:52 - loss: 0.6888 - acc: 0.5359
6528/9333 [===================>..........] - ETA: 1:50 - loss: 0.6889 - acc: 0.5366
6592/9333 [====================>.........] - ETA: 1:47 - loss: 0.6889 - acc: 0.5366
6656/9333 [====================>.........] - ETA: 1:45 - loss: 0.6886 - acc: 0.5371
6720/9333 [====================>.........] - ETA: 1:42 - loss: 0.6887 - acc: 0.5365
6784/9333 [====================>.........] - ETA: 1:40 - loss: 0.6890 - acc: 0.5355
6848/9333 [=====================>........] - ETA: 1:37 - loss: 0.6889 - acc: 0.5359
6912/9333 [=====================>........] - ETA: 1:35 - loss: 0.6889 - acc: 0.5360
6976/9333 [=====================>........] - ETA: 1:32 - loss: 0.6888 - acc: 0.5363
7040/9333 [=====================>........] - ETA: 1:30 - loss: 0.6888 - acc: 0.5359
7104/9333 [=====================>........] - ETA: 1:27 - loss: 0.6888 - acc: 0.5362
7168/9333 [======================>.......] - ETA: 1:25 - loss: 0.6887 - acc: 0.5363
7232/9333 [======================>.......] - ETA: 1:22 - loss: 0.6886 - acc: 0.5368
7296/9333 [======================>.......] - ETA: 1:20 - loss: 0.6884 - acc: 0.5373
7360/9333 [======================>.......] - ETA: 1:17 - loss: 0.6882 - acc: 0.5376
7424/9333 [======================>.......] - ETA: 1:15 - loss: 0.6882 - acc: 0.5374
7488/9333 [=======================>......] - ETA: 1:12 - loss: 0.6883 - acc: 0.5374
7552/9333 [=======================>......] - ETA: 1:10 - loss: 0.6885 - acc: 0.5367
7616/9333 [=======================>......] - ETA: 1:07 - loss: 0.6885 - acc: 0.5368
7680/9333 [=======================>......] - ETA: 1:05 - loss: 0.6882 - acc: 0.5374
7744/9333 [=======================>......] - ETA: 1:02 - loss: 0.6885 - acc: 0.5369
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6884 - acc: 0.5374
7872/9333 [========================>.....] - ETA: 57s - loss: 0.6884 - acc: 0.5373 
7936/9333 [========================>.....] - ETA: 54s - loss: 0.6886 - acc: 0.5364
8000/9333 [========================>.....] - ETA: 52s - loss: 0.6885 - acc: 0.5363
8064/9333 [========================>.....] - ETA: 50s - loss: 0.6884 - acc: 0.5362
8128/9333 [=========================>....] - ETA: 47s - loss: 0.6886 - acc: 0.5356
8192/9333 [=========================>....] - ETA: 44s - loss: 0.6887 - acc: 0.5353
8256/9333 [=========================>....] - ETA: 42s - loss: 0.6886 - acc: 0.5359
8320/9333 [=========================>....] - ETA: 39s - loss: 0.6886 - acc: 0.5356
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6889 - acc: 0.5348
8448/9333 [==========================>...] - ETA: 34s - loss: 0.6889 - acc: 0.5347
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6890 - acc: 0.5348
8576/9333 [==========================>...] - ETA: 29s - loss: 0.6890 - acc: 0.5353
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6891 - acc: 0.5355
8704/9333 [==========================>...] - ETA: 24s - loss: 0.6893 - acc: 0.5353
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6893 - acc: 0.5350
8832/9333 [===========================>..] - ETA: 19s - loss: 0.6892 - acc: 0.5354
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6893 - acc: 0.5352
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6894 - acc: 0.5350
9024/9333 [============================>.] - ETA: 12s - loss: 0.6894 - acc: 0.5347
9088/9333 [============================>.] - ETA: 9s - loss: 0.6895 - acc: 0.5341 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6896 - acc: 0.5337
9216/9333 [============================>.] - ETA: 4s - loss: 0.6895 - acc: 0.5339
9280/9333 [============================>.] - ETA: 2s - loss: 0.6896 - acc: 0.5334
9333/9333 [==============================] - 384s 41ms/step - loss: 0.6896 - acc: 0.5338 - val_loss: 0.6881 - val_acc: 0.5294

Epoch 00005: val_acc did not improve from 0.54098
Epoch 6/10

  64/9333 [..............................] - ETA: 5:50 - loss: 0.6901 - acc: 0.5469
 128/9333 [..............................] - ETA: 5:37 - loss: 0.6888 - acc: 0.5391
 192/9333 [..............................] - ETA: 5:37 - loss: 0.6849 - acc: 0.5469
 256/9333 [..............................] - ETA: 5:33 - loss: 0.6883 - acc: 0.5391
 320/9333 [>.............................] - ETA: 5:38 - loss: 0.6900 - acc: 0.5406
 384/9333 [>.............................] - ETA: 5:35 - loss: 0.6861 - acc: 0.5495
 448/9333 [>.............................] - ETA: 5:32 - loss: 0.6842 - acc: 0.5603
 512/9333 [>.............................] - ETA: 5:42 - loss: 0.6847 - acc: 0.5469
 576/9333 [>.............................] - ETA: 5:42 - loss: 0.6863 - acc: 0.5417
 640/9333 [=>............................] - ETA: 5:38 - loss: 0.6846 - acc: 0.5516
 704/9333 [=>............................] - ETA: 5:34 - loss: 0.6813 - acc: 0.5682
 768/9333 [=>............................] - ETA: 5:30 - loss: 0.6852 - acc: 0.5560
 832/9333 [=>............................] - ETA: 5:32 - loss: 0.6856 - acc: 0.5517
 896/9333 [=>............................] - ETA: 5:28 - loss: 0.6855 - acc: 0.5513
 960/9333 [==>...........................] - ETA: 5:27 - loss: 0.6868 - acc: 0.5510
1024/9333 [==>...........................] - ETA: 5:24 - loss: 0.6868 - acc: 0.5449
1088/9333 [==>...........................] - ETA: 5:22 - loss: 0.6865 - acc: 0.5432
1152/9333 [==>...........................] - ETA: 5:21 - loss: 0.6852 - acc: 0.5469
1216/9333 [==>...........................] - ETA: 5:20 - loss: 0.6836 - acc: 0.5535
1280/9333 [===>..........................] - ETA: 5:16 - loss: 0.6835 - acc: 0.5523
1344/9333 [===>..........................] - ETA: 5:13 - loss: 0.6832 - acc: 0.5521
1408/9333 [===>..........................] - ETA: 5:10 - loss: 0.6837 - acc: 0.5497
1472/9333 [===>..........................] - ETA: 5:06 - loss: 0.6855 - acc: 0.5448
1536/9333 [===>..........................] - ETA: 5:02 - loss: 0.6868 - acc: 0.5430
1600/9333 [====>.........................] - ETA: 5:01 - loss: 0.6876 - acc: 0.5413
1664/9333 [====>.........................] - ETA: 4:59 - loss: 0.6881 - acc: 0.5427
1728/9333 [====>.........................] - ETA: 4:57 - loss: 0.6888 - acc: 0.5405
1792/9333 [====>.........................] - ETA: 4:54 - loss: 0.6884 - acc: 0.5402
1856/9333 [====>.........................] - ETA: 4:50 - loss: 0.6871 - acc: 0.5447
1920/9333 [=====>........................] - ETA: 4:49 - loss: 0.6872 - acc: 0.5432
1984/9333 [=====>........................] - ETA: 4:46 - loss: 0.6863 - acc: 0.5449
2048/9333 [=====>........................] - ETA: 4:43 - loss: 0.6867 - acc: 0.5435
2112/9333 [=====>........................] - ETA: 4:40 - loss: 0.6868 - acc: 0.5426
2176/9333 [=====>........................] - ETA: 4:40 - loss: 0.6863 - acc: 0.5441
2240/9333 [======>.......................] - ETA: 4:37 - loss: 0.6861 - acc: 0.5446
2304/9333 [======>.......................] - ETA: 4:36 - loss: 0.6861 - acc: 0.5456
2368/9333 [======>.......................] - ETA: 4:33 - loss: 0.6865 - acc: 0.5465
2432/9333 [======>.......................] - ETA: 4:29 - loss: 0.6869 - acc: 0.5432
2496/9333 [=======>......................] - ETA: 4:27 - loss: 0.6873 - acc: 0.5417
2560/9333 [=======>......................] - ETA: 4:24 - loss: 0.6878 - acc: 0.5410
2624/9333 [=======>......................] - ETA: 4:22 - loss: 0.6878 - acc: 0.5423
2688/9333 [=======>......................] - ETA: 4:21 - loss: 0.6881 - acc: 0.5432
2752/9333 [=======>......................] - ETA: 4:18 - loss: 0.6876 - acc: 0.5432
2816/9333 [========>.....................] - ETA: 4:16 - loss: 0.6878 - acc: 0.5423
2880/9333 [========>.....................] - ETA: 4:13 - loss: 0.6877 - acc: 0.5437
2944/9333 [========>.....................] - ETA: 4:10 - loss: 0.6878 - acc: 0.5428
3008/9333 [========>.....................] - ETA: 4:08 - loss: 0.6872 - acc: 0.5445
3072/9333 [========>.....................] - ETA: 4:05 - loss: 0.6869 - acc: 0.5439
3136/9333 [=========>....................] - ETA: 4:03 - loss: 0.6868 - acc: 0.5443
3200/9333 [=========>....................] - ETA: 4:01 - loss: 0.6864 - acc: 0.5463
3264/9333 [=========>....................] - ETA: 3:59 - loss: 0.6868 - acc: 0.5456
3328/9333 [=========>....................] - ETA: 3:56 - loss: 0.6866 - acc: 0.5457
3392/9333 [=========>....................] - ETA: 3:53 - loss: 0.6865 - acc: 0.5457
3456/9333 [==========>...................] - ETA: 3:51 - loss: 0.6866 - acc: 0.5448
3520/9333 [==========>...................] - ETA: 3:48 - loss: 0.6866 - acc: 0.5446
3584/9333 [==========>...................] - ETA: 3:45 - loss: 0.6867 - acc: 0.5446
3648/9333 [==========>...................] - ETA: 3:42 - loss: 0.6876 - acc: 0.5433
3712/9333 [==========>...................] - ETA: 3:39 - loss: 0.6879 - acc: 0.5428
3776/9333 [===========>..................] - ETA: 3:37 - loss: 0.6882 - acc: 0.5429
3840/9333 [===========>..................] - ETA: 3:35 - loss: 0.6883 - acc: 0.5427
3904/9333 [===========>..................] - ETA: 3:33 - loss: 0.6877 - acc: 0.5451
3968/9333 [===========>..................] - ETA: 3:30 - loss: 0.6877 - acc: 0.5456
4032/9333 [===========>..................] - ETA: 3:28 - loss: 0.6880 - acc: 0.5456
4096/9333 [============>.................] - ETA: 3:25 - loss: 0.6878 - acc: 0.5457
4160/9333 [============>.................] - ETA: 3:22 - loss: 0.6877 - acc: 0.5457
4224/9333 [============>.................] - ETA: 3:20 - loss: 0.6878 - acc: 0.5459
4288/9333 [============>.................] - ETA: 3:18 - loss: 0.6878 - acc: 0.5457
4352/9333 [============>.................] - ETA: 3:16 - loss: 0.6881 - acc: 0.5439
4416/9333 [=============>................] - ETA: 3:14 - loss: 0.6885 - acc: 0.5417
4480/9333 [=============>................] - ETA: 3:11 - loss: 0.6883 - acc: 0.5417
4544/9333 [=============>................] - ETA: 3:09 - loss: 0.6881 - acc: 0.5425
4608/9333 [=============>................] - ETA: 3:06 - loss: 0.6880 - acc: 0.5428
4672/9333 [==============>...............] - ETA: 3:03 - loss: 0.6881 - acc: 0.5424
4736/9333 [==============>...............] - ETA: 3:01 - loss: 0.6880 - acc: 0.5427
4800/9333 [==============>...............] - ETA: 2:58 - loss: 0.6882 - acc: 0.5410
4864/9333 [==============>...............] - ETA: 2:56 - loss: 0.6880 - acc: 0.5413
4928/9333 [==============>...............] - ETA: 2:54 - loss: 0.6878 - acc: 0.5410
4992/9333 [===============>..............] - ETA: 2:51 - loss: 0.6876 - acc: 0.5423
5056/9333 [===============>..............] - ETA: 2:48 - loss: 0.6877 - acc: 0.5419
5120/9333 [===============>..............] - ETA: 2:46 - loss: 0.6877 - acc: 0.5422
5184/9333 [===============>..............] - ETA: 2:43 - loss: 0.6879 - acc: 0.5415
5248/9333 [===============>..............] - ETA: 2:40 - loss: 0.6880 - acc: 0.5415
5312/9333 [================>.............] - ETA: 2:38 - loss: 0.6879 - acc: 0.5410
5376/9333 [================>.............] - ETA: 2:36 - loss: 0.6881 - acc: 0.5406
5440/9333 [================>.............] - ETA: 2:33 - loss: 0.6882 - acc: 0.5401
5504/9333 [================>.............] - ETA: 2:31 - loss: 0.6883 - acc: 0.5392
5568/9333 [================>.............] - ETA: 2:28 - loss: 0.6883 - acc: 0.5397
5632/9333 [=================>............] - ETA: 2:26 - loss: 0.6888 - acc: 0.5378
5696/9333 [=================>............] - ETA: 2:23 - loss: 0.6884 - acc: 0.5390
5760/9333 [=================>............] - ETA: 2:21 - loss: 0.6884 - acc: 0.5384
5824/9333 [=================>............] - ETA: 2:18 - loss: 0.6884 - acc: 0.5379
5888/9333 [=================>............] - ETA: 2:15 - loss: 0.6884 - acc: 0.5384
5952/9333 [==================>...........] - ETA: 2:13 - loss: 0.6886 - acc: 0.5380
6016/9333 [==================>...........] - ETA: 2:11 - loss: 0.6885 - acc: 0.5382
6080/9333 [==================>...........] - ETA: 2:08 - loss: 0.6886 - acc: 0.5385
6144/9333 [==================>...........] - ETA: 2:05 - loss: 0.6888 - acc: 0.5379
6208/9333 [==================>...........] - ETA: 2:03 - loss: 0.6887 - acc: 0.5379
6272/9333 [===================>..........] - ETA: 2:00 - loss: 0.6888 - acc: 0.5378
6336/9333 [===================>..........] - ETA: 1:58 - loss: 0.6886 - acc: 0.5379
6400/9333 [===================>..........] - ETA: 1:55 - loss: 0.6886 - acc: 0.5383
6464/9333 [===================>..........] - ETA: 1:53 - loss: 0.6884 - acc: 0.5382
6528/9333 [===================>..........] - ETA: 1:50 - loss: 0.6886 - acc: 0.5377
6592/9333 [====================>.........] - ETA: 1:48 - loss: 0.6887 - acc: 0.5373
6656/9333 [====================>.........] - ETA: 1:45 - loss: 0.6886 - acc: 0.5380
6720/9333 [====================>.........] - ETA: 1:43 - loss: 0.6885 - acc: 0.5388
6784/9333 [====================>.........] - ETA: 1:40 - loss: 0.6882 - acc: 0.5404
6848/9333 [=====================>........] - ETA: 1:38 - loss: 0.6881 - acc: 0.5409
6912/9333 [=====================>........] - ETA: 1:35 - loss: 0.6882 - acc: 0.5408
6976/9333 [=====================>........] - ETA: 1:33 - loss: 0.6883 - acc: 0.5403
7040/9333 [=====================>........] - ETA: 1:30 - loss: 0.6883 - acc: 0.5405
7104/9333 [=====================>........] - ETA: 1:28 - loss: 0.6887 - acc: 0.5394
7168/9333 [======================>.......] - ETA: 1:25 - loss: 0.6893 - acc: 0.5385
7232/9333 [======================>.......] - ETA: 1:22 - loss: 0.6895 - acc: 0.5383
7296/9333 [======================>.......] - ETA: 1:20 - loss: 0.6895 - acc: 0.5382
7360/9333 [======================>.......] - ETA: 1:17 - loss: 0.6894 - acc: 0.5385
7424/9333 [======================>.......] - ETA: 1:15 - loss: 0.6895 - acc: 0.5381
7488/9333 [=======================>......] - ETA: 1:12 - loss: 0.6896 - acc: 0.5378
7552/9333 [=======================>......] - ETA: 1:10 - loss: 0.6896 - acc: 0.5375
7616/9333 [=======================>......] - ETA: 1:07 - loss: 0.6896 - acc: 0.5374
7680/9333 [=======================>......] - ETA: 1:05 - loss: 0.6895 - acc: 0.5376
7744/9333 [=======================>......] - ETA: 1:02 - loss: 0.6895 - acc: 0.5376
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6895 - acc: 0.5380
7872/9333 [========================>.....] - ETA: 57s - loss: 0.6896 - acc: 0.5380 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6896 - acc: 0.5372
8000/9333 [========================>.....] - ETA: 52s - loss: 0.6897 - acc: 0.5360
8064/9333 [========================>.....] - ETA: 50s - loss: 0.6897 - acc: 0.5353
8128/9333 [=========================>....] - ETA: 47s - loss: 0.6898 - acc: 0.5347
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6898 - acc: 0.5352
8256/9333 [=========================>....] - ETA: 42s - loss: 0.6897 - acc: 0.5360
8320/9333 [=========================>....] - ETA: 39s - loss: 0.6896 - acc: 0.5362
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6897 - acc: 0.5369
8448/9333 [==========================>...] - ETA: 34s - loss: 0.6897 - acc: 0.5367
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6897 - acc: 0.5368
8576/9333 [==========================>...] - ETA: 29s - loss: 0.6897 - acc: 0.5370
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6897 - acc: 0.5373
8704/9333 [==========================>...] - ETA: 24s - loss: 0.6897 - acc: 0.5375
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6896 - acc: 0.5378
8832/9333 [===========================>..] - ETA: 19s - loss: 0.6896 - acc: 0.5377
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6897 - acc: 0.5373
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6896 - acc: 0.5373
9024/9333 [============================>.] - ETA: 12s - loss: 0.6897 - acc: 0.5372
9088/9333 [============================>.] - ETA: 9s - loss: 0.6897 - acc: 0.5368 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6898 - acc: 0.5363
9216/9333 [============================>.] - ETA: 4s - loss: 0.6898 - acc: 0.5362
9280/9333 [============================>.] - ETA: 2s - loss: 0.6898 - acc: 0.5362
9333/9333 [==============================] - 385s 41ms/step - loss: 0.6898 - acc: 0.5361 - val_loss: 0.6869 - val_acc: 0.5400

Epoch 00006: val_acc did not improve from 0.54098
Epoch 7/10

  64/9333 [..............................] - ETA: 6:10 - loss: 0.6826 - acc: 0.5000
 128/9333 [..............................] - ETA: 5:41 - loss: 0.6808 - acc: 0.5234
 192/9333 [..............................] - ETA: 5:42 - loss: 0.6800 - acc: 0.5469
 256/9333 [..............................] - ETA: 5:54 - loss: 0.6753 - acc: 0.5586
 320/9333 [>.............................] - ETA: 6:00 - loss: 0.6791 - acc: 0.5531
 384/9333 [>.............................] - ETA: 5:56 - loss: 0.6771 - acc: 0.5625
 448/9333 [>.............................] - ETA: 5:54 - loss: 0.6776 - acc: 0.5692
 512/9333 [>.............................] - ETA: 5:48 - loss: 0.6793 - acc: 0.5625
 576/9333 [>.............................] - ETA: 5:43 - loss: 0.6826 - acc: 0.5538
 640/9333 [=>............................] - ETA: 5:38 - loss: 0.6834 - acc: 0.5484
 704/9333 [=>............................] - ETA: 5:33 - loss: 0.6817 - acc: 0.5511
 768/9333 [=>............................] - ETA: 5:32 - loss: 0.6832 - acc: 0.5430
 832/9333 [=>............................] - ETA: 5:30 - loss: 0.6827 - acc: 0.5421
 896/9333 [=>............................] - ETA: 5:25 - loss: 0.6829 - acc: 0.5424
 960/9333 [==>...........................] - ETA: 5:22 - loss: 0.6818 - acc: 0.5448
1024/9333 [==>...........................] - ETA: 5:22 - loss: 0.6824 - acc: 0.5420
1088/9333 [==>...........................] - ETA: 5:22 - loss: 0.6832 - acc: 0.5404
1152/9333 [==>...........................] - ETA: 5:21 - loss: 0.6827 - acc: 0.5425
1216/9333 [==>...........................] - ETA: 5:17 - loss: 0.6836 - acc: 0.5444
1280/9333 [===>..........................] - ETA: 5:15 - loss: 0.6821 - acc: 0.5500
1344/9333 [===>..........................] - ETA: 5:12 - loss: 0.6824 - acc: 0.5469
1408/9333 [===>..........................] - ETA: 5:09 - loss: 0.6833 - acc: 0.5455
1472/9333 [===>..........................] - ETA: 5:05 - loss: 0.6844 - acc: 0.5448
1536/9333 [===>..........................] - ETA: 5:01 - loss: 0.6844 - acc: 0.5469
1600/9333 [====>.........................] - ETA: 4:58 - loss: 0.6843 - acc: 0.5475
1664/9333 [====>.........................] - ETA: 4:57 - loss: 0.6846 - acc: 0.5475
1728/9333 [====>.........................] - ETA: 4:57 - loss: 0.6853 - acc: 0.5475
1792/9333 [====>.........................] - ETA: 4:57 - loss: 0.6854 - acc: 0.5458
1856/9333 [====>.........................] - ETA: 4:53 - loss: 0.6856 - acc: 0.5442
1920/9333 [=====>........................] - ETA: 4:51 - loss: 0.6862 - acc: 0.5422
1984/9333 [=====>........................] - ETA: 4:48 - loss: 0.6861 - acc: 0.5418
2048/9333 [=====>........................] - ETA: 4:44 - loss: 0.6862 - acc: 0.5420
2112/9333 [=====>........................] - ETA: 4:41 - loss: 0.6862 - acc: 0.5431
2176/9333 [=====>........................] - ETA: 4:39 - loss: 0.6863 - acc: 0.5427
2240/9333 [======>.......................] - ETA: 4:36 - loss: 0.6857 - acc: 0.5446
2304/9333 [======>.......................] - ETA: 4:34 - loss: 0.6859 - acc: 0.5447
2368/9333 [======>.......................] - ETA: 4:32 - loss: 0.6855 - acc: 0.5460
2432/9333 [======>.......................] - ETA: 4:29 - loss: 0.6858 - acc: 0.5444
2496/9333 [=======>......................] - ETA: 4:27 - loss: 0.6857 - acc: 0.5437
2560/9333 [=======>......................] - ETA: 4:26 - loss: 0.6859 - acc: 0.5418
2624/9333 [=======>......................] - ETA: 4:23 - loss: 0.6867 - acc: 0.5396
2688/9333 [=======>......................] - ETA: 4:21 - loss: 0.6870 - acc: 0.5394
2752/9333 [=======>......................] - ETA: 4:17 - loss: 0.6869 - acc: 0.5400
2816/9333 [========>.....................] - ETA: 4:14 - loss: 0.6868 - acc: 0.5412
2880/9333 [========>.....................] - ETA: 4:13 - loss: 0.6870 - acc: 0.5399
2944/9333 [========>.....................] - ETA: 4:11 - loss: 0.6867 - acc: 0.5421
3008/9333 [========>.....................] - ETA: 4:09 - loss: 0.6865 - acc: 0.5436
3072/9333 [========>.....................] - ETA: 4:06 - loss: 0.6857 - acc: 0.5462
3136/9333 [=========>....................] - ETA: 4:03 - loss: 0.6855 - acc: 0.5466
3200/9333 [=========>....................] - ETA: 4:00 - loss: 0.6854 - acc: 0.5466
3264/9333 [=========>....................] - ETA: 3:58 - loss: 0.6853 - acc: 0.5472
3328/9333 [=========>....................] - ETA: 3:56 - loss: 0.6853 - acc: 0.5478
3392/9333 [=========>....................] - ETA: 3:53 - loss: 0.6853 - acc: 0.5495
3456/9333 [==========>...................] - ETA: 3:52 - loss: 0.6853 - acc: 0.5492
3520/9333 [==========>...................] - ETA: 3:51 - loss: 0.6848 - acc: 0.5503
3584/9333 [==========>...................] - ETA: 3:48 - loss: 0.6847 - acc: 0.5511
3648/9333 [==========>...................] - ETA: 3:45 - loss: 0.6847 - acc: 0.5518
3712/9333 [==========>...................] - ETA: 3:42 - loss: 0.6851 - acc: 0.5509
3776/9333 [===========>..................] - ETA: 3:41 - loss: 0.6857 - acc: 0.5487
3840/9333 [===========>..................] - ETA: 3:38 - loss: 0.6854 - acc: 0.5497
3904/9333 [===========>..................] - ETA: 3:35 - loss: 0.6853 - acc: 0.5507
3968/9333 [===========>..................] - ETA: 3:33 - loss: 0.6853 - acc: 0.5504
4032/9333 [===========>..................] - ETA: 3:30 - loss: 0.6850 - acc: 0.5511
4096/9333 [============>.................] - ETA: 3:28 - loss: 0.6854 - acc: 0.5508
4160/9333 [============>.................] - ETA: 3:25 - loss: 0.6859 - acc: 0.5490
4224/9333 [============>.................] - ETA: 3:22 - loss: 0.6859 - acc: 0.5490
4288/9333 [============>.................] - ETA: 3:20 - loss: 0.6856 - acc: 0.5494
4352/9333 [============>.................] - ETA: 3:17 - loss: 0.6857 - acc: 0.5480
4416/9333 [=============>................] - ETA: 3:15 - loss: 0.6857 - acc: 0.5482
4480/9333 [=============>................] - ETA: 3:12 - loss: 0.6854 - acc: 0.5487
4544/9333 [=============>................] - ETA: 3:09 - loss: 0.6852 - acc: 0.5500
4608/9333 [=============>................] - ETA: 3:07 - loss: 0.6853 - acc: 0.5497
4672/9333 [==============>...............] - ETA: 3:05 - loss: 0.6854 - acc: 0.5490
4736/9333 [==============>...............] - ETA: 3:03 - loss: 0.6853 - acc: 0.5496
4800/9333 [==============>...............] - ETA: 3:00 - loss: 0.6853 - acc: 0.5498
4864/9333 [==============>...............] - ETA: 2:57 - loss: 0.6854 - acc: 0.5500
4928/9333 [==============>...............] - ETA: 2:54 - loss: 0.6852 - acc: 0.5511
4992/9333 [===============>..............] - ETA: 2:52 - loss: 0.6854 - acc: 0.5509
5056/9333 [===============>..............] - ETA: 2:49 - loss: 0.6856 - acc: 0.5502
5120/9333 [===============>..............] - ETA: 2:47 - loss: 0.6855 - acc: 0.5504
5184/9333 [===============>..............] - ETA: 2:45 - loss: 0.6855 - acc: 0.5500
5248/9333 [===============>..............] - ETA: 2:42 - loss: 0.6854 - acc: 0.5505
5312/9333 [================>.............] - ETA: 2:40 - loss: 0.6854 - acc: 0.5505
5376/9333 [================>.............] - ETA: 2:37 - loss: 0.6855 - acc: 0.5506
5440/9333 [================>.............] - ETA: 2:35 - loss: 0.6854 - acc: 0.5509
5504/9333 [================>.............] - ETA: 2:32 - loss: 0.6854 - acc: 0.5507
5568/9333 [================>.............] - ETA: 2:30 - loss: 0.6857 - acc: 0.5501
5632/9333 [=================>............] - ETA: 2:28 - loss: 0.6858 - acc: 0.5494
5696/9333 [=================>............] - ETA: 2:25 - loss: 0.6859 - acc: 0.5490
5760/9333 [=================>............] - ETA: 2:22 - loss: 0.6858 - acc: 0.5491
5824/9333 [=================>............] - ETA: 2:20 - loss: 0.6860 - acc: 0.5491
5888/9333 [=================>............] - ETA: 2:17 - loss: 0.6859 - acc: 0.5504
5952/9333 [==================>...........] - ETA: 2:14 - loss: 0.6863 - acc: 0.5491
6016/9333 [==================>...........] - ETA: 2:12 - loss: 0.6864 - acc: 0.5487
6080/9333 [==================>...........] - ETA: 2:09 - loss: 0.6863 - acc: 0.5490
6144/9333 [==================>...........] - ETA: 2:07 - loss: 0.6862 - acc: 0.5496
6208/9333 [==================>...........] - ETA: 2:04 - loss: 0.6862 - acc: 0.5499
6272/9333 [===================>..........] - ETA: 2:02 - loss: 0.6861 - acc: 0.5501
6336/9333 [===================>..........] - ETA: 1:59 - loss: 0.6862 - acc: 0.5492
6400/9333 [===================>..........] - ETA: 1:57 - loss: 0.6862 - acc: 0.5491
6464/9333 [===================>..........] - ETA: 1:54 - loss: 0.6862 - acc: 0.5487
6528/9333 [===================>..........] - ETA: 1:51 - loss: 0.6861 - acc: 0.5499
6592/9333 [====================>.........] - ETA: 1:49 - loss: 0.6860 - acc: 0.5510
6656/9333 [====================>.........] - ETA: 1:46 - loss: 0.6861 - acc: 0.5511
6720/9333 [====================>.........] - ETA: 1:44 - loss: 0.6860 - acc: 0.5512
6784/9333 [====================>.........] - ETA: 1:41 - loss: 0.6859 - acc: 0.5517
6848/9333 [=====================>........] - ETA: 1:39 - loss: 0.6861 - acc: 0.5505
6912/9333 [=====================>........] - ETA: 1:36 - loss: 0.6862 - acc: 0.5502
6976/9333 [=====================>........] - ETA: 1:33 - loss: 0.6863 - acc: 0.5500
7040/9333 [=====================>........] - ETA: 1:31 - loss: 0.6865 - acc: 0.5499
7104/9333 [=====================>........] - ETA: 1:28 - loss: 0.6864 - acc: 0.5503
7168/9333 [======================>.......] - ETA: 1:26 - loss: 0.6864 - acc: 0.5508
7232/9333 [======================>.......] - ETA: 1:23 - loss: 0.6863 - acc: 0.5509
7296/9333 [======================>.......] - ETA: 1:21 - loss: 0.6864 - acc: 0.5510
7360/9333 [======================>.......] - ETA: 1:18 - loss: 0.6863 - acc: 0.5510
7424/9333 [======================>.......] - ETA: 1:16 - loss: 0.6863 - acc: 0.5506
7488/9333 [=======================>......] - ETA: 1:13 - loss: 0.6865 - acc: 0.5507
7552/9333 [=======================>......] - ETA: 1:10 - loss: 0.6867 - acc: 0.5505
7616/9333 [=======================>......] - ETA: 1:08 - loss: 0.6864 - acc: 0.5509
7680/9333 [=======================>......] - ETA: 1:05 - loss: 0.6864 - acc: 0.5508
7744/9333 [=======================>......] - ETA: 1:03 - loss: 0.6869 - acc: 0.5498
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6871 - acc: 0.5496
7872/9333 [========================>.....] - ETA: 58s - loss: 0.6870 - acc: 0.5502 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6869 - acc: 0.5503
8000/9333 [========================>.....] - ETA: 52s - loss: 0.6869 - acc: 0.5507
8064/9333 [========================>.....] - ETA: 50s - loss: 0.6870 - acc: 0.5507
8128/9333 [=========================>....] - ETA: 47s - loss: 0.6868 - acc: 0.5509
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6869 - acc: 0.5500
8256/9333 [=========================>....] - ETA: 42s - loss: 0.6870 - acc: 0.5498
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6868 - acc: 0.5500
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6869 - acc: 0.5501
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6868 - acc: 0.5498
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6870 - acc: 0.5493
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6872 - acc: 0.5489
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6873 - acc: 0.5488
8704/9333 [==========================>...] - ETA: 24s - loss: 0.6873 - acc: 0.5486
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6874 - acc: 0.5477
8832/9333 [===========================>..] - ETA: 19s - loss: 0.6874 - acc: 0.5473
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6873 - acc: 0.5480
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6872 - acc: 0.5484
9024/9333 [============================>.] - ETA: 12s - loss: 0.6873 - acc: 0.5475
9088/9333 [============================>.] - ETA: 9s - loss: 0.6874 - acc: 0.5473 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6873 - acc: 0.5477
9216/9333 [============================>.] - ETA: 4s - loss: 0.6871 - acc: 0.5484
9280/9333 [============================>.] - ETA: 2s - loss: 0.6872 - acc: 0.5482
9333/9333 [==============================] - 388s 42ms/step - loss: 0.6872 - acc: 0.5478 - val_loss: 0.6919 - val_acc: 0.5198

Epoch 00007: val_acc did not improve from 0.54098
Epoch 8/10

  64/9333 [..............................] - ETA: 6:18 - loss: 0.6963 - acc: 0.5000
 128/9333 [..............................] - ETA: 6:16 - loss: 0.6940 - acc: 0.5312
 192/9333 [..............................] - ETA: 6:02 - loss: 0.6947 - acc: 0.5208
 256/9333 [..............................] - ETA: 5:53 - loss: 0.6887 - acc: 0.5430
 320/9333 [>.............................] - ETA: 5:47 - loss: 0.6898 - acc: 0.5281
 384/9333 [>.............................] - ETA: 5:48 - loss: 0.6906 - acc: 0.5260
 448/9333 [>.............................] - ETA: 5:48 - loss: 0.6924 - acc: 0.5134
 512/9333 [>.............................] - ETA: 5:42 - loss: 0.6908 - acc: 0.5156
 576/9333 [>.............................] - ETA: 5:38 - loss: 0.6911 - acc: 0.5156
 640/9333 [=>............................] - ETA: 5:38 - loss: 0.6874 - acc: 0.5344
 704/9333 [=>............................] - ETA: 5:38 - loss: 0.6859 - acc: 0.5398
 768/9333 [=>............................] - ETA: 5:39 - loss: 0.6867 - acc: 0.5365
 832/9333 [=>............................] - ETA: 5:37 - loss: 0.6859 - acc: 0.5385
 896/9333 [=>............................] - ETA: 5:32 - loss: 0.6851 - acc: 0.5458
 960/9333 [==>...........................] - ETA: 5:29 - loss: 0.6855 - acc: 0.5479
1024/9333 [==>...........................] - ETA: 5:26 - loss: 0.6849 - acc: 0.5508
1088/9333 [==>...........................] - ETA: 5:23 - loss: 0.6849 - acc: 0.5496
1152/9333 [==>...........................] - ETA: 5:19 - loss: 0.6849 - acc: 0.5538
1216/9333 [==>...........................] - ETA: 5:19 - loss: 0.6858 - acc: 0.5526
1280/9333 [===>..........................] - ETA: 5:17 - loss: 0.6858 - acc: 0.5523
1344/9333 [===>..........................] - ETA: 5:15 - loss: 0.6865 - acc: 0.5491
1408/9333 [===>..........................] - ETA: 5:12 - loss: 0.6867 - acc: 0.5476
1472/9333 [===>..........................] - ETA: 5:08 - loss: 0.6875 - acc: 0.5455
1536/9333 [===>..........................] - ETA: 5:04 - loss: 0.6861 - acc: 0.5501
1600/9333 [====>.........................] - ETA: 5:01 - loss: 0.6859 - acc: 0.5500
1664/9333 [====>.........................] - ETA: 4:58 - loss: 0.6857 - acc: 0.5511
1728/9333 [====>.........................] - ETA: 4:55 - loss: 0.6852 - acc: 0.5550
1792/9333 [====>.........................] - ETA: 4:54 - loss: 0.6850 - acc: 0.5575
1856/9333 [====>.........................] - ETA: 4:52 - loss: 0.6843 - acc: 0.5598
1920/9333 [=====>........................] - ETA: 4:51 - loss: 0.6839 - acc: 0.5604
1984/9333 [=====>........................] - ETA: 4:49 - loss: 0.6843 - acc: 0.5585
2048/9333 [=====>........................] - ETA: 4:46 - loss: 0.6845 - acc: 0.5566
2112/9333 [=====>........................] - ETA: 4:45 - loss: 0.6848 - acc: 0.5554
2176/9333 [=====>........................] - ETA: 4:42 - loss: 0.6845 - acc: 0.5556
2240/9333 [======>.......................] - ETA: 4:38 - loss: 0.6834 - acc: 0.5576
2304/9333 [======>.......................] - ETA: 4:37 - loss: 0.6836 - acc: 0.5590
2368/9333 [======>.......................] - ETA: 4:36 - loss: 0.6835 - acc: 0.5595
2432/9333 [======>.......................] - ETA: 4:33 - loss: 0.6837 - acc: 0.5596
2496/9333 [=======>......................] - ETA: 4:31 - loss: 0.6835 - acc: 0.5597
2560/9333 [=======>......................] - ETA: 4:28 - loss: 0.6836 - acc: 0.5578
2624/9333 [=======>......................] - ETA: 4:25 - loss: 0.6832 - acc: 0.5579
2688/9333 [=======>......................] - ETA: 4:21 - loss: 0.6828 - acc: 0.5595
2752/9333 [=======>......................] - ETA: 4:18 - loss: 0.6831 - acc: 0.5578
2816/9333 [========>.....................] - ETA: 4:16 - loss: 0.6829 - acc: 0.5579
2880/9333 [========>.....................] - ETA: 4:13 - loss: 0.6844 - acc: 0.5542
2944/9333 [========>.....................] - ETA: 4:11 - loss: 0.6848 - acc: 0.5526
3008/9333 [========>.....................] - ETA: 4:09 - loss: 0.6845 - acc: 0.5532
3072/9333 [========>.....................] - ETA: 4:07 - loss: 0.6848 - acc: 0.5511
3136/9333 [=========>....................] - ETA: 4:04 - loss: 0.6849 - acc: 0.5510
3200/9333 [=========>....................] - ETA: 4:01 - loss: 0.6853 - acc: 0.5500
3264/9333 [=========>....................] - ETA: 3:58 - loss: 0.6853 - acc: 0.5506
3328/9333 [=========>....................] - ETA: 3:55 - loss: 0.6852 - acc: 0.5505
3392/9333 [=========>....................] - ETA: 3:53 - loss: 0.6853 - acc: 0.5501
3456/9333 [==========>...................] - ETA: 3:53 - loss: 0.6853 - acc: 0.5503
3520/9333 [==========>...................] - ETA: 3:50 - loss: 0.6851 - acc: 0.5500
3584/9333 [==========>...................] - ETA: 3:47 - loss: 0.6855 - acc: 0.5480
3648/9333 [==========>...................] - ETA: 3:45 - loss: 0.6860 - acc: 0.5471
3712/9333 [==========>...................] - ETA: 3:42 - loss: 0.6862 - acc: 0.5463
3776/9333 [===========>..................] - ETA: 3:40 - loss: 0.6866 - acc: 0.5453
3840/9333 [===========>..................] - ETA: 3:37 - loss: 0.6866 - acc: 0.5453
3904/9333 [===========>..................] - ETA: 3:35 - loss: 0.6871 - acc: 0.5438
3968/9333 [===========>..................] - ETA: 3:32 - loss: 0.6874 - acc: 0.5431
4032/9333 [===========>..................] - ETA: 3:30 - loss: 0.6874 - acc: 0.5429
4096/9333 [============>.................] - ETA: 3:27 - loss: 0.6876 - acc: 0.5422
4160/9333 [============>.................] - ETA: 3:25 - loss: 0.6875 - acc: 0.5425
4224/9333 [============>.................] - ETA: 3:22 - loss: 0.6874 - acc: 0.5431
4288/9333 [============>.................] - ETA: 3:19 - loss: 0.6875 - acc: 0.5434
4352/9333 [============>.................] - ETA: 3:17 - loss: 0.6875 - acc: 0.5420
4416/9333 [=============>................] - ETA: 3:14 - loss: 0.6877 - acc: 0.5417
4480/9333 [=============>................] - ETA: 3:12 - loss: 0.6878 - acc: 0.5411
4544/9333 [=============>................] - ETA: 3:10 - loss: 0.6877 - acc: 0.5414
4608/9333 [=============>................] - ETA: 3:07 - loss: 0.6875 - acc: 0.5423
4672/9333 [==============>...............] - ETA: 3:05 - loss: 0.6877 - acc: 0.5420
4736/9333 [==============>...............] - ETA: 3:02 - loss: 0.6882 - acc: 0.5410
4800/9333 [==============>...............] - ETA: 3:00 - loss: 0.6882 - acc: 0.5410
4864/9333 [==============>...............] - ETA: 2:57 - loss: 0.6884 - acc: 0.5405
4928/9333 [==============>...............] - ETA: 2:54 - loss: 0.6885 - acc: 0.5404
4992/9333 [===============>..............] - ETA: 2:52 - loss: 0.6884 - acc: 0.5405
5056/9333 [===============>..............] - ETA: 2:49 - loss: 0.6887 - acc: 0.5392
5120/9333 [===============>..............] - ETA: 2:46 - loss: 0.6887 - acc: 0.5389
5184/9333 [===============>..............] - ETA: 2:44 - loss: 0.6888 - acc: 0.5392
5248/9333 [===============>..............] - ETA: 2:41 - loss: 0.6886 - acc: 0.5394
5312/9333 [================>.............] - ETA: 2:39 - loss: 0.6889 - acc: 0.5384
5376/9333 [================>.............] - ETA: 2:36 - loss: 0.6887 - acc: 0.5398
5440/9333 [================>.............] - ETA: 2:34 - loss: 0.6887 - acc: 0.5403
5504/9333 [================>.............] - ETA: 2:31 - loss: 0.6886 - acc: 0.5405
5568/9333 [================>.............] - ETA: 2:28 - loss: 0.6888 - acc: 0.5393
5632/9333 [=================>............] - ETA: 2:26 - loss: 0.6887 - acc: 0.5394
5696/9333 [=================>............] - ETA: 2:23 - loss: 0.6888 - acc: 0.5392
5760/9333 [=================>............] - ETA: 2:21 - loss: 0.6886 - acc: 0.5394
5824/9333 [=================>............] - ETA: 2:19 - loss: 0.6885 - acc: 0.5397
5888/9333 [=================>............] - ETA: 2:16 - loss: 0.6884 - acc: 0.5396
5952/9333 [==================>...........] - ETA: 2:14 - loss: 0.6885 - acc: 0.5395
6016/9333 [==================>...........] - ETA: 2:11 - loss: 0.6888 - acc: 0.5392
6080/9333 [==================>...........] - ETA: 2:08 - loss: 0.6890 - acc: 0.5383
6144/9333 [==================>...........] - ETA: 2:06 - loss: 0.6893 - acc: 0.5376
6208/9333 [==================>...........] - ETA: 2:03 - loss: 0.6892 - acc: 0.5387
6272/9333 [===================>..........] - ETA: 2:01 - loss: 0.6895 - acc: 0.5384
6336/9333 [===================>..........] - ETA: 1:58 - loss: 0.6893 - acc: 0.5387
6400/9333 [===================>..........] - ETA: 1:56 - loss: 0.6894 - acc: 0.5391
6464/9333 [===================>..........] - ETA: 1:53 - loss: 0.6892 - acc: 0.5396
6528/9333 [===================>..........] - ETA: 1:51 - loss: 0.6892 - acc: 0.5395
6592/9333 [====================>.........] - ETA: 1:48 - loss: 0.6890 - acc: 0.5399
6656/9333 [====================>.........] - ETA: 1:45 - loss: 0.6890 - acc: 0.5398
6720/9333 [====================>.........] - ETA: 1:43 - loss: 0.6890 - acc: 0.5403
6784/9333 [====================>.........] - ETA: 1:40 - loss: 0.6890 - acc: 0.5410
6848/9333 [=====================>........] - ETA: 1:38 - loss: 0.6889 - acc: 0.5412
6912/9333 [=====================>........] - ETA: 1:35 - loss: 0.6886 - acc: 0.5414
6976/9333 [=====================>........] - ETA: 1:33 - loss: 0.6885 - acc: 0.5419
7040/9333 [=====================>........] - ETA: 1:30 - loss: 0.6885 - acc: 0.5425
7104/9333 [=====================>........] - ETA: 1:28 - loss: 0.6886 - acc: 0.5417
7168/9333 [======================>.......] - ETA: 1:25 - loss: 0.6889 - acc: 0.5414
7232/9333 [======================>.......] - ETA: 1:23 - loss: 0.6889 - acc: 0.5415
7296/9333 [======================>.......] - ETA: 1:20 - loss: 0.6891 - acc: 0.5418
7360/9333 [======================>.......] - ETA: 1:17 - loss: 0.6892 - acc: 0.5418
7424/9333 [======================>.......] - ETA: 1:15 - loss: 0.6890 - acc: 0.5415
7488/9333 [=======================>......] - ETA: 1:12 - loss: 0.6890 - acc: 0.5415
7552/9333 [=======================>......] - ETA: 1:10 - loss: 0.6890 - acc: 0.5414
7616/9333 [=======================>......] - ETA: 1:07 - loss: 0.6888 - acc: 0.5421
7680/9333 [=======================>......] - ETA: 1:05 - loss: 0.6888 - acc: 0.5422
7744/9333 [=======================>......] - ETA: 1:02 - loss: 0.6889 - acc: 0.5412
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6889 - acc: 0.5412
7872/9333 [========================>.....] - ETA: 57s - loss: 0.6888 - acc: 0.5414 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6887 - acc: 0.5423
8000/9333 [========================>.....] - ETA: 52s - loss: 0.6888 - acc: 0.5415
8064/9333 [========================>.....] - ETA: 49s - loss: 0.6887 - acc: 0.5415
8128/9333 [=========================>....] - ETA: 47s - loss: 0.6887 - acc: 0.5418
8192/9333 [=========================>....] - ETA: 44s - loss: 0.6889 - acc: 0.5414
8256/9333 [=========================>....] - ETA: 42s - loss: 0.6887 - acc: 0.5414
8320/9333 [=========================>....] - ETA: 39s - loss: 0.6884 - acc: 0.5419
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6886 - acc: 0.5419
8448/9333 [==========================>...] - ETA: 34s - loss: 0.6888 - acc: 0.5413
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6888 - acc: 0.5414
8576/9333 [==========================>...] - ETA: 29s - loss: 0.6889 - acc: 0.5414
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6888 - acc: 0.5414
8704/9333 [==========================>...] - ETA: 24s - loss: 0.6889 - acc: 0.5418
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6890 - acc: 0.5412
8832/9333 [===========================>..] - ETA: 19s - loss: 0.6888 - acc: 0.5418
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6887 - acc: 0.5422
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6886 - acc: 0.5423
9024/9333 [============================>.] - ETA: 12s - loss: 0.6886 - acc: 0.5423
9088/9333 [============================>.] - ETA: 9s - loss: 0.6886 - acc: 0.5423 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6884 - acc: 0.5424
9216/9333 [============================>.] - ETA: 4s - loss: 0.6882 - acc: 0.5432
9280/9333 [============================>.] - ETA: 2s - loss: 0.6881 - acc: 0.5437
9333/9333 [==============================] - 383s 41ms/step - loss: 0.6879 - acc: 0.5443 - val_loss: 0.6932 - val_acc: 0.5217

Epoch 00008: val_acc did not improve from 0.54098
Epoch 9/10

  64/9333 [..............................] - ETA: 5:54 - loss: 0.6884 - acc: 0.5781
 128/9333 [..............................] - ETA: 6:07 - loss: 0.6805 - acc: 0.6016
 192/9333 [..............................] - ETA: 6:23 - loss: 0.6804 - acc: 0.5833
 256/9333 [..............................] - ETA: 6:10 - loss: 0.6833 - acc: 0.5742
 320/9333 [>.............................] - ETA: 6:14 - loss: 0.6844 - acc: 0.5750
 384/9333 [>.............................] - ETA: 6:10 - loss: 0.6835 - acc: 0.5833
 448/9333 [>.............................] - ETA: 6:10 - loss: 0.6853 - acc: 0.5759
 512/9333 [>.............................] - ETA: 6:08 - loss: 0.6863 - acc: 0.5664
 576/9333 [>.............................] - ETA: 5:58 - loss: 0.6831 - acc: 0.5712
 640/9333 [=>............................] - ETA: 5:53 - loss: 0.6871 - acc: 0.5594
 704/9333 [=>............................] - ETA: 5:47 - loss: 0.6885 - acc: 0.5511
 768/9333 [=>............................] - ETA: 5:42 - loss: 0.6890 - acc: 0.5495
 832/9333 [=>............................] - ETA: 5:35 - loss: 0.6910 - acc: 0.5445
 896/9333 [=>............................] - ETA: 5:36 - loss: 0.6922 - acc: 0.5413
 960/9333 [==>...........................] - ETA: 5:36 - loss: 0.6917 - acc: 0.5427
1024/9333 [==>...........................] - ETA: 5:33 - loss: 0.6900 - acc: 0.5439
1088/9333 [==>...........................] - ETA: 5:29 - loss: 0.6884 - acc: 0.5441
1152/9333 [==>...........................] - ETA: 5:24 - loss: 0.6890 - acc: 0.5451
1216/9333 [==>...........................] - ETA: 5:20 - loss: 0.6880 - acc: 0.5485
1280/9333 [===>..........................] - ETA: 5:16 - loss: 0.6874 - acc: 0.5492
1344/9333 [===>..........................] - ETA: 5:12 - loss: 0.6887 - acc: 0.5454
1408/9333 [===>..........................] - ETA: 5:12 - loss: 0.6885 - acc: 0.5462
1472/9333 [===>..........................] - ETA: 5:10 - loss: 0.6887 - acc: 0.5448
1536/9333 [===>..........................] - ETA: 5:07 - loss: 0.6882 - acc: 0.5475
1600/9333 [====>.........................] - ETA: 5:05 - loss: 0.6884 - acc: 0.5469
1664/9333 [====>.........................] - ETA: 5:01 - loss: 0.6884 - acc: 0.5493
1728/9333 [====>.........................] - ETA: 4:58 - loss: 0.6882 - acc: 0.5527
1792/9333 [====>.........................] - ETA: 4:55 - loss: 0.6882 - acc: 0.5525
1856/9333 [====>.........................] - ETA: 4:55 - loss: 0.6883 - acc: 0.5501
1920/9333 [=====>........................] - ETA: 4:53 - loss: 0.6887 - acc: 0.5469
1984/9333 [=====>........................] - ETA: 4:52 - loss: 0.6897 - acc: 0.5454
2048/9333 [=====>........................] - ETA: 4:49 - loss: 0.6893 - acc: 0.5464
2112/9333 [=====>........................] - ETA: 4:47 - loss: 0.6889 - acc: 0.5478
2176/9333 [=====>........................] - ETA: 4:44 - loss: 0.6898 - acc: 0.5455
2240/9333 [======>.......................] - ETA: 4:42 - loss: 0.6897 - acc: 0.5451
2304/9333 [======>.......................] - ETA: 4:40 - loss: 0.6894 - acc: 0.5486
2368/9333 [======>.......................] - ETA: 4:36 - loss: 0.6896 - acc: 0.5486
2432/9333 [======>.......................] - ETA: 4:34 - loss: 0.6891 - acc: 0.5485
2496/9333 [=======>......................] - ETA: 4:31 - loss: 0.6886 - acc: 0.5497
2560/9333 [=======>......................] - ETA: 4:29 - loss: 0.6884 - acc: 0.5488
2624/9333 [=======>......................] - ETA: 4:26 - loss: 0.6883 - acc: 0.5522
2688/9333 [=======>......................] - ETA: 4:24 - loss: 0.6877 - acc: 0.5539
2752/9333 [=======>......................] - ETA: 4:21 - loss: 0.6881 - acc: 0.5516
2816/9333 [========>.....................] - ETA: 4:19 - loss: 0.6879 - acc: 0.5504
2880/9333 [========>.....................] - ETA: 4:16 - loss: 0.6875 - acc: 0.5521
2944/9333 [========>.....................] - ETA: 4:13 - loss: 0.6878 - acc: 0.5506
3008/9333 [========>.....................] - ETA: 4:10 - loss: 0.6876 - acc: 0.5522
3072/9333 [========>.....................] - ETA: 4:08 - loss: 0.6873 - acc: 0.5521
3136/9333 [=========>....................] - ETA: 4:06 - loss: 0.6874 - acc: 0.5526
3200/9333 [=========>....................] - ETA: 4:03 - loss: 0.6873 - acc: 0.5531
3264/9333 [=========>....................] - ETA: 4:00 - loss: 0.6872 - acc: 0.5536
3328/9333 [=========>....................] - ETA: 3:57 - loss: 0.6873 - acc: 0.5547
3392/9333 [=========>....................] - ETA: 3:54 - loss: 0.6873 - acc: 0.5557
3456/9333 [==========>...................] - ETA: 3:51 - loss: 0.6875 - acc: 0.5553
3520/9333 [==========>...................] - ETA: 3:48 - loss: 0.6871 - acc: 0.5557
3584/9333 [==========>...................] - ETA: 3:45 - loss: 0.6870 - acc: 0.5561
3648/9333 [==========>...................] - ETA: 3:43 - loss: 0.6872 - acc: 0.5559
3712/9333 [==========>...................] - ETA: 3:40 - loss: 0.6866 - acc: 0.5577
3776/9333 [===========>..................] - ETA: 3:37 - loss: 0.6865 - acc: 0.5593
3840/9333 [===========>..................] - ETA: 3:35 - loss: 0.6867 - acc: 0.5573
3904/9333 [===========>..................] - ETA: 3:32 - loss: 0.6870 - acc: 0.5561
3968/9333 [===========>..................] - ETA: 3:30 - loss: 0.6872 - acc: 0.5549
4032/9333 [===========>..................] - ETA: 3:27 - loss: 0.6871 - acc: 0.5548
4096/9333 [============>.................] - ETA: 3:25 - loss: 0.6870 - acc: 0.5557
4160/9333 [============>.................] - ETA: 3:23 - loss: 0.6871 - acc: 0.5543
4224/9333 [============>.................] - ETA: 3:20 - loss: 0.6867 - acc: 0.5554
4288/9333 [============>.................] - ETA: 3:18 - loss: 0.6868 - acc: 0.5555
4352/9333 [============>.................] - ETA: 3:15 - loss: 0.6866 - acc: 0.5554
4416/9333 [=============>................] - ETA: 3:13 - loss: 0.6867 - acc: 0.5543
4480/9333 [=============>................] - ETA: 3:10 - loss: 0.6871 - acc: 0.5520
4544/9333 [=============>................] - ETA: 3:08 - loss: 0.6869 - acc: 0.5522
4608/9333 [=============>................] - ETA: 3:05 - loss: 0.6866 - acc: 0.5532
4672/9333 [==============>...............] - ETA: 3:02 - loss: 0.6866 - acc: 0.5529
4736/9333 [==============>...............] - ETA: 3:00 - loss: 0.6863 - acc: 0.5532
4800/9333 [==============>...............] - ETA: 2:57 - loss: 0.6859 - acc: 0.5533
4864/9333 [==============>...............] - ETA: 2:54 - loss: 0.6858 - acc: 0.5541
4928/9333 [==============>...............] - ETA: 2:52 - loss: 0.6856 - acc: 0.5552
4992/9333 [===============>..............] - ETA: 2:49 - loss: 0.6854 - acc: 0.5561
5056/9333 [===============>..............] - ETA: 2:47 - loss: 0.6853 - acc: 0.5564
5120/9333 [===============>..............] - ETA: 2:44 - loss: 0.6858 - acc: 0.5555
5184/9333 [===============>..............] - ETA: 2:42 - loss: 0.6858 - acc: 0.5552
5248/9333 [===============>..............] - ETA: 2:39 - loss: 0.6856 - acc: 0.5562
5312/9333 [================>.............] - ETA: 2:37 - loss: 0.6855 - acc: 0.5563
5376/9333 [================>.............] - ETA: 2:34 - loss: 0.6861 - acc: 0.5554
5440/9333 [================>.............] - ETA: 2:31 - loss: 0.6864 - acc: 0.5551
5504/9333 [================>.............] - ETA: 2:29 - loss: 0.6862 - acc: 0.5560
5568/9333 [================>.............] - ETA: 2:26 - loss: 0.6862 - acc: 0.5562
5632/9333 [=================>............] - ETA: 2:24 - loss: 0.6861 - acc: 0.5561
5696/9333 [=================>............] - ETA: 2:21 - loss: 0.6863 - acc: 0.5555
5760/9333 [=================>............] - ETA: 2:19 - loss: 0.6865 - acc: 0.5552
5824/9333 [=================>............] - ETA: 2:16 - loss: 0.6866 - acc: 0.5543
5888/9333 [=================>............] - ETA: 2:14 - loss: 0.6868 - acc: 0.5535
5952/9333 [==================>...........] - ETA: 2:11 - loss: 0.6868 - acc: 0.5529
6016/9333 [==================>...........] - ETA: 2:08 - loss: 0.6865 - acc: 0.5537
6080/9333 [==================>...........] - ETA: 2:06 - loss: 0.6866 - acc: 0.5530
6144/9333 [==================>...........] - ETA: 2:03 - loss: 0.6866 - acc: 0.5534
6208/9333 [==================>...........] - ETA: 2:01 - loss: 0.6866 - acc: 0.5530
6272/9333 [===================>..........] - ETA: 1:59 - loss: 0.6867 - acc: 0.5528
6336/9333 [===================>..........] - ETA: 1:56 - loss: 0.6869 - acc: 0.5521
6400/9333 [===================>..........] - ETA: 1:54 - loss: 0.6869 - acc: 0.5517
6464/9333 [===================>..........] - ETA: 1:51 - loss: 0.6869 - acc: 0.5514
6528/9333 [===================>..........] - ETA: 1:49 - loss: 0.6867 - acc: 0.5522
6592/9333 [====================>.........] - ETA: 1:46 - loss: 0.6866 - acc: 0.5523
6656/9333 [====================>.........] - ETA: 1:44 - loss: 0.6865 - acc: 0.5527
6720/9333 [====================>.........] - ETA: 1:41 - loss: 0.6864 - acc: 0.5533
6784/9333 [====================>.........] - ETA: 1:39 - loss: 0.6863 - acc: 0.5534
6848/9333 [=====================>........] - ETA: 1:36 - loss: 0.6866 - acc: 0.5526
6912/9333 [=====================>........] - ETA: 1:34 - loss: 0.6865 - acc: 0.5535
6976/9333 [=====================>........] - ETA: 1:31 - loss: 0.6865 - acc: 0.5538
7040/9333 [=====================>........] - ETA: 1:29 - loss: 0.6864 - acc: 0.5543
7104/9333 [=====================>........] - ETA: 1:26 - loss: 0.6864 - acc: 0.5538
7168/9333 [======================>.......] - ETA: 1:24 - loss: 0.6864 - acc: 0.5536
7232/9333 [======================>.......] - ETA: 1:21 - loss: 0.6863 - acc: 0.5542
7296/9333 [======================>.......] - ETA: 1:19 - loss: 0.6864 - acc: 0.5536
7360/9333 [======================>.......] - ETA: 1:16 - loss: 0.6863 - acc: 0.5537
7424/9333 [======================>.......] - ETA: 1:14 - loss: 0.6862 - acc: 0.5539
7488/9333 [=======================>......] - ETA: 1:11 - loss: 0.6860 - acc: 0.5541
7552/9333 [=======================>......] - ETA: 1:09 - loss: 0.6861 - acc: 0.5539
7616/9333 [=======================>......] - ETA: 1:06 - loss: 0.6862 - acc: 0.5542
7680/9333 [=======================>......] - ETA: 1:04 - loss: 0.6859 - acc: 0.5546
7744/9333 [=======================>......] - ETA: 1:01 - loss: 0.6859 - acc: 0.5542
7808/9333 [========================>.....] - ETA: 59s - loss: 0.6858 - acc: 0.5539 
7872/9333 [========================>.....] - ETA: 56s - loss: 0.6860 - acc: 0.5537
7936/9333 [========================>.....] - ETA: 54s - loss: 0.6861 - acc: 0.5536
8000/9333 [========================>.....] - ETA: 51s - loss: 0.6861 - acc: 0.5539
8064/9333 [========================>.....] - ETA: 49s - loss: 0.6862 - acc: 0.5534
8128/9333 [=========================>....] - ETA: 46s - loss: 0.6861 - acc: 0.5535
8192/9333 [=========================>....] - ETA: 44s - loss: 0.6859 - acc: 0.5544
8256/9333 [=========================>....] - ETA: 41s - loss: 0.6859 - acc: 0.5551
8320/9333 [=========================>....] - ETA: 39s - loss: 0.6859 - acc: 0.5552
8384/9333 [=========================>....] - ETA: 36s - loss: 0.6859 - acc: 0.5555
8448/9333 [==========================>...] - ETA: 34s - loss: 0.6858 - acc: 0.5560
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6862 - acc: 0.5552
8576/9333 [==========================>...] - ETA: 29s - loss: 0.6863 - acc: 0.5549
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6864 - acc: 0.5543
8704/9333 [==========================>...] - ETA: 24s - loss: 0.6866 - acc: 0.5537
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6866 - acc: 0.5541
8832/9333 [===========================>..] - ETA: 19s - loss: 0.6867 - acc: 0.5537
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6867 - acc: 0.5536
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6866 - acc: 0.5538
9024/9333 [============================>.] - ETA: 12s - loss: 0.6865 - acc: 0.5540
9088/9333 [============================>.] - ETA: 9s - loss: 0.6865 - acc: 0.5544 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6865 - acc: 0.5538
9216/9333 [============================>.] - ETA: 4s - loss: 0.6865 - acc: 0.5543
9280/9333 [============================>.] - ETA: 2s - loss: 0.6864 - acc: 0.5542
9333/9333 [==============================] - 382s 41ms/step - loss: 0.6865 - acc: 0.5542 - val_loss: 0.7009 - val_acc: 0.5207

Epoch 00009: val_acc did not improve from 0.54098
Epoch 10/10

  64/9333 [..............................] - ETA: 5:24 - loss: 0.6765 - acc: 0.6406
 128/9333 [..............................] - ETA: 5:56 - loss: 0.6774 - acc: 0.5859
 192/9333 [..............................] - ETA: 5:54 - loss: 0.6755 - acc: 0.5677
 256/9333 [..............................] - ETA: 5:54 - loss: 0.6770 - acc: 0.5742
 320/9333 [>.............................] - ETA: 5:47 - loss: 0.6830 - acc: 0.5531
 384/9333 [>.............................] - ETA: 5:46 - loss: 0.6785 - acc: 0.5729
 448/9333 [>.............................] - ETA: 5:46 - loss: 0.6779 - acc: 0.5781
 512/9333 [>.............................] - ETA: 5:45 - loss: 0.6820 - acc: 0.5625
 576/9333 [>.............................] - ETA: 5:43 - loss: 0.6843 - acc: 0.5608
 640/9333 [=>............................] - ETA: 5:40 - loss: 0.6847 - acc: 0.5641
 704/9333 [=>............................] - ETA: 5:37 - loss: 0.6831 - acc: 0.5639
 768/9333 [=>............................] - ETA: 5:34 - loss: 0.6844 - acc: 0.5586
 832/9333 [=>............................] - ETA: 5:32 - loss: 0.6825 - acc: 0.5613
 896/9333 [=>............................] - ETA: 5:30 - loss: 0.6842 - acc: 0.5580
 960/9333 [==>...........................] - ETA: 5:30 - loss: 0.6840 - acc: 0.5573
1024/9333 [==>...........................] - ETA: 5:28 - loss: 0.6830 - acc: 0.5664
1088/9333 [==>...........................] - ETA: 5:26 - loss: 0.6823 - acc: 0.5689
1152/9333 [==>...........................] - ETA: 5:21 - loss: 0.6835 - acc: 0.5625
1216/9333 [==>...........................] - ETA: 5:19 - loss: 0.6828 - acc: 0.5658
1280/9333 [===>..........................] - ETA: 5:14 - loss: 0.6849 - acc: 0.5586
1344/9333 [===>..........................] - ETA: 5:10 - loss: 0.6847 - acc: 0.5565
1408/9333 [===>..........................] - ETA: 5:09 - loss: 0.6854 - acc: 0.5561
1472/9333 [===>..........................] - ETA: 5:08 - loss: 0.6845 - acc: 0.5591
1536/9333 [===>..........................] - ETA: 5:06 - loss: 0.6852 - acc: 0.5534
1600/9333 [====>.........................] - ETA: 5:03 - loss: 0.6853 - acc: 0.5550
1664/9333 [====>.........................] - ETA: 5:00 - loss: 0.6859 - acc: 0.5541
1728/9333 [====>.........................] - ETA: 4:57 - loss: 0.6866 - acc: 0.5503
1792/9333 [====>.........................] - ETA: 4:54 - loss: 0.6867 - acc: 0.5497
1856/9333 [====>.........................] - ETA: 4:51 - loss: 0.6868 - acc: 0.5490
1920/9333 [=====>........................] - ETA: 4:50 - loss: 0.6862 - acc: 0.5505
1984/9333 [=====>........................] - ETA: 4:47 - loss: 0.6855 - acc: 0.5534
2048/9333 [=====>........................] - ETA: 4:46 - loss: 0.6861 - acc: 0.5537
2112/9333 [=====>........................] - ETA: 4:44 - loss: 0.6865 - acc: 0.5530
2176/9333 [=====>........................] - ETA: 4:41 - loss: 0.6864 - acc: 0.5538
2240/9333 [======>.......................] - ETA: 4:39 - loss: 0.6861 - acc: 0.5549
2304/9333 [======>.......................] - ETA: 4:36 - loss: 0.6859 - acc: 0.5573
2368/9333 [======>.......................] - ETA: 4:34 - loss: 0.6860 - acc: 0.5566
2432/9333 [======>.......................] - ETA: 4:32 - loss: 0.6862 - acc: 0.5580
2496/9333 [=======>......................] - ETA: 4:28 - loss: 0.6859 - acc: 0.5573
2560/9333 [=======>......................] - ETA: 4:26 - loss: 0.6853 - acc: 0.5578
2624/9333 [=======>......................] - ETA: 4:23 - loss: 0.6849 - acc: 0.5591
2688/9333 [=======>......................] - ETA: 4:21 - loss: 0.6857 - acc: 0.5565
2752/9333 [=======>......................] - ETA: 4:18 - loss: 0.6860 - acc: 0.5567
2816/9333 [========>.....................] - ETA: 4:16 - loss: 0.6864 - acc: 0.5558
2880/9333 [========>.....................] - ETA: 4:13 - loss: 0.6865 - acc: 0.5549
2944/9333 [========>.....................] - ETA: 4:10 - loss: 0.6865 - acc: 0.5547
3008/9333 [========>.....................] - ETA: 4:08 - loss: 0.6863 - acc: 0.5555
3072/9333 [========>.....................] - ETA: 4:05 - loss: 0.6867 - acc: 0.5547
3136/9333 [=========>....................] - ETA: 4:02 - loss: 0.6866 - acc: 0.5542
3200/9333 [=========>....................] - ETA: 4:01 - loss: 0.6868 - acc: 0.5531
3264/9333 [=========>....................] - ETA: 3:59 - loss: 0.6877 - acc: 0.5512
3328/9333 [=========>....................] - ETA: 3:56 - loss: 0.6870 - acc: 0.5532
3392/9333 [=========>....................] - ETA: 3:54 - loss: 0.6874 - acc: 0.5516
3456/9333 [==========>...................] - ETA: 3:51 - loss: 0.6871 - acc: 0.5524
3520/9333 [==========>...................] - ETA: 3:48 - loss: 0.6876 - acc: 0.5514
3584/9333 [==========>...................] - ETA: 3:45 - loss: 0.6871 - acc: 0.5527
3648/9333 [==========>...................] - ETA: 3:42 - loss: 0.6867 - acc: 0.5543
3712/9333 [==========>...................] - ETA: 3:40 - loss: 0.6873 - acc: 0.5525
3776/9333 [===========>..................] - ETA: 3:38 - loss: 0.6874 - acc: 0.5514
3840/9333 [===========>..................] - ETA: 3:35 - loss: 0.6876 - acc: 0.5523
3904/9333 [===========>..................] - ETA: 3:33 - loss: 0.6875 - acc: 0.5530
3968/9333 [===========>..................] - ETA: 3:30 - loss: 0.6880 - acc: 0.5524
4032/9333 [===========>..................] - ETA: 3:27 - loss: 0.6880 - acc: 0.5523
4096/9333 [============>.................] - ETA: 3:25 - loss: 0.6878 - acc: 0.5537
4160/9333 [============>.................] - ETA: 3:22 - loss: 0.6876 - acc: 0.5548
4224/9333 [============>.................] - ETA: 3:20 - loss: 0.6876 - acc: 0.5554
4288/9333 [============>.................] - ETA: 3:17 - loss: 0.6876 - acc: 0.5541
4352/9333 [============>.................] - ETA: 3:15 - loss: 0.6873 - acc: 0.5556
4416/9333 [=============>................] - ETA: 3:12 - loss: 0.6875 - acc: 0.5546
4480/9333 [=============>................] - ETA: 3:10 - loss: 0.6874 - acc: 0.5542
4544/9333 [=============>................] - ETA: 3:07 - loss: 0.6871 - acc: 0.5541
4608/9333 [=============>................] - ETA: 3:04 - loss: 0.6871 - acc: 0.5525
4672/9333 [==============>...............] - ETA: 3:02 - loss: 0.6870 - acc: 0.5537
4736/9333 [==============>...............] - ETA: 2:59 - loss: 0.6869 - acc: 0.5543
4800/9333 [==============>...............] - ETA: 2:57 - loss: 0.6870 - acc: 0.5533
4864/9333 [==============>...............] - ETA: 2:54 - loss: 0.6874 - acc: 0.5524
4928/9333 [==============>...............] - ETA: 2:52 - loss: 0.6874 - acc: 0.5532
4992/9333 [===============>..............] - ETA: 2:49 - loss: 0.6871 - acc: 0.5535
5056/9333 [===============>..............] - ETA: 2:46 - loss: 0.6869 - acc: 0.5542
5120/9333 [===============>..............] - ETA: 2:44 - loss: 0.6866 - acc: 0.5549
5184/9333 [===============>..............] - ETA: 2:41 - loss: 0.6865 - acc: 0.5557
5248/9333 [===============>..............] - ETA: 2:39 - loss: 0.6863 - acc: 0.5560
5312/9333 [================>.............] - ETA: 2:36 - loss: 0.6863 - acc: 0.5553
5376/9333 [================>.............] - ETA: 2:34 - loss: 0.6865 - acc: 0.5552
5440/9333 [================>.............] - ETA: 2:32 - loss: 0.6859 - acc: 0.5574
5504/9333 [================>.............] - ETA: 2:29 - loss: 0.6859 - acc: 0.5572
5568/9333 [================>.............] - ETA: 2:26 - loss: 0.6860 - acc: 0.5568
5632/9333 [=================>............] - ETA: 2:24 - loss: 0.6863 - acc: 0.5561
5696/9333 [=================>............] - ETA: 2:21 - loss: 0.6863 - acc: 0.5553
5760/9333 [=================>............] - ETA: 2:19 - loss: 0.6862 - acc: 0.5556
5824/9333 [=================>............] - ETA: 2:16 - loss: 0.6859 - acc: 0.5565
5888/9333 [=================>............] - ETA: 2:14 - loss: 0.6862 - acc: 0.5559
5952/9333 [==================>...........] - ETA: 2:11 - loss: 0.6859 - acc: 0.5565
6016/9333 [==================>...........] - ETA: 2:09 - loss: 0.6857 - acc: 0.5570
6080/9333 [==================>...........] - ETA: 2:07 - loss: 0.6855 - acc: 0.5576
6144/9333 [==================>...........] - ETA: 2:04 - loss: 0.6854 - acc: 0.5584
6208/9333 [==================>...........] - ETA: 2:02 - loss: 0.6856 - acc: 0.5582
6272/9333 [===================>..........] - ETA: 1:59 - loss: 0.6855 - acc: 0.5582
6336/9333 [===================>..........] - ETA: 1:57 - loss: 0.6852 - acc: 0.5589
6400/9333 [===================>..........] - ETA: 1:54 - loss: 0.6852 - acc: 0.5586
6464/9333 [===================>..........] - ETA: 1:52 - loss: 0.6852 - acc: 0.5585
6528/9333 [===================>..........] - ETA: 1:49 - loss: 0.6854 - acc: 0.5581
6592/9333 [====================>.........] - ETA: 1:47 - loss: 0.6855 - acc: 0.5576
6656/9333 [====================>.........] - ETA: 1:44 - loss: 0.6855 - acc: 0.5577
6720/9333 [====================>.........] - ETA: 1:42 - loss: 0.6856 - acc: 0.5576
6784/9333 [====================>.........] - ETA: 1:39 - loss: 0.6856 - acc: 0.5573
6848/9333 [=====================>........] - ETA: 1:37 - loss: 0.6856 - acc: 0.5572
6912/9333 [=====================>........] - ETA: 1:34 - loss: 0.6856 - acc: 0.5577
6976/9333 [=====================>........] - ETA: 1:32 - loss: 0.6855 - acc: 0.5581
7040/9333 [=====================>........] - ETA: 1:29 - loss: 0.6857 - acc: 0.5580
7104/9333 [=====================>........] - ETA: 1:27 - loss: 0.6857 - acc: 0.5577
7168/9333 [======================>.......] - ETA: 1:24 - loss: 0.6860 - acc: 0.5569
7232/9333 [======================>.......] - ETA: 1:22 - loss: 0.6859 - acc: 0.5571
7296/9333 [======================>.......] - ETA: 1:19 - loss: 0.6861 - acc: 0.5566
7360/9333 [======================>.......] - ETA: 1:17 - loss: 0.6860 - acc: 0.5568
7424/9333 [======================>.......] - ETA: 1:14 - loss: 0.6859 - acc: 0.5570
7488/9333 [=======================>......] - ETA: 1:12 - loss: 0.6859 - acc: 0.5569
7552/9333 [=======================>......] - ETA: 1:09 - loss: 0.6860 - acc: 0.5563
7616/9333 [=======================>......] - ETA: 1:07 - loss: 0.6864 - acc: 0.5551
7680/9333 [=======================>......] - ETA: 1:04 - loss: 0.6864 - acc: 0.5549
7744/9333 [=======================>......] - ETA: 1:02 - loss: 0.6864 - acc: 0.5546
7808/9333 [========================>.....] - ETA: 59s - loss: 0.6865 - acc: 0.5535 
7872/9333 [========================>.....] - ETA: 57s - loss: 0.6864 - acc: 0.5539
7936/9333 [========================>.....] - ETA: 54s - loss: 0.6867 - acc: 0.5529
8000/9333 [========================>.....] - ETA: 52s - loss: 0.6865 - acc: 0.5533
8064/9333 [========================>.....] - ETA: 49s - loss: 0.6865 - acc: 0.5536
8128/9333 [=========================>....] - ETA: 47s - loss: 0.6866 - acc: 0.5531
8192/9333 [=========================>....] - ETA: 44s - loss: 0.6866 - acc: 0.5529
8256/9333 [=========================>....] - ETA: 42s - loss: 0.6865 - acc: 0.5531
8320/9333 [=========================>....] - ETA: 39s - loss: 0.6864 - acc: 0.5536
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6866 - acc: 0.5527
8448/9333 [==========================>...] - ETA: 34s - loss: 0.6866 - acc: 0.5524
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6868 - acc: 0.5520
8576/9333 [==========================>...] - ETA: 29s - loss: 0.6867 - acc: 0.5525
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6868 - acc: 0.5521
8704/9333 [==========================>...] - ETA: 24s - loss: 0.6868 - acc: 0.5516
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6866 - acc: 0.5527
8832/9333 [===========================>..] - ETA: 19s - loss: 0.6867 - acc: 0.5520
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6868 - acc: 0.5519
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6870 - acc: 0.5512
9024/9333 [============================>.] - ETA: 12s - loss: 0.6871 - acc: 0.5510
9088/9333 [============================>.] - ETA: 9s - loss: 0.6872 - acc: 0.5506 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6871 - acc: 0.5504
9216/9333 [============================>.] - ETA: 4s - loss: 0.6869 - acc: 0.5511
9280/9333 [============================>.] - ETA: 2s - loss: 0.6871 - acc: 0.5510
9333/9333 [==============================] - 384s 41ms/step - loss: 0.6871 - acc: 0.5505 - val_loss: 0.6869 - val_acc: 0.5400

Epoch 00010: val_acc did not improve from 0.54098
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4fa0ef29d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4fa0ef29d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f4f98ccfe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f4f98ccfe50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4fa0e8ccd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4fa0e8ccd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f985ecfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f985ecfd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ec4530510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ec4530510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f984c1650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f984c1650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f985ec850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f985ec850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f984b3610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f984b3610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f98bd9690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f98bd9690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f984101d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f984101d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98afa6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98afa6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f983be310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f983be310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb30845d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb30845d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49845cde10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49845cde10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f9805de90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f9805de90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb306ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eb306ff90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f984a2e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f984a2e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f9805d2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f9805d2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f9800bbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f9800bbd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f8fd059d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f8fd059d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f97e3b390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f97e3b390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f9800b790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f9800b790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f97e1fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f97e1fa50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f97e65590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f97e65590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f8fb7ed50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f8fb7ed50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f8f8b91d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f8f8b91d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f8fba7a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f8fba7a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f8f8d7fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f8f8d7fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f8f84dfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f8f84dfd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f8fa0ffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f8fa0ffd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f8fac4050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f8fac4050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f8fab5b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f8fab5b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f8f577e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f8f577e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f8f756a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f8f756a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f7f36ca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f7f36ca90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98726350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98726350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f8f756d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f8f756d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f7f3f2410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f7f3f2410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f7f3e8510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f7f3e8510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f7f03ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f7f03ee90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f7f36ccd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f7f36ccd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f7f3e8d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f7f3e8d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f7f085f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f7f085f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f7ee3fa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f7ee3fa90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f7f03e090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f7f03e090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f97eb3090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f97eb3090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f7ee3f4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f7ee3f4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f97f10f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f97f10f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f76af0b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f76af0b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f76a04e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f76a04e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f76b82e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f76b82e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f76b8b9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f76b8b9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f76907ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f76907ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f7f09d210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f7f09d210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f766f8fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f766f8fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f768e7810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f768e7810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f768263d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f768263d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f765f1d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f765f1d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f766f5990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f766f5990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f6e4b4a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f6e4b4a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f6e2bd750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f6e2bd750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f7687ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f7687ff90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f6e2a3e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f6e2a3e90>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 1:25
 128/2592 [>.............................] - ETA: 1:00
 192/2592 [=>............................] - ETA: 52s 
 256/2592 [=>............................] - ETA: 48s
 320/2592 [==>...........................] - ETA: 45s
 384/2592 [===>..........................] - ETA: 41s
 448/2592 [====>.........................] - ETA: 39s
 512/2592 [====>.........................] - ETA: 37s
 576/2592 [=====>........................] - ETA: 35s
 640/2592 [======>.......................] - ETA: 33s
 704/2592 [=======>......................] - ETA: 32s
 768/2592 [=======>......................] - ETA: 31s
 832/2592 [========>.....................] - ETA: 29s
 896/2592 [=========>....................] - ETA: 28s
 960/2592 [==========>...................] - ETA: 27s
1024/2592 [==========>...................] - ETA: 26s
1088/2592 [===========>..................] - ETA: 25s
1152/2592 [============>.................] - ETA: 24s
1216/2592 [=============>................] - ETA: 23s
1280/2592 [=============>................] - ETA: 21s
1344/2592 [==============>...............] - ETA: 20s
1408/2592 [===============>..............] - ETA: 19s
1472/2592 [================>.............] - ETA: 18s
1536/2592 [================>.............] - ETA: 17s
1600/2592 [=================>............] - ETA: 16s
1664/2592 [==================>...........] - ETA: 15s
1728/2592 [===================>..........] - ETA: 14s
1792/2592 [===================>..........] - ETA: 13s
1856/2592 [====================>.........] - ETA: 12s
1920/2592 [=====================>........] - ETA: 11s
1984/2592 [=====================>........] - ETA: 9s 
2048/2592 [======================>.......] - ETA: 8s
2112/2592 [=======================>......] - ETA: 7s
2176/2592 [========================>.....] - ETA: 6s
2240/2592 [========================>.....] - ETA: 5s
2304/2592 [=========================>....] - ETA: 4s
2368/2592 [==========================>...] - ETA: 3s
2432/2592 [===========================>..] - ETA: 2s
2496/2592 [===========================>..] - ETA: 1s
2560/2592 [============================>.] - ETA: 0s
2592/2592 [==============================] - 42s 16ms/step
loss: 0.6878911271507357
acc: 0.5424382716049383
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4984617c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4984617c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f47644cfcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f47644cfcd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f3b2bb650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f3b2bb650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f3b19acd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f3b19acd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f76d31b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f76d31b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f32c63150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f32c63150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f3b19ac10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f3b19ac10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f32cf5110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f32cf5110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f98a5dcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f98a5dcd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4fa0db6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4fa0db6c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98b026d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98b026d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f98a482d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f98a482d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4fa0db67d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4fa0db67d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4fa0ed2450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4fa0ed2450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f98a08dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f98a08dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49843fcc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49843fcc10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4fa0ed2a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4fa0ed2a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f989f9250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f989f9250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4fa0edcad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4fa0edcad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4984252610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4984252610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4984357f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4984357f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f98c82810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f98c82810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4984244d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4984244d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49840f7e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49840f7e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4968745110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4968745110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4984271ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4984271ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f49842d3750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f49842d3750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49684fe250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49684fe250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4968501e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4968501e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4968387a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4968387a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f496852c290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f496852c290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f49684dae50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f49684dae50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4968454050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4968454050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4984271590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4984271590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f49680f22d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f49680f22d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f496818e450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f496818e450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f49680eda90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f49680eda90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4944682dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4944682dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49446501d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49446501d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f494454bf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f494454bf50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49680ea4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49680ea4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f496809d390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f496809d390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49445e2a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49445e2a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49445b3810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49445b3810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f494426dc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f494426dc90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f494410d150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f494410d150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f494466aa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f494466aa10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4944092550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4944092550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4944264090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4944264090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f49442ef590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f49442ef590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4944254c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4944254c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4944108a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4944108a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f494421b2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f494421b2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49245f5110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49245f5110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f49243e4d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f49243e4d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49245eba10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49245eba10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f49247afb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f49247afb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49244c0c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49244c0c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49241a49d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f49241a49d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f492408a1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f492408a1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4904768950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4904768950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f49241a4150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f49241a4150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49243e4250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f49243e4250>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 18:22 - loss: 0.7394 - acc: 0.4219
 128/9333 [..............................] - ETA: 12:09 - loss: 0.6963 - acc: 0.5312
 192/9333 [..............................] - ETA: 10:16 - loss: 0.7152 - acc: 0.5365
 256/9333 [..............................] - ETA: 9:01 - loss: 0.7302 - acc: 0.5430 
 320/9333 [>.............................] - ETA: 8:16 - loss: 0.7416 - acc: 0.5281
 384/9333 [>.............................] - ETA: 7:42 - loss: 0.7507 - acc: 0.5208
 448/9333 [>.............................] - ETA: 7:37 - loss: 0.7484 - acc: 0.5223
 512/9333 [>.............................] - ETA: 7:23 - loss: 0.7492 - acc: 0.5098
 576/9333 [>.............................] - ETA: 7:10 - loss: 0.7466 - acc: 0.5156
 640/9333 [=>............................] - ETA: 6:57 - loss: 0.7452 - acc: 0.5172
 704/9333 [=>............................] - ETA: 6:48 - loss: 0.7455 - acc: 0.5170
 768/9333 [=>............................] - ETA: 6:39 - loss: 0.7424 - acc: 0.5195
 832/9333 [=>............................] - ETA: 6:34 - loss: 0.7456 - acc: 0.5132
 896/9333 [=>............................] - ETA: 6:26 - loss: 0.7405 - acc: 0.5201
 960/9333 [==>...........................] - ETA: 6:21 - loss: 0.7410 - acc: 0.5156
1024/9333 [==>...........................] - ETA: 6:17 - loss: 0.7415 - acc: 0.5137
1088/9333 [==>...........................] - ETA: 6:13 - loss: 0.7408 - acc: 0.5147
1152/9333 [==>...........................] - ETA: 6:07 - loss: 0.7423 - acc: 0.5148
1216/9333 [==>...........................] - ETA: 6:01 - loss: 0.7421 - acc: 0.5164
1280/9333 [===>..........................] - ETA: 5:55 - loss: 0.7412 - acc: 0.5141
1344/9333 [===>..........................] - ETA: 5:50 - loss: 0.7382 - acc: 0.5156
1408/9333 [===>..........................] - ETA: 5:46 - loss: 0.7380 - acc: 0.5156
1472/9333 [===>..........................] - ETA: 5:45 - loss: 0.7392 - acc: 0.5143
1536/9333 [===>..........................] - ETA: 5:45 - loss: 0.7433 - acc: 0.5111
1600/9333 [====>.........................] - ETA: 5:41 - loss: 0.7442 - acc: 0.5094
1664/9333 [====>.........................] - ETA: 5:36 - loss: 0.7433 - acc: 0.5096
1728/9333 [====>.........................] - ETA: 5:31 - loss: 0.7439 - acc: 0.5075
1792/9333 [====>.........................] - ETA: 5:27 - loss: 0.7428 - acc: 0.5078
1856/9333 [====>.........................] - ETA: 5:24 - loss: 0.7443 - acc: 0.5054
1920/9333 [=====>........................] - ETA: 5:20 - loss: 0.7427 - acc: 0.5083
1984/9333 [=====>........................] - ETA: 5:15 - loss: 0.7415 - acc: 0.5096
2048/9333 [=====>........................] - ETA: 5:12 - loss: 0.7404 - acc: 0.5088
2112/9333 [=====>........................] - ETA: 5:09 - loss: 0.7400 - acc: 0.5090
2176/9333 [=====>........................] - ETA: 5:06 - loss: 0.7378 - acc: 0.5119
2240/9333 [======>.......................] - ETA: 5:03 - loss: 0.7376 - acc: 0.5112
2304/9333 [======>.......................] - ETA: 4:59 - loss: 0.7356 - acc: 0.5148
2368/9333 [======>.......................] - ETA: 4:55 - loss: 0.7348 - acc: 0.5160
2432/9333 [======>.......................] - ETA: 4:53 - loss: 0.7352 - acc: 0.5132
2496/9333 [=======>......................] - ETA: 4:49 - loss: 0.7342 - acc: 0.5136
2560/9333 [=======>......................] - ETA: 4:47 - loss: 0.7340 - acc: 0.5109
2624/9333 [=======>......................] - ETA: 4:44 - loss: 0.7340 - acc: 0.5088
2688/9333 [=======>......................] - ETA: 4:41 - loss: 0.7339 - acc: 0.5086
2752/9333 [=======>......................] - ETA: 4:37 - loss: 0.7339 - acc: 0.5080
2816/9333 [========>.....................] - ETA: 4:33 - loss: 0.7347 - acc: 0.5075
2880/9333 [========>.....................] - ETA: 4:30 - loss: 0.7336 - acc: 0.5073
2944/9333 [========>.....................] - ETA: 4:27 - loss: 0.7332 - acc: 0.5068
3008/9333 [========>.....................] - ETA: 4:24 - loss: 0.7335 - acc: 0.5063
3072/9333 [========>.....................] - ETA: 4:21 - loss: 0.7323 - acc: 0.5075
3136/9333 [=========>....................] - ETA: 4:18 - loss: 0.7314 - acc: 0.5092
3200/9333 [=========>....................] - ETA: 4:14 - loss: 0.7315 - acc: 0.5081
3264/9333 [=========>....................] - ETA: 4:12 - loss: 0.7307 - acc: 0.5092
3328/9333 [=========>....................] - ETA: 4:10 - loss: 0.7305 - acc: 0.5084
3392/9333 [=========>....................] - ETA: 4:06 - loss: 0.7300 - acc: 0.5085
3456/9333 [==========>...................] - ETA: 4:03 - loss: 0.7299 - acc: 0.5090
3520/9333 [==========>...................] - ETA: 4:00 - loss: 0.7286 - acc: 0.5102
3584/9333 [==========>...................] - ETA: 3:57 - loss: 0.7283 - acc: 0.5095
3648/9333 [==========>...................] - ETA: 3:54 - loss: 0.7282 - acc: 0.5079
3712/9333 [==========>...................] - ETA: 3:51 - loss: 0.7278 - acc: 0.5075
3776/9333 [===========>..................] - ETA: 3:48 - loss: 0.7284 - acc: 0.5064
3840/9333 [===========>..................] - ETA: 3:45 - loss: 0.7282 - acc: 0.5055
3904/9333 [===========>..................] - ETA: 3:43 - loss: 0.7272 - acc: 0.5079
3968/9333 [===========>..................] - ETA: 3:41 - loss: 0.7270 - acc: 0.5088
4032/9333 [===========>..................] - ETA: 3:38 - loss: 0.7273 - acc: 0.5079
4096/9333 [============>.................] - ETA: 3:35 - loss: 0.7268 - acc: 0.5093
4160/9333 [============>.................] - ETA: 3:32 - loss: 0.7263 - acc: 0.5099
4224/9333 [============>.................] - ETA: 3:29 - loss: 0.7261 - acc: 0.5095
4288/9333 [============>.................] - ETA: 3:26 - loss: 0.7259 - acc: 0.5091
4352/9333 [============>.................] - ETA: 3:24 - loss: 0.7252 - acc: 0.5099
4416/9333 [=============>................] - ETA: 3:21 - loss: 0.7249 - acc: 0.5100
4480/9333 [=============>................] - ETA: 3:19 - loss: 0.7247 - acc: 0.5089
4544/9333 [=============>................] - ETA: 3:16 - loss: 0.7246 - acc: 0.5095
4608/9333 [=============>................] - ETA: 3:14 - loss: 0.7244 - acc: 0.5091
4672/9333 [==============>...............] - ETA: 3:11 - loss: 0.7237 - acc: 0.5098
4736/9333 [==============>...............] - ETA: 3:09 - loss: 0.7237 - acc: 0.5099
4800/9333 [==============>...............] - ETA: 3:06 - loss: 0.7237 - acc: 0.5094
4864/9333 [==============>...............] - ETA: 3:03 - loss: 0.7237 - acc: 0.5086
4928/9333 [==============>...............] - ETA: 3:00 - loss: 0.7241 - acc: 0.5077
4992/9333 [===============>..............] - ETA: 2:58 - loss: 0.7240 - acc: 0.5080
5056/9333 [===============>..............] - ETA: 2:55 - loss: 0.7237 - acc: 0.5081
5120/9333 [===============>..............] - ETA: 2:53 - loss: 0.7234 - acc: 0.5078
5184/9333 [===============>..............] - ETA: 2:50 - loss: 0.7236 - acc: 0.5073
5248/9333 [===============>..............] - ETA: 2:48 - loss: 0.7232 - acc: 0.5078
5312/9333 [================>.............] - ETA: 2:45 - loss: 0.7232 - acc: 0.5072
5376/9333 [================>.............] - ETA: 2:42 - loss: 0.7229 - acc: 0.5069
5440/9333 [================>.............] - ETA: 2:39 - loss: 0.7227 - acc: 0.5064
5504/9333 [================>.............] - ETA: 2:37 - loss: 0.7226 - acc: 0.5064
5568/9333 [================>.............] - ETA: 2:34 - loss: 0.7227 - acc: 0.5050
5632/9333 [=================>............] - ETA: 2:31 - loss: 0.7223 - acc: 0.5053
5696/9333 [=================>............] - ETA: 2:29 - loss: 0.7223 - acc: 0.5046
5760/9333 [=================>............] - ETA: 2:26 - loss: 0.7223 - acc: 0.5047
5824/9333 [=================>............] - ETA: 2:23 - loss: 0.7221 - acc: 0.5048
5888/9333 [=================>............] - ETA: 2:21 - loss: 0.7217 - acc: 0.5054
5952/9333 [==================>...........] - ETA: 2:18 - loss: 0.7213 - acc: 0.5057
6016/9333 [==================>...........] - ETA: 2:15 - loss: 0.7214 - acc: 0.5053
6080/9333 [==================>...........] - ETA: 2:12 - loss: 0.7215 - acc: 0.5046
6144/9333 [==================>...........] - ETA: 2:10 - loss: 0.7216 - acc: 0.5047
6208/9333 [==================>...........] - ETA: 2:07 - loss: 0.7211 - acc: 0.5047
6272/9333 [===================>..........] - ETA: 2:05 - loss: 0.7214 - acc: 0.5045
6336/9333 [===================>..........] - ETA: 2:02 - loss: 0.7208 - acc: 0.5052
6400/9333 [===================>..........] - ETA: 1:59 - loss: 0.7211 - acc: 0.5044
6464/9333 [===================>..........] - ETA: 1:57 - loss: 0.7207 - acc: 0.5051
6528/9333 [===================>..........] - ETA: 1:54 - loss: 0.7206 - acc: 0.5047
6592/9333 [====================>.........] - ETA: 1:51 - loss: 0.7202 - acc: 0.5047
6656/9333 [====================>.........] - ETA: 1:49 - loss: 0.7198 - acc: 0.5056
6720/9333 [====================>.........] - ETA: 1:46 - loss: 0.7194 - acc: 0.5062
6784/9333 [====================>.........] - ETA: 1:44 - loss: 0.7188 - acc: 0.5065
6848/9333 [=====================>........] - ETA: 1:41 - loss: 0.7186 - acc: 0.5064
6912/9333 [=====================>........] - ETA: 1:38 - loss: 0.7186 - acc: 0.5064
6976/9333 [=====================>........] - ETA: 1:36 - loss: 0.7186 - acc: 0.5059
7040/9333 [=====================>........] - ETA: 1:33 - loss: 0.7183 - acc: 0.5064
7104/9333 [=====================>........] - ETA: 1:30 - loss: 0.7179 - acc: 0.5069
7168/9333 [======================>.......] - ETA: 1:28 - loss: 0.7178 - acc: 0.5075
7232/9333 [======================>.......] - ETA: 1:25 - loss: 0.7178 - acc: 0.5075
7296/9333 [======================>.......] - ETA: 1:22 - loss: 0.7175 - acc: 0.5084
7360/9333 [======================>.......] - ETA: 1:20 - loss: 0.7177 - acc: 0.5077
7424/9333 [======================>.......] - ETA: 1:17 - loss: 0.7173 - acc: 0.5086
7488/9333 [=======================>......] - ETA: 1:15 - loss: 0.7171 - acc: 0.5089
7552/9333 [=======================>......] - ETA: 1:12 - loss: 0.7171 - acc: 0.5091
7616/9333 [=======================>......] - ETA: 1:09 - loss: 0.7169 - acc: 0.5096
7680/9333 [=======================>......] - ETA: 1:07 - loss: 0.7168 - acc: 0.5095
7744/9333 [=======================>......] - ETA: 1:04 - loss: 0.7165 - acc: 0.5103
7808/9333 [========================>.....] - ETA: 1:02 - loss: 0.7166 - acc: 0.5093
7872/9333 [========================>.....] - ETA: 59s - loss: 0.7168 - acc: 0.5084 
7936/9333 [========================>.....] - ETA: 56s - loss: 0.7166 - acc: 0.5087
8000/9333 [========================>.....] - ETA: 54s - loss: 0.7165 - acc: 0.5082
8064/9333 [========================>.....] - ETA: 51s - loss: 0.7166 - acc: 0.5079
8128/9333 [=========================>....] - ETA: 48s - loss: 0.7166 - acc: 0.5074
8192/9333 [=========================>....] - ETA: 46s - loss: 0.7164 - acc: 0.5074
8256/9333 [=========================>....] - ETA: 43s - loss: 0.7162 - acc: 0.5074
8320/9333 [=========================>....] - ETA: 41s - loss: 0.7160 - acc: 0.5072
8384/9333 [=========================>....] - ETA: 38s - loss: 0.7158 - acc: 0.5074
8448/9333 [==========================>...] - ETA: 35s - loss: 0.7156 - acc: 0.5072
8512/9333 [==========================>...] - ETA: 33s - loss: 0.7154 - acc: 0.5073
8576/9333 [==========================>...] - ETA: 30s - loss: 0.7151 - acc: 0.5079
8640/9333 [==========================>...] - ETA: 28s - loss: 0.7147 - acc: 0.5088
8704/9333 [==========================>...] - ETA: 25s - loss: 0.7146 - acc: 0.5091
8768/9333 [===========================>..] - ETA: 22s - loss: 0.7146 - acc: 0.5091
8832/9333 [===========================>..] - ETA: 20s - loss: 0.7145 - acc: 0.5088
8896/9333 [===========================>..] - ETA: 17s - loss: 0.7145 - acc: 0.5091
8960/9333 [===========================>..] - ETA: 15s - loss: 0.7144 - acc: 0.5086
9024/9333 [============================>.] - ETA: 12s - loss: 0.7146 - acc: 0.5083
9088/9333 [============================>.] - ETA: 9s - loss: 0.7144 - acc: 0.5089 
9152/9333 [============================>.] - ETA: 7s - loss: 0.7142 - acc: 0.5092
9216/9333 [============================>.] - ETA: 4s - loss: 0.7141 - acc: 0.5094
9280/9333 [============================>.] - ETA: 2s - loss: 0.7140 - acc: 0.5096
9333/9333 [==============================] - 396s 42ms/step - loss: 0.7142 - acc: 0.5086 - val_loss: 0.6900 - val_acc: 0.5391

Epoch 00001: val_acc improved from -inf to 0.53905, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window02/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 6:32 - loss: 0.7160 - acc: 0.4531
 128/9333 [..............................] - ETA: 6:23 - loss: 0.7144 - acc: 0.4219
 192/9333 [..............................] - ETA: 6:05 - loss: 0.7225 - acc: 0.4115
 256/9333 [..............................] - ETA: 5:56 - loss: 0.7176 - acc: 0.4414
 320/9333 [>.............................] - ETA: 5:52 - loss: 0.7150 - acc: 0.4406
 384/9333 [>.............................] - ETA: 5:49 - loss: 0.7141 - acc: 0.4531
 448/9333 [>.............................] - ETA: 5:56 - loss: 0.7091 - acc: 0.4732
 512/9333 [>.............................] - ETA: 6:02 - loss: 0.7132 - acc: 0.4707
 576/9333 [>.............................] - ETA: 6:00 - loss: 0.7132 - acc: 0.4757
 640/9333 [=>............................] - ETA: 5:56 - loss: 0.7128 - acc: 0.4797
 704/9333 [=>............................] - ETA: 5:52 - loss: 0.7105 - acc: 0.4915
 768/9333 [=>............................] - ETA: 5:47 - loss: 0.7108 - acc: 0.4922
 832/9333 [=>............................] - ETA: 5:42 - loss: 0.7081 - acc: 0.5000
 896/9333 [=>............................] - ETA: 5:39 - loss: 0.7072 - acc: 0.5045
 960/9333 [==>...........................] - ETA: 5:35 - loss: 0.7073 - acc: 0.5104
1024/9333 [==>...........................] - ETA: 5:29 - loss: 0.7074 - acc: 0.5098
1088/9333 [==>...........................] - ETA: 5:33 - loss: 0.7070 - acc: 0.5101
1152/9333 [==>...........................] - ETA: 5:30 - loss: 0.7079 - acc: 0.5087
1216/9333 [==>...........................] - ETA: 5:26 - loss: 0.7089 - acc: 0.5066
1280/9333 [===>..........................] - ETA: 5:21 - loss: 0.7103 - acc: 0.5023
1344/9333 [===>..........................] - ETA: 5:17 - loss: 0.7103 - acc: 0.5037
1408/9333 [===>..........................] - ETA: 5:13 - loss: 0.7109 - acc: 0.5007
1472/9333 [===>..........................] - ETA: 5:11 - loss: 0.7104 - acc: 0.5000
1536/9333 [===>..........................] - ETA: 5:07 - loss: 0.7101 - acc: 0.4967
1600/9333 [====>.........................] - ETA: 5:05 - loss: 0.7086 - acc: 0.5006
1664/9333 [====>.........................] - ETA: 5:03 - loss: 0.7089 - acc: 0.5006
1728/9333 [====>.........................] - ETA: 5:01 - loss: 0.7089 - acc: 0.5017
1792/9333 [====>.........................] - ETA: 4:58 - loss: 0.7078 - acc: 0.5033
1856/9333 [====>.........................] - ETA: 4:55 - loss: 0.7075 - acc: 0.5022
1920/9333 [=====>........................] - ETA: 4:53 - loss: 0.7065 - acc: 0.5042
1984/9333 [=====>........................] - ETA: 4:50 - loss: 0.7072 - acc: 0.4990
2048/9333 [=====>........................] - ETA: 4:48 - loss: 0.7075 - acc: 0.4966
2112/9333 [=====>........................] - ETA: 4:47 - loss: 0.7073 - acc: 0.4962
2176/9333 [=====>........................] - ETA: 4:46 - loss: 0.7067 - acc: 0.4986
2240/9333 [======>.......................] - ETA: 4:43 - loss: 0.7074 - acc: 0.4942
2304/9333 [======>.......................] - ETA: 4:40 - loss: 0.7073 - acc: 0.4926
2368/9333 [======>.......................] - ETA: 4:37 - loss: 0.7069 - acc: 0.4949
2432/9333 [======>.......................] - ETA: 4:33 - loss: 0.7069 - acc: 0.4951
2496/9333 [=======>......................] - ETA: 4:30 - loss: 0.7063 - acc: 0.4976
2560/9333 [=======>......................] - ETA: 4:28 - loss: 0.7057 - acc: 0.4992
2624/9333 [=======>......................] - ETA: 4:27 - loss: 0.7049 - acc: 0.5008
2688/9333 [=======>......................] - ETA: 4:25 - loss: 0.7051 - acc: 0.4993
2752/9333 [=======>......................] - ETA: 4:22 - loss: 0.7043 - acc: 0.5015
2816/9333 [========>.....................] - ETA: 4:19 - loss: 0.7039 - acc: 0.5011
2880/9333 [========>.....................] - ETA: 4:16 - loss: 0.7035 - acc: 0.5017
2944/9333 [========>.....................] - ETA: 4:13 - loss: 0.7035 - acc: 0.5024
3008/9333 [========>.....................] - ETA: 4:11 - loss: 0.7025 - acc: 0.5040
3072/9333 [========>.....................] - ETA: 4:09 - loss: 0.7021 - acc: 0.5059
3136/9333 [=========>....................] - ETA: 4:06 - loss: 0.7023 - acc: 0.5054
3200/9333 [=========>....................] - ETA: 4:04 - loss: 0.7017 - acc: 0.5081
3264/9333 [=========>....................] - ETA: 4:02 - loss: 0.7018 - acc: 0.5077
3328/9333 [=========>....................] - ETA: 3:59 - loss: 0.7016 - acc: 0.5096
3392/9333 [=========>....................] - ETA: 3:56 - loss: 0.7014 - acc: 0.5103
3456/9333 [==========>...................] - ETA: 3:54 - loss: 0.7016 - acc: 0.5093
3520/9333 [==========>...................] - ETA: 3:51 - loss: 0.7020 - acc: 0.5074
3584/9333 [==========>...................] - ETA: 3:48 - loss: 0.7021 - acc: 0.5070
3648/9333 [==========>...................] - ETA: 3:46 - loss: 0.7018 - acc: 0.5079
3712/9333 [==========>...................] - ETA: 3:44 - loss: 0.7013 - acc: 0.5094
3776/9333 [===========>..................] - ETA: 3:41 - loss: 0.7015 - acc: 0.5101
3840/9333 [===========>..................] - ETA: 3:39 - loss: 0.7014 - acc: 0.5096
3904/9333 [===========>..................] - ETA: 3:36 - loss: 0.7013 - acc: 0.5092
3968/9333 [===========>..................] - ETA: 3:33 - loss: 0.7008 - acc: 0.5093
4032/9333 [===========>..................] - ETA: 3:31 - loss: 0.7009 - acc: 0.5094
4096/9333 [============>.................] - ETA: 3:29 - loss: 0.7009 - acc: 0.5090
4160/9333 [============>.................] - ETA: 3:27 - loss: 0.7013 - acc: 0.5084
4224/9333 [============>.................] - ETA: 3:24 - loss: 0.7010 - acc: 0.5088
4288/9333 [============>.................] - ETA: 3:22 - loss: 0.7005 - acc: 0.5100
4352/9333 [============>.................] - ETA: 3:19 - loss: 0.7004 - acc: 0.5110
4416/9333 [=============>................] - ETA: 3:17 - loss: 0.7004 - acc: 0.5106
4480/9333 [=============>................] - ETA: 3:14 - loss: 0.7004 - acc: 0.5103
4544/9333 [=============>................] - ETA: 3:12 - loss: 0.7005 - acc: 0.5110
4608/9333 [=============>................] - ETA: 3:09 - loss: 0.7004 - acc: 0.5106
4672/9333 [==============>...............] - ETA: 3:06 - loss: 0.7005 - acc: 0.5098
4736/9333 [==============>...............] - ETA: 3:03 - loss: 0.7007 - acc: 0.5093
4800/9333 [==============>...............] - ETA: 3:01 - loss: 0.7002 - acc: 0.5115
4864/9333 [==============>...............] - ETA: 2:59 - loss: 0.7001 - acc: 0.5117
4928/9333 [==============>...............] - ETA: 2:56 - loss: 0.7000 - acc: 0.5118
4992/9333 [===============>..............] - ETA: 2:54 - loss: 0.7002 - acc: 0.5118
5056/9333 [===============>..............] - ETA: 2:51 - loss: 0.7000 - acc: 0.5121
5120/9333 [===============>..............] - ETA: 2:48 - loss: 0.7001 - acc: 0.5113
5184/9333 [===============>..............] - ETA: 2:45 - loss: 0.6998 - acc: 0.5120
5248/9333 [===============>..............] - ETA: 2:43 - loss: 0.7000 - acc: 0.5112
5312/9333 [================>.............] - ETA: 2:40 - loss: 0.7001 - acc: 0.5117
5376/9333 [================>.............] - ETA: 2:38 - loss: 0.6998 - acc: 0.5125
5440/9333 [================>.............] - ETA: 2:35 - loss: 0.6998 - acc: 0.5127
5504/9333 [================>.............] - ETA: 2:33 - loss: 0.6997 - acc: 0.5122
5568/9333 [================>.............] - ETA: 2:30 - loss: 0.6998 - acc: 0.5129
5632/9333 [=================>............] - ETA: 2:27 - loss: 0.7000 - acc: 0.5119
5696/9333 [=================>............] - ETA: 2:25 - loss: 0.6999 - acc: 0.5125
5760/9333 [=================>............] - ETA: 2:22 - loss: 0.6998 - acc: 0.5127
5824/9333 [=================>............] - ETA: 2:20 - loss: 0.6999 - acc: 0.5120
5888/9333 [=================>............] - ETA: 2:17 - loss: 0.6997 - acc: 0.5124
5952/9333 [==================>...........] - ETA: 2:15 - loss: 0.6998 - acc: 0.5114
6016/9333 [==================>...........] - ETA: 2:12 - loss: 0.6997 - acc: 0.5120
6080/9333 [==================>...........] - ETA: 2:10 - loss: 0.6996 - acc: 0.5113
6144/9333 [==================>...........] - ETA: 2:08 - loss: 0.6995 - acc: 0.5116
6208/9333 [==================>...........] - ETA: 2:05 - loss: 0.6996 - acc: 0.5119
6272/9333 [===================>..........] - ETA: 2:02 - loss: 0.6993 - acc: 0.5120
6336/9333 [===================>..........] - ETA: 2:00 - loss: 0.6993 - acc: 0.5126
6400/9333 [===================>..........] - ETA: 1:57 - loss: 0.6992 - acc: 0.5131
6464/9333 [===================>..........] - ETA: 1:54 - loss: 0.6994 - acc: 0.5124
6528/9333 [===================>..........] - ETA: 1:52 - loss: 0.6996 - acc: 0.5113
6592/9333 [====================>.........] - ETA: 1:50 - loss: 0.6994 - acc: 0.5123
6656/9333 [====================>.........] - ETA: 1:47 - loss: 0.6991 - acc: 0.5135
6720/9333 [====================>.........] - ETA: 1:45 - loss: 0.6989 - acc: 0.5152
6784/9333 [====================>.........] - ETA: 1:42 - loss: 0.6989 - acc: 0.5153
6848/9333 [=====================>........] - ETA: 1:39 - loss: 0.6986 - acc: 0.5164
6912/9333 [=====================>........] - ETA: 1:37 - loss: 0.6987 - acc: 0.5163
6976/9333 [=====================>........] - ETA: 1:34 - loss: 0.6988 - acc: 0.5159
7040/9333 [=====================>........] - ETA: 1:32 - loss: 0.6990 - acc: 0.5152
7104/9333 [=====================>........] - ETA: 1:29 - loss: 0.6989 - acc: 0.5149
7168/9333 [======================>.......] - ETA: 1:27 - loss: 0.6989 - acc: 0.5151
7232/9333 [======================>.......] - ETA: 1:24 - loss: 0.6987 - acc: 0.5149
7296/9333 [======================>.......] - ETA: 1:21 - loss: 0.6986 - acc: 0.5155
7360/9333 [======================>.......] - ETA: 1:19 - loss: 0.6985 - acc: 0.5162
7424/9333 [======================>.......] - ETA: 1:16 - loss: 0.6987 - acc: 0.5156
7488/9333 [=======================>......] - ETA: 1:14 - loss: 0.6987 - acc: 0.5150
7552/9333 [=======================>......] - ETA: 1:11 - loss: 0.6989 - acc: 0.5143
7616/9333 [=======================>......] - ETA: 1:09 - loss: 0.6990 - acc: 0.5137
7680/9333 [=======================>......] - ETA: 1:06 - loss: 0.6988 - acc: 0.5145
7744/9333 [=======================>......] - ETA: 1:03 - loss: 0.6989 - acc: 0.5141
7808/9333 [========================>.....] - ETA: 1:01 - loss: 0.6988 - acc: 0.5146
7872/9333 [========================>.....] - ETA: 58s - loss: 0.6987 - acc: 0.5150 
7936/9333 [========================>.....] - ETA: 56s - loss: 0.6987 - acc: 0.5142
8000/9333 [========================>.....] - ETA: 53s - loss: 0.6987 - acc: 0.5145
8064/9333 [========================>.....] - ETA: 51s - loss: 0.6987 - acc: 0.5140
8128/9333 [=========================>....] - ETA: 48s - loss: 0.6989 - acc: 0.5133
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6990 - acc: 0.5129
8256/9333 [=========================>....] - ETA: 43s - loss: 0.6992 - acc: 0.5124
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6990 - acc: 0.5126
8384/9333 [=========================>....] - ETA: 38s - loss: 0.6990 - acc: 0.5129
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6988 - acc: 0.5134
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6988 - acc: 0.5133
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6989 - acc: 0.5127
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6989 - acc: 0.5126
8704/9333 [==========================>...] - ETA: 25s - loss: 0.6989 - acc: 0.5129
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6989 - acc: 0.5130
8832/9333 [===========================>..] - ETA: 20s - loss: 0.6990 - acc: 0.5123
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6989 - acc: 0.5124
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6988 - acc: 0.5124
9024/9333 [============================>.] - ETA: 12s - loss: 0.6990 - acc: 0.5120
9088/9333 [============================>.] - ETA: 9s - loss: 0.6991 - acc: 0.5114 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6990 - acc: 0.5116
9216/9333 [============================>.] - ETA: 4s - loss: 0.6990 - acc: 0.5114
9280/9333 [============================>.] - ETA: 2s - loss: 0.6989 - acc: 0.5115
9333/9333 [==============================] - 392s 42ms/step - loss: 0.6989 - acc: 0.5115 - val_loss: 0.6910 - val_acc: 0.5265

Epoch 00002: val_acc did not improve from 0.53905
Epoch 3/10

  64/9333 [..............................] - ETA: 6:14 - loss: 0.7045 - acc: 0.4844
 128/9333 [..............................] - ETA: 6:02 - loss: 0.7040 - acc: 0.5078
 192/9333 [..............................] - ETA: 5:56 - loss: 0.7040 - acc: 0.4948
 256/9333 [..............................] - ETA: 5:46 - loss: 0.7008 - acc: 0.5039
 320/9333 [>.............................] - ETA: 5:40 - loss: 0.7049 - acc: 0.4906
 384/9333 [>.............................] - ETA: 5:35 - loss: 0.7037 - acc: 0.4896
 448/9333 [>.............................] - ETA: 5:32 - loss: 0.6997 - acc: 0.5000
 512/9333 [>.............................] - ETA: 5:29 - loss: 0.6965 - acc: 0.5039
 576/9333 [>.............................] - ETA: 5:28 - loss: 0.6946 - acc: 0.5122
 640/9333 [=>............................] - ETA: 5:32 - loss: 0.6972 - acc: 0.5000
 704/9333 [=>............................] - ETA: 5:35 - loss: 0.6946 - acc: 0.5128
 768/9333 [=>............................] - ETA: 5:31 - loss: 0.6952 - acc: 0.5104
 832/9333 [=>............................] - ETA: 5:27 - loss: 0.6929 - acc: 0.5228
 896/9333 [=>............................] - ETA: 5:24 - loss: 0.6927 - acc: 0.5223
 960/9333 [==>...........................] - ETA: 5:21 - loss: 0.6931 - acc: 0.5219
1024/9333 [==>...........................] - ETA: 5:20 - loss: 0.6946 - acc: 0.5166
1088/9333 [==>...........................] - ETA: 5:19 - loss: 0.6942 - acc: 0.5175
1152/9333 [==>...........................] - ETA: 5:17 - loss: 0.6940 - acc: 0.5208
1216/9333 [==>...........................] - ETA: 5:18 - loss: 0.6951 - acc: 0.5164
1280/9333 [===>..........................] - ETA: 5:19 - loss: 0.6953 - acc: 0.5188
1344/9333 [===>..........................] - ETA: 5:17 - loss: 0.6971 - acc: 0.5097
1408/9333 [===>..........................] - ETA: 5:14 - loss: 0.6971 - acc: 0.5085
1472/9333 [===>..........................] - ETA: 5:10 - loss: 0.6973 - acc: 0.5068
1536/9333 [===>..........................] - ETA: 5:08 - loss: 0.6977 - acc: 0.5046
1600/9333 [====>.........................] - ETA: 5:05 - loss: 0.6985 - acc: 0.5031
1664/9333 [====>.........................] - ETA: 5:02 - loss: 0.6973 - acc: 0.5084
1728/9333 [====>.........................] - ETA: 4:59 - loss: 0.6968 - acc: 0.5116
1792/9333 [====>.........................] - ETA: 4:56 - loss: 0.6973 - acc: 0.5100
1856/9333 [====>.........................] - ETA: 4:56 - loss: 0.6971 - acc: 0.5102
1920/9333 [=====>........................] - ETA: 4:53 - loss: 0.6968 - acc: 0.5115
1984/9333 [=====>........................] - ETA: 4:50 - loss: 0.6969 - acc: 0.5116
2048/9333 [=====>........................] - ETA: 4:47 - loss: 0.6970 - acc: 0.5078
2112/9333 [=====>........................] - ETA: 4:45 - loss: 0.6970 - acc: 0.5071
2176/9333 [=====>........................] - ETA: 4:41 - loss: 0.6966 - acc: 0.5092
2240/9333 [======>.......................] - ETA: 4:37 - loss: 0.6968 - acc: 0.5076
2304/9333 [======>.......................] - ETA: 4:36 - loss: 0.6984 - acc: 0.5030
2368/9333 [======>.......................] - ETA: 4:34 - loss: 0.6979 - acc: 0.5042
2432/9333 [======>.......................] - ETA: 4:31 - loss: 0.6980 - acc: 0.5041
2496/9333 [=======>......................] - ETA: 4:28 - loss: 0.6971 - acc: 0.5064
2560/9333 [=======>......................] - ETA: 4:27 - loss: 0.6973 - acc: 0.5059
2624/9333 [=======>......................] - ETA: 4:24 - loss: 0.6974 - acc: 0.5076
2688/9333 [=======>......................] - ETA: 4:21 - loss: 0.6968 - acc: 0.5089
2752/9333 [=======>......................] - ETA: 4:18 - loss: 0.6966 - acc: 0.5098
2816/9333 [========>.....................] - ETA: 4:15 - loss: 0.6965 - acc: 0.5107
2880/9333 [========>.....................] - ETA: 4:14 - loss: 0.6968 - acc: 0.5097
2944/9333 [========>.....................] - ETA: 4:12 - loss: 0.6964 - acc: 0.5092
3008/9333 [========>.....................] - ETA: 4:10 - loss: 0.6965 - acc: 0.5090
3072/9333 [========>.....................] - ETA: 4:08 - loss: 0.6961 - acc: 0.5091
3136/9333 [=========>....................] - ETA: 4:04 - loss: 0.6963 - acc: 0.5083
3200/9333 [=========>....................] - ETA: 4:03 - loss: 0.6963 - acc: 0.5088
3264/9333 [=========>....................] - ETA: 4:00 - loss: 0.6964 - acc: 0.5086
3328/9333 [=========>....................] - ETA: 3:57 - loss: 0.6964 - acc: 0.5099
3392/9333 [=========>....................] - ETA: 3:54 - loss: 0.6963 - acc: 0.5103
3456/9333 [==========>...................] - ETA: 3:53 - loss: 0.6962 - acc: 0.5101
3520/9333 [==========>...................] - ETA: 3:51 - loss: 0.6963 - acc: 0.5108
3584/9333 [==========>...................] - ETA: 3:48 - loss: 0.6964 - acc: 0.5103
3648/9333 [==========>...................] - ETA: 3:45 - loss: 0.6963 - acc: 0.5101
3712/9333 [==========>...................] - ETA: 3:44 - loss: 0.6964 - acc: 0.5105
3776/9333 [===========>..................] - ETA: 3:41 - loss: 0.6966 - acc: 0.5090
3840/9333 [===========>..................] - ETA: 3:38 - loss: 0.6968 - acc: 0.5076
3904/9333 [===========>..................] - ETA: 3:35 - loss: 0.6969 - acc: 0.5067
3968/9333 [===========>..................] - ETA: 3:32 - loss: 0.6968 - acc: 0.5066
4032/9333 [===========>..................] - ETA: 3:29 - loss: 0.6967 - acc: 0.5069
4096/9333 [============>.................] - ETA: 3:27 - loss: 0.6969 - acc: 0.5059
4160/9333 [============>.................] - ETA: 3:24 - loss: 0.6965 - acc: 0.5079
4224/9333 [============>.................] - ETA: 3:23 - loss: 0.6967 - acc: 0.5069
4288/9333 [============>.................] - ETA: 3:21 - loss: 0.6967 - acc: 0.5075
4352/9333 [============>.................] - ETA: 3:18 - loss: 0.6969 - acc: 0.5067
4416/9333 [=============>................] - ETA: 3:15 - loss: 0.6967 - acc: 0.5077
4480/9333 [=============>................] - ETA: 3:13 - loss: 0.6965 - acc: 0.5092
4544/9333 [=============>................] - ETA: 3:10 - loss: 0.6965 - acc: 0.5090
4608/9333 [=============>................] - ETA: 3:08 - loss: 0.6967 - acc: 0.5091
4672/9333 [==============>...............] - ETA: 3:05 - loss: 0.6967 - acc: 0.5094
4736/9333 [==============>...............] - ETA: 3:03 - loss: 0.6966 - acc: 0.5099
4800/9333 [==============>...............] - ETA: 3:00 - loss: 0.6964 - acc: 0.5102
4864/9333 [==============>...............] - ETA: 2:58 - loss: 0.6964 - acc: 0.5095
4928/9333 [==============>...............] - ETA: 2:55 - loss: 0.6963 - acc: 0.5101
4992/9333 [===============>..............] - ETA: 2:52 - loss: 0.6963 - acc: 0.5102
5056/9333 [===============>..............] - ETA: 2:50 - loss: 0.6962 - acc: 0.5111
5120/9333 [===============>..............] - ETA: 2:47 - loss: 0.6961 - acc: 0.5109
5184/9333 [===============>..............] - ETA: 2:45 - loss: 0.6963 - acc: 0.5100
5248/9333 [===============>..............] - ETA: 2:42 - loss: 0.6961 - acc: 0.5107
5312/9333 [================>.............] - ETA: 2:39 - loss: 0.6959 - acc: 0.5122
5376/9333 [================>.............] - ETA: 2:37 - loss: 0.6959 - acc: 0.5128
5440/9333 [================>.............] - ETA: 2:34 - loss: 0.6959 - acc: 0.5118
5504/9333 [================>.............] - ETA: 2:32 - loss: 0.6957 - acc: 0.5125
5568/9333 [================>.............] - ETA: 2:29 - loss: 0.6955 - acc: 0.5135
5632/9333 [=================>............] - ETA: 2:27 - loss: 0.6951 - acc: 0.5153
5696/9333 [=================>............] - ETA: 2:24 - loss: 0.6954 - acc: 0.5146
5760/9333 [=================>............] - ETA: 2:22 - loss: 0.6956 - acc: 0.5139
5824/9333 [=================>............] - ETA: 2:19 - loss: 0.6953 - acc: 0.5151
5888/9333 [=================>............] - ETA: 2:17 - loss: 0.6951 - acc: 0.5160
5952/9333 [==================>...........] - ETA: 2:14 - loss: 0.6951 - acc: 0.5163
6016/9333 [==================>...........] - ETA: 2:12 - loss: 0.6948 - acc: 0.5173
6080/9333 [==================>...........] - ETA: 2:09 - loss: 0.6949 - acc: 0.5164
6144/9333 [==================>...........] - ETA: 2:07 - loss: 0.6952 - acc: 0.5161
6208/9333 [==================>...........] - ETA: 2:04 - loss: 0.6953 - acc: 0.5156
6272/9333 [===================>..........] - ETA: 2:01 - loss: 0.6951 - acc: 0.5164
6336/9333 [===================>..........] - ETA: 1:59 - loss: 0.6952 - acc: 0.5155
6400/9333 [===================>..........] - ETA: 1:56 - loss: 0.6952 - acc: 0.5145
6464/9333 [===================>..........] - ETA: 1:54 - loss: 0.6953 - acc: 0.5152
6528/9333 [===================>..........] - ETA: 1:51 - loss: 0.6951 - acc: 0.5161
6592/9333 [====================>.........] - ETA: 1:49 - loss: 0.6950 - acc: 0.5168
6656/9333 [====================>.........] - ETA: 1:46 - loss: 0.6949 - acc: 0.5167
6720/9333 [====================>.........] - ETA: 1:44 - loss: 0.6948 - acc: 0.5162
6784/9333 [====================>.........] - ETA: 1:41 - loss: 0.6946 - acc: 0.5170
6848/9333 [=====================>........] - ETA: 1:39 - loss: 0.6948 - acc: 0.5168
6912/9333 [=====================>........] - ETA: 1:36 - loss: 0.6947 - acc: 0.5174
6976/9333 [=====================>........] - ETA: 1:33 - loss: 0.6946 - acc: 0.5185
7040/9333 [=====================>........] - ETA: 1:31 - loss: 0.6947 - acc: 0.5173
7104/9333 [=====================>........] - ETA: 1:28 - loss: 0.6945 - acc: 0.5179
7168/9333 [======================>.......] - ETA: 1:26 - loss: 0.6945 - acc: 0.5179
7232/9333 [======================>.......] - ETA: 1:23 - loss: 0.6946 - acc: 0.5174
7296/9333 [======================>.......] - ETA: 1:21 - loss: 0.6948 - acc: 0.5171
7360/9333 [======================>.......] - ETA: 1:18 - loss: 0.6948 - acc: 0.5168
7424/9333 [======================>.......] - ETA: 1:16 - loss: 0.6951 - acc: 0.5151
7488/9333 [=======================>......] - ETA: 1:13 - loss: 0.6952 - acc: 0.5143
7552/9333 [=======================>......] - ETA: 1:11 - loss: 0.6952 - acc: 0.5150
7616/9333 [=======================>......] - ETA: 1:08 - loss: 0.6951 - acc: 0.5148
7680/9333 [=======================>......] - ETA: 1:05 - loss: 0.6951 - acc: 0.5148
7744/9333 [=======================>......] - ETA: 1:03 - loss: 0.6949 - acc: 0.5155
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6949 - acc: 0.5152
7872/9333 [========================>.....] - ETA: 58s - loss: 0.6949 - acc: 0.5156 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6948 - acc: 0.5160
8000/9333 [========================>.....] - ETA: 53s - loss: 0.6948 - acc: 0.5156
8064/9333 [========================>.....] - ETA: 50s - loss: 0.6947 - acc: 0.5160
8128/9333 [=========================>....] - ETA: 48s - loss: 0.6948 - acc: 0.5161
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6947 - acc: 0.5159
8256/9333 [=========================>....] - ETA: 43s - loss: 0.6949 - acc: 0.5153
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6948 - acc: 0.5161
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6948 - acc: 0.5160
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6949 - acc: 0.5157
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6949 - acc: 0.5160
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6949 - acc: 0.5163
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6948 - acc: 0.5168
8704/9333 [==========================>...] - ETA: 25s - loss: 0.6948 - acc: 0.5172
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6949 - acc: 0.5170
8832/9333 [===========================>..] - ETA: 20s - loss: 0.6947 - acc: 0.5180
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6947 - acc: 0.5176
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6948 - acc: 0.5169
9024/9333 [============================>.] - ETA: 12s - loss: 0.6947 - acc: 0.5171
9088/9333 [============================>.] - ETA: 9s - loss: 0.6947 - acc: 0.5165 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6946 - acc: 0.5167
9216/9333 [============================>.] - ETA: 4s - loss: 0.6946 - acc: 0.5169
9280/9333 [============================>.] - ETA: 2s - loss: 0.6947 - acc: 0.5164
9333/9333 [==============================] - 390s 42ms/step - loss: 0.6948 - acc: 0.5158 - val_loss: 0.6889 - val_acc: 0.5342

Epoch 00003: val_acc did not improve from 0.53905
Epoch 4/10

  64/9333 [..............................] - ETA: 6:26 - loss: 0.6900 - acc: 0.6094
 128/9333 [..............................] - ETA: 6:27 - loss: 0.6931 - acc: 0.5469
 192/9333 [..............................] - ETA: 6:23 - loss: 0.6928 - acc: 0.5260
 256/9333 [..............................] - ETA: 6:08 - loss: 0.6888 - acc: 0.5586
 320/9333 [>.............................] - ETA: 6:03 - loss: 0.6884 - acc: 0.5625
 384/9333 [>.............................] - ETA: 5:56 - loss: 0.6881 - acc: 0.5521
 448/9333 [>.............................] - ETA: 5:49 - loss: 0.6871 - acc: 0.5558
 512/9333 [>.............................] - ETA: 5:44 - loss: 0.6858 - acc: 0.5527
 576/9333 [>.............................] - ETA: 5:38 - loss: 0.6861 - acc: 0.5486
 640/9333 [=>............................] - ETA: 5:40 - loss: 0.6833 - acc: 0.5594
 704/9333 [=>............................] - ETA: 5:34 - loss: 0.6841 - acc: 0.5597
 768/9333 [=>............................] - ETA: 5:28 - loss: 0.6874 - acc: 0.5521
 832/9333 [=>............................] - ETA: 5:35 - loss: 0.6883 - acc: 0.5481
 896/9333 [=>............................] - ETA: 5:36 - loss: 0.6888 - acc: 0.5413
 960/9333 [==>...........................] - ETA: 5:34 - loss: 0.6885 - acc: 0.5417
1024/9333 [==>...........................] - ETA: 5:31 - loss: 0.6883 - acc: 0.5420
1088/9333 [==>...........................] - ETA: 5:27 - loss: 0.6883 - acc: 0.5469
1152/9333 [==>...........................] - ETA: 5:22 - loss: 0.6880 - acc: 0.5477
1216/9333 [==>...........................] - ETA: 5:19 - loss: 0.6884 - acc: 0.5436
1280/9333 [===>..........................] - ETA: 5:18 - loss: 0.6903 - acc: 0.5375
1344/9333 [===>..........................] - ETA: 5:15 - loss: 0.6902 - acc: 0.5379
1408/9333 [===>..........................] - ETA: 5:16 - loss: 0.6911 - acc: 0.5348
1472/9333 [===>..........................] - ETA: 5:15 - loss: 0.6921 - acc: 0.5299
1536/9333 [===>..........................] - ETA: 5:11 - loss: 0.6916 - acc: 0.5312
1600/9333 [====>.........................] - ETA: 5:07 - loss: 0.6913 - acc: 0.5294
1664/9333 [====>.........................] - ETA: 5:05 - loss: 0.6927 - acc: 0.5234
1728/9333 [====>.........................] - ETA: 5:02 - loss: 0.6925 - acc: 0.5243
1792/9333 [====>.........................] - ETA: 4:59 - loss: 0.6921 - acc: 0.5268
1856/9333 [====>.........................] - ETA: 4:56 - loss: 0.6918 - acc: 0.5259
1920/9333 [=====>........................] - ETA: 4:55 - loss: 0.6925 - acc: 0.5229
1984/9333 [=====>........................] - ETA: 4:52 - loss: 0.6919 - acc: 0.5252
2048/9333 [=====>........................] - ETA: 4:49 - loss: 0.6921 - acc: 0.5249
2112/9333 [=====>........................] - ETA: 4:49 - loss: 0.6922 - acc: 0.5270
2176/9333 [=====>........................] - ETA: 4:46 - loss: 0.6922 - acc: 0.5262
2240/9333 [======>.......................] - ETA: 4:43 - loss: 0.6925 - acc: 0.5232
2304/9333 [======>.......................] - ETA: 4:40 - loss: 0.6932 - acc: 0.5195
2368/9333 [======>.......................] - ETA: 4:37 - loss: 0.6931 - acc: 0.5203
2432/9333 [======>.......................] - ETA: 4:33 - loss: 0.6932 - acc: 0.5189
2496/9333 [=======>......................] - ETA: 4:31 - loss: 0.6932 - acc: 0.5180
2560/9333 [=======>......................] - ETA: 4:28 - loss: 0.6929 - acc: 0.5168
2624/9333 [=======>......................] - ETA: 4:26 - loss: 0.6929 - acc: 0.5179
2688/9333 [=======>......................] - ETA: 4:25 - loss: 0.6930 - acc: 0.5171
2752/9333 [=======>......................] - ETA: 4:23 - loss: 0.6931 - acc: 0.5160
2816/9333 [========>.....................] - ETA: 4:21 - loss: 0.6929 - acc: 0.5185
2880/9333 [========>.....................] - ETA: 4:17 - loss: 0.6928 - acc: 0.5191
2944/9333 [========>.....................] - ETA: 4:15 - loss: 0.6924 - acc: 0.5211
3008/9333 [========>.....................] - ETA: 4:12 - loss: 0.6925 - acc: 0.5223
3072/9333 [========>.....................] - ETA: 4:09 - loss: 0.6927 - acc: 0.5212
3136/9333 [=========>....................] - ETA: 4:06 - loss: 0.6926 - acc: 0.5217
3200/9333 [=========>....................] - ETA: 4:04 - loss: 0.6929 - acc: 0.5197
3264/9333 [=========>....................] - ETA: 4:02 - loss: 0.6929 - acc: 0.5205
3328/9333 [=========>....................] - ETA: 3:59 - loss: 0.6928 - acc: 0.5207
3392/9333 [=========>....................] - ETA: 3:56 - loss: 0.6926 - acc: 0.5209
3456/9333 [==========>...................] - ETA: 3:54 - loss: 0.6928 - acc: 0.5200
3520/9333 [==========>...................] - ETA: 3:51 - loss: 0.6929 - acc: 0.5199
3584/9333 [==========>...................] - ETA: 3:48 - loss: 0.6928 - acc: 0.5195
3648/9333 [==========>...................] - ETA: 3:45 - loss: 0.6927 - acc: 0.5197
3712/9333 [==========>...................] - ETA: 3:43 - loss: 0.6927 - acc: 0.5202
3776/9333 [===========>..................] - ETA: 3:40 - loss: 0.6930 - acc: 0.5188
3840/9333 [===========>..................] - ETA: 3:38 - loss: 0.6928 - acc: 0.5201
3904/9333 [===========>..................] - ETA: 3:36 - loss: 0.6928 - acc: 0.5195
3968/9333 [===========>..................] - ETA: 3:34 - loss: 0.6927 - acc: 0.5197
4032/9333 [===========>..................] - ETA: 3:31 - loss: 0.6927 - acc: 0.5208
4096/9333 [============>.................] - ETA: 3:28 - loss: 0.6924 - acc: 0.5212
4160/9333 [============>.................] - ETA: 3:26 - loss: 0.6925 - acc: 0.5212
4224/9333 [============>.................] - ETA: 3:23 - loss: 0.6925 - acc: 0.5201
4288/9333 [============>.................] - ETA: 3:20 - loss: 0.6925 - acc: 0.5203
4352/9333 [============>.................] - ETA: 3:18 - loss: 0.6921 - acc: 0.5207
4416/9333 [=============>................] - ETA: 3:15 - loss: 0.6921 - acc: 0.5206
4480/9333 [=============>................] - ETA: 3:12 - loss: 0.6919 - acc: 0.5214
4544/9333 [=============>................] - ETA: 3:10 - loss: 0.6918 - acc: 0.5229
4608/9333 [=============>................] - ETA: 3:08 - loss: 0.6915 - acc: 0.5237
4672/9333 [==============>...............] - ETA: 3:05 - loss: 0.6914 - acc: 0.5250
4736/9333 [==============>...............] - ETA: 3:03 - loss: 0.6915 - acc: 0.5247
4800/9333 [==============>...............] - ETA: 3:00 - loss: 0.6916 - acc: 0.5238
4864/9333 [==============>...............] - ETA: 2:57 - loss: 0.6914 - acc: 0.5245
4928/9333 [==============>...............] - ETA: 2:55 - loss: 0.6910 - acc: 0.5256
4992/9333 [===============>..............] - ETA: 2:52 - loss: 0.6909 - acc: 0.5262
5056/9333 [===============>..............] - ETA: 2:50 - loss: 0.6907 - acc: 0.5265
5120/9333 [===============>..............] - ETA: 2:47 - loss: 0.6908 - acc: 0.5268
5184/9333 [===============>..............] - ETA: 2:45 - loss: 0.6903 - acc: 0.5280
5248/9333 [===============>..............] - ETA: 2:42 - loss: 0.6909 - acc: 0.5267
5312/9333 [================>.............] - ETA: 2:40 - loss: 0.6910 - acc: 0.5265
5376/9333 [================>.............] - ETA: 2:37 - loss: 0.6913 - acc: 0.5268
5440/9333 [================>.............] - ETA: 2:34 - loss: 0.6912 - acc: 0.5267
5504/9333 [================>.............] - ETA: 2:32 - loss: 0.6911 - acc: 0.5273
5568/9333 [================>.............] - ETA: 2:29 - loss: 0.6910 - acc: 0.5280
5632/9333 [=================>............] - ETA: 2:27 - loss: 0.6911 - acc: 0.5282
5696/9333 [=================>............] - ETA: 2:25 - loss: 0.6912 - acc: 0.5279
5760/9333 [=================>............] - ETA: 2:22 - loss: 0.6909 - acc: 0.5286
5824/9333 [=================>............] - ETA: 2:19 - loss: 0.6908 - acc: 0.5285
5888/9333 [=================>............] - ETA: 2:17 - loss: 0.6906 - acc: 0.5296
5952/9333 [==================>...........] - ETA: 2:14 - loss: 0.6904 - acc: 0.5301
6016/9333 [==================>...........] - ETA: 2:12 - loss: 0.6902 - acc: 0.5308
6080/9333 [==================>...........] - ETA: 2:09 - loss: 0.6903 - acc: 0.5306
6144/9333 [==================>...........] - ETA: 2:06 - loss: 0.6904 - acc: 0.5306
6208/9333 [==================>...........] - ETA: 2:04 - loss: 0.6902 - acc: 0.5314
6272/9333 [===================>..........] - ETA: 2:02 - loss: 0.6901 - acc: 0.5314
6336/9333 [===================>..........] - ETA: 1:59 - loss: 0.6900 - acc: 0.5317
6400/9333 [===================>..........] - ETA: 1:56 - loss: 0.6902 - acc: 0.5316
6464/9333 [===================>..........] - ETA: 1:54 - loss: 0.6900 - acc: 0.5316
6528/9333 [===================>..........] - ETA: 1:51 - loss: 0.6897 - acc: 0.5322
6592/9333 [====================>.........] - ETA: 1:49 - loss: 0.6898 - acc: 0.5322
6656/9333 [====================>.........] - ETA: 1:46 - loss: 0.6901 - acc: 0.5316
6720/9333 [====================>.........] - ETA: 1:44 - loss: 0.6902 - acc: 0.5311
6784/9333 [====================>.........] - ETA: 1:41 - loss: 0.6902 - acc: 0.5314
6848/9333 [=====================>........] - ETA: 1:38 - loss: 0.6903 - acc: 0.5315
6912/9333 [=====================>........] - ETA: 1:36 - loss: 0.6902 - acc: 0.5326
6976/9333 [=====================>........] - ETA: 1:33 - loss: 0.6903 - acc: 0.5321
7040/9333 [=====================>........] - ETA: 1:31 - loss: 0.6907 - acc: 0.5310
7104/9333 [=====================>........] - ETA: 1:28 - loss: 0.6910 - acc: 0.5303
7168/9333 [======================>.......] - ETA: 1:26 - loss: 0.6911 - acc: 0.5301
7232/9333 [======================>.......] - ETA: 1:23 - loss: 0.6909 - acc: 0.5308
7296/9333 [======================>.......] - ETA: 1:21 - loss: 0.6909 - acc: 0.5302
7360/9333 [======================>.......] - ETA: 1:18 - loss: 0.6909 - acc: 0.5300
7424/9333 [======================>.......] - ETA: 1:15 - loss: 0.6910 - acc: 0.5300
7488/9333 [=======================>......] - ETA: 1:13 - loss: 0.6910 - acc: 0.5303
7552/9333 [=======================>......] - ETA: 1:10 - loss: 0.6911 - acc: 0.5298
7616/9333 [=======================>......] - ETA: 1:08 - loss: 0.6911 - acc: 0.5293
7680/9333 [=======================>......] - ETA: 1:05 - loss: 0.6913 - acc: 0.5283
7744/9333 [=======================>......] - ETA: 1:03 - loss: 0.6914 - acc: 0.5283
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6916 - acc: 0.5269
7872/9333 [========================>.....] - ETA: 58s - loss: 0.6916 - acc: 0.5271 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6916 - acc: 0.5270
8000/9333 [========================>.....] - ETA: 53s - loss: 0.6915 - acc: 0.5269
8064/9333 [========================>.....] - ETA: 50s - loss: 0.6917 - acc: 0.5263
8128/9333 [=========================>....] - ETA: 47s - loss: 0.6917 - acc: 0.5262
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6916 - acc: 0.5262
8256/9333 [=========================>....] - ETA: 42s - loss: 0.6916 - acc: 0.5263
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6915 - acc: 0.5274
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6914 - acc: 0.5279
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6914 - acc: 0.5275
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6913 - acc: 0.5278
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6913 - acc: 0.5283
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6913 - acc: 0.5286
8704/9333 [==========================>...] - ETA: 25s - loss: 0.6913 - acc: 0.5290
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6914 - acc: 0.5286
8832/9333 [===========================>..] - ETA: 19s - loss: 0.6915 - acc: 0.5285
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6915 - acc: 0.5279
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6914 - acc: 0.5283
9024/9333 [============================>.] - ETA: 12s - loss: 0.6912 - acc: 0.5289
9088/9333 [============================>.] - ETA: 9s - loss: 0.6911 - acc: 0.5293 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6911 - acc: 0.5297
9216/9333 [============================>.] - ETA: 4s - loss: 0.6911 - acc: 0.5298
9280/9333 [============================>.] - ETA: 2s - loss: 0.6912 - acc: 0.5294
9333/9333 [==============================] - 388s 42ms/step - loss: 0.6913 - acc: 0.5293 - val_loss: 0.6907 - val_acc: 0.5178

Epoch 00004: val_acc did not improve from 0.53905
Epoch 5/10

  64/9333 [..............................] - ETA: 6:04 - loss: 0.6923 - acc: 0.5000
 128/9333 [..............................] - ETA: 5:57 - loss: 0.6969 - acc: 0.5078
 192/9333 [..............................] - ETA: 5:51 - loss: 0.6893 - acc: 0.5521
 256/9333 [..............................] - ETA: 5:42 - loss: 0.6908 - acc: 0.5469
 320/9333 [>.............................] - ETA: 5:45 - loss: 0.6947 - acc: 0.5375
 384/9333 [>.............................] - ETA: 5:39 - loss: 0.6920 - acc: 0.5391
 448/9333 [>.............................] - ETA: 5:34 - loss: 0.6916 - acc: 0.5335
 512/9333 [>.............................] - ETA: 5:30 - loss: 0.6892 - acc: 0.5371
 576/9333 [>.............................] - ETA: 5:30 - loss: 0.6889 - acc: 0.5399
 640/9333 [=>............................] - ETA: 5:34 - loss: 0.6879 - acc: 0.5422
 704/9333 [=>............................] - ETA: 5:36 - loss: 0.6861 - acc: 0.5511
 768/9333 [=>............................] - ETA: 5:31 - loss: 0.6851 - acc: 0.5560
 832/9333 [=>............................] - ETA: 5:26 - loss: 0.6863 - acc: 0.5517
 896/9333 [=>............................] - ETA: 5:24 - loss: 0.6867 - acc: 0.5491
 960/9333 [==>...........................] - ETA: 5:21 - loss: 0.6875 - acc: 0.5469
1024/9333 [==>...........................] - ETA: 5:17 - loss: 0.6874 - acc: 0.5469
1088/9333 [==>...........................] - ETA: 5:19 - loss: 0.6877 - acc: 0.5432
1152/9333 [==>...........................] - ETA: 5:18 - loss: 0.6873 - acc: 0.5486
1216/9333 [==>...........................] - ETA: 5:18 - loss: 0.6876 - acc: 0.5485
1280/9333 [===>..........................] - ETA: 5:20 - loss: 0.6881 - acc: 0.5461
1344/9333 [===>..........................] - ETA: 5:18 - loss: 0.6884 - acc: 0.5454
1408/9333 [===>..........................] - ETA: 5:14 - loss: 0.6888 - acc: 0.5433
1472/9333 [===>..........................] - ETA: 5:10 - loss: 0.6884 - acc: 0.5455
1536/9333 [===>..........................] - ETA: 5:06 - loss: 0.6880 - acc: 0.5462
1600/9333 [====>.........................] - ETA: 5:04 - loss: 0.6883 - acc: 0.5481
1664/9333 [====>.........................] - ETA: 5:02 - loss: 0.6878 - acc: 0.5511
1728/9333 [====>.........................] - ETA: 4:59 - loss: 0.6880 - acc: 0.5492
1792/9333 [====>.........................] - ETA: 4:57 - loss: 0.6877 - acc: 0.5502
1856/9333 [====>.........................] - ETA: 4:56 - loss: 0.6877 - acc: 0.5501
1920/9333 [=====>........................] - ETA: 4:54 - loss: 0.6885 - acc: 0.5490
1984/9333 [=====>........................] - ETA: 4:52 - loss: 0.6893 - acc: 0.5444
2048/9333 [=====>........................] - ETA: 4:50 - loss: 0.6896 - acc: 0.5430
2112/9333 [=====>........................] - ETA: 4:49 - loss: 0.6896 - acc: 0.5436
2176/9333 [=====>........................] - ETA: 4:48 - loss: 0.6893 - acc: 0.5427
2240/9333 [======>.......................] - ETA: 4:45 - loss: 0.6894 - acc: 0.5424
2304/9333 [======>.......................] - ETA: 4:41 - loss: 0.6896 - acc: 0.5417
2368/9333 [======>.......................] - ETA: 4:39 - loss: 0.6899 - acc: 0.5422
2432/9333 [======>.......................] - ETA: 4:37 - loss: 0.6895 - acc: 0.5440
2496/9333 [=======>......................] - ETA: 4:36 - loss: 0.6898 - acc: 0.5437
2560/9333 [=======>......................] - ETA: 4:33 - loss: 0.6893 - acc: 0.5461
2624/9333 [=======>......................] - ETA: 4:30 - loss: 0.6893 - acc: 0.5450
2688/9333 [=======>......................] - ETA: 4:27 - loss: 0.6895 - acc: 0.5446
2752/9333 [=======>......................] - ETA: 4:23 - loss: 0.6897 - acc: 0.5440
2816/9333 [========>.....................] - ETA: 4:21 - loss: 0.6892 - acc: 0.5469
2880/9333 [========>.....................] - ETA: 4:18 - loss: 0.6890 - acc: 0.5476
2944/9333 [========>.....................] - ETA: 4:16 - loss: 0.6889 - acc: 0.5472
3008/9333 [========>.....................] - ETA: 4:14 - loss: 0.6890 - acc: 0.5482
3072/9333 [========>.....................] - ETA: 4:11 - loss: 0.6885 - acc: 0.5498
3136/9333 [=========>....................] - ETA: 4:08 - loss: 0.6889 - acc: 0.5482
3200/9333 [=========>....................] - ETA: 4:06 - loss: 0.6885 - acc: 0.5487
3264/9333 [=========>....................] - ETA: 4:03 - loss: 0.6887 - acc: 0.5481
3328/9333 [=========>....................] - ETA: 4:01 - loss: 0.6886 - acc: 0.5469
3392/9333 [=========>....................] - ETA: 3:58 - loss: 0.6882 - acc: 0.5481
3456/9333 [==========>...................] - ETA: 3:57 - loss: 0.6879 - acc: 0.5495
3520/9333 [==========>...................] - ETA: 3:53 - loss: 0.6880 - acc: 0.5497
3584/9333 [==========>...................] - ETA: 3:51 - loss: 0.6881 - acc: 0.5502
3648/9333 [==========>...................] - ETA: 3:48 - loss: 0.6879 - acc: 0.5504
3712/9333 [==========>...................] - ETA: 3:45 - loss: 0.6878 - acc: 0.5515
3776/9333 [===========>..................] - ETA: 3:42 - loss: 0.6884 - acc: 0.5482
3840/9333 [===========>..................] - ETA: 3:40 - loss: 0.6883 - acc: 0.5477
3904/9333 [===========>..................] - ETA: 3:37 - loss: 0.6885 - acc: 0.5459
3968/9333 [===========>..................] - ETA: 3:35 - loss: 0.6885 - acc: 0.5449
4032/9333 [===========>..................] - ETA: 3:32 - loss: 0.6884 - acc: 0.5446
4096/9333 [============>.................] - ETA: 3:30 - loss: 0.6884 - acc: 0.5452
4160/9333 [============>.................] - ETA: 3:27 - loss: 0.6883 - acc: 0.5459
4224/9333 [============>.................] - ETA: 3:24 - loss: 0.6884 - acc: 0.5455
4288/9333 [============>.................] - ETA: 3:21 - loss: 0.6885 - acc: 0.5445
4352/9333 [============>.................] - ETA: 3:19 - loss: 0.6882 - acc: 0.5453
4416/9333 [=============>................] - ETA: 3:16 - loss: 0.6881 - acc: 0.5455
4480/9333 [=============>................] - ETA: 3:13 - loss: 0.6881 - acc: 0.5444
4544/9333 [=============>................] - ETA: 3:11 - loss: 0.6882 - acc: 0.5440
4608/9333 [=============>................] - ETA: 3:08 - loss: 0.6880 - acc: 0.5451
4672/9333 [==============>...............] - ETA: 3:06 - loss: 0.6879 - acc: 0.5460
4736/9333 [==============>...............] - ETA: 3:04 - loss: 0.6884 - acc: 0.5443
4800/9333 [==============>...............] - ETA: 3:01 - loss: 0.6885 - acc: 0.5446
4864/9333 [==============>...............] - ETA: 2:58 - loss: 0.6886 - acc: 0.5438
4928/9333 [==============>...............] - ETA: 2:56 - loss: 0.6887 - acc: 0.5434
4992/9333 [===============>..............] - ETA: 2:53 - loss: 0.6886 - acc: 0.5435
5056/9333 [===============>..............] - ETA: 2:50 - loss: 0.6889 - acc: 0.5427
5120/9333 [===============>..............] - ETA: 2:48 - loss: 0.6888 - acc: 0.5430
5184/9333 [===============>..............] - ETA: 2:45 - loss: 0.6890 - acc: 0.5417
5248/9333 [===============>..............] - ETA: 2:43 - loss: 0.6889 - acc: 0.5423
5312/9333 [================>.............] - ETA: 2:41 - loss: 0.6891 - acc: 0.5414
5376/9333 [================>.............] - ETA: 2:38 - loss: 0.6889 - acc: 0.5422
5440/9333 [================>.............] - ETA: 2:35 - loss: 0.6890 - acc: 0.5419
5504/9333 [================>.............] - ETA: 2:33 - loss: 0.6891 - acc: 0.5405
5568/9333 [================>.............] - ETA: 2:30 - loss: 0.6889 - acc: 0.5411
5632/9333 [=================>............] - ETA: 2:27 - loss: 0.6887 - acc: 0.5419
5696/9333 [=================>............] - ETA: 2:25 - loss: 0.6892 - acc: 0.5407
5760/9333 [=================>............] - ETA: 2:22 - loss: 0.6895 - acc: 0.5403
5824/9333 [=================>............] - ETA: 2:20 - loss: 0.6897 - acc: 0.5402
5888/9333 [=================>............] - ETA: 2:17 - loss: 0.6896 - acc: 0.5406
5952/9333 [==================>...........] - ETA: 2:15 - loss: 0.6897 - acc: 0.5412
6016/9333 [==================>...........] - ETA: 2:12 - loss: 0.6898 - acc: 0.5411
6080/9333 [==================>...........] - ETA: 2:10 - loss: 0.6898 - acc: 0.5411
6144/9333 [==================>...........] - ETA: 2:07 - loss: 0.6897 - acc: 0.5418
6208/9333 [==================>...........] - ETA: 2:05 - loss: 0.6898 - acc: 0.5409
6272/9333 [===================>..........] - ETA: 2:02 - loss: 0.6897 - acc: 0.5407
6336/9333 [===================>..........] - ETA: 2:00 - loss: 0.6895 - acc: 0.5410
6400/9333 [===================>..........] - ETA: 1:57 - loss: 0.6895 - acc: 0.5409
6464/9333 [===================>..........] - ETA: 1:55 - loss: 0.6895 - acc: 0.5408
6528/9333 [===================>..........] - ETA: 1:52 - loss: 0.6898 - acc: 0.5400
6592/9333 [====================>.........] - ETA: 1:49 - loss: 0.6898 - acc: 0.5400
6656/9333 [====================>.........] - ETA: 1:47 - loss: 0.6896 - acc: 0.5416
6720/9333 [====================>.........] - ETA: 1:44 - loss: 0.6896 - acc: 0.5408
6784/9333 [====================>.........] - ETA: 1:41 - loss: 0.6898 - acc: 0.5410
6848/9333 [=====================>........] - ETA: 1:39 - loss: 0.6896 - acc: 0.5413
6912/9333 [=====================>........] - ETA: 1:37 - loss: 0.6897 - acc: 0.5409
6976/9333 [=====================>........] - ETA: 1:34 - loss: 0.6896 - acc: 0.5413
7040/9333 [=====================>........] - ETA: 1:31 - loss: 0.6896 - acc: 0.5413
7104/9333 [=====================>........] - ETA: 1:29 - loss: 0.6894 - acc: 0.5417
7168/9333 [======================>.......] - ETA: 1:26 - loss: 0.6894 - acc: 0.5420
7232/9333 [======================>.......] - ETA: 1:23 - loss: 0.6895 - acc: 0.5419
7296/9333 [======================>.......] - ETA: 1:21 - loss: 0.6894 - acc: 0.5417
7360/9333 [======================>.......] - ETA: 1:18 - loss: 0.6894 - acc: 0.5418
7424/9333 [======================>.......] - ETA: 1:16 - loss: 0.6895 - acc: 0.5408
7488/9333 [=======================>......] - ETA: 1:13 - loss: 0.6894 - acc: 0.5418
7552/9333 [=======================>......] - ETA: 1:11 - loss: 0.6895 - acc: 0.5413
7616/9333 [=======================>......] - ETA: 1:08 - loss: 0.6894 - acc: 0.5416
7680/9333 [=======================>......] - ETA: 1:05 - loss: 0.6895 - acc: 0.5411
7744/9333 [=======================>......] - ETA: 1:03 - loss: 0.6897 - acc: 0.5403
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6898 - acc: 0.5402
7872/9333 [========================>.....] - ETA: 58s - loss: 0.6899 - acc: 0.5396 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6900 - acc: 0.5393
8000/9333 [========================>.....] - ETA: 53s - loss: 0.6901 - acc: 0.5381
8064/9333 [========================>.....] - ETA: 50s - loss: 0.6901 - acc: 0.5384
8128/9333 [=========================>....] - ETA: 48s - loss: 0.6902 - acc: 0.5375
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6902 - acc: 0.5377
8256/9333 [=========================>....] - ETA: 43s - loss: 0.6900 - acc: 0.5384
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6900 - acc: 0.5379
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6899 - acc: 0.5385
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6899 - acc: 0.5382
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6898 - acc: 0.5390
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6896 - acc: 0.5395
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6895 - acc: 0.5403
8704/9333 [==========================>...] - ETA: 25s - loss: 0.6895 - acc: 0.5402
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6895 - acc: 0.5404
8832/9333 [===========================>..] - ETA: 20s - loss: 0.6894 - acc: 0.5400
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6895 - acc: 0.5397
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6896 - acc: 0.5394
9024/9333 [============================>.] - ETA: 12s - loss: 0.6897 - acc: 0.5395
9088/9333 [============================>.] - ETA: 9s - loss: 0.6898 - acc: 0.5394 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6897 - acc: 0.5399
9216/9333 [============================>.] - ETA: 4s - loss: 0.6898 - acc: 0.5396
9280/9333 [============================>.] - ETA: 2s - loss: 0.6896 - acc: 0.5403
9333/9333 [==============================] - 389s 42ms/step - loss: 0.6897 - acc: 0.5402 - val_loss: 0.6889 - val_acc: 0.5236

Epoch 00005: val_acc did not improve from 0.53905
Epoch 6/10

  64/9333 [..............................] - ETA: 5:42 - loss: 0.6630 - acc: 0.5938
 128/9333 [..............................] - ETA: 5:31 - loss: 0.6807 - acc: 0.5625
 192/9333 [..............................] - ETA: 5:17 - loss: 0.6761 - acc: 0.5885
 256/9333 [..............................] - ETA: 5:33 - loss: 0.6797 - acc: 0.5742
 320/9333 [>.............................] - ETA: 5:31 - loss: 0.6742 - acc: 0.6062
 384/9333 [>.............................] - ETA: 5:36 - loss: 0.6791 - acc: 0.5859
 448/9333 [>.............................] - ETA: 5:50 - loss: 0.6807 - acc: 0.5804
 512/9333 [>.............................] - ETA: 5:49 - loss: 0.6814 - acc: 0.5762
 576/9333 [>.............................] - ETA: 5:45 - loss: 0.6817 - acc: 0.5764
 640/9333 [=>............................] - ETA: 5:47 - loss: 0.6807 - acc: 0.5750
 704/9333 [=>............................] - ETA: 5:43 - loss: 0.6816 - acc: 0.5739
 768/9333 [=>............................] - ETA: 5:37 - loss: 0.6841 - acc: 0.5664
 832/9333 [=>............................] - ETA: 5:37 - loss: 0.6839 - acc: 0.5625
 896/9333 [=>............................] - ETA: 5:34 - loss: 0.6852 - acc: 0.5603
 960/9333 [==>...........................] - ETA: 5:29 - loss: 0.6862 - acc: 0.5594
1024/9333 [==>...........................] - ETA: 5:31 - loss: 0.6881 - acc: 0.5469
1088/9333 [==>...........................] - ETA: 5:29 - loss: 0.6871 - acc: 0.5469
1152/9333 [==>...........................] - ETA: 5:26 - loss: 0.6861 - acc: 0.5503
1216/9333 [==>...........................] - ETA: 5:24 - loss: 0.6873 - acc: 0.5469
1280/9333 [===>..........................] - ETA: 5:21 - loss: 0.6866 - acc: 0.5508
1344/9333 [===>..........................] - ETA: 5:18 - loss: 0.6870 - acc: 0.5469
1408/9333 [===>..........................] - ETA: 5:14 - loss: 0.6871 - acc: 0.5469
1472/9333 [===>..........................] - ETA: 5:11 - loss: 0.6870 - acc: 0.5476
1536/9333 [===>..........................] - ETA: 5:07 - loss: 0.6877 - acc: 0.5456
1600/9333 [====>.........................] - ETA: 5:06 - loss: 0.6878 - acc: 0.5419
1664/9333 [====>.........................] - ETA: 5:05 - loss: 0.6876 - acc: 0.5439
1728/9333 [====>.........................] - ETA: 5:04 - loss: 0.6886 - acc: 0.5399
1792/9333 [====>.........................] - ETA: 5:01 - loss: 0.6892 - acc: 0.5379
1856/9333 [====>.........................] - ETA: 4:58 - loss: 0.6898 - acc: 0.5366
1920/9333 [=====>........................] - ETA: 4:55 - loss: 0.6900 - acc: 0.5349
1984/9333 [=====>........................] - ETA: 4:52 - loss: 0.6906 - acc: 0.5323
2048/9333 [=====>........................] - ETA: 4:49 - loss: 0.6904 - acc: 0.5312
2112/9333 [=====>........................] - ETA: 4:47 - loss: 0.6899 - acc: 0.5336
2176/9333 [=====>........................] - ETA: 4:45 - loss: 0.6896 - acc: 0.5372
2240/9333 [======>.......................] - ETA: 4:44 - loss: 0.6896 - acc: 0.5366
2304/9333 [======>.......................] - ETA: 4:42 - loss: 0.6902 - acc: 0.5356
2368/9333 [======>.......................] - ETA: 4:39 - loss: 0.6897 - acc: 0.5359
2432/9333 [======>.......................] - ETA: 4:36 - loss: 0.6895 - acc: 0.5354
2496/9333 [=======>......................] - ETA: 4:33 - loss: 0.6892 - acc: 0.5365
2560/9333 [=======>......................] - ETA: 4:31 - loss: 0.6886 - acc: 0.5371
2624/9333 [=======>......................] - ETA: 4:28 - loss: 0.6896 - acc: 0.5332
2688/9333 [=======>......................] - ETA: 4:26 - loss: 0.6901 - acc: 0.5309
2752/9333 [=======>......................] - ETA: 4:24 - loss: 0.6901 - acc: 0.5331
2816/9333 [========>.....................] - ETA: 4:21 - loss: 0.6900 - acc: 0.5323
2880/9333 [========>.....................] - ETA: 4:18 - loss: 0.6897 - acc: 0.5333
2944/9333 [========>.....................] - ETA: 4:15 - loss: 0.6896 - acc: 0.5333
3008/9333 [========>.....................] - ETA: 4:12 - loss: 0.6891 - acc: 0.5356
3072/9333 [========>.....................] - ETA: 4:08 - loss: 0.6892 - acc: 0.5355
3136/9333 [=========>....................] - ETA: 4:06 - loss: 0.6894 - acc: 0.5351
3200/9333 [=========>....................] - ETA: 4:05 - loss: 0.6892 - acc: 0.5356
3264/9333 [=========>....................] - ETA: 4:03 - loss: 0.6890 - acc: 0.5355
3328/9333 [=========>....................] - ETA: 3:59 - loss: 0.6888 - acc: 0.5352
3392/9333 [=========>....................] - ETA: 3:57 - loss: 0.6890 - acc: 0.5357
3456/9333 [==========>...................] - ETA: 3:54 - loss: 0.6882 - acc: 0.5379
3520/9333 [==========>...................] - ETA: 3:52 - loss: 0.6877 - acc: 0.5401
3584/9333 [==========>...................] - ETA: 3:51 - loss: 0.6881 - acc: 0.5393
3648/9333 [==========>...................] - ETA: 3:49 - loss: 0.6879 - acc: 0.5406
3712/9333 [==========>...................] - ETA: 3:46 - loss: 0.6888 - acc: 0.5396
3776/9333 [===========>..................] - ETA: 3:44 - loss: 0.6886 - acc: 0.5400
3840/9333 [===========>..................] - ETA: 3:41 - loss: 0.6891 - acc: 0.5388
3904/9333 [===========>..................] - ETA: 3:38 - loss: 0.6885 - acc: 0.5402
3968/9333 [===========>..................] - ETA: 3:36 - loss: 0.6885 - acc: 0.5398
4032/9333 [===========>..................] - ETA: 3:35 - loss: 0.6882 - acc: 0.5404
4096/9333 [============>.................] - ETA: 3:32 - loss: 0.6876 - acc: 0.5408
4160/9333 [============>.................] - ETA: 3:29 - loss: 0.6878 - acc: 0.5399
4224/9333 [============>.................] - ETA: 3:26 - loss: 0.6878 - acc: 0.5391
4288/9333 [============>.................] - ETA: 3:24 - loss: 0.6878 - acc: 0.5387
4352/9333 [============>.................] - ETA: 3:21 - loss: 0.6881 - acc: 0.5377
4416/9333 [=============>................] - ETA: 3:18 - loss: 0.6885 - acc: 0.5365
4480/9333 [=============>................] - ETA: 3:16 - loss: 0.6883 - acc: 0.5379
4544/9333 [=============>................] - ETA: 3:14 - loss: 0.6880 - acc: 0.5392
4608/9333 [=============>................] - ETA: 3:12 - loss: 0.6883 - acc: 0.5384
4672/9333 [==============>...............] - ETA: 3:09 - loss: 0.6884 - acc: 0.5381
4736/9333 [==============>...............] - ETA: 3:07 - loss: 0.6887 - acc: 0.5380
4800/9333 [==============>...............] - ETA: 3:04 - loss: 0.6886 - acc: 0.5385
4864/9333 [==============>...............] - ETA: 3:01 - loss: 0.6889 - acc: 0.5376
4928/9333 [==============>...............] - ETA: 2:58 - loss: 0.6890 - acc: 0.5379
4992/9333 [===============>..............] - ETA: 2:56 - loss: 0.6886 - acc: 0.5399
5056/9333 [===============>..............] - ETA: 2:53 - loss: 0.6887 - acc: 0.5392
5120/9333 [===============>..............] - ETA: 2:51 - loss: 0.6890 - acc: 0.5383
5184/9333 [===============>..............] - ETA: 2:48 - loss: 0.6891 - acc: 0.5388
5248/9333 [===============>..............] - ETA: 2:46 - loss: 0.6891 - acc: 0.5389
5312/9333 [================>.............] - ETA: 2:43 - loss: 0.6891 - acc: 0.5386
5376/9333 [================>.............] - ETA: 2:40 - loss: 0.6892 - acc: 0.5391
5440/9333 [================>.............] - ETA: 2:38 - loss: 0.6892 - acc: 0.5388
5504/9333 [================>.............] - ETA: 2:35 - loss: 0.6889 - acc: 0.5392
5568/9333 [================>.............] - ETA: 2:32 - loss: 0.6888 - acc: 0.5392
5632/9333 [=================>............] - ETA: 2:30 - loss: 0.6887 - acc: 0.5394
5696/9333 [=================>............] - ETA: 2:28 - loss: 0.6885 - acc: 0.5397
5760/9333 [=================>............] - ETA: 2:25 - loss: 0.6888 - acc: 0.5378
5824/9333 [=================>............] - ETA: 2:22 - loss: 0.6887 - acc: 0.5379
5888/9333 [=================>............] - ETA: 2:20 - loss: 0.6887 - acc: 0.5389
5952/9333 [==================>...........] - ETA: 2:17 - loss: 0.6885 - acc: 0.5395
6016/9333 [==================>...........] - ETA: 2:14 - loss: 0.6884 - acc: 0.5409
6080/9333 [==================>...........] - ETA: 2:12 - loss: 0.6883 - acc: 0.5411
6144/9333 [==================>...........] - ETA: 2:09 - loss: 0.6882 - acc: 0.5417
6208/9333 [==================>...........] - ETA: 2:06 - loss: 0.6881 - acc: 0.5419
6272/9333 [===================>..........] - ETA: 2:04 - loss: 0.6880 - acc: 0.5419
6336/9333 [===================>..........] - ETA: 2:01 - loss: 0.6881 - acc: 0.5412
6400/9333 [===================>..........] - ETA: 1:59 - loss: 0.6882 - acc: 0.5414
6464/9333 [===================>..........] - ETA: 1:56 - loss: 0.6881 - acc: 0.5416
6528/9333 [===================>..........] - ETA: 1:53 - loss: 0.6881 - acc: 0.5423
6592/9333 [====================>.........] - ETA: 1:51 - loss: 0.6884 - acc: 0.5411
6656/9333 [====================>.........] - ETA: 1:48 - loss: 0.6884 - acc: 0.5409
6720/9333 [====================>.........] - ETA: 1:45 - loss: 0.6884 - acc: 0.5414
6784/9333 [====================>.........] - ETA: 1:43 - loss: 0.6882 - acc: 0.5423
6848/9333 [=====================>........] - ETA: 1:40 - loss: 0.6880 - acc: 0.5429
6912/9333 [=====================>........] - ETA: 1:37 - loss: 0.6878 - acc: 0.5433
6976/9333 [=====================>........] - ETA: 1:35 - loss: 0.6879 - acc: 0.5431
7040/9333 [=====================>........] - ETA: 1:32 - loss: 0.6881 - acc: 0.5426
7104/9333 [=====================>........] - ETA: 1:30 - loss: 0.6881 - acc: 0.5418
7168/9333 [======================>.......] - ETA: 1:27 - loss: 0.6882 - acc: 0.5419
7232/9333 [======================>.......] - ETA: 1:24 - loss: 0.6882 - acc: 0.5418
7296/9333 [======================>.......] - ETA: 1:22 - loss: 0.6882 - acc: 0.5417
7360/9333 [======================>.......] - ETA: 1:19 - loss: 0.6881 - acc: 0.5418
7424/9333 [======================>.......] - ETA: 1:17 - loss: 0.6879 - acc: 0.5423
7488/9333 [=======================>......] - ETA: 1:14 - loss: 0.6878 - acc: 0.5425
7552/9333 [=======================>......] - ETA: 1:11 - loss: 0.6879 - acc: 0.5424
7616/9333 [=======================>......] - ETA: 1:09 - loss: 0.6882 - acc: 0.5419
7680/9333 [=======================>......] - ETA: 1:06 - loss: 0.6879 - acc: 0.5432
7744/9333 [=======================>......] - ETA: 1:04 - loss: 0.6877 - acc: 0.5435
7808/9333 [========================>.....] - ETA: 1:01 - loss: 0.6878 - acc: 0.5433
7872/9333 [========================>.....] - ETA: 58s - loss: 0.6879 - acc: 0.5427 
7936/9333 [========================>.....] - ETA: 56s - loss: 0.6882 - acc: 0.5421
8000/9333 [========================>.....] - ETA: 53s - loss: 0.6880 - acc: 0.5423
8064/9333 [========================>.....] - ETA: 51s - loss: 0.6879 - acc: 0.5427
8128/9333 [=========================>....] - ETA: 48s - loss: 0.6881 - acc: 0.5422
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6883 - acc: 0.5414
8256/9333 [=========================>....] - ETA: 43s - loss: 0.6882 - acc: 0.5414
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6885 - acc: 0.5406
8384/9333 [=========================>....] - ETA: 38s - loss: 0.6888 - acc: 0.5397
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6888 - acc: 0.5395
8512/9333 [==========================>...] - ETA: 33s - loss: 0.6891 - acc: 0.5391
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6891 - acc: 0.5392
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6889 - acc: 0.5398
8704/9333 [==========================>...] - ETA: 25s - loss: 0.6890 - acc: 0.5398
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6890 - acc: 0.5397
8832/9333 [===========================>..] - ETA: 20s - loss: 0.6892 - acc: 0.5394
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6893 - acc: 0.5389
8960/9333 [===========================>..] - ETA: 15s - loss: 0.6893 - acc: 0.5391
9024/9333 [============================>.] - ETA: 12s - loss: 0.6892 - acc: 0.5397
9088/9333 [============================>.] - ETA: 9s - loss: 0.6892 - acc: 0.5395 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6892 - acc: 0.5399
9216/9333 [============================>.] - ETA: 4s - loss: 0.6891 - acc: 0.5406
9280/9333 [============================>.] - ETA: 2s - loss: 0.6892 - acc: 0.5399
9333/9333 [==============================] - 391s 42ms/step - loss: 0.6892 - acc: 0.5400 - val_loss: 0.6882 - val_acc: 0.5439

Epoch 00006: val_acc improved from 0.53905 to 0.54388, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window02/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 7/10

  64/9333 [..............................] - ETA: 5:22 - loss: 0.6971 - acc: 0.5156
 128/9333 [..............................] - ETA: 5:34 - loss: 0.6908 - acc: 0.5312
 192/9333 [..............................] - ETA: 5:40 - loss: 0.6878 - acc: 0.5417
 256/9333 [..............................] - ETA: 5:55 - loss: 0.6874 - acc: 0.5469
 320/9333 [>.............................] - ETA: 5:50 - loss: 0.6861 - acc: 0.5437
 384/9333 [>.............................] - ETA: 6:13 - loss: 0.6873 - acc: 0.5443
 448/9333 [>.............................] - ETA: 6:11 - loss: 0.6897 - acc: 0.5335
 512/9333 [>.............................] - ETA: 6:04 - loss: 0.6905 - acc: 0.5254
 576/9333 [>.............................] - ETA: 6:02 - loss: 0.6937 - acc: 0.5174
 640/9333 [=>............................] - ETA: 6:01 - loss: 0.6902 - acc: 0.5281
 704/9333 [=>............................] - ETA: 5:56 - loss: 0.6897 - acc: 0.5270
 768/9333 [=>............................] - ETA: 5:56 - loss: 0.6911 - acc: 0.5195
 832/9333 [=>............................] - ETA: 5:50 - loss: 0.6899 - acc: 0.5204
 896/9333 [=>............................] - ETA: 5:44 - loss: 0.6891 - acc: 0.5246
 960/9333 [==>...........................] - ETA: 5:46 - loss: 0.6885 - acc: 0.5281
1024/9333 [==>...........................] - ETA: 5:45 - loss: 0.6897 - acc: 0.5234
1088/9333 [==>...........................] - ETA: 5:42 - loss: 0.6888 - acc: 0.5294
1152/9333 [==>...........................] - ETA: 5:40 - loss: 0.6890 - acc: 0.5321
1216/9333 [==>...........................] - ETA: 5:36 - loss: 0.6887 - acc: 0.5345
1280/9333 [===>..........................] - ETA: 5:30 - loss: 0.6888 - acc: 0.5344
1344/9333 [===>..........................] - ETA: 5:27 - loss: 0.6893 - acc: 0.5335
1408/9333 [===>..........................] - ETA: 5:26 - loss: 0.6891 - acc: 0.5362
1472/9333 [===>..........................] - ETA: 5:25 - loss: 0.6882 - acc: 0.5387
1536/9333 [===>..........................] - ETA: 5:22 - loss: 0.6881 - acc: 0.5378
1600/9333 [====>.........................] - ETA: 5:20 - loss: 0.6880 - acc: 0.5375
1664/9333 [====>.........................] - ETA: 5:16 - loss: 0.6879 - acc: 0.5397
1728/9333 [====>.........................] - ETA: 5:12 - loss: 0.6878 - acc: 0.5417
1792/9333 [====>.........................] - ETA: 5:10 - loss: 0.6876 - acc: 0.5402
1856/9333 [====>.........................] - ETA: 5:07 - loss: 0.6875 - acc: 0.5415
1920/9333 [=====>........................] - ETA: 5:07 - loss: 0.6873 - acc: 0.5401
1984/9333 [=====>........................] - ETA: 5:05 - loss: 0.6877 - acc: 0.5383
2048/9333 [=====>........................] - ETA: 5:01 - loss: 0.6871 - acc: 0.5405
2112/9333 [=====>........................] - ETA: 4:58 - loss: 0.6880 - acc: 0.5369
2176/9333 [=====>........................] - ETA: 4:55 - loss: 0.6879 - acc: 0.5381
2240/9333 [======>.......................] - ETA: 4:51 - loss: 0.6873 - acc: 0.5415
2304/9333 [======>.......................] - ETA: 4:48 - loss: 0.6875 - acc: 0.5399
2368/9333 [======>.......................] - ETA: 4:45 - loss: 0.6874 - acc: 0.5401
2432/9333 [======>.......................] - ETA: 4:44 - loss: 0.6882 - acc: 0.5382
2496/9333 [=======>......................] - ETA: 4:44 - loss: 0.6884 - acc: 0.5373
2560/9333 [=======>......................] - ETA: 4:41 - loss: 0.6880 - acc: 0.5387
2624/9333 [=======>......................] - ETA: 4:38 - loss: 0.6879 - acc: 0.5385
2688/9333 [=======>......................] - ETA: 4:35 - loss: 0.6884 - acc: 0.5368
2752/9333 [=======>......................] - ETA: 4:32 - loss: 0.6876 - acc: 0.5389
2816/9333 [========>.....................] - ETA: 4:29 - loss: 0.6878 - acc: 0.5394
2880/9333 [========>.....................] - ETA: 4:25 - loss: 0.6876 - acc: 0.5396
2944/9333 [========>.....................] - ETA: 4:22 - loss: 0.6876 - acc: 0.5391
3008/9333 [========>.....................] - ETA: 4:19 - loss: 0.6876 - acc: 0.5409
3072/9333 [========>.....................] - ETA: 4:17 - loss: 0.6878 - acc: 0.5410
3136/9333 [=========>....................] - ETA: 4:15 - loss: 0.6878 - acc: 0.5415
3200/9333 [=========>....................] - ETA: 4:12 - loss: 0.6882 - acc: 0.5406
3264/9333 [=========>....................] - ETA: 4:10 - loss: 0.6880 - acc: 0.5420
3328/9333 [=========>....................] - ETA: 4:07 - loss: 0.6880 - acc: 0.5421
3392/9333 [=========>....................] - ETA: 4:04 - loss: 0.6884 - acc: 0.5416
3456/9333 [==========>...................] - ETA: 4:00 - loss: 0.6886 - acc: 0.5408
3520/9333 [==========>...................] - ETA: 3:57 - loss: 0.6884 - acc: 0.5412
3584/9333 [==========>...................] - ETA: 3:54 - loss: 0.6882 - acc: 0.5407
3648/9333 [==========>...................] - ETA: 3:52 - loss: 0.6878 - acc: 0.5419
3712/9333 [==========>...................] - ETA: 3:50 - loss: 0.6880 - acc: 0.5420
3776/9333 [===========>..................] - ETA: 3:48 - loss: 0.6884 - acc: 0.5410
3840/9333 [===========>..................] - ETA: 3:45 - loss: 0.6884 - acc: 0.5417
3904/9333 [===========>..................] - ETA: 3:42 - loss: 0.6882 - acc: 0.5412
3968/9333 [===========>..................] - ETA: 3:39 - loss: 0.6882 - acc: 0.5411
4032/9333 [===========>..................] - ETA: 3:36 - loss: 0.6882 - acc: 0.5419
4096/9333 [============>.................] - ETA: 3:34 - loss: 0.6882 - acc: 0.5415
4160/9333 [============>.................] - ETA: 3:32 - loss: 0.6878 - acc: 0.5418
4224/9333 [============>.................] - ETA: 3:29 - loss: 0.6877 - acc: 0.5431
4288/9333 [============>.................] - ETA: 3:27 - loss: 0.6879 - acc: 0.5441
4352/9333 [============>.................] - ETA: 3:24 - loss: 0.6880 - acc: 0.5441
4416/9333 [=============>................] - ETA: 3:21 - loss: 0.6881 - acc: 0.5439
4480/9333 [=============>................] - ETA: 3:18 - loss: 0.6886 - acc: 0.5426
4544/9333 [=============>................] - ETA: 3:15 - loss: 0.6886 - acc: 0.5423
4608/9333 [=============>................] - ETA: 3:13 - loss: 0.6889 - acc: 0.5406
4672/9333 [==============>...............] - ETA: 3:10 - loss: 0.6891 - acc: 0.5398
4736/9333 [==============>...............] - ETA: 3:08 - loss: 0.6892 - acc: 0.5397
4800/9333 [==============>...............] - ETA: 3:05 - loss: 0.6892 - acc: 0.5396
4864/9333 [==============>...............] - ETA: 3:03 - loss: 0.6895 - acc: 0.5389
4928/9333 [==============>...............] - ETA: 3:00 - loss: 0.6895 - acc: 0.5384
4992/9333 [===============>..............] - ETA: 2:57 - loss: 0.6894 - acc: 0.5383
5056/9333 [===============>..............] - ETA: 2:54 - loss: 0.6893 - acc: 0.5382
5120/9333 [===============>..............] - ETA: 2:51 - loss: 0.6896 - acc: 0.5375
5184/9333 [===============>..............] - ETA: 2:49 - loss: 0.6897 - acc: 0.5367
5248/9333 [===============>..............] - ETA: 2:46 - loss: 0.6900 - acc: 0.5364
5312/9333 [================>.............] - ETA: 2:44 - loss: 0.6900 - acc: 0.5365
5376/9333 [================>.............] - ETA: 2:41 - loss: 0.6902 - acc: 0.5365
5440/9333 [================>.............] - ETA: 2:38 - loss: 0.6903 - acc: 0.5364
5504/9333 [================>.............] - ETA: 2:36 - loss: 0.6904 - acc: 0.5369
5568/9333 [================>.............] - ETA: 2:33 - loss: 0.6904 - acc: 0.5368
5632/9333 [=================>............] - ETA: 2:30 - loss: 0.6901 - acc: 0.5384
5696/9333 [=================>............] - ETA: 2:28 - loss: 0.6899 - acc: 0.5377
5760/9333 [=================>............] - ETA: 2:25 - loss: 0.6901 - acc: 0.5372
5824/9333 [=================>............] - ETA: 2:23 - loss: 0.6903 - acc: 0.5369
5888/9333 [=================>............] - ETA: 2:20 - loss: 0.6902 - acc: 0.5379
5952/9333 [==================>...........] - ETA: 2:17 - loss: 0.6903 - acc: 0.5381
6016/9333 [==================>...........] - ETA: 2:14 - loss: 0.6904 - acc: 0.5382
6080/9333 [==================>...........] - ETA: 2:12 - loss: 0.6905 - acc: 0.5378
6144/9333 [==================>...........] - ETA: 2:09 - loss: 0.6906 - acc: 0.5378
6208/9333 [==================>...........] - ETA: 2:07 - loss: 0.6906 - acc: 0.5377
6272/9333 [===================>..........] - ETA: 2:04 - loss: 0.6906 - acc: 0.5375
6336/9333 [===================>..........] - ETA: 2:02 - loss: 0.6906 - acc: 0.5377
6400/9333 [===================>..........] - ETA: 1:59 - loss: 0.6907 - acc: 0.5372
6464/9333 [===================>..........] - ETA: 1:56 - loss: 0.6906 - acc: 0.5374
6528/9333 [===================>..........] - ETA: 1:54 - loss: 0.6905 - acc: 0.5375
6592/9333 [====================>.........] - ETA: 1:51 - loss: 0.6907 - acc: 0.5369
6656/9333 [====================>.........] - ETA: 1:48 - loss: 0.6907 - acc: 0.5374
6720/9333 [====================>.........] - ETA: 1:46 - loss: 0.6904 - acc: 0.5385
6784/9333 [====================>.........] - ETA: 1:43 - loss: 0.6903 - acc: 0.5388
6848/9333 [=====================>........] - ETA: 1:40 - loss: 0.6902 - acc: 0.5399
6912/9333 [=====================>........] - ETA: 1:38 - loss: 0.6902 - acc: 0.5399
6976/9333 [=====================>........] - ETA: 1:35 - loss: 0.6900 - acc: 0.5407
7040/9333 [=====================>........] - ETA: 1:33 - loss: 0.6901 - acc: 0.5409
7104/9333 [=====================>........] - ETA: 1:30 - loss: 0.6901 - acc: 0.5405
7168/9333 [======================>.......] - ETA: 1:27 - loss: 0.6902 - acc: 0.5402
7232/9333 [======================>.......] - ETA: 1:25 - loss: 0.6903 - acc: 0.5394
7296/9333 [======================>.......] - ETA: 1:22 - loss: 0.6902 - acc: 0.5399
7360/9333 [======================>.......] - ETA: 1:19 - loss: 0.6902 - acc: 0.5402
7424/9333 [======================>.......] - ETA: 1:17 - loss: 0.6900 - acc: 0.5415
7488/9333 [=======================>......] - ETA: 1:15 - loss: 0.6898 - acc: 0.5423
7552/9333 [=======================>......] - ETA: 1:12 - loss: 0.6900 - acc: 0.5417
7616/9333 [=======================>......] - ETA: 1:09 - loss: 0.6901 - acc: 0.5408
7680/9333 [=======================>......] - ETA: 1:07 - loss: 0.6902 - acc: 0.5404
7744/9333 [=======================>......] - ETA: 1:04 - loss: 0.6899 - acc: 0.5408
7808/9333 [========================>.....] - ETA: 1:01 - loss: 0.6898 - acc: 0.5415
7872/9333 [========================>.....] - ETA: 59s - loss: 0.6898 - acc: 0.5414 
7936/9333 [========================>.....] - ETA: 56s - loss: 0.6900 - acc: 0.5411
8000/9333 [========================>.....] - ETA: 54s - loss: 0.6900 - acc: 0.5409
8064/9333 [========================>.....] - ETA: 51s - loss: 0.6899 - acc: 0.5413
8128/9333 [=========================>....] - ETA: 48s - loss: 0.6900 - acc: 0.5411
8192/9333 [=========================>....] - ETA: 46s - loss: 0.6899 - acc: 0.5415
8256/9333 [=========================>....] - ETA: 43s - loss: 0.6899 - acc: 0.5411
8320/9333 [=========================>....] - ETA: 41s - loss: 0.6896 - acc: 0.5419
8384/9333 [=========================>....] - ETA: 38s - loss: 0.6898 - acc: 0.5413
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6899 - acc: 0.5411
8512/9333 [==========================>...] - ETA: 33s - loss: 0.6895 - acc: 0.5422
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6895 - acc: 0.5421
8640/9333 [==========================>...] - ETA: 28s - loss: 0.6893 - acc: 0.5427
8704/9333 [==========================>...] - ETA: 25s - loss: 0.6891 - acc: 0.5435
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6891 - acc: 0.5437
8832/9333 [===========================>..] - ETA: 20s - loss: 0.6891 - acc: 0.5435
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6891 - acc: 0.5437
8960/9333 [===========================>..] - ETA: 15s - loss: 0.6891 - acc: 0.5435
9024/9333 [============================>.] - ETA: 12s - loss: 0.6892 - acc: 0.5433
9088/9333 [============================>.] - ETA: 9s - loss: 0.6891 - acc: 0.5439 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6890 - acc: 0.5441
9216/9333 [============================>.] - ETA: 4s - loss: 0.6891 - acc: 0.5438
9280/9333 [============================>.] - ETA: 2s - loss: 0.6891 - acc: 0.5439
9333/9333 [==============================] - 393s 42ms/step - loss: 0.6892 - acc: 0.5436 - val_loss: 0.6903 - val_acc: 0.5121

Epoch 00007: val_acc did not improve from 0.54388
Epoch 8/10

  64/9333 [..............................] - ETA: 5:28 - loss: 0.6805 - acc: 0.5781
 128/9333 [..............................] - ETA: 6:05 - loss: 0.6721 - acc: 0.5625
 192/9333 [..............................] - ETA: 6:15 - loss: 0.6825 - acc: 0.5521
 256/9333 [..............................] - ETA: 6:02 - loss: 0.6838 - acc: 0.5547
 320/9333 [>.............................] - ETA: 6:03 - loss: 0.6799 - acc: 0.5656
 384/9333 [>.............................] - ETA: 5:57 - loss: 0.6780 - acc: 0.5703
 448/9333 [>.............................] - ETA: 5:54 - loss: 0.6803 - acc: 0.5558
 512/9333 [>.............................] - ETA: 5:53 - loss: 0.6853 - acc: 0.5488
 576/9333 [>.............................] - ETA: 5:51 - loss: 0.6876 - acc: 0.5347
 640/9333 [=>............................] - ETA: 5:47 - loss: 0.6879 - acc: 0.5328
 704/9333 [=>............................] - ETA: 5:49 - loss: 0.6892 - acc: 0.5312
 768/9333 [=>............................] - ETA: 5:53 - loss: 0.6879 - acc: 0.5417
 832/9333 [=>............................] - ETA: 5:47 - loss: 0.6868 - acc: 0.5469
 896/9333 [=>............................] - ETA: 5:45 - loss: 0.6873 - acc: 0.5480
 960/9333 [==>...........................] - ETA: 5:40 - loss: 0.6877 - acc: 0.5510
1024/9333 [==>...........................] - ETA: 5:37 - loss: 0.6869 - acc: 0.5508
1088/9333 [==>...........................] - ETA: 5:32 - loss: 0.6865 - acc: 0.5515
1152/9333 [==>...........................] - ETA: 5:29 - loss: 0.6857 - acc: 0.5564
1216/9333 [==>...........................] - ETA: 5:26 - loss: 0.6844 - acc: 0.5625
1280/9333 [===>..........................] - ETA: 5:30 - loss: 0.6842 - acc: 0.5648
1344/9333 [===>..........................] - ETA: 5:30 - loss: 0.6844 - acc: 0.5632
1408/9333 [===>..........................] - ETA: 5:29 - loss: 0.6850 - acc: 0.5604
1472/9333 [===>..........................] - ETA: 5:25 - loss: 0.6847 - acc: 0.5625
1536/9333 [===>..........................] - ETA: 5:21 - loss: 0.6847 - acc: 0.5625
1600/9333 [====>.........................] - ETA: 5:18 - loss: 0.6845 - acc: 0.5644
1664/9333 [====>.........................] - ETA: 5:15 - loss: 0.6856 - acc: 0.5595
1728/9333 [====>.........................] - ETA: 5:11 - loss: 0.6856 - acc: 0.5584
1792/9333 [====>.........................] - ETA: 5:09 - loss: 0.6857 - acc: 0.5592
1856/9333 [====>.........................] - ETA: 5:08 - loss: 0.6862 - acc: 0.5550
1920/9333 [=====>........................] - ETA: 5:05 - loss: 0.6862 - acc: 0.5552
1984/9333 [=====>........................] - ETA: 5:02 - loss: 0.6855 - acc: 0.5580
2048/9333 [=====>........................] - ETA: 4:59 - loss: 0.6856 - acc: 0.5571
2112/9333 [=====>........................] - ETA: 4:56 - loss: 0.6850 - acc: 0.5582
2176/9333 [=====>........................] - ETA: 4:53 - loss: 0.6853 - acc: 0.5556
2240/9333 [======>.......................] - ETA: 4:49 - loss: 0.6856 - acc: 0.5536
2304/9333 [======>.......................] - ETA: 4:46 - loss: 0.6861 - acc: 0.5512
2368/9333 [======>.......................] - ETA: 4:42 - loss: 0.6863 - acc: 0.5515
2432/9333 [======>.......................] - ETA: 4:40 - loss: 0.6863 - acc: 0.5514
2496/9333 [=======>......................] - ETA: 4:38 - loss: 0.6866 - acc: 0.5513
2560/9333 [=======>......................] - ETA: 4:36 - loss: 0.6867 - acc: 0.5508
2624/9333 [=======>......................] - ETA: 4:33 - loss: 0.6875 - acc: 0.5495
2688/9333 [=======>......................] - ETA: 4:30 - loss: 0.6875 - acc: 0.5499
2752/9333 [=======>......................] - ETA: 4:27 - loss: 0.6874 - acc: 0.5491
2816/9333 [========>.....................] - ETA: 4:23 - loss: 0.6874 - acc: 0.5490
2880/9333 [========>.....................] - ETA: 4:21 - loss: 0.6880 - acc: 0.5476
2944/9333 [========>.....................] - ETA: 4:18 - loss: 0.6880 - acc: 0.5472
3008/9333 [========>.....................] - ETA: 4:16 - loss: 0.6882 - acc: 0.5465
3072/9333 [========>.....................] - ETA: 4:14 - loss: 0.6877 - acc: 0.5475
3136/9333 [=========>....................] - ETA: 4:11 - loss: 0.6875 - acc: 0.5497
3200/9333 [=========>....................] - ETA: 4:08 - loss: 0.6881 - acc: 0.5484
3264/9333 [=========>....................] - ETA: 4:05 - loss: 0.6883 - acc: 0.5478
3328/9333 [=========>....................] - ETA: 4:02 - loss: 0.6885 - acc: 0.5469
3392/9333 [=========>....................] - ETA: 3:59 - loss: 0.6888 - acc: 0.5454
3456/9333 [==========>...................] - ETA: 3:56 - loss: 0.6889 - acc: 0.5457
3520/9333 [==========>...................] - ETA: 3:53 - loss: 0.6891 - acc: 0.5446
3584/9333 [==========>...................] - ETA: 3:51 - loss: 0.6889 - acc: 0.5449
3648/9333 [==========>...................] - ETA: 3:49 - loss: 0.6887 - acc: 0.5463
3712/9333 [==========>...................] - ETA: 3:46 - loss: 0.6882 - acc: 0.5488
3776/9333 [===========>..................] - ETA: 3:43 - loss: 0.6883 - acc: 0.5490
3840/9333 [===========>..................] - ETA: 3:41 - loss: 0.6880 - acc: 0.5487
3904/9333 [===========>..................] - ETA: 3:38 - loss: 0.6875 - acc: 0.5497
3968/9333 [===========>..................] - ETA: 3:36 - loss: 0.6873 - acc: 0.5507
4032/9333 [===========>..................] - ETA: 3:33 - loss: 0.6871 - acc: 0.5503
4096/9333 [============>.................] - ETA: 3:31 - loss: 0.6873 - acc: 0.5500
4160/9333 [============>.................] - ETA: 3:29 - loss: 0.6876 - acc: 0.5495
4224/9333 [============>.................] - ETA: 3:26 - loss: 0.6872 - acc: 0.5500
4288/9333 [============>.................] - ETA: 3:24 - loss: 0.6870 - acc: 0.5511
4352/9333 [============>.................] - ETA: 3:21 - loss: 0.6868 - acc: 0.5512
4416/9333 [=============>................] - ETA: 3:18 - loss: 0.6869 - acc: 0.5512
4480/9333 [=============>................] - ETA: 3:15 - loss: 0.6869 - acc: 0.5525
4544/9333 [=============>................] - ETA: 3:13 - loss: 0.6872 - acc: 0.5519
4608/9333 [=============>................] - ETA: 3:11 - loss: 0.6870 - acc: 0.5525
4672/9333 [==============>...............] - ETA: 3:08 - loss: 0.6872 - acc: 0.5514
4736/9333 [==============>...............] - ETA: 3:05 - loss: 0.6866 - acc: 0.5526
4800/9333 [==============>...............] - ETA: 3:03 - loss: 0.6863 - acc: 0.5535
4864/9333 [==============>...............] - ETA: 3:01 - loss: 0.6863 - acc: 0.5532
4928/9333 [==============>...............] - ETA: 2:58 - loss: 0.6866 - acc: 0.5526
4992/9333 [===============>..............] - ETA: 2:56 - loss: 0.6867 - acc: 0.5525
5056/9333 [===============>..............] - ETA: 2:53 - loss: 0.6869 - acc: 0.5522
5120/9333 [===============>..............] - ETA: 2:50 - loss: 0.6869 - acc: 0.5525
5184/9333 [===============>..............] - ETA: 2:47 - loss: 0.6863 - acc: 0.5544
5248/9333 [===============>..............] - ETA: 2:45 - loss: 0.6867 - acc: 0.5534
5312/9333 [================>.............] - ETA: 2:42 - loss: 0.6869 - acc: 0.5523
5376/9333 [================>.............] - ETA: 2:40 - loss: 0.6868 - acc: 0.5528
5440/9333 [================>.............] - ETA: 2:37 - loss: 0.6869 - acc: 0.5529
5504/9333 [================>.............] - ETA: 2:35 - loss: 0.6868 - acc: 0.5534
5568/9333 [================>.............] - ETA: 2:32 - loss: 0.6868 - acc: 0.5532
5632/9333 [=================>............] - ETA: 2:29 - loss: 0.6867 - acc: 0.5533
5696/9333 [=================>............] - ETA: 2:27 - loss: 0.6869 - acc: 0.5534
5760/9333 [=================>............] - ETA: 2:24 - loss: 0.6866 - acc: 0.5542
5824/9333 [=================>............] - ETA: 2:22 - loss: 0.6866 - acc: 0.5541
5888/9333 [=================>............] - ETA: 2:19 - loss: 0.6865 - acc: 0.5552
5952/9333 [==================>...........] - ETA: 2:17 - loss: 0.6867 - acc: 0.5544
6016/9333 [==================>...........] - ETA: 2:14 - loss: 0.6870 - acc: 0.5534
6080/9333 [==================>...........] - ETA: 2:11 - loss: 0.6872 - acc: 0.5525
6144/9333 [==================>...........] - ETA: 2:09 - loss: 0.6870 - acc: 0.5527
6208/9333 [==================>...........] - ETA: 2:06 - loss: 0.6867 - acc: 0.5540
6272/9333 [===================>..........] - ETA: 2:04 - loss: 0.6870 - acc: 0.5536
6336/9333 [===================>..........] - ETA: 2:01 - loss: 0.6872 - acc: 0.5530
6400/9333 [===================>..........] - ETA: 1:58 - loss: 0.6873 - acc: 0.5523
6464/9333 [===================>..........] - ETA: 1:56 - loss: 0.6873 - acc: 0.5520
6528/9333 [===================>..........] - ETA: 1:53 - loss: 0.6875 - acc: 0.5513
6592/9333 [====================>.........] - ETA: 1:50 - loss: 0.6875 - acc: 0.5517
6656/9333 [====================>.........] - ETA: 1:48 - loss: 0.6874 - acc: 0.5521
6720/9333 [====================>.........] - ETA: 1:45 - loss: 0.6875 - acc: 0.5516
6784/9333 [====================>.........] - ETA: 1:43 - loss: 0.6875 - acc: 0.5517
6848/9333 [=====================>........] - ETA: 1:40 - loss: 0.6874 - acc: 0.5521
6912/9333 [=====================>........] - ETA: 1:37 - loss: 0.6874 - acc: 0.5522
6976/9333 [=====================>........] - ETA: 1:34 - loss: 0.6875 - acc: 0.5522
7040/9333 [=====================>........] - ETA: 1:32 - loss: 0.6875 - acc: 0.5524
7104/9333 [=====================>........] - ETA: 1:29 - loss: 0.6873 - acc: 0.5531
7168/9333 [======================>.......] - ETA: 1:26 - loss: 0.6874 - acc: 0.5529
7232/9333 [======================>.......] - ETA: 1:24 - loss: 0.6873 - acc: 0.5538
7296/9333 [======================>.......] - ETA: 1:22 - loss: 0.6871 - acc: 0.5550
7360/9333 [======================>.......] - ETA: 1:19 - loss: 0.6869 - acc: 0.5554
7424/9333 [======================>.......] - ETA: 1:16 - loss: 0.6866 - acc: 0.5560
7488/9333 [=======================>......] - ETA: 1:14 - loss: 0.6869 - acc: 0.5553
7552/9333 [=======================>......] - ETA: 1:11 - loss: 0.6869 - acc: 0.5552
7616/9333 [=======================>......] - ETA: 1:09 - loss: 0.6869 - acc: 0.5551
7680/9333 [=======================>......] - ETA: 1:06 - loss: 0.6869 - acc: 0.5547
7744/9333 [=======================>......] - ETA: 1:04 - loss: 0.6872 - acc: 0.5544
7808/9333 [========================>.....] - ETA: 1:01 - loss: 0.6871 - acc: 0.5548
7872/9333 [========================>.....] - ETA: 58s - loss: 0.6873 - acc: 0.5541 
7936/9333 [========================>.....] - ETA: 56s - loss: 0.6871 - acc: 0.5546
8000/9333 [========================>.....] - ETA: 53s - loss: 0.6873 - acc: 0.5540
8064/9333 [========================>.....] - ETA: 51s - loss: 0.6874 - acc: 0.5542
8128/9333 [=========================>....] - ETA: 48s - loss: 0.6875 - acc: 0.5546
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6875 - acc: 0.5544
8256/9333 [=========================>....] - ETA: 43s - loss: 0.6878 - acc: 0.5537
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6877 - acc: 0.5537
8384/9333 [=========================>....] - ETA: 38s - loss: 0.6878 - acc: 0.5528
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6878 - acc: 0.5528
8512/9333 [==========================>...] - ETA: 33s - loss: 0.6879 - acc: 0.5524
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6879 - acc: 0.5531
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6882 - acc: 0.5519
8704/9333 [==========================>...] - ETA: 25s - loss: 0.6882 - acc: 0.5518
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6884 - acc: 0.5512
8832/9333 [===========================>..] - ETA: 20s - loss: 0.6884 - acc: 0.5516
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6884 - acc: 0.5519
8960/9333 [===========================>..] - ETA: 15s - loss: 0.6884 - acc: 0.5517
9024/9333 [============================>.] - ETA: 12s - loss: 0.6884 - acc: 0.5518
9088/9333 [============================>.] - ETA: 9s - loss: 0.6884 - acc: 0.5517 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6884 - acc: 0.5514
9216/9333 [============================>.] - ETA: 4s - loss: 0.6885 - acc: 0.5507
9280/9333 [============================>.] - ETA: 2s - loss: 0.6886 - acc: 0.5503
9333/9333 [==============================] - 392s 42ms/step - loss: 0.6886 - acc: 0.5506 - val_loss: 0.6938 - val_acc: 0.5265

Epoch 00008: val_acc did not improve from 0.54388
Epoch 9/10

  64/9333 [..............................] - ETA: 5:59 - loss: 0.7000 - acc: 0.5000
 128/9333 [..............................] - ETA: 5:44 - loss: 0.6845 - acc: 0.5547
 192/9333 [..............................] - ETA: 5:56 - loss: 0.6844 - acc: 0.5365
 256/9333 [..............................] - ETA: 6:05 - loss: 0.6892 - acc: 0.5273
 320/9333 [>.............................] - ETA: 6:07 - loss: 0.6867 - acc: 0.5500
 384/9333 [>.............................] - ETA: 6:07 - loss: 0.6895 - acc: 0.5469
 448/9333 [>.............................] - ETA: 6:10 - loss: 0.6867 - acc: 0.5469
 512/9333 [>.............................] - ETA: 6:05 - loss: 0.6862 - acc: 0.5449
 576/9333 [>.............................] - ETA: 5:58 - loss: 0.6877 - acc: 0.5382
 640/9333 [=>............................] - ETA: 5:55 - loss: 0.6880 - acc: 0.5391
 704/9333 [=>............................] - ETA: 5:48 - loss: 0.6855 - acc: 0.5582
 768/9333 [=>............................] - ETA: 5:47 - loss: 0.6877 - acc: 0.5482
 832/9333 [=>............................] - ETA: 5:43 - loss: 0.6879 - acc: 0.5481
 896/9333 [=>............................] - ETA: 5:43 - loss: 0.6896 - acc: 0.5413
 960/9333 [==>...........................] - ETA: 5:41 - loss: 0.6906 - acc: 0.5354
1024/9333 [==>...........................] - ETA: 5:35 - loss: 0.6900 - acc: 0.5400
1088/9333 [==>...........................] - ETA: 5:30 - loss: 0.6897 - acc: 0.5377
1152/9333 [==>...........................] - ETA: 5:28 - loss: 0.6894 - acc: 0.5356
1216/9333 [==>...........................] - ETA: 5:25 - loss: 0.6899 - acc: 0.5312
1280/9333 [===>..........................] - ETA: 5:22 - loss: 0.6899 - acc: 0.5297
1344/9333 [===>..........................] - ETA: 5:20 - loss: 0.6894 - acc: 0.5312
1408/9333 [===>..........................] - ETA: 5:15 - loss: 0.6891 - acc: 0.5327
1472/9333 [===>..........................] - ETA: 5:11 - loss: 0.6888 - acc: 0.5326
1536/9333 [===>..........................] - ETA: 5:10 - loss: 0.6890 - acc: 0.5312
1600/9333 [====>.........................] - ETA: 5:09 - loss: 0.6894 - acc: 0.5312
1664/9333 [====>.........................] - ETA: 5:07 - loss: 0.6890 - acc: 0.5331
1728/9333 [====>.........................] - ETA: 5:04 - loss: 0.6886 - acc: 0.5353
1792/9333 [====>.........................] - ETA: 5:01 - loss: 0.6882 - acc: 0.5368
1856/9333 [====>.........................] - ETA: 4:59 - loss: 0.6883 - acc: 0.5372
1920/9333 [=====>........................] - ETA: 4:55 - loss: 0.6878 - acc: 0.5401
1984/9333 [=====>........................] - ETA: 4:51 - loss: 0.6879 - acc: 0.5398
2048/9333 [=====>........................] - ETA: 4:47 - loss: 0.6881 - acc: 0.5400
2112/9333 [=====>........................] - ETA: 4:47 - loss: 0.6888 - acc: 0.5365
2176/9333 [=====>........................] - ETA: 4:46 - loss: 0.6889 - acc: 0.5358
2240/9333 [======>.......................] - ETA: 4:43 - loss: 0.6884 - acc: 0.5397
2304/9333 [======>.......................] - ETA: 4:41 - loss: 0.6881 - acc: 0.5408
2368/9333 [======>.......................] - ETA: 4:38 - loss: 0.6882 - acc: 0.5405
2432/9333 [======>.......................] - ETA: 4:34 - loss: 0.6879 - acc: 0.5419
2496/9333 [=======>......................] - ETA: 4:31 - loss: 0.6874 - acc: 0.5457
2560/9333 [=======>......................] - ETA: 4:28 - loss: 0.6874 - acc: 0.5461
2624/9333 [=======>......................] - ETA: 4:26 - loss: 0.6877 - acc: 0.5438
2688/9333 [=======>......................] - ETA: 4:23 - loss: 0.6882 - acc: 0.5417
2752/9333 [=======>......................] - ETA: 4:22 - loss: 0.6885 - acc: 0.5396
2816/9333 [========>.....................] - ETA: 4:20 - loss: 0.6883 - acc: 0.5408
2880/9333 [========>.....................] - ETA: 4:17 - loss: 0.6878 - acc: 0.5431
2944/9333 [========>.....................] - ETA: 4:14 - loss: 0.6873 - acc: 0.5448
3008/9333 [========>.....................] - ETA: 4:11 - loss: 0.6876 - acc: 0.5436
3072/9333 [========>.....................] - ETA: 4:09 - loss: 0.6876 - acc: 0.5420
3136/9333 [=========>....................] - ETA: 4:06 - loss: 0.6880 - acc: 0.5405
3200/9333 [=========>....................] - ETA: 4:03 - loss: 0.6881 - acc: 0.5400
3264/9333 [=========>....................] - ETA: 4:00 - loss: 0.6886 - acc: 0.5386
3328/9333 [=========>....................] - ETA: 3:57 - loss: 0.6885 - acc: 0.5379
3392/9333 [=========>....................] - ETA: 3:55 - loss: 0.6885 - acc: 0.5380
3456/9333 [==========>...................] - ETA: 3:53 - loss: 0.6883 - acc: 0.5379
3520/9333 [==========>...................] - ETA: 3:50 - loss: 0.6885 - acc: 0.5375
3584/9333 [==========>...................] - ETA: 3:47 - loss: 0.6884 - acc: 0.5366
3648/9333 [==========>...................] - ETA: 3:45 - loss: 0.6883 - acc: 0.5373
3712/9333 [==========>...................] - ETA: 3:42 - loss: 0.6882 - acc: 0.5385
3776/9333 [===========>..................] - ETA: 3:40 - loss: 0.6879 - acc: 0.5400
3840/9333 [===========>..................] - ETA: 3:38 - loss: 0.6877 - acc: 0.5401
3904/9333 [===========>..................] - ETA: 3:36 - loss: 0.6877 - acc: 0.5402
3968/9333 [===========>..................] - ETA: 3:34 - loss: 0.6877 - acc: 0.5408
4032/9333 [===========>..................] - ETA: 3:32 - loss: 0.6874 - acc: 0.5409
4096/9333 [============>.................] - ETA: 3:29 - loss: 0.6872 - acc: 0.5410
4160/9333 [============>.................] - ETA: 3:27 - loss: 0.6874 - acc: 0.5413
4224/9333 [============>.................] - ETA: 3:24 - loss: 0.6875 - acc: 0.5410
4288/9333 [============>.................] - ETA: 3:21 - loss: 0.6871 - acc: 0.5420
4352/9333 [============>.................] - ETA: 3:18 - loss: 0.6867 - acc: 0.5434
4416/9333 [=============>................] - ETA: 3:16 - loss: 0.6870 - acc: 0.5428
4480/9333 [=============>................] - ETA: 3:13 - loss: 0.6868 - acc: 0.5433
4544/9333 [=============>................] - ETA: 3:11 - loss: 0.6870 - acc: 0.5427
4608/9333 [=============>................] - ETA: 3:09 - loss: 0.6871 - acc: 0.5430
4672/9333 [==============>...............] - ETA: 3:06 - loss: 0.6869 - acc: 0.5428
4736/9333 [==============>...............] - ETA: 3:04 - loss: 0.6867 - acc: 0.5439
4800/9333 [==============>...............] - ETA: 3:01 - loss: 0.6868 - acc: 0.5437
4864/9333 [==============>...............] - ETA: 2:58 - loss: 0.6867 - acc: 0.5442
4928/9333 [==============>...............] - ETA: 2:56 - loss: 0.6867 - acc: 0.5440
4992/9333 [===============>..............] - ETA: 2:53 - loss: 0.6866 - acc: 0.5447
5056/9333 [===============>..............] - ETA: 2:51 - loss: 0.6866 - acc: 0.5449
5120/9333 [===============>..............] - ETA: 2:48 - loss: 0.6868 - acc: 0.5439
5184/9333 [===============>..............] - ETA: 2:46 - loss: 0.6867 - acc: 0.5440
5248/9333 [===============>..............] - ETA: 2:44 - loss: 0.6865 - acc: 0.5440
5312/9333 [================>.............] - ETA: 2:41 - loss: 0.6867 - acc: 0.5441
5376/9333 [================>.............] - ETA: 2:39 - loss: 0.6868 - acc: 0.5432
5440/9333 [================>.............] - ETA: 2:36 - loss: 0.6869 - acc: 0.5432
5504/9333 [================>.............] - ETA: 2:34 - loss: 0.6869 - acc: 0.5436
5568/9333 [================>.............] - ETA: 2:31 - loss: 0.6871 - acc: 0.5431
5632/9333 [=================>............] - ETA: 2:29 - loss: 0.6870 - acc: 0.5437
5696/9333 [=================>............] - ETA: 2:26 - loss: 0.6872 - acc: 0.5425
5760/9333 [=================>............] - ETA: 2:24 - loss: 0.6872 - acc: 0.5429
5824/9333 [=================>............] - ETA: 2:21 - loss: 0.6872 - acc: 0.5428
5888/9333 [=================>............] - ETA: 2:18 - loss: 0.6873 - acc: 0.5433
5952/9333 [==================>...........] - ETA: 2:16 - loss: 0.6872 - acc: 0.5439
6016/9333 [==================>...........] - ETA: 2:13 - loss: 0.6873 - acc: 0.5442
6080/9333 [==================>...........] - ETA: 2:10 - loss: 0.6874 - acc: 0.5433
6144/9333 [==================>...........] - ETA: 2:08 - loss: 0.6872 - acc: 0.5436
6208/9333 [==================>...........] - ETA: 2:05 - loss: 0.6869 - acc: 0.5441
6272/9333 [===================>..........] - ETA: 2:03 - loss: 0.6869 - acc: 0.5446
6336/9333 [===================>..........] - ETA: 2:00 - loss: 0.6871 - acc: 0.5442
6400/9333 [===================>..........] - ETA: 1:58 - loss: 0.6868 - acc: 0.5453
6464/9333 [===================>..........] - ETA: 1:55 - loss: 0.6867 - acc: 0.5455
6528/9333 [===================>..........] - ETA: 1:52 - loss: 0.6867 - acc: 0.5460
6592/9333 [====================>.........] - ETA: 1:50 - loss: 0.6868 - acc: 0.5457
6656/9333 [====================>.........] - ETA: 1:47 - loss: 0.6867 - acc: 0.5466
6720/9333 [====================>.........] - ETA: 1:44 - loss: 0.6866 - acc: 0.5470
6784/9333 [====================>.........] - ETA: 1:42 - loss: 0.6867 - acc: 0.5467
6848/9333 [=====================>........] - ETA: 1:39 - loss: 0.6865 - acc: 0.5478
6912/9333 [=====================>........] - ETA: 1:36 - loss: 0.6868 - acc: 0.5472
6976/9333 [=====================>........] - ETA: 1:34 - loss: 0.6866 - acc: 0.5479
7040/9333 [=====================>........] - ETA: 1:31 - loss: 0.6865 - acc: 0.5484
7104/9333 [=====================>........] - ETA: 1:29 - loss: 0.6863 - acc: 0.5488
7168/9333 [======================>.......] - ETA: 1:26 - loss: 0.6861 - acc: 0.5497
7232/9333 [======================>.......] - ETA: 1:24 - loss: 0.6858 - acc: 0.5509
7296/9333 [======================>.......] - ETA: 1:21 - loss: 0.6859 - acc: 0.5511
7360/9333 [======================>.......] - ETA: 1:18 - loss: 0.6861 - acc: 0.5501
7424/9333 [======================>.......] - ETA: 1:16 - loss: 0.6860 - acc: 0.5505
7488/9333 [=======================>......] - ETA: 1:13 - loss: 0.6860 - acc: 0.5503
7552/9333 [=======================>......] - ETA: 1:11 - loss: 0.6860 - acc: 0.5502
7616/9333 [=======================>......] - ETA: 1:08 - loss: 0.6861 - acc: 0.5500
7680/9333 [=======================>......] - ETA: 1:06 - loss: 0.6863 - acc: 0.5500
7744/9333 [=======================>......] - ETA: 1:03 - loss: 0.6864 - acc: 0.5501
7808/9333 [========================>.....] - ETA: 1:00 - loss: 0.6868 - acc: 0.5491
7872/9333 [========================>.....] - ETA: 58s - loss: 0.6867 - acc: 0.5485 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6868 - acc: 0.5484
8000/9333 [========================>.....] - ETA: 53s - loss: 0.6865 - acc: 0.5487
8064/9333 [========================>.....] - ETA: 50s - loss: 0.6865 - acc: 0.5486
8128/9333 [=========================>....] - ETA: 48s - loss: 0.6868 - acc: 0.5484
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6870 - acc: 0.5480
8256/9333 [=========================>....] - ETA: 43s - loss: 0.6869 - acc: 0.5483
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6869 - acc: 0.5487
8384/9333 [=========================>....] - ETA: 37s - loss: 0.6870 - acc: 0.5483
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6871 - acc: 0.5479
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6870 - acc: 0.5482
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6869 - acc: 0.5491
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6868 - acc: 0.5494
8704/9333 [==========================>...] - ETA: 25s - loss: 0.6864 - acc: 0.5503
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6866 - acc: 0.5500
8832/9333 [===========================>..] - ETA: 20s - loss: 0.6866 - acc: 0.5502
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6866 - acc: 0.5497
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6864 - acc: 0.5504
9024/9333 [============================>.] - ETA: 12s - loss: 0.6864 - acc: 0.5504
9088/9333 [============================>.] - ETA: 9s - loss: 0.6864 - acc: 0.5502 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6866 - acc: 0.5503
9216/9333 [============================>.] - ETA: 4s - loss: 0.6866 - acc: 0.5498
9280/9333 [============================>.] - ETA: 2s - loss: 0.6866 - acc: 0.5499
9333/9333 [==============================] - 389s 42ms/step - loss: 0.6868 - acc: 0.5492 - val_loss: 0.6906 - val_acc: 0.5159

Epoch 00009: val_acc did not improve from 0.54388
Epoch 10/10

  64/9333 [..............................] - ETA: 5:47 - loss: 0.6926 - acc: 0.5312
 128/9333 [..............................] - ETA: 6:17 - loss: 0.6869 - acc: 0.5391
 192/9333 [..............................] - ETA: 6:25 - loss: 0.6786 - acc: 0.5625
 256/9333 [..............................] - ETA: 6:18 - loss: 0.6795 - acc: 0.5703
 320/9333 [>.............................] - ETA: 6:07 - loss: 0.6797 - acc: 0.5719
 384/9333 [>.............................] - ETA: 5:55 - loss: 0.6836 - acc: 0.5651
 448/9333 [>.............................] - ETA: 5:54 - loss: 0.6872 - acc: 0.5580
 512/9333 [>.............................] - ETA: 5:49 - loss: 0.6892 - acc: 0.5508
 576/9333 [>.............................] - ETA: 5:47 - loss: 0.6875 - acc: 0.5573
 640/9333 [=>............................] - ETA: 5:52 - loss: 0.6874 - acc: 0.5563
 704/9333 [=>............................] - ETA: 5:51 - loss: 0.6854 - acc: 0.5597
 768/9333 [=>............................] - ETA: 5:45 - loss: 0.6865 - acc: 0.5547
 832/9333 [=>............................] - ETA: 5:40 - loss: 0.6891 - acc: 0.5493
 896/9333 [=>............................] - ETA: 5:35 - loss: 0.6895 - acc: 0.5458
 960/9333 [==>...........................] - ETA: 5:34 - loss: 0.6888 - acc: 0.5448
1024/9333 [==>...........................] - ETA: 5:33 - loss: 0.6876 - acc: 0.5498
1088/9333 [==>...........................] - ETA: 5:30 - loss: 0.6870 - acc: 0.5487
1152/9333 [==>...........................] - ETA: 5:26 - loss: 0.6882 - acc: 0.5425
1216/9333 [==>...........................] - ETA: 5:25 - loss: 0.6883 - acc: 0.5395
1280/9333 [===>..........................] - ETA: 5:23 - loss: 0.6872 - acc: 0.5430
1344/9333 [===>..........................] - ETA: 5:21 - loss: 0.6869 - acc: 0.5454
1408/9333 [===>..........................] - ETA: 5:18 - loss: 0.6865 - acc: 0.5490
1472/9333 [===>..........................] - ETA: 5:16 - loss: 0.6870 - acc: 0.5469
1536/9333 [===>..........................] - ETA: 5:13 - loss: 0.6872 - acc: 0.5449
1600/9333 [====>.........................] - ETA: 5:10 - loss: 0.6867 - acc: 0.5469
1664/9333 [====>.........................] - ETA: 5:08 - loss: 0.6869 - acc: 0.5439
1728/9333 [====>.........................] - ETA: 5:04 - loss: 0.6863 - acc: 0.5463
1792/9333 [====>.........................] - ETA: 5:01 - loss: 0.6871 - acc: 0.5419
1856/9333 [====>.........................] - ETA: 5:01 - loss: 0.6876 - acc: 0.5415
1920/9333 [=====>........................] - ETA: 4:59 - loss: 0.6885 - acc: 0.5385
1984/9333 [=====>........................] - ETA: 4:55 - loss: 0.6878 - acc: 0.5398
2048/9333 [=====>........................] - ETA: 4:53 - loss: 0.6873 - acc: 0.5415
2112/9333 [=====>........................] - ETA: 4:50 - loss: 0.6866 - acc: 0.5459
2176/9333 [=====>........................] - ETA: 4:46 - loss: 0.6859 - acc: 0.5483
2240/9333 [======>.......................] - ETA: 4:44 - loss: 0.6861 - acc: 0.5473
2304/9333 [======>.......................] - ETA: 4:41 - loss: 0.6856 - acc: 0.5486
2368/9333 [======>.......................] - ETA: 4:37 - loss: 0.6851 - acc: 0.5490
2432/9333 [======>.......................] - ETA: 4:34 - loss: 0.6865 - acc: 0.5461
2496/9333 [=======>......................] - ETA: 4:32 - loss: 0.6866 - acc: 0.5465
2560/9333 [=======>......................] - ETA: 4:30 - loss: 0.6866 - acc: 0.5469
2624/9333 [=======>......................] - ETA: 4:26 - loss: 0.6866 - acc: 0.5473
2688/9333 [=======>......................] - ETA: 4:23 - loss: 0.6862 - acc: 0.5495
2752/9333 [=======>......................] - ETA: 4:20 - loss: 0.6857 - acc: 0.5520
2816/9333 [========>.....................] - ETA: 4:17 - loss: 0.6861 - acc: 0.5504
2880/9333 [========>.....................] - ETA: 4:14 - loss: 0.6861 - acc: 0.5514
2944/9333 [========>.....................] - ETA: 4:11 - loss: 0.6863 - acc: 0.5503
3008/9333 [========>.....................] - ETA: 4:09 - loss: 0.6864 - acc: 0.5492
3072/9333 [========>.....................] - ETA: 4:07 - loss: 0.6858 - acc: 0.5498
3136/9333 [=========>....................] - ETA: 4:05 - loss: 0.6854 - acc: 0.5513
3200/9333 [=========>....................] - ETA: 4:03 - loss: 0.6855 - acc: 0.5513
3264/9333 [=========>....................] - ETA: 4:00 - loss: 0.6857 - acc: 0.5499
3328/9333 [=========>....................] - ETA: 3:57 - loss: 0.6858 - acc: 0.5499
3392/9333 [=========>....................] - ETA: 3:54 - loss: 0.6859 - acc: 0.5498
3456/9333 [==========>...................] - ETA: 3:52 - loss: 0.6859 - acc: 0.5492
3520/9333 [==========>...................] - ETA: 3:49 - loss: 0.6860 - acc: 0.5491
3584/9333 [==========>...................] - ETA: 3:46 - loss: 0.6854 - acc: 0.5519
3648/9333 [==========>...................] - ETA: 3:43 - loss: 0.6855 - acc: 0.5521
3712/9333 [==========>...................] - ETA: 3:41 - loss: 0.6850 - acc: 0.5541
3776/9333 [===========>..................] - ETA: 3:39 - loss: 0.6847 - acc: 0.5548
3840/9333 [===========>..................] - ETA: 3:36 - loss: 0.6847 - acc: 0.5549
3904/9333 [===========>..................] - ETA: 3:33 - loss: 0.6845 - acc: 0.5561
3968/9333 [===========>..................] - ETA: 3:31 - loss: 0.6845 - acc: 0.5554
4032/9333 [===========>..................] - ETA: 3:28 - loss: 0.6851 - acc: 0.5538
4096/9333 [============>.................] - ETA: 3:25 - loss: 0.6854 - acc: 0.5527
4160/9333 [============>.................] - ETA: 3:23 - loss: 0.6857 - acc: 0.5526
4224/9333 [============>.................] - ETA: 3:21 - loss: 0.6857 - acc: 0.5521
4288/9333 [============>.................] - ETA: 3:19 - loss: 0.6856 - acc: 0.5518
4352/9333 [============>.................] - ETA: 3:17 - loss: 0.6857 - acc: 0.5526
4416/9333 [=============>................] - ETA: 3:14 - loss: 0.6856 - acc: 0.5530
4480/9333 [=============>................] - ETA: 3:11 - loss: 0.6856 - acc: 0.5529
4544/9333 [=============>................] - ETA: 3:09 - loss: 0.6854 - acc: 0.5544
4608/9333 [=============>................] - ETA: 3:07 - loss: 0.6857 - acc: 0.5540
4672/9333 [==============>...............] - ETA: 3:04 - loss: 0.6856 - acc: 0.5542
4736/9333 [==============>...............] - ETA: 3:02 - loss: 0.6854 - acc: 0.5545
4800/9333 [==============>...............] - ETA: 2:59 - loss: 0.6853 - acc: 0.5542
4864/9333 [==============>...............] - ETA: 2:57 - loss: 0.6850 - acc: 0.5549
4928/9333 [==============>...............] - ETA: 2:54 - loss: 0.6853 - acc: 0.5542
4992/9333 [===============>..............] - ETA: 2:52 - loss: 0.6851 - acc: 0.5545
5056/9333 [===============>..............] - ETA: 2:50 - loss: 0.6851 - acc: 0.5548
5120/9333 [===============>..............] - ETA: 2:47 - loss: 0.6847 - acc: 0.5561
5184/9333 [===============>..............] - ETA: 2:44 - loss: 0.6851 - acc: 0.5552
5248/9333 [===============>..............] - ETA: 2:42 - loss: 0.6852 - acc: 0.5545
5312/9333 [================>.............] - ETA: 2:39 - loss: 0.6850 - acc: 0.5550
5376/9333 [================>.............] - ETA: 2:37 - loss: 0.6845 - acc: 0.5567
5440/9333 [================>.............] - ETA: 2:34 - loss: 0.6846 - acc: 0.5564
5504/9333 [================>.............] - ETA: 2:32 - loss: 0.6843 - acc: 0.5569
5568/9333 [================>.............] - ETA: 2:29 - loss: 0.6846 - acc: 0.5566
5632/9333 [=================>............] - ETA: 2:26 - loss: 0.6847 - acc: 0.5563
5696/9333 [=================>............] - ETA: 2:24 - loss: 0.6844 - acc: 0.5567
5760/9333 [=================>............] - ETA: 2:21 - loss: 0.6843 - acc: 0.5573
5824/9333 [=================>............] - ETA: 2:19 - loss: 0.6844 - acc: 0.5561
5888/9333 [=================>............] - ETA: 2:17 - loss: 0.6847 - acc: 0.5557
5952/9333 [==================>...........] - ETA: 2:14 - loss: 0.6845 - acc: 0.5561
6016/9333 [==================>...........] - ETA: 2:11 - loss: 0.6846 - acc: 0.5565
6080/9333 [==================>...........] - ETA: 2:09 - loss: 0.6849 - acc: 0.5554
6144/9333 [==================>...........] - ETA: 2:06 - loss: 0.6848 - acc: 0.5555
6208/9333 [==================>...........] - ETA: 2:04 - loss: 0.6851 - acc: 0.5546
6272/9333 [===================>..........] - ETA: 2:01 - loss: 0.6854 - acc: 0.5539
6336/9333 [===================>..........] - ETA: 1:59 - loss: 0.6855 - acc: 0.5533
6400/9333 [===================>..........] - ETA: 1:56 - loss: 0.6858 - acc: 0.5527
6464/9333 [===================>..........] - ETA: 1:54 - loss: 0.6857 - acc: 0.5526
6528/9333 [===================>..........] - ETA: 1:51 - loss: 0.6861 - acc: 0.5512
6592/9333 [====================>.........] - ETA: 1:48 - loss: 0.6860 - acc: 0.5517
6656/9333 [====================>.........] - ETA: 1:46 - loss: 0.6861 - acc: 0.5511
6720/9333 [====================>.........] - ETA: 1:43 - loss: 0.6862 - acc: 0.5506
6784/9333 [====================>.........] - ETA: 1:41 - loss: 0.6860 - acc: 0.5517
6848/9333 [=====================>........] - ETA: 1:38 - loss: 0.6861 - acc: 0.5518
6912/9333 [=====================>........] - ETA: 1:36 - loss: 0.6860 - acc: 0.5519
6976/9333 [=====================>........] - ETA: 1:33 - loss: 0.6862 - acc: 0.5512
7040/9333 [=====================>........] - ETA: 1:31 - loss: 0.6864 - acc: 0.5507
7104/9333 [=====================>........] - ETA: 1:28 - loss: 0.6866 - acc: 0.5497
7168/9333 [======================>.......] - ETA: 1:26 - loss: 0.6867 - acc: 0.5495
7232/9333 [======================>.......] - ETA: 1:23 - loss: 0.6867 - acc: 0.5495
7296/9333 [======================>.......] - ETA: 1:21 - loss: 0.6865 - acc: 0.5504
7360/9333 [======================>.......] - ETA: 1:18 - loss: 0.6865 - acc: 0.5503
7424/9333 [======================>.......] - ETA: 1:16 - loss: 0.6865 - acc: 0.5500
7488/9333 [=======================>......] - ETA: 1:13 - loss: 0.6866 - acc: 0.5501
7552/9333 [=======================>......] - ETA: 1:11 - loss: 0.6866 - acc: 0.5499
7616/9333 [=======================>......] - ETA: 1:08 - loss: 0.6866 - acc: 0.5502
7680/9333 [=======================>......] - ETA: 1:06 - loss: 0.6866 - acc: 0.5500
7744/9333 [=======================>......] - ETA: 1:03 - loss: 0.6866 - acc: 0.5505
7808/9333 [========================>.....] - ETA: 1:01 - loss: 0.6866 - acc: 0.5499
7872/9333 [========================>.....] - ETA: 58s - loss: 0.6866 - acc: 0.5495 
7936/9333 [========================>.....] - ETA: 55s - loss: 0.6867 - acc: 0.5500
8000/9333 [========================>.....] - ETA: 53s - loss: 0.6868 - acc: 0.5497
8064/9333 [========================>.....] - ETA: 50s - loss: 0.6868 - acc: 0.5495
8128/9333 [=========================>....] - ETA: 48s - loss: 0.6867 - acc: 0.5500
8192/9333 [=========================>....] - ETA: 45s - loss: 0.6868 - acc: 0.5499
8256/9333 [=========================>....] - ETA: 43s - loss: 0.6869 - acc: 0.5497
8320/9333 [=========================>....] - ETA: 40s - loss: 0.6869 - acc: 0.5496
8384/9333 [=========================>....] - ETA: 38s - loss: 0.6868 - acc: 0.5490
8448/9333 [==========================>...] - ETA: 35s - loss: 0.6868 - acc: 0.5497
8512/9333 [==========================>...] - ETA: 32s - loss: 0.6867 - acc: 0.5500
8576/9333 [==========================>...] - ETA: 30s - loss: 0.6868 - acc: 0.5497
8640/9333 [==========================>...] - ETA: 27s - loss: 0.6868 - acc: 0.5497
8704/9333 [==========================>...] - ETA: 25s - loss: 0.6868 - acc: 0.5496
8768/9333 [===========================>..] - ETA: 22s - loss: 0.6868 - acc: 0.5497
8832/9333 [===========================>..] - ETA: 20s - loss: 0.6866 - acc: 0.5505
8896/9333 [===========================>..] - ETA: 17s - loss: 0.6865 - acc: 0.5504
8960/9333 [===========================>..] - ETA: 14s - loss: 0.6866 - acc: 0.5504
9024/9333 [============================>.] - ETA: 12s - loss: 0.6867 - acc: 0.5504
9088/9333 [============================>.] - ETA: 9s - loss: 0.6868 - acc: 0.5502 
9152/9333 [============================>.] - ETA: 7s - loss: 0.6868 - acc: 0.5500
9216/9333 [============================>.] - ETA: 4s - loss: 0.6870 - acc: 0.5489
9280/9333 [============================>.] - ETA: 2s - loss: 0.6870 - acc: 0.5488
9333/9333 [==============================] - 389s 42ms/step - loss: 0.6870 - acc: 0.5490 - val_loss: 0.6855 - val_acc: 0.5391

Epoch 00010: val_acc did not improve from 0.54388
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4f3b447f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4f3b447f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f47246a4f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f47246a4f90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98d39950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98d39950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f32ca1e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f32ca1e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f32b67ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f32b67ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4984596d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4984596d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f32ca1150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f32ca1150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f6e1cf7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f6e1cf7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4764605e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4764605e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f32a8cb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f32a8cb10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f32c0cb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f32c0cb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f492448bed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f492448bed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f476471fcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f476471fcd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f32b12d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f32b12d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f326edc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f326edc90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f327dd390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f327dd390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f327f5d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f327f5d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f326dd0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f326dd0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f2a543e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f2a543e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f2a40f5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f2a40f5d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2a3fe610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2a3fe610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f2a543ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f2a543ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2a3ba310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2a3ba310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f2a494e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f2a494e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f2a1193d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f2a1193d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2a1c1810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2a1c1810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f2a4946d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f2a4946d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2a1c1190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2a1c1190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f2a143190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f2a143190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f29dd7390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f29dd7390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f29e622d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f29e622d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f29f09e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f29f09e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f21ba6490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f21ba6490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f29d856d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f29d856d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f21a7a390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f21a7a390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2a05f910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2a05f910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f29d854d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f29d854d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f21a6d310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f21a6d310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f218cd790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f218cd790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f2171ad50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f2171ad50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f21978c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f21978c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f218cdfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f218cdfd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2178b850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f2178b850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f194da790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f194da790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f1943cb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f1943cb10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f21743690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f21743690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f217a5750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f217a5750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f192eae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f192eae10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f191f5ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f191f5ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f19113910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f19113910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f193ea650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f193ea650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f19440f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f19440f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f1900f890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f1900f890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f190120d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f190120d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f18e026d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f18e026d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f215705d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f215705d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f1910c810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f1910c810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f18e8fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f18e8fb90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f18e7da10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f18e7da10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f08b38c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f08b38c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f18dfe2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f18dfe2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f08b99f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f08b99f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f08aa0f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f08aa0f50>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 2:28
 128/2592 [>.............................] - ETA: 1:31
 192/2592 [=>............................] - ETA: 1:09
 256/2592 [=>............................] - ETA: 59s 
 320/2592 [==>...........................] - ETA: 52s
 384/2592 [===>..........................] - ETA: 47s
 448/2592 [====>.........................] - ETA: 44s
 512/2592 [====>.........................] - ETA: 41s
 576/2592 [=====>........................] - ETA: 38s
 640/2592 [======>.......................] - ETA: 36s
 704/2592 [=======>......................] - ETA: 34s
 768/2592 [=======>......................] - ETA: 33s
 832/2592 [========>.....................] - ETA: 32s
 896/2592 [=========>....................] - ETA: 30s
 960/2592 [==========>...................] - ETA: 29s
1024/2592 [==========>...................] - ETA: 27s
1088/2592 [===========>..................] - ETA: 27s
1152/2592 [============>.................] - ETA: 26s
1216/2592 [=============>................] - ETA: 24s
1280/2592 [=============>................] - ETA: 23s
1344/2592 [==============>...............] - ETA: 22s
1408/2592 [===============>..............] - ETA: 20s
1472/2592 [================>.............] - ETA: 19s
1536/2592 [================>.............] - ETA: 18s
1600/2592 [=================>............] - ETA: 17s
1664/2592 [==================>...........] - ETA: 15s
1728/2592 [===================>..........] - ETA: 14s
1792/2592 [===================>..........] - ETA: 13s
1856/2592 [====================>.........] - ETA: 12s
1920/2592 [=====================>........] - ETA: 11s
1984/2592 [=====================>........] - ETA: 10s
2048/2592 [======================>.......] - ETA: 9s 
2112/2592 [=======================>......] - ETA: 8s
2176/2592 [========================>.....] - ETA: 6s
2240/2592 [========================>.....] - ETA: 5s
2304/2592 [=========================>....] - ETA: 4s
2368/2592 [==========================>...] - ETA: 3s
2432/2592 [===========================>..] - ETA: 2s
2496/2592 [===========================>..] - ETA: 1s
2560/2592 [============================>.] - ETA: 0s
2592/2592 [==============================] - 43s 16ms/step
loss: 0.6867052927429294
acc: 0.5486111111111112
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f47246817d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f47246817d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f47246ac290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f47246ac290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98d39c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f98d39c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ef74a5110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ef74a5110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ef72f6850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ef72f6850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef74a51d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef74a51d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ef74a5150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ef74a5150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47246b5410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47246b5410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f3b10ce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f3b10ce50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f3ad6b890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4f3ad6b890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f3b1e6050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f3b1e6050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ef7153750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ef7153750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f3b09b610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f3b09b610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f3b065410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4f3b065410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ef6e0f050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ef6e0f050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47245a8910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47245a8910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f3aeee8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4f3aeee8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f3aedf510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f3aedf510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4684200bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4684200bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47243a7ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47243a7ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47243a3510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47243a3510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4724593bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4724593bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4724396b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4724396b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f472417fcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f472417fcd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4724387fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4724387fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f472415ab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f472415ab50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4724425b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4724425b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47240da0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47240da0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47243ad190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47243ad190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4704524f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4704524f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f472404a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f472404a690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f470461e110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f470461e110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f470451a1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f470451a1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4704511950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4704511950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47041c7250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47041c7250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4704438210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4704438210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f470465fc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f470465fc90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47040ddd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47040ddd10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46e4781310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46e4781310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46e46a4310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46e46a4310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e4743250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e4743250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4704338f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4704338f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47040cc850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47040cc850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46e445e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46e445e550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46e469ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46e469ee90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e445ef50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e445ef50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46e46543d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46e46543d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e433e450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e433e450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46e4154ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46e4154ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46e413ffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46e413ffd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e4163b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e4163b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46e4154b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46e4154b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e4050a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e4050a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46c4646c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46c4646c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46c44c12d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46c44c12d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46c45d0550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46c45d0550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46c45455d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46c45455d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46c43d83d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46c43d83d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46c44beed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46c44beed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46c461dfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46c461dfd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46c44bec10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46c44bec10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46c44be890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46c44be890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46c4058d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46c4058d50>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 24:19 - loss: 0.8537 - acc: 0.4062
 128/9333 [..............................] - ETA: 14:50 - loss: 0.8926 - acc: 0.4375
 192/9333 [..............................] - ETA: 11:58 - loss: 0.8801 - acc: 0.4479
 256/9333 [..............................] - ETA: 10:32 - loss: 0.8551 - acc: 0.4336
 320/9333 [>.............................] - ETA: 9:29 - loss: 0.8302 - acc: 0.4656 
 384/9333 [>.............................] - ETA: 8:49 - loss: 0.8049 - acc: 0.4818
 448/9333 [>.............................] - ETA: 8:18 - loss: 0.7791 - acc: 0.5112
 512/9333 [>.............................] - ETA: 7:53 - loss: 0.7777 - acc: 0.5059
 576/9333 [>.............................] - ETA: 7:51 - loss: 0.7715 - acc: 0.5174
 640/9333 [=>............................] - ETA: 7:42 - loss: 0.7658 - acc: 0.5250
 704/9333 [=>............................] - ETA: 7:26 - loss: 0.7646 - acc: 0.5227
 768/9333 [=>............................] - ETA: 7:16 - loss: 0.7597 - acc: 0.5299
 832/9333 [=>............................] - ETA: 7:02 - loss: 0.7620 - acc: 0.5204
 896/9333 [=>............................] - ETA: 6:51 - loss: 0.7626 - acc: 0.5179
 960/9333 [==>...........................] - ETA: 6:49 - loss: 0.7626 - acc: 0.5125
1024/9333 [==>...........................] - ETA: 6:40 - loss: 0.7574 - acc: 0.5107
1088/9333 [==>...........................] - ETA: 6:37 - loss: 0.7559 - acc: 0.5101
1152/9333 [==>...........................] - ETA: 6:33 - loss: 0.7534 - acc: 0.5113
1216/9333 [==>...........................] - ETA: 6:26 - loss: 0.7521 - acc: 0.5099
1280/9333 [===>..........................] - ETA: 6:19 - loss: 0.7542 - acc: 0.5031
1344/9333 [===>..........................] - ETA: 6:14 - loss: 0.7568 - acc: 0.5015
1408/9333 [===>..........................] - ETA: 6:08 - loss: 0.7544 - acc: 0.5036
1472/9333 [===>..........................] - ETA: 6:02 - loss: 0.7522 - acc: 0.5075
1536/9333 [===>..........................] - ETA: 5:56 - loss: 0.7553 - acc: 0.5039
1600/9333 [====>.........................] - ETA: 5:52 - loss: 0.7551 - acc: 0.5012
1664/9333 [====>.........................] - ETA: 5:49 - loss: 0.7550 - acc: 0.4988
1728/9333 [====>.........................] - ETA: 5:44 - loss: 0.7525 - acc: 0.5006
1792/9333 [====>.........................] - ETA: 5:41 - loss: 0.7523 - acc: 0.4972
1856/9333 [====>.........................] - ETA: 5:37 - loss: 0.7501 - acc: 0.5000
1920/9333 [=====>........................] - ETA: 5:33 - loss: 0.7500 - acc: 0.4995
1984/9333 [=====>........................] - ETA: 5:30 - loss: 0.7477 - acc: 0.5005
2048/9333 [=====>........................] - ETA: 5:27 - loss: 0.7478 - acc: 0.4980
2112/9333 [=====>........................] - ETA: 5:23 - loss: 0.7466 - acc: 0.4967
2176/9333 [=====>........................] - ETA: 5:19 - loss: 0.7465 - acc: 0.4963
2240/9333 [======>.......................] - ETA: 5:17 - loss: 0.7463 - acc: 0.4955
2304/9333 [======>.......................] - ETA: 5:12 - loss: 0.7469 - acc: 0.4944
2368/9333 [======>.......................] - ETA: 5:09 - loss: 0.7466 - acc: 0.4949
2432/9333 [======>.......................] - ETA: 5:06 - loss: 0.7457 - acc: 0.4942
2496/9333 [=======>......................] - ETA: 5:04 - loss: 0.7451 - acc: 0.4948
2560/9333 [=======>......................] - ETA: 5:00 - loss: 0.7449 - acc: 0.4953
2624/9333 [=======>......................] - ETA: 4:56 - loss: 0.7436 - acc: 0.4970
2688/9333 [=======>......................] - ETA: 4:52 - loss: 0.7428 - acc: 0.4959
2752/9333 [=======>......................] - ETA: 4:47 - loss: 0.7426 - acc: 0.4956
2816/9333 [========>.....................] - ETA: 4:46 - loss: 0.7414 - acc: 0.4964
2880/9333 [========>.....................] - ETA: 4:43 - loss: 0.7402 - acc: 0.4979
2944/9333 [========>.....................] - ETA: 4:40 - loss: 0.7412 - acc: 0.4959
3008/9333 [========>.....................] - ETA: 4:37 - loss: 0.7403 - acc: 0.4963
3072/9333 [========>.....................] - ETA: 4:34 - loss: 0.7394 - acc: 0.4971
3136/9333 [=========>....................] - ETA: 4:31 - loss: 0.7391 - acc: 0.4974
3200/9333 [=========>....................] - ETA: 4:27 - loss: 0.7391 - acc: 0.4956
3264/9333 [=========>....................] - ETA: 4:23 - loss: 0.7377 - acc: 0.4975
3328/9333 [=========>....................] - ETA: 4:21 - loss: 0.7371 - acc: 0.4991
3392/9333 [=========>....................] - ETA: 4:17 - loss: 0.7366 - acc: 0.4994
3456/9333 [==========>...................] - ETA: 4:14 - loss: 0.7360 - acc: 0.5009
3520/9333 [==========>...................] - ETA: 4:12 - loss: 0.7359 - acc: 0.5006
3584/9333 [==========>...................] - ETA: 4:09 - loss: 0.7346 - acc: 0.5014
3648/9333 [==========>...................] - ETA: 4:05 - loss: 0.7341 - acc: 0.5022
3712/9333 [==========>...................] - ETA: 4:02 - loss: 0.7345 - acc: 0.5005
3776/9333 [===========>..................] - ETA: 3:59 - loss: 0.7349 - acc: 0.4984
3840/9333 [===========>..................] - ETA: 3:57 - loss: 0.7347 - acc: 0.4987
3904/9333 [===========>..................] - ETA: 3:54 - loss: 0.7354 - acc: 0.4964
3968/9333 [===========>..................] - ETA: 3:51 - loss: 0.7350 - acc: 0.4957
4032/9333 [===========>..................] - ETA: 3:48 - loss: 0.7338 - acc: 0.4973
4096/9333 [============>.................] - ETA: 3:45 - loss: 0.7334 - acc: 0.4973
4160/9333 [============>.................] - ETA: 3:42 - loss: 0.7324 - acc: 0.4990
4224/9333 [============>.................] - ETA: 3:38 - loss: 0.7314 - acc: 0.5002
4288/9333 [============>.................] - ETA: 3:35 - loss: 0.7313 - acc: 0.5005
4352/9333 [============>.................] - ETA: 3:33 - loss: 0.7305 - acc: 0.5011
4416/9333 [=============>................] - ETA: 3:30 - loss: 0.7300 - acc: 0.5025
4480/9333 [=============>................] - ETA: 3:27 - loss: 0.7295 - acc: 0.5025
4544/9333 [=============>................] - ETA: 3:24 - loss: 0.7284 - acc: 0.5040
4608/9333 [=============>................] - ETA: 3:21 - loss: 0.7283 - acc: 0.5033
4672/9333 [==============>...............] - ETA: 3:18 - loss: 0.7279 - acc: 0.5036
4736/9333 [==============>...............] - ETA: 3:15 - loss: 0.7282 - acc: 0.5036
4800/9333 [==============>...............] - ETA: 3:12 - loss: 0.7287 - acc: 0.5025
4864/9333 [==============>...............] - ETA: 3:10 - loss: 0.7280 - acc: 0.5035
4928/9333 [==============>...............] - ETA: 3:07 - loss: 0.7279 - acc: 0.5034
4992/9333 [===============>..............] - ETA: 3:05 - loss: 0.7274 - acc: 0.5040
5056/9333 [===============>..............] - ETA: 3:01 - loss: 0.7266 - acc: 0.5047
5120/9333 [===============>..............] - ETA: 2:58 - loss: 0.7268 - acc: 0.5043
5184/9333 [===============>..............] - ETA: 2:55 - loss: 0.7262 - acc: 0.5048
5248/9333 [===============>..............] - ETA: 2:52 - loss: 0.7261 - acc: 0.5042
5312/9333 [================>.............] - ETA: 2:50 - loss: 0.7254 - acc: 0.5058
5376/9333 [================>.............] - ETA: 2:47 - loss: 0.7255 - acc: 0.5054
5440/9333 [================>.............] - ETA: 2:44 - loss: 0.7252 - acc: 0.5057
5504/9333 [================>.............] - ETA: 2:41 - loss: 0.7248 - acc: 0.5056
5568/9333 [================>.............] - ETA: 2:39 - loss: 0.7244 - acc: 0.5063
5632/9333 [=================>............] - ETA: 2:35 - loss: 0.7242 - acc: 0.5059
5696/9333 [=================>............] - ETA: 2:33 - loss: 0.7235 - acc: 0.5070
5760/9333 [=================>............] - ETA: 2:30 - loss: 0.7232 - acc: 0.5075
5824/9333 [=================>............] - ETA: 2:27 - loss: 0.7230 - acc: 0.5079
5888/9333 [=================>............] - ETA: 2:24 - loss: 0.7230 - acc: 0.5075
5952/9333 [==================>...........] - ETA: 2:22 - loss: 0.7229 - acc: 0.5076
6016/9333 [==================>...........] - ETA: 2:19 - loss: 0.7225 - acc: 0.5083
6080/9333 [==================>...........] - ETA: 2:16 - loss: 0.7224 - acc: 0.5087
6144/9333 [==================>...........] - ETA: 2:13 - loss: 0.7223 - acc: 0.5081
6208/9333 [==================>...........] - ETA: 2:11 - loss: 0.7223 - acc: 0.5076
6272/9333 [===================>..........] - ETA: 2:08 - loss: 0.7224 - acc: 0.5069
6336/9333 [===================>..........] - ETA: 2:06 - loss: 0.7226 - acc: 0.5055
6400/9333 [===================>..........] - ETA: 2:03 - loss: 0.7227 - acc: 0.5052
6464/9333 [===================>..........] - ETA: 2:01 - loss: 0.7224 - acc: 0.5057
6528/9333 [===================>..........] - ETA: 1:58 - loss: 0.7227 - acc: 0.5047
6592/9333 [====================>.........] - ETA: 1:55 - loss: 0.7225 - acc: 0.5042
6656/9333 [====================>.........] - ETA: 1:52 - loss: 0.7226 - acc: 0.5041
6720/9333 [====================>.........] - ETA: 1:50 - loss: 0.7225 - acc: 0.5037
6784/9333 [====================>.........] - ETA: 1:47 - loss: 0.7224 - acc: 0.5035
6848/9333 [=====================>........] - ETA: 1:44 - loss: 0.7221 - acc: 0.5035
6912/9333 [=====================>........] - ETA: 1:42 - loss: 0.7220 - acc: 0.5038
6976/9333 [=====================>........] - ETA: 1:39 - loss: 0.7219 - acc: 0.5039
7040/9333 [=====================>........] - ETA: 1:36 - loss: 0.7217 - acc: 0.5036
7104/9333 [=====================>........] - ETA: 1:33 - loss: 0.7214 - acc: 0.5038
7168/9333 [======================>.......] - ETA: 1:31 - loss: 0.7213 - acc: 0.5040
7232/9333 [======================>.......] - ETA: 1:28 - loss: 0.7209 - acc: 0.5043
7296/9333 [======================>.......] - ETA: 1:25 - loss: 0.7207 - acc: 0.5042
7360/9333 [======================>.......] - ETA: 1:23 - loss: 0.7209 - acc: 0.5037
7424/9333 [======================>.......] - ETA: 1:20 - loss: 0.7205 - acc: 0.5035
7488/9333 [=======================>......] - ETA: 1:17 - loss: 0.7204 - acc: 0.5037
7552/9333 [=======================>......] - ETA: 1:14 - loss: 0.7205 - acc: 0.5037
7616/9333 [=======================>......] - ETA: 1:12 - loss: 0.7204 - acc: 0.5038
7680/9333 [=======================>......] - ETA: 1:09 - loss: 0.7205 - acc: 0.5035
7744/9333 [=======================>......] - ETA: 1:06 - loss: 0.7206 - acc: 0.5030
7808/9333 [========================>.....] - ETA: 1:04 - loss: 0.7202 - acc: 0.5036
7872/9333 [========================>.....] - ETA: 1:01 - loss: 0.7201 - acc: 0.5032
7936/9333 [========================>.....] - ETA: 58s - loss: 0.7200 - acc: 0.5029 
8000/9333 [========================>.....] - ETA: 55s - loss: 0.7200 - acc: 0.5020
8064/9333 [========================>.....] - ETA: 53s - loss: 0.7198 - acc: 0.5020
8128/9333 [=========================>....] - ETA: 50s - loss: 0.7196 - acc: 0.5021
8192/9333 [=========================>....] - ETA: 47s - loss: 0.7191 - acc: 0.5032
8256/9333 [=========================>....] - ETA: 45s - loss: 0.7188 - acc: 0.5040
8320/9333 [=========================>....] - ETA: 42s - loss: 0.7189 - acc: 0.5035
8384/9333 [=========================>....] - ETA: 39s - loss: 0.7187 - acc: 0.5036
8448/9333 [==========================>...] - ETA: 37s - loss: 0.7187 - acc: 0.5030
8512/9333 [==========================>...] - ETA: 34s - loss: 0.7187 - acc: 0.5025
8576/9333 [==========================>...] - ETA: 31s - loss: 0.7189 - acc: 0.5022
8640/9333 [==========================>...] - ETA: 28s - loss: 0.7187 - acc: 0.5027
8704/9333 [==========================>...] - ETA: 26s - loss: 0.7185 - acc: 0.5032
8768/9333 [===========================>..] - ETA: 23s - loss: 0.7183 - acc: 0.5032
8832/9333 [===========================>..] - ETA: 20s - loss: 0.7184 - acc: 0.5028
8896/9333 [===========================>..] - ETA: 18s - loss: 0.7183 - acc: 0.5029
8960/9333 [===========================>..] - ETA: 15s - loss: 0.7181 - acc: 0.5023
9024/9333 [============================>.] - ETA: 12s - loss: 0.7179 - acc: 0.5025
9088/9333 [============================>.] - ETA: 10s - loss: 0.7179 - acc: 0.5022
9152/9333 [============================>.] - ETA: 7s - loss: 0.7178 - acc: 0.5025 
9216/9333 [============================>.] - ETA: 4s - loss: 0.7177 - acc: 0.5021
9280/9333 [============================>.] - ETA: 2s - loss: 0.7177 - acc: 0.5017
9333/9333 [==============================] - 408s 44ms/step - loss: 0.7176 - acc: 0.5014 - val_loss: 0.6919 - val_acc: 0.5169

Epoch 00001: val_acc improved from -inf to 0.51688, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window03/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 6:20 - loss: 0.7028 - acc: 0.4844
 128/9333 [..............................] - ETA: 6:41 - loss: 0.6963 - acc: 0.4766
 192/9333 [..............................] - ETA: 6:22 - loss: 0.7127 - acc: 0.4323
 256/9333 [..............................] - ETA: 6:12 - loss: 0.7100 - acc: 0.4492
 320/9333 [>.............................] - ETA: 6:20 - loss: 0.7089 - acc: 0.4750
 384/9333 [>.............................] - ETA: 6:21 - loss: 0.7043 - acc: 0.4922
 448/9333 [>.............................] - ETA: 6:13 - loss: 0.7046 - acc: 0.4933
 512/9333 [>.............................] - ETA: 6:06 - loss: 0.7039 - acc: 0.4902
 576/9333 [>.............................] - ETA: 6:08 - loss: 0.7018 - acc: 0.5000
 640/9333 [=>............................] - ETA: 6:01 - loss: 0.7005 - acc: 0.5078
 704/9333 [=>............................] - ETA: 5:59 - loss: 0.6988 - acc: 0.5170
 768/9333 [=>............................] - ETA: 5:54 - loss: 0.6974 - acc: 0.5208
 832/9333 [=>............................] - ETA: 5:51 - loss: 0.6966 - acc: 0.5180
 896/9333 [=>............................] - ETA: 5:53 - loss: 0.6957 - acc: 0.5212
 960/9333 [==>...........................] - ETA: 5:48 - loss: 0.6965 - acc: 0.5188
1024/9333 [==>...........................] - ETA: 5:49 - loss: 0.6962 - acc: 0.5215
1088/9333 [==>...........................] - ETA: 5:44 - loss: 0.6957 - acc: 0.5211
1152/9333 [==>...........................] - ETA: 5:43 - loss: 0.6954 - acc: 0.5243
1216/9333 [==>...........................] - ETA: 5:38 - loss: 0.6944 - acc: 0.5280
1280/9333 [===>..........................] - ETA: 5:35 - loss: 0.6944 - acc: 0.5258
1344/9333 [===>..........................] - ETA: 5:34 - loss: 0.6940 - acc: 0.5268
1408/9333 [===>..........................] - ETA: 5:30 - loss: 0.6942 - acc: 0.5234
1472/9333 [===>..........................] - ETA: 5:30 - loss: 0.6951 - acc: 0.5190
1536/9333 [===>..........................] - ETA: 5:26 - loss: 0.6953 - acc: 0.5202
1600/9333 [====>.........................] - ETA: 5:23 - loss: 0.6951 - acc: 0.5188
1664/9333 [====>.........................] - ETA: 5:20 - loss: 0.6954 - acc: 0.5180
1728/9333 [====>.........................] - ETA: 5:20 - loss: 0.6956 - acc: 0.5174
1792/9333 [====>.........................] - ETA: 5:17 - loss: 0.6961 - acc: 0.5173
1856/9333 [====>.........................] - ETA: 5:14 - loss: 0.6958 - acc: 0.5167
1920/9333 [=====>........................] - ETA: 5:11 - loss: 0.6963 - acc: 0.5156
1984/9333 [=====>........................] - ETA: 5:07 - loss: 0.6961 - acc: 0.5176
2048/9333 [=====>........................] - ETA: 5:03 - loss: 0.6964 - acc: 0.5171
2112/9333 [=====>........................] - ETA: 4:59 - loss: 0.6958 - acc: 0.5189
2176/9333 [=====>........................] - ETA: 4:55 - loss: 0.6968 - acc: 0.5152
2240/9333 [======>.......................] - ETA: 4:52 - loss: 0.6965 - acc: 0.5170
2304/9333 [======>.......................] - ETA: 4:53 - loss: 0.6961 - acc: 0.5178
2368/9333 [======>.......................] - ETA: 4:51 - loss: 0.6959 - acc: 0.5198
2432/9333 [======>.......................] - ETA: 4:48 - loss: 0.6956 - acc: 0.5218
2496/9333 [=======>......................] - ETA: 4:44 - loss: 0.6962 - acc: 0.5188
2560/9333 [=======>......................] - ETA: 4:40 - loss: 0.6965 - acc: 0.5191
2624/9333 [=======>......................] - ETA: 4:36 - loss: 0.6968 - acc: 0.5183
2688/9333 [=======>......................] - ETA: 4:33 - loss: 0.6965 - acc: 0.5201
2752/9333 [=======>......................] - ETA: 4:32 - loss: 0.6961 - acc: 0.5207
2816/9333 [========>.....................] - ETA: 4:29 - loss: 0.6959 - acc: 0.5213
2880/9333 [========>.....................] - ETA: 4:26 - loss: 0.6964 - acc: 0.5201
2944/9333 [========>.....................] - ETA: 4:23 - loss: 0.6958 - acc: 0.5217
3008/9333 [========>.....................] - ETA: 4:20 - loss: 0.6964 - acc: 0.5203
3072/9333 [========>.....................] - ETA: 4:17 - loss: 0.6971 - acc: 0.5176
3136/9333 [=========>....................] - ETA: 4:13 - loss: 0.6969 - acc: 0.5185
3200/9333 [=========>....................] - ETA: 4:11 - loss: 0.6969 - acc: 0.5178
3264/9333 [=========>....................] - ETA: 4:10 - loss: 0.6969 - acc: 0.5187
3328/9333 [=========>....................] - ETA: 4:07 - loss: 0.6968 - acc: 0.5192
3392/9333 [=========>....................] - ETA: 4:04 - loss: 0.6968 - acc: 0.5186
3456/9333 [==========>...................] - ETA: 4:01 - loss: 0.6965 - acc: 0.5191
3520/9333 [==========>...................] - ETA: 3:58 - loss: 0.6961 - acc: 0.5202
3584/9333 [==========>...................] - ETA: 3:55 - loss: 0.6963 - acc: 0.5204
3648/9333 [==========>...................] - ETA: 3:52 - loss: 0.6959 - acc: 0.5214
3712/9333 [==========>...................] - ETA: 3:49 - loss: 0.6959 - acc: 0.5221
3776/9333 [===========>..................] - ETA: 3:46 - loss: 0.6957 - acc: 0.5222
3840/9333 [===========>..................] - ETA: 3:44 - loss: 0.6953 - acc: 0.5224
3904/9333 [===========>..................] - ETA: 3:41 - loss: 0.6954 - acc: 0.5231
3968/9333 [===========>..................] - ETA: 3:38 - loss: 0.6955 - acc: 0.5227
4032/9333 [===========>..................] - ETA: 3:35 - loss: 0.6957 - acc: 0.5223
4096/9333 [============>.................] - ETA: 3:32 - loss: 0.6954 - acc: 0.5234
4160/9333 [============>.................] - ETA: 3:29 - loss: 0.6951 - acc: 0.5243
4224/9333 [============>.................] - ETA: 3:27 - loss: 0.6955 - acc: 0.5232
4288/9333 [============>.................] - ETA: 3:25 - loss: 0.6951 - acc: 0.5238
4352/9333 [============>.................] - ETA: 3:23 - loss: 0.6947 - acc: 0.5246
4416/9333 [=============>................] - ETA: 3:20 - loss: 0.6946 - acc: 0.5256
4480/9333 [=============>................] - ETA: 3:17 - loss: 0.6944 - acc: 0.5257
4544/9333 [=============>................] - ETA: 3:14 - loss: 0.6944 - acc: 0.5266
4608/9333 [=============>................] - ETA: 3:11 - loss: 0.6947 - acc: 0.5267
4672/9333 [==============>...............] - ETA: 3:08 - loss: 0.6947 - acc: 0.5261
4736/9333 [==============>...............] - ETA: 3:06 - loss: 0.6942 - acc: 0.5274
4800/9333 [==============>...............] - ETA: 3:03 - loss: 0.6949 - acc: 0.5252
4864/9333 [==============>...............] - ETA: 3:01 - loss: 0.6950 - acc: 0.5257
4928/9333 [==============>...............] - ETA: 2:58 - loss: 0.6947 - acc: 0.5262
4992/9333 [===============>..............] - ETA: 2:55 - loss: 0.6944 - acc: 0.5270
5056/9333 [===============>..............] - ETA: 2:53 - loss: 0.6944 - acc: 0.5269
5120/9333 [===============>..............] - ETA: 2:50 - loss: 0.6942 - acc: 0.5270
5184/9333 [===============>..............] - ETA: 2:47 - loss: 0.6943 - acc: 0.5270
5248/9333 [===============>..............] - ETA: 2:45 - loss: 0.6941 - acc: 0.5278
5312/9333 [================>.............] - ETA: 2:42 - loss: 0.6943 - acc: 0.5269
5376/9333 [================>.............] - ETA: 2:40 - loss: 0.6940 - acc: 0.5270
5440/9333 [================>.............] - ETA: 2:37 - loss: 0.6940 - acc: 0.5267
5504/9333 [================>.............] - ETA: 2:34 - loss: 0.6939 - acc: 0.5269
5568/9333 [================>.............] - ETA: 2:31 - loss: 0.6943 - acc: 0.5259
5632/9333 [=================>............] - ETA: 2:29 - loss: 0.6942 - acc: 0.5263
5696/9333 [=================>............] - ETA: 2:26 - loss: 0.6945 - acc: 0.5256
5760/9333 [=================>............] - ETA: 2:24 - loss: 0.6948 - acc: 0.5257
5824/9333 [=================>............] - ETA: 2:22 - loss: 0.6945 - acc: 0.5270
5888/9333 [=================>............] - ETA: 2:19 - loss: 0.6946 - acc: 0.5263
5952/9333 [==================>...........] - ETA: 2:17 - loss: 0.6946 - acc: 0.5260
6016/9333 [==================>...........] - ETA: 2:14 - loss: 0.6944 - acc: 0.5259
6080/9333 [==================>...........] - ETA: 2:11 - loss: 0.6945 - acc: 0.5258
6144/9333 [==================>...........] - ETA: 2:09 - loss: 0.6946 - acc: 0.5252
6208/9333 [==================>...........] - ETA: 2:07 - loss: 0.6946 - acc: 0.5250
6272/9333 [===================>..........] - ETA: 2:04 - loss: 0.6946 - acc: 0.5246
6336/9333 [===================>..........] - ETA: 2:02 - loss: 0.6944 - acc: 0.5249
6400/9333 [===================>..........] - ETA: 1:59 - loss: 0.6942 - acc: 0.5253
6464/9333 [===================>..........] - ETA: 1:56 - loss: 0.6943 - acc: 0.5252
6528/9333 [===================>..........] - ETA: 1:54 - loss: 0.6945 - acc: 0.5241
6592/9333 [====================>.........] - ETA: 1:51 - loss: 0.6944 - acc: 0.5246
6656/9333 [====================>.........] - ETA: 1:49 - loss: 0.6944 - acc: 0.5249
6720/9333 [====================>.........] - ETA: 1:46 - loss: 0.6945 - acc: 0.5251
6784/9333 [====================>.........] - ETA: 1:44 - loss: 0.6944 - acc: 0.5259
6848/9333 [=====================>........] - ETA: 1:41 - loss: 0.6942 - acc: 0.5256
6912/9333 [=====================>........] - ETA: 1:38 - loss: 0.6943 - acc: 0.5256
6976/9333 [=====================>........] - ETA: 1:36 - loss: 0.6941 - acc: 0.5259
7040/9333 [=====================>........] - ETA: 1:33 - loss: 0.6942 - acc: 0.5253
7104/9333 [=====================>........] - ETA: 1:31 - loss: 0.6941 - acc: 0.5262
7168/9333 [======================>.......] - ETA: 1:28 - loss: 0.6938 - acc: 0.5271
7232/9333 [======================>.......] - ETA: 1:25 - loss: 0.6938 - acc: 0.5271
7296/9333 [======================>.......] - ETA: 1:23 - loss: 0.6937 - acc: 0.5277
7360/9333 [======================>.......] - ETA: 1:20 - loss: 0.6938 - acc: 0.5272
7424/9333 [======================>.......] - ETA: 1:17 - loss: 0.6939 - acc: 0.5271
7488/9333 [=======================>......] - ETA: 1:15 - loss: 0.6937 - acc: 0.5279
7552/9333 [=======================>......] - ETA: 1:12 - loss: 0.6937 - acc: 0.5274
7616/9333 [=======================>......] - ETA: 1:10 - loss: 0.6938 - acc: 0.5272
7680/9333 [=======================>......] - ETA: 1:07 - loss: 0.6937 - acc: 0.5272
7744/9333 [=======================>......] - ETA: 1:05 - loss: 0.6936 - acc: 0.5275
7808/9333 [========================>.....] - ETA: 1:02 - loss: 0.6936 - acc: 0.5275
7872/9333 [========================>.....] - ETA: 59s - loss: 0.6934 - acc: 0.5285 
7936/9333 [========================>.....] - ETA: 57s - loss: 0.6935 - acc: 0.5278
8000/9333 [========================>.....] - ETA: 54s - loss: 0.6937 - acc: 0.5275
8064/9333 [========================>.....] - ETA: 52s - loss: 0.6938 - acc: 0.5272
8128/9333 [=========================>....] - ETA: 49s - loss: 0.6941 - acc: 0.5263
8192/9333 [=========================>....] - ETA: 46s - loss: 0.6944 - acc: 0.5253
8256/9333 [=========================>....] - ETA: 44s - loss: 0.6942 - acc: 0.5260
8320/9333 [=========================>....] - ETA: 41s - loss: 0.6939 - acc: 0.5267
8384/9333 [=========================>....] - ETA: 39s - loss: 0.6940 - acc: 0.5267
8448/9333 [==========================>...] - ETA: 36s - loss: 0.6942 - acc: 0.5264
8512/9333 [==========================>...] - ETA: 33s - loss: 0.6942 - acc: 0.5263
8576/9333 [==========================>...] - ETA: 31s - loss: 0.6939 - acc: 0.5269
8640/9333 [==========================>...] - ETA: 28s - loss: 0.6939 - acc: 0.5270
8704/9333 [==========================>...] - ETA: 25s - loss: 0.6935 - acc: 0.5279
8768/9333 [===========================>..] - ETA: 23s - loss: 0.6936 - acc: 0.5282
8832/9333 [===========================>..] - ETA: 20s - loss: 0.6936 - acc: 0.5280
8896/9333 [===========================>..] - ETA: 18s - loss: 0.6937 - acc: 0.5274
8960/9333 [===========================>..] - ETA: 15s - loss: 0.6936 - acc: 0.5276
9024/9333 [============================>.] - ETA: 12s - loss: 0.6937 - acc: 0.5277
9088/9333 [============================>.] - ETA: 10s - loss: 0.6937 - acc: 0.5278
9152/9333 [============================>.] - ETA: 7s - loss: 0.6936 - acc: 0.5280 
9216/9333 [============================>.] - ETA: 4s - loss: 0.6935 - acc: 0.5283
9280/9333 [============================>.] - ETA: 2s - loss: 0.6936 - acc: 0.5277
9333/9333 [==============================] - 402s 43ms/step - loss: 0.6937 - acc: 0.5271 - val_loss: 0.6920 - val_acc: 0.5246

Epoch 00002: val_acc improved from 0.51688 to 0.52459, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window03/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 3/10

  64/9333 [..............................] - ETA: 5:27 - loss: 0.6851 - acc: 0.5625
 128/9333 [..............................] - ETA: 6:57 - loss: 0.6784 - acc: 0.5859
 192/9333 [..............................] - ETA: 6:55 - loss: 0.6926 - acc: 0.5729
 256/9333 [..............................] - ETA: 6:39 - loss: 0.6899 - acc: 0.5586
 320/9333 [>.............................] - ETA: 6:30 - loss: 0.6908 - acc: 0.5594
 384/9333 [>.............................] - ETA: 6:18 - loss: 0.6948 - acc: 0.5417
 448/9333 [>.............................] - ETA: 6:09 - loss: 0.6951 - acc: 0.5357
 512/9333 [>.............................] - ETA: 6:00 - loss: 0.6945 - acc: 0.5410
 576/9333 [>.............................] - ETA: 6:03 - loss: 0.6936 - acc: 0.5399
 640/9333 [=>............................] - ETA: 6:07 - loss: 0.6931 - acc: 0.5391
 704/9333 [=>............................] - ETA: 6:12 - loss: 0.6932 - acc: 0.5412
 768/9333 [=>............................] - ETA: 6:05 - loss: 0.6937 - acc: 0.5391
 832/9333 [=>............................] - ETA: 5:58 - loss: 0.6948 - acc: 0.5349
 896/9333 [=>............................] - ETA: 5:53 - loss: 0.6947 - acc: 0.5391
 960/9333 [==>...........................] - ETA: 5:48 - loss: 0.6958 - acc: 0.5365
1024/9333 [==>...........................] - ETA: 5:45 - loss: 0.6965 - acc: 0.5361
1088/9333 [==>...........................] - ETA: 5:44 - loss: 0.6962 - acc: 0.5368
1152/9333 [==>...........................] - ETA: 5:43 - loss: 0.6953 - acc: 0.5373
1216/9333 [==>...........................] - ETA: 5:44 - loss: 0.6954 - acc: 0.5354
1280/9333 [===>..........................] - ETA: 5:40 - loss: 0.6976 - acc: 0.5273
1344/9333 [===>..........................] - ETA: 5:35 - loss: 0.6965 - acc: 0.5298
1408/9333 [===>..........................] - ETA: 5:30 - loss: 0.6966 - acc: 0.5284
1472/9333 [===>..........................] - ETA: 5:31 - loss: 0.6961 - acc: 0.5272
1536/9333 [===>..........................] - ETA: 5:28 - loss: 0.6959 - acc: 0.5286
1600/9333 [====>.........................] - ETA: 5:24 - loss: 0.6968 - acc: 0.5281
1664/9333 [====>.........................] - ETA: 5:22 - loss: 0.6974 - acc: 0.5240
1728/9333 [====>.........................] - ETA: 5:20 - loss: 0.6966 - acc: 0.5260
1792/9333 [====>.........................] - ETA: 5:16 - loss: 0.6958 - acc: 0.5268
1856/9333 [====>.........................] - ETA: 5:14 - loss: 0.6959 - acc: 0.5253
1920/9333 [=====>........................] - ETA: 5:13 - loss: 0.6966 - acc: 0.5214
1984/9333 [=====>........................] - ETA: 5:10 - loss: 0.6958 - acc: 0.5252
2048/9333 [=====>........................] - ETA: 5:07 - loss: 0.6963 - acc: 0.5239
2112/9333 [=====>........................] - ETA: 5:06 - loss: 0.6963 - acc: 0.5241
2176/9333 [=====>........................] - ETA: 5:06 - loss: 0.6965 - acc: 0.5239
2240/9333 [======>.......................] - ETA: 5:04 - loss: 0.6961 - acc: 0.5263
2304/9333 [======>.......................] - ETA: 5:05 - loss: 0.6960 - acc: 0.5256
2368/9333 [======>.......................] - ETA: 5:03 - loss: 0.6958 - acc: 0.5266
2432/9333 [======>.......................] - ETA: 5:02 - loss: 0.6949 - acc: 0.5304
2496/9333 [=======>......................] - ETA: 4:59 - loss: 0.6951 - acc: 0.5300
2560/9333 [=======>......................] - ETA: 4:56 - loss: 0.6951 - acc: 0.5305
2624/9333 [=======>......................] - ETA: 4:54 - loss: 0.6945 - acc: 0.5312
2688/9333 [=======>......................] - ETA: 4:54 - loss: 0.6955 - acc: 0.5283
2752/9333 [=======>......................] - ETA: 4:54 - loss: 0.6947 - acc: 0.5305
2816/9333 [========>.....................] - ETA: 4:51 - loss: 0.6949 - acc: 0.5288
2880/9333 [========>.....................] - ETA: 4:49 - loss: 0.6947 - acc: 0.5299
2944/9333 [========>.....................] - ETA: 4:46 - loss: 0.6947 - acc: 0.5292
3008/9333 [========>.....................] - ETA: 4:45 - loss: 0.6942 - acc: 0.5309
3072/9333 [========>.....................] - ETA: 4:43 - loss: 0.6941 - acc: 0.5290
3136/9333 [=========>....................] - ETA: 4:42 - loss: 0.6942 - acc: 0.5271
3200/9333 [=========>....................] - ETA: 4:40 - loss: 0.6943 - acc: 0.5278
3264/9333 [=========>....................] - ETA: 4:37 - loss: 0.6949 - acc: 0.5260
3328/9333 [=========>....................] - ETA: 4:35 - loss: 0.6947 - acc: 0.5255
3392/9333 [=========>....................] - ETA: 4:32 - loss: 0.6949 - acc: 0.5259
3456/9333 [==========>...................] - ETA: 4:30 - loss: 0.6947 - acc: 0.5275
3520/9333 [==========>...................] - ETA: 4:27 - loss: 0.6945 - acc: 0.5276
3584/9333 [==========>...................] - ETA: 4:25 - loss: 0.6946 - acc: 0.5268
3648/9333 [==========>...................] - ETA: 4:22 - loss: 0.6945 - acc: 0.5266
3712/9333 [==========>...................] - ETA: 4:20 - loss: 0.6945 - acc: 0.5275
3776/9333 [===========>..................] - ETA: 4:17 - loss: 0.6948 - acc: 0.5260
3840/9333 [===========>..................] - ETA: 4:15 - loss: 0.6945 - acc: 0.5268
3904/9333 [===========>..................] - ETA: 4:13 - loss: 0.6943 - acc: 0.5282
3968/9333 [===========>..................] - ETA: 4:10 - loss: 0.6943 - acc: 0.5277
4032/9333 [===========>..................] - ETA: 4:07 - loss: 0.6941 - acc: 0.5283
4096/9333 [============>.................] - ETA: 4:05 - loss: 0.6938 - acc: 0.5293
4160/9333 [============>.................] - ETA: 4:03 - loss: 0.6940 - acc: 0.5298
4224/9333 [============>.................] - ETA: 3:59 - loss: 0.6938 - acc: 0.5296
4288/9333 [============>.................] - ETA: 3:56 - loss: 0.6943 - acc: 0.5282
4352/9333 [============>.................] - ETA: 3:53 - loss: 0.6942 - acc: 0.5294
4416/9333 [=============>................] - ETA: 3:51 - loss: 0.6944 - acc: 0.5297
4480/9333 [=============>................] - ETA: 3:48 - loss: 0.6941 - acc: 0.5306
4544/9333 [=============>................] - ETA: 3:45 - loss: 0.6938 - acc: 0.5308
4608/9333 [=============>................] - ETA: 3:42 - loss: 0.6938 - acc: 0.5308
4672/9333 [==============>...............] - ETA: 3:39 - loss: 0.6937 - acc: 0.5306
4736/9333 [==============>...............] - ETA: 3:36 - loss: 0.6936 - acc: 0.5304
4800/9333 [==============>...............] - ETA: 3:33 - loss: 0.6938 - acc: 0.5308
4864/9333 [==============>...............] - ETA: 3:30 - loss: 0.6938 - acc: 0.5306
4928/9333 [==============>...............] - ETA: 3:27 - loss: 0.6940 - acc: 0.5302
4992/9333 [===============>..............] - ETA: 3:25 - loss: 0.6938 - acc: 0.5304
5056/9333 [===============>..............] - ETA: 3:22 - loss: 0.6936 - acc: 0.5311
5120/9333 [===============>..............] - ETA: 3:19 - loss: 0.6935 - acc: 0.5309
5184/9333 [===============>..............] - ETA: 3:16 - loss: 0.6938 - acc: 0.5297
5248/9333 [===============>..............] - ETA: 3:13 - loss: 0.6939 - acc: 0.5297
5312/9333 [================>.............] - ETA: 3:10 - loss: 0.6938 - acc: 0.5294
5376/9333 [================>.............] - ETA: 3:07 - loss: 0.6937 - acc: 0.5298
5440/9333 [================>.............] - ETA: 3:04 - loss: 0.6938 - acc: 0.5292
5504/9333 [================>.............] - ETA: 3:01 - loss: 0.6940 - acc: 0.5283
5568/9333 [================>.............] - ETA: 2:58 - loss: 0.6942 - acc: 0.5275
5632/9333 [=================>............] - ETA: 2:55 - loss: 0.6938 - acc: 0.5286
5696/9333 [=================>............] - ETA: 2:52 - loss: 0.6939 - acc: 0.5286
5760/9333 [=================>............] - ETA: 2:49 - loss: 0.6938 - acc: 0.5285
5824/9333 [=================>............] - ETA: 2:46 - loss: 0.6939 - acc: 0.5283
5888/9333 [=================>............] - ETA: 2:43 - loss: 0.6938 - acc: 0.5279
5952/9333 [==================>...........] - ETA: 2:40 - loss: 0.6938 - acc: 0.5279
6016/9333 [==================>...........] - ETA: 2:37 - loss: 0.6941 - acc: 0.5268
6080/9333 [==================>...........] - ETA: 2:34 - loss: 0.6940 - acc: 0.5271
6144/9333 [==================>...........] - ETA: 2:31 - loss: 0.6937 - acc: 0.5278
6208/9333 [==================>...........] - ETA: 2:28 - loss: 0.6941 - acc: 0.5271
6272/9333 [===================>..........] - ETA: 2:25 - loss: 0.6941 - acc: 0.5271
6336/9333 [===================>..........] - ETA: 2:22 - loss: 0.6939 - acc: 0.5278
6400/9333 [===================>..........] - ETA: 2:19 - loss: 0.6940 - acc: 0.5275
6464/9333 [===================>..........] - ETA: 2:16 - loss: 0.6941 - acc: 0.5263
6528/9333 [===================>..........] - ETA: 2:13 - loss: 0.6940 - acc: 0.5271
6592/9333 [====================>.........] - ETA: 2:10 - loss: 0.6938 - acc: 0.5272
6656/9333 [====================>.........] - ETA: 2:07 - loss: 0.6936 - acc: 0.5279
6720/9333 [====================>.........] - ETA: 2:04 - loss: 0.6938 - acc: 0.5271
6784/9333 [====================>.........] - ETA: 2:01 - loss: 0.6938 - acc: 0.5267
6848/9333 [=====================>........] - ETA: 1:58 - loss: 0.6939 - acc: 0.5264
6912/9333 [=====================>........] - ETA: 1:55 - loss: 0.6942 - acc: 0.5256
6976/9333 [=====================>........] - ETA: 1:52 - loss: 0.6942 - acc: 0.5262
7040/9333 [=====================>........] - ETA: 1:49 - loss: 0.6938 - acc: 0.5281
7104/9333 [=====================>........] - ETA: 1:46 - loss: 0.6939 - acc: 0.5273
7168/9333 [======================>.......] - ETA: 1:43 - loss: 0.6937 - acc: 0.5276
7232/9333 [======================>.......] - ETA: 1:40 - loss: 0.6938 - acc: 0.5275
7296/9333 [======================>.......] - ETA: 1:37 - loss: 0.6937 - acc: 0.5273
7360/9333 [======================>.......] - ETA: 1:34 - loss: 0.6937 - acc: 0.5276
7424/9333 [======================>.......] - ETA: 1:31 - loss: 0.6936 - acc: 0.5277
7488/9333 [=======================>......] - ETA: 1:28 - loss: 0.6935 - acc: 0.5276
7552/9333 [=======================>......] - ETA: 1:25 - loss: 0.6935 - acc: 0.5275
7616/9333 [=======================>......] - ETA: 1:22 - loss: 0.6934 - acc: 0.5280
7680/9333 [=======================>......] - ETA: 1:19 - loss: 0.6934 - acc: 0.5283
7744/9333 [=======================>......] - ETA: 1:16 - loss: 0.6934 - acc: 0.5284
7808/9333 [========================>.....] - ETA: 1:13 - loss: 0.6933 - acc: 0.5282
7872/9333 [========================>.....] - ETA: 1:09 - loss: 0.6934 - acc: 0.5278
7936/9333 [========================>.....] - ETA: 1:06 - loss: 0.6934 - acc: 0.5272
8000/9333 [========================>.....] - ETA: 1:03 - loss: 0.6932 - acc: 0.5276
8064/9333 [========================>.....] - ETA: 1:00 - loss: 0.6931 - acc: 0.5274
8128/9333 [=========================>....] - ETA: 57s - loss: 0.6933 - acc: 0.5271 
8192/9333 [=========================>....] - ETA: 54s - loss: 0.6932 - acc: 0.5271
8256/9333 [=========================>....] - ETA: 51s - loss: 0.6933 - acc: 0.5268
8320/9333 [=========================>....] - ETA: 48s - loss: 0.6933 - acc: 0.5268
8384/9333 [=========================>....] - ETA: 45s - loss: 0.6931 - acc: 0.5268
8448/9333 [==========================>...] - ETA: 42s - loss: 0.6932 - acc: 0.5271
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6931 - acc: 0.5276
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6931 - acc: 0.5269
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6931 - acc: 0.5273
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6928 - acc: 0.5279
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6926 - acc: 0.5281
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6926 - acc: 0.5282
8896/9333 [===========================>..] - ETA: 20s - loss: 0.6926 - acc: 0.5289
8960/9333 [===========================>..] - ETA: 17s - loss: 0.6930 - acc: 0.5283
9024/9333 [============================>.] - ETA: 14s - loss: 0.6933 - acc: 0.5281
9088/9333 [============================>.] - ETA: 11s - loss: 0.6934 - acc: 0.5277
9152/9333 [============================>.] - ETA: 8s - loss: 0.6938 - acc: 0.5273 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6936 - acc: 0.5279
9280/9333 [============================>.] - ETA: 2s - loss: 0.6935 - acc: 0.5281
9333/9333 [==============================] - 466s 50ms/step - loss: 0.6936 - acc: 0.5277 - val_loss: 0.6910 - val_acc: 0.5265

Epoch 00003: val_acc improved from 0.52459 to 0.52652, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window03/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 4/10

  64/9333 [..............................] - ETA: 6:32 - loss: 0.6945 - acc: 0.4844
 128/9333 [..............................] - ETA: 6:36 - loss: 0.6896 - acc: 0.5078
 192/9333 [..............................] - ETA: 6:41 - loss: 0.7013 - acc: 0.5000
 256/9333 [..............................] - ETA: 6:30 - loss: 0.7065 - acc: 0.4844
 320/9333 [>.............................] - ETA: 6:31 - loss: 0.7028 - acc: 0.5000
 384/9333 [>.............................] - ETA: 6:34 - loss: 0.7022 - acc: 0.5026
 448/9333 [>.............................] - ETA: 7:03 - loss: 0.7018 - acc: 0.5045
 512/9333 [>.............................] - ETA: 7:06 - loss: 0.7008 - acc: 0.5117
 576/9333 [>.............................] - ETA: 6:59 - loss: 0.7015 - acc: 0.5000
 640/9333 [=>............................] - ETA: 6:53 - loss: 0.7017 - acc: 0.4922
 704/9333 [=>............................] - ETA: 6:46 - loss: 0.7011 - acc: 0.4901
 768/9333 [=>............................] - ETA: 6:39 - loss: 0.6987 - acc: 0.4948
 832/9333 [=>............................] - ETA: 6:44 - loss: 0.6985 - acc: 0.4928
 896/9333 [=>............................] - ETA: 6:40 - loss: 0.6978 - acc: 0.4967
 960/9333 [==>...........................] - ETA: 6:33 - loss: 0.6981 - acc: 0.4958
1024/9333 [==>...........................] - ETA: 6:30 - loss: 0.6979 - acc: 0.4922
1088/9333 [==>...........................] - ETA: 6:28 - loss: 0.6968 - acc: 0.4972
1152/9333 [==>...........................] - ETA: 6:25 - loss: 0.6960 - acc: 0.4983
1216/9333 [==>...........................] - ETA: 6:27 - loss: 0.6974 - acc: 0.4926
1280/9333 [===>..........................] - ETA: 6:21 - loss: 0.6969 - acc: 0.4922
1344/9333 [===>..........................] - ETA: 6:18 - loss: 0.6967 - acc: 0.4948
1408/9333 [===>..........................] - ETA: 6:13 - loss: 0.6967 - acc: 0.4972
1472/9333 [===>..........................] - ETA: 6:10 - loss: 0.6970 - acc: 0.4973
1536/9333 [===>..........................] - ETA: 6:08 - loss: 0.6982 - acc: 0.4941
1600/9333 [====>.........................] - ETA: 6:09 - loss: 0.6984 - acc: 0.4938
1664/9333 [====>.........................] - ETA: 6:06 - loss: 0.6976 - acc: 0.4988
1728/9333 [====>.........................] - ETA: 6:02 - loss: 0.6969 - acc: 0.5006
1792/9333 [====>.........................] - ETA: 5:58 - loss: 0.6967 - acc: 0.4994
1856/9333 [====>.........................] - ETA: 5:53 - loss: 0.6970 - acc: 0.4978
1920/9333 [=====>........................] - ETA: 5:51 - loss: 0.6968 - acc: 0.4995
1984/9333 [=====>........................] - ETA: 5:48 - loss: 0.6964 - acc: 0.5020
2048/9333 [=====>........................] - ETA: 5:47 - loss: 0.6965 - acc: 0.5024
2112/9333 [=====>........................] - ETA: 5:43 - loss: 0.6961 - acc: 0.5047
2176/9333 [=====>........................] - ETA: 5:40 - loss: 0.6956 - acc: 0.5064
2240/9333 [======>.......................] - ETA: 5:37 - loss: 0.6953 - acc: 0.5080
2304/9333 [======>.......................] - ETA: 5:34 - loss: 0.6958 - acc: 0.5043
2368/9333 [======>.......................] - ETA: 5:31 - loss: 0.6953 - acc: 0.5063
2432/9333 [======>.......................] - ETA: 5:27 - loss: 0.6951 - acc: 0.5066
2496/9333 [=======>......................] - ETA: 5:25 - loss: 0.6952 - acc: 0.5068
2560/9333 [=======>......................] - ETA: 5:21 - loss: 0.6950 - acc: 0.5066
2624/9333 [=======>......................] - ETA: 5:17 - loss: 0.6948 - acc: 0.5042
2688/9333 [=======>......................] - ETA: 5:13 - loss: 0.6943 - acc: 0.5071
2752/9333 [=======>......................] - ETA: 5:10 - loss: 0.6937 - acc: 0.5087
2816/9333 [========>.....................] - ETA: 5:09 - loss: 0.6938 - acc: 0.5092
2880/9333 [========>.....................] - ETA: 5:05 - loss: 0.6937 - acc: 0.5094
2944/9333 [========>.....................] - ETA: 5:02 - loss: 0.6938 - acc: 0.5078
3008/9333 [========>.....................] - ETA: 4:59 - loss: 0.6942 - acc: 0.5060
3072/9333 [========>.....................] - ETA: 4:55 - loss: 0.6943 - acc: 0.5072
3136/9333 [=========>....................] - ETA: 4:51 - loss: 0.6946 - acc: 0.5051
3200/9333 [=========>....................] - ETA: 4:49 - loss: 0.6939 - acc: 0.5072
3264/9333 [=========>....................] - ETA: 4:47 - loss: 0.6938 - acc: 0.5077
3328/9333 [=========>....................] - ETA: 4:45 - loss: 0.6934 - acc: 0.5078
3392/9333 [=========>....................] - ETA: 4:41 - loss: 0.6928 - acc: 0.5115
3456/9333 [==========>...................] - ETA: 4:38 - loss: 0.6927 - acc: 0.5110
3520/9333 [==========>...................] - ETA: 4:34 - loss: 0.6924 - acc: 0.5128
3584/9333 [==========>...................] - ETA: 4:31 - loss: 0.6925 - acc: 0.5120
3648/9333 [==========>...................] - ETA: 4:28 - loss: 0.6924 - acc: 0.5132
3712/9333 [==========>...................] - ETA: 4:27 - loss: 0.6927 - acc: 0.5132
3776/9333 [===========>..................] - ETA: 4:24 - loss: 0.6932 - acc: 0.5117
3840/9333 [===========>..................] - ETA: 4:21 - loss: 0.6931 - acc: 0.5120
3904/9333 [===========>..................] - ETA: 4:18 - loss: 0.6933 - acc: 0.5126
3968/9333 [===========>..................] - ETA: 4:14 - loss: 0.6931 - acc: 0.5136
4032/9333 [===========>..................] - ETA: 4:11 - loss: 0.6937 - acc: 0.5124
4096/9333 [============>.................] - ETA: 4:09 - loss: 0.6933 - acc: 0.5129
4160/9333 [============>.................] - ETA: 4:06 - loss: 0.6934 - acc: 0.5123
4224/9333 [============>.................] - ETA: 4:03 - loss: 0.6933 - acc: 0.5128
4288/9333 [============>.................] - ETA: 4:00 - loss: 0.6928 - acc: 0.5142
4352/9333 [============>.................] - ETA: 3:57 - loss: 0.6928 - acc: 0.5149
4416/9333 [=============>................] - ETA: 3:53 - loss: 0.6931 - acc: 0.5138
4480/9333 [=============>................] - ETA: 3:51 - loss: 0.6928 - acc: 0.5145
4544/9333 [=============>................] - ETA: 3:47 - loss: 0.6933 - acc: 0.5143
4608/9333 [=============>................] - ETA: 3:45 - loss: 0.6930 - acc: 0.5154
4672/9333 [==============>...............] - ETA: 3:42 - loss: 0.6927 - acc: 0.5161
4736/9333 [==============>...............] - ETA: 3:39 - loss: 0.6927 - acc: 0.5167
4800/9333 [==============>...............] - ETA: 3:36 - loss: 0.6929 - acc: 0.5156
4864/9333 [==============>...............] - ETA: 3:33 - loss: 0.6928 - acc: 0.5158
4928/9333 [==============>...............] - ETA: 3:30 - loss: 0.6927 - acc: 0.5166
4992/9333 [===============>..............] - ETA: 3:27 - loss: 0.6926 - acc: 0.5168
5056/9333 [===============>..............] - ETA: 3:24 - loss: 0.6927 - acc: 0.5166
5120/9333 [===============>..............] - ETA: 3:20 - loss: 0.6929 - acc: 0.5158
5184/9333 [===============>..............] - ETA: 3:18 - loss: 0.6932 - acc: 0.5154
5248/9333 [===============>..............] - ETA: 3:14 - loss: 0.6932 - acc: 0.5160
5312/9333 [================>.............] - ETA: 3:11 - loss: 0.6931 - acc: 0.5171
5376/9333 [================>.............] - ETA: 3:08 - loss: 0.6930 - acc: 0.5169
5440/9333 [================>.............] - ETA: 3:05 - loss: 0.6931 - acc: 0.5169
5504/9333 [================>.............] - ETA: 3:03 - loss: 0.6929 - acc: 0.5180
5568/9333 [================>.............] - ETA: 3:00 - loss: 0.6928 - acc: 0.5178
5632/9333 [=================>............] - ETA: 2:57 - loss: 0.6926 - acc: 0.5192
5696/9333 [=================>............] - ETA: 2:54 - loss: 0.6927 - acc: 0.5186
5760/9333 [=================>............] - ETA: 2:50 - loss: 0.6925 - acc: 0.5193
5824/9333 [=================>............] - ETA: 2:47 - loss: 0.6926 - acc: 0.5184
5888/9333 [=================>............] - ETA: 2:44 - loss: 0.6924 - acc: 0.5192
5952/9333 [==================>...........] - ETA: 2:41 - loss: 0.6924 - acc: 0.5192
6016/9333 [==================>...........] - ETA: 2:38 - loss: 0.6924 - acc: 0.5191
6080/9333 [==================>...........] - ETA: 2:35 - loss: 0.6925 - acc: 0.5178
6144/9333 [==================>...........] - ETA: 2:32 - loss: 0.6925 - acc: 0.5181
6208/9333 [==================>...........] - ETA: 2:29 - loss: 0.6925 - acc: 0.5184
6272/9333 [===================>..........] - ETA: 2:26 - loss: 0.6925 - acc: 0.5185
6336/9333 [===================>..........] - ETA: 2:23 - loss: 0.6925 - acc: 0.5180
6400/9333 [===================>..........] - ETA: 2:21 - loss: 0.6926 - acc: 0.5172
6464/9333 [===================>..........] - ETA: 2:18 - loss: 0.6927 - acc: 0.5170
6528/9333 [===================>..........] - ETA: 2:14 - loss: 0.6927 - acc: 0.5178
6592/9333 [====================>.........] - ETA: 2:11 - loss: 0.6927 - acc: 0.5174
6656/9333 [====================>.........] - ETA: 2:08 - loss: 0.6926 - acc: 0.5179
6720/9333 [====================>.........] - ETA: 2:05 - loss: 0.6924 - acc: 0.5186
6784/9333 [====================>.........] - ETA: 2:02 - loss: 0.6922 - acc: 0.5202
6848/9333 [=====================>........] - ETA: 1:59 - loss: 0.6923 - acc: 0.5203
6912/9333 [=====================>........] - ETA: 1:56 - loss: 0.6921 - acc: 0.5216
6976/9333 [=====================>........] - ETA: 1:53 - loss: 0.6921 - acc: 0.5216
7040/9333 [=====================>........] - ETA: 1:50 - loss: 0.6920 - acc: 0.5229
7104/9333 [=====================>........] - ETA: 1:46 - loss: 0.6921 - acc: 0.5227
7168/9333 [======================>.......] - ETA: 1:43 - loss: 0.6920 - acc: 0.5230
7232/9333 [======================>.......] - ETA: 1:40 - loss: 0.6918 - acc: 0.5236
7296/9333 [======================>.......] - ETA: 1:37 - loss: 0.6916 - acc: 0.5244
7360/9333 [======================>.......] - ETA: 1:34 - loss: 0.6916 - acc: 0.5247
7424/9333 [======================>.......] - ETA: 1:31 - loss: 0.6915 - acc: 0.5246
7488/9333 [=======================>......] - ETA: 1:28 - loss: 0.6915 - acc: 0.5246
7552/9333 [=======================>......] - ETA: 1:25 - loss: 0.6915 - acc: 0.5250
7616/9333 [=======================>......] - ETA: 1:22 - loss: 0.6915 - acc: 0.5255
7680/9333 [=======================>......] - ETA: 1:19 - loss: 0.6913 - acc: 0.5262
7744/9333 [=======================>......] - ETA: 1:16 - loss: 0.6913 - acc: 0.5270
7808/9333 [========================>.....] - ETA: 1:13 - loss: 0.6912 - acc: 0.5278
7872/9333 [========================>.....] - ETA: 1:10 - loss: 0.6914 - acc: 0.5273
7936/9333 [========================>.....] - ETA: 1:07 - loss: 0.6916 - acc: 0.5272
8000/9333 [========================>.....] - ETA: 1:04 - loss: 0.6916 - acc: 0.5274
8064/9333 [========================>.....] - ETA: 1:00 - loss: 0.6917 - acc: 0.5275
8128/9333 [=========================>....] - ETA: 57s - loss: 0.6916 - acc: 0.5274 
8192/9333 [=========================>....] - ETA: 55s - loss: 0.6918 - acc: 0.5267
8256/9333 [=========================>....] - ETA: 51s - loss: 0.6918 - acc: 0.5268
8320/9333 [=========================>....] - ETA: 48s - loss: 0.6919 - acc: 0.5262
8384/9333 [=========================>....] - ETA: 45s - loss: 0.6919 - acc: 0.5258
8448/9333 [==========================>...] - ETA: 42s - loss: 0.6919 - acc: 0.5254
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6920 - acc: 0.5251
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6920 - acc: 0.5253
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6921 - acc: 0.5251
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6921 - acc: 0.5250
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6920 - acc: 0.5250
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6920 - acc: 0.5246
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6919 - acc: 0.5247
8960/9333 [===========================>..] - ETA: 17s - loss: 0.6919 - acc: 0.5249
9024/9333 [============================>.] - ETA: 14s - loss: 0.6918 - acc: 0.5257
9088/9333 [============================>.] - ETA: 11s - loss: 0.6917 - acc: 0.5262
9152/9333 [============================>.] - ETA: 8s - loss: 0.6916 - acc: 0.5268 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6916 - acc: 0.5270
9280/9333 [============================>.] - ETA: 2s - loss: 0.6917 - acc: 0.5270
9333/9333 [==============================] - 469s 50ms/step - loss: 0.6917 - acc: 0.5265 - val_loss: 0.6883 - val_acc: 0.5323

Epoch 00004: val_acc improved from 0.52652 to 0.53230, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window03/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 5/10

  64/9333 [..............................] - ETA: 6:51 - loss: 0.6968 - acc: 0.5312
 128/9333 [..............................] - ETA: 7:13 - loss: 0.7005 - acc: 0.5078
 192/9333 [..............................] - ETA: 7:27 - loss: 0.6971 - acc: 0.5208
 256/9333 [..............................] - ETA: 7:20 - loss: 0.6927 - acc: 0.5312
 320/9333 [>.............................] - ETA: 7:08 - loss: 0.6925 - acc: 0.5312
 384/9333 [>.............................] - ETA: 7:01 - loss: 0.6895 - acc: 0.5417
 448/9333 [>.............................] - ETA: 6:58 - loss: 0.6918 - acc: 0.5379
 512/9333 [>.............................] - ETA: 6:52 - loss: 0.6888 - acc: 0.5508
 576/9333 [>.............................] - ETA: 6:49 - loss: 0.6865 - acc: 0.5625
 640/9333 [=>............................] - ETA: 6:52 - loss: 0.6861 - acc: 0.5578
 704/9333 [=>............................] - ETA: 6:53 - loss: 0.6860 - acc: 0.5526
 768/9333 [=>............................] - ETA: 6:57 - loss: 0.6855 - acc: 0.5586
 832/9333 [=>............................] - ETA: 6:52 - loss: 0.6900 - acc: 0.5445
 896/9333 [=>............................] - ETA: 6:46 - loss: 0.6905 - acc: 0.5435
 960/9333 [==>...........................] - ETA: 6:42 - loss: 0.6894 - acc: 0.5458
1024/9333 [==>...........................] - ETA: 6:35 - loss: 0.6898 - acc: 0.5439
1088/9333 [==>...........................] - ETA: 6:29 - loss: 0.6903 - acc: 0.5432
1152/9333 [==>...........................] - ETA: 6:25 - loss: 0.6898 - acc: 0.5425
1216/9333 [==>...........................] - ETA: 6:27 - loss: 0.6920 - acc: 0.5354
1280/9333 [===>..........................] - ETA: 6:24 - loss: 0.6913 - acc: 0.5414
1344/9333 [===>..........................] - ETA: 6:20 - loss: 0.6903 - acc: 0.5461
1408/9333 [===>..........................] - ETA: 6:16 - loss: 0.6909 - acc: 0.5440
1472/9333 [===>..........................] - ETA: 6:12 - loss: 0.6901 - acc: 0.5442
1536/9333 [===>..........................] - ETA: 6:08 - loss: 0.6903 - acc: 0.5423
1600/9333 [====>.........................] - ETA: 6:09 - loss: 0.6900 - acc: 0.5425
1664/9333 [====>.........................] - ETA: 6:07 - loss: 0.6898 - acc: 0.5421
1728/9333 [====>.........................] - ETA: 6:05 - loss: 0.6895 - acc: 0.5440
1792/9333 [====>.........................] - ETA: 6:03 - loss: 0.6902 - acc: 0.5413
1856/9333 [====>.........................] - ETA: 6:00 - loss: 0.6900 - acc: 0.5436
1920/9333 [=====>........................] - ETA: 5:58 - loss: 0.6898 - acc: 0.5448
1984/9333 [=====>........................] - ETA: 5:56 - loss: 0.6896 - acc: 0.5464
2048/9333 [=====>........................] - ETA: 5:52 - loss: 0.6896 - acc: 0.5454
2112/9333 [=====>........................] - ETA: 5:48 - loss: 0.6896 - acc: 0.5436
2176/9333 [=====>........................] - ETA: 5:45 - loss: 0.6894 - acc: 0.5446
2240/9333 [======>.......................] - ETA: 5:43 - loss: 0.6894 - acc: 0.5433
2304/9333 [======>.......................] - ETA: 5:42 - loss: 0.6897 - acc: 0.5421
2368/9333 [======>.......................] - ETA: 5:40 - loss: 0.6904 - acc: 0.5405
2432/9333 [======>.......................] - ETA: 5:37 - loss: 0.6903 - acc: 0.5419
2496/9333 [=======>......................] - ETA: 5:33 - loss: 0.6903 - acc: 0.5417
2560/9333 [=======>......................] - ETA: 5:28 - loss: 0.6899 - acc: 0.5422
2624/9333 [=======>......................] - ETA: 5:26 - loss: 0.6896 - acc: 0.5419
2688/9333 [=======>......................] - ETA: 5:24 - loss: 0.6896 - acc: 0.5413
2752/9333 [=======>......................] - ETA: 5:20 - loss: 0.6896 - acc: 0.5403
2816/9333 [========>.....................] - ETA: 5:17 - loss: 0.6898 - acc: 0.5398
2880/9333 [========>.....................] - ETA: 5:13 - loss: 0.6901 - acc: 0.5410
2944/9333 [========>.....................] - ETA: 5:10 - loss: 0.6902 - acc: 0.5418
3008/9333 [========>.....................] - ETA: 5:06 - loss: 0.6901 - acc: 0.5412
3072/9333 [========>.....................] - ETA: 5:02 - loss: 0.6900 - acc: 0.5420
3136/9333 [=========>....................] - ETA: 4:59 - loss: 0.6897 - acc: 0.5437
3200/9333 [=========>....................] - ETA: 4:57 - loss: 0.6898 - acc: 0.5428
3264/9333 [=========>....................] - ETA: 4:55 - loss: 0.6903 - acc: 0.5407
3328/9333 [=========>....................] - ETA: 4:52 - loss: 0.6910 - acc: 0.5385
3392/9333 [=========>....................] - ETA: 4:48 - loss: 0.6908 - acc: 0.5398
3456/9333 [==========>...................] - ETA: 4:45 - loss: 0.6905 - acc: 0.5408
3520/9333 [==========>...................] - ETA: 4:42 - loss: 0.6904 - acc: 0.5395
3584/9333 [==========>...................] - ETA: 4:38 - loss: 0.6902 - acc: 0.5407
3648/9333 [==========>...................] - ETA: 4:35 - loss: 0.6903 - acc: 0.5406
3712/9333 [==========>...................] - ETA: 4:32 - loss: 0.6905 - acc: 0.5396
3776/9333 [===========>..................] - ETA: 4:29 - loss: 0.6905 - acc: 0.5389
3840/9333 [===========>..................] - ETA: 4:27 - loss: 0.6900 - acc: 0.5409
3904/9333 [===========>..................] - ETA: 4:24 - loss: 0.6899 - acc: 0.5415
3968/9333 [===========>..................] - ETA: 4:21 - loss: 0.6898 - acc: 0.5411
4032/9333 [===========>..................] - ETA: 4:17 - loss: 0.6900 - acc: 0.5407
4096/9333 [============>.................] - ETA: 4:14 - loss: 0.6898 - acc: 0.5403
4160/9333 [============>.................] - ETA: 4:11 - loss: 0.6896 - acc: 0.5409
4224/9333 [============>.................] - ETA: 4:08 - loss: 0.6895 - acc: 0.5405
4288/9333 [============>.................] - ETA: 4:05 - loss: 0.6893 - acc: 0.5410
4352/9333 [============>.................] - ETA: 4:02 - loss: 0.6897 - acc: 0.5398
4416/9333 [=============>................] - ETA: 3:58 - loss: 0.6896 - acc: 0.5396
4480/9333 [=============>................] - ETA: 3:55 - loss: 0.6897 - acc: 0.5386
4544/9333 [=============>................] - ETA: 3:52 - loss: 0.6898 - acc: 0.5390
4608/9333 [=============>................] - ETA: 3:49 - loss: 0.6894 - acc: 0.5401
4672/9333 [==============>...............] - ETA: 3:46 - loss: 0.6895 - acc: 0.5405
4736/9333 [==============>...............] - ETA: 3:43 - loss: 0.6896 - acc: 0.5397
4800/9333 [==============>...............] - ETA: 3:39 - loss: 0.6898 - acc: 0.5392
4864/9333 [==============>...............] - ETA: 3:36 - loss: 0.6899 - acc: 0.5389
4928/9333 [==============>...............] - ETA: 3:33 - loss: 0.6898 - acc: 0.5384
4992/9333 [===============>..............] - ETA: 3:29 - loss: 0.6895 - acc: 0.5389
5056/9333 [===============>..............] - ETA: 3:27 - loss: 0.6898 - acc: 0.5382
5120/9333 [===============>..............] - ETA: 3:24 - loss: 0.6898 - acc: 0.5377
5184/9333 [===============>..............] - ETA: 3:21 - loss: 0.6898 - acc: 0.5374
5248/9333 [===============>..............] - ETA: 3:17 - loss: 0.6899 - acc: 0.5368
5312/9333 [================>.............] - ETA: 3:14 - loss: 0.6899 - acc: 0.5369
5376/9333 [================>.............] - ETA: 3:11 - loss: 0.6896 - acc: 0.5387
5440/9333 [================>.............] - ETA: 3:08 - loss: 0.6896 - acc: 0.5390
5504/9333 [================>.............] - ETA: 3:05 - loss: 0.6896 - acc: 0.5389
5568/9333 [================>.............] - ETA: 3:02 - loss: 0.6898 - acc: 0.5386
5632/9333 [=================>............] - ETA: 2:59 - loss: 0.6898 - acc: 0.5384
5696/9333 [=================>............] - ETA: 2:56 - loss: 0.6897 - acc: 0.5388
5760/9333 [=================>............] - ETA: 2:53 - loss: 0.6899 - acc: 0.5372
5824/9333 [=================>............] - ETA: 2:50 - loss: 0.6895 - acc: 0.5386
5888/9333 [=================>............] - ETA: 2:47 - loss: 0.6894 - acc: 0.5392
5952/9333 [==================>...........] - ETA: 2:44 - loss: 0.6896 - acc: 0.5383
6016/9333 [==================>...........] - ETA: 2:41 - loss: 0.6895 - acc: 0.5387
6080/9333 [==================>...........] - ETA: 2:37 - loss: 0.6894 - acc: 0.5391
6144/9333 [==================>...........] - ETA: 2:34 - loss: 0.6893 - acc: 0.5394
6208/9333 [==================>...........] - ETA: 2:31 - loss: 0.6894 - acc: 0.5388
6272/9333 [===================>..........] - ETA: 2:28 - loss: 0.6894 - acc: 0.5379
6336/9333 [===================>..........] - ETA: 2:25 - loss: 0.6896 - acc: 0.5372
6400/9333 [===================>..........] - ETA: 2:22 - loss: 0.6894 - acc: 0.5375
6464/9333 [===================>..........] - ETA: 2:19 - loss: 0.6894 - acc: 0.5376
6528/9333 [===================>..........] - ETA: 2:16 - loss: 0.6894 - acc: 0.5380
6592/9333 [====================>.........] - ETA: 2:12 - loss: 0.6894 - acc: 0.5385
6656/9333 [====================>.........] - ETA: 2:09 - loss: 0.6896 - acc: 0.5383
6720/9333 [====================>.........] - ETA: 2:07 - loss: 0.6897 - acc: 0.5384
6784/9333 [====================>.........] - ETA: 2:03 - loss: 0.6897 - acc: 0.5388
6848/9333 [=====================>........] - ETA: 2:00 - loss: 0.6898 - acc: 0.5390
6912/9333 [=====================>........] - ETA: 1:57 - loss: 0.6896 - acc: 0.5395
6976/9333 [=====================>........] - ETA: 1:54 - loss: 0.6895 - acc: 0.5396
7040/9333 [=====================>........] - ETA: 1:51 - loss: 0.6894 - acc: 0.5405
7104/9333 [=====================>........] - ETA: 1:48 - loss: 0.6894 - acc: 0.5405
7168/9333 [======================>.......] - ETA: 1:45 - loss: 0.6895 - acc: 0.5406
7232/9333 [======================>.......] - ETA: 1:42 - loss: 0.6895 - acc: 0.5400
7296/9333 [======================>.......] - ETA: 1:38 - loss: 0.6892 - acc: 0.5406
7360/9333 [======================>.......] - ETA: 1:35 - loss: 0.6892 - acc: 0.5408
7424/9333 [======================>.......] - ETA: 1:32 - loss: 0.6891 - acc: 0.5405
7488/9333 [=======================>......] - ETA: 1:29 - loss: 0.6891 - acc: 0.5399
7552/9333 [=======================>......] - ETA: 1:26 - loss: 0.6892 - acc: 0.5392
7616/9333 [=======================>......] - ETA: 1:23 - loss: 0.6891 - acc: 0.5395
7680/9333 [=======================>......] - ETA: 1:20 - loss: 0.6890 - acc: 0.5398
7744/9333 [=======================>......] - ETA: 1:17 - loss: 0.6892 - acc: 0.5389
7808/9333 [========================>.....] - ETA: 1:13 - loss: 0.6891 - acc: 0.5389
7872/9333 [========================>.....] - ETA: 1:10 - loss: 0.6892 - acc: 0.5386
7936/9333 [========================>.....] - ETA: 1:07 - loss: 0.6892 - acc: 0.5381
8000/9333 [========================>.....] - ETA: 1:04 - loss: 0.6891 - acc: 0.5387
8064/9333 [========================>.....] - ETA: 1:01 - loss: 0.6894 - acc: 0.5376
8128/9333 [=========================>....] - ETA: 58s - loss: 0.6894 - acc: 0.5379 
8192/9333 [=========================>....] - ETA: 55s - loss: 0.6892 - acc: 0.5382
8256/9333 [=========================>....] - ETA: 52s - loss: 0.6893 - acc: 0.5383
8320/9333 [=========================>....] - ETA: 48s - loss: 0.6892 - acc: 0.5383
8384/9333 [=========================>....] - ETA: 45s - loss: 0.6892 - acc: 0.5384
8448/9333 [==========================>...] - ETA: 42s - loss: 0.6892 - acc: 0.5382
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6891 - acc: 0.5383
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6893 - acc: 0.5372
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6891 - acc: 0.5383
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6890 - acc: 0.5384
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6889 - acc: 0.5384
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6888 - acc: 0.5386
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6888 - acc: 0.5384
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6887 - acc: 0.5392
9024/9333 [============================>.] - ETA: 14s - loss: 0.6888 - acc: 0.5387
9088/9333 [============================>.] - ETA: 11s - loss: 0.6890 - acc: 0.5381
9152/9333 [============================>.] - ETA: 8s - loss: 0.6893 - acc: 0.5376 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6895 - acc: 0.5371
9280/9333 [============================>.] - ETA: 2s - loss: 0.6895 - acc: 0.5372
9333/9333 [==============================] - 469s 50ms/step - loss: 0.6894 - acc: 0.5374 - val_loss: 0.6882 - val_acc: 0.5400

Epoch 00005: val_acc improved from 0.53230 to 0.54002, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window03/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 6/10

  64/9333 [..............................] - ETA: 6:29 - loss: 0.6753 - acc: 0.6094
 128/9333 [..............................] - ETA: 6:41 - loss: 0.6691 - acc: 0.6094
 192/9333 [..............................] - ETA: 6:48 - loss: 0.6678 - acc: 0.6146
 256/9333 [..............................] - ETA: 6:47 - loss: 0.6737 - acc: 0.6094
 320/9333 [>.............................] - ETA: 7:00 - loss: 0.6799 - acc: 0.5844
 384/9333 [>.............................] - ETA: 7:03 - loss: 0.6837 - acc: 0.5807
 448/9333 [>.............................] - ETA: 6:59 - loss: 0.6849 - acc: 0.5647
 512/9333 [>.............................] - ETA: 6:56 - loss: 0.6833 - acc: 0.5723
 576/9333 [>.............................] - ETA: 6:48 - loss: 0.6852 - acc: 0.5660
 640/9333 [=>............................] - ETA: 6:52 - loss: 0.6861 - acc: 0.5594
 704/9333 [=>............................] - ETA: 6:50 - loss: 0.6874 - acc: 0.5554
 768/9333 [=>............................] - ETA: 6:49 - loss: 0.6905 - acc: 0.5508
 832/9333 [=>............................] - ETA: 6:45 - loss: 0.6905 - acc: 0.5481
 896/9333 [=>............................] - ETA: 6:38 - loss: 0.6899 - acc: 0.5502
 960/9333 [==>...........................] - ETA: 6:33 - loss: 0.6890 - acc: 0.5552
1024/9333 [==>...........................] - ETA: 6:28 - loss: 0.6887 - acc: 0.5586
1088/9333 [==>...........................] - ETA: 6:36 - loss: 0.6879 - acc: 0.5597
1152/9333 [==>...........................] - ETA: 6:36 - loss: 0.6867 - acc: 0.5625
1216/9333 [==>...........................] - ETA: 6:32 - loss: 0.6874 - acc: 0.5584
1280/9333 [===>..........................] - ETA: 6:27 - loss: 0.6871 - acc: 0.5602
1344/9333 [===>..........................] - ETA: 6:23 - loss: 0.6861 - acc: 0.5618
1408/9333 [===>..........................] - ETA: 6:24 - loss: 0.6862 - acc: 0.5632
1472/9333 [===>..........................] - ETA: 6:26 - loss: 0.6866 - acc: 0.5611
1536/9333 [===>..........................] - ETA: 6:21 - loss: 0.6866 - acc: 0.5592
1600/9333 [====>.........................] - ETA: 6:16 - loss: 0.6863 - acc: 0.5587
1664/9333 [====>.........................] - ETA: 6:10 - loss: 0.6859 - acc: 0.5595
1728/9333 [====>.........................] - ETA: 6:07 - loss: 0.6858 - acc: 0.5590
1792/9333 [====>.........................] - ETA: 6:03 - loss: 0.6856 - acc: 0.5603
1856/9333 [====>.........................] - ETA: 5:59 - loss: 0.6856 - acc: 0.5587
1920/9333 [=====>........................] - ETA: 5:57 - loss: 0.6856 - acc: 0.5594
1984/9333 [=====>........................] - ETA: 5:54 - loss: 0.6857 - acc: 0.5595
2048/9333 [=====>........................] - ETA: 5:50 - loss: 0.6852 - acc: 0.5610
2112/9333 [=====>........................] - ETA: 5:50 - loss: 0.6859 - acc: 0.5563
2176/9333 [=====>........................] - ETA: 5:47 - loss: 0.6858 - acc: 0.5579
2240/9333 [======>.......................] - ETA: 5:43 - loss: 0.6853 - acc: 0.5589
2304/9333 [======>.......................] - ETA: 5:39 - loss: 0.6853 - acc: 0.5573
2368/9333 [======>.......................] - ETA: 5:36 - loss: 0.6854 - acc: 0.5553
2432/9333 [======>.......................] - ETA: 5:34 - loss: 0.6859 - acc: 0.5551
2496/9333 [=======>......................] - ETA: 5:31 - loss: 0.6857 - acc: 0.5549
2560/9333 [=======>......................] - ETA: 5:28 - loss: 0.6859 - acc: 0.5543
2624/9333 [=======>......................] - ETA: 5:25 - loss: 0.6861 - acc: 0.5530
2688/9333 [=======>......................] - ETA: 5:22 - loss: 0.6863 - acc: 0.5521
2752/9333 [=======>......................] - ETA: 5:19 - loss: 0.6860 - acc: 0.5531
2816/9333 [========>.....................] - ETA: 5:17 - loss: 0.6859 - acc: 0.5540
2880/9333 [========>.....................] - ETA: 5:15 - loss: 0.6856 - acc: 0.5552
2944/9333 [========>.....................] - ETA: 5:12 - loss: 0.6855 - acc: 0.5543
3008/9333 [========>.....................] - ETA: 5:08 - loss: 0.6848 - acc: 0.5568
3072/9333 [========>.....................] - ETA: 5:05 - loss: 0.6849 - acc: 0.5573
3136/9333 [=========>....................] - ETA: 5:02 - loss: 0.6851 - acc: 0.5571
3200/9333 [=========>....................] - ETA: 5:00 - loss: 0.6852 - acc: 0.5566
3264/9333 [=========>....................] - ETA: 4:56 - loss: 0.6851 - acc: 0.5570
3328/9333 [=========>....................] - ETA: 4:52 - loss: 0.6849 - acc: 0.5574
3392/9333 [=========>....................] - ETA: 4:49 - loss: 0.6854 - acc: 0.5563
3456/9333 [==========>...................] - ETA: 4:45 - loss: 0.6852 - acc: 0.5570
3520/9333 [==========>...................] - ETA: 4:42 - loss: 0.6852 - acc: 0.5557
3584/9333 [==========>...................] - ETA: 4:38 - loss: 0.6849 - acc: 0.5561
3648/9333 [==========>...................] - ETA: 4:37 - loss: 0.6853 - acc: 0.5551
3712/9333 [==========>...................] - ETA: 4:34 - loss: 0.6854 - acc: 0.5547
3776/9333 [===========>..................] - ETA: 4:31 - loss: 0.6858 - acc: 0.5538
3840/9333 [===========>..................] - ETA: 4:27 - loss: 0.6859 - acc: 0.5536
3904/9333 [===========>..................] - ETA: 4:24 - loss: 0.6862 - acc: 0.5520
3968/9333 [===========>..................] - ETA: 4:20 - loss: 0.6859 - acc: 0.5522
4032/9333 [===========>..................] - ETA: 4:16 - loss: 0.6859 - acc: 0.5521
4096/9333 [============>.................] - ETA: 4:14 - loss: 0.6863 - acc: 0.5508
4160/9333 [============>.................] - ETA: 4:11 - loss: 0.6864 - acc: 0.5517
4224/9333 [============>.................] - ETA: 4:08 - loss: 0.6864 - acc: 0.5509
4288/9333 [============>.................] - ETA: 4:05 - loss: 0.6868 - acc: 0.5497
4352/9333 [============>.................] - ETA: 4:01 - loss: 0.6864 - acc: 0.5512
4416/9333 [=============>................] - ETA: 3:57 - loss: 0.6864 - acc: 0.5525
4480/9333 [=============>................] - ETA: 3:55 - loss: 0.6867 - acc: 0.5502
4544/9333 [=============>................] - ETA: 3:52 - loss: 0.6867 - acc: 0.5504
4608/9333 [=============>................] - ETA: 3:49 - loss: 0.6871 - acc: 0.5486
4672/9333 [==============>...............] - ETA: 3:46 - loss: 0.6871 - acc: 0.5479
4736/9333 [==============>...............] - ETA: 3:42 - loss: 0.6873 - acc: 0.5484
4800/9333 [==============>...............] - ETA: 3:39 - loss: 0.6874 - acc: 0.5467
4864/9333 [==============>...............] - ETA: 3:36 - loss: 0.6872 - acc: 0.5477
4928/9333 [==============>...............] - ETA: 3:33 - loss: 0.6876 - acc: 0.5457
4992/9333 [===============>..............] - ETA: 3:30 - loss: 0.6877 - acc: 0.5451
5056/9333 [===============>..............] - ETA: 3:26 - loss: 0.6876 - acc: 0.5453
5120/9333 [===============>..............] - ETA: 3:23 - loss: 0.6876 - acc: 0.5455
5184/9333 [===============>..............] - ETA: 3:20 - loss: 0.6877 - acc: 0.5448
5248/9333 [===============>..............] - ETA: 3:17 - loss: 0.6879 - acc: 0.5431
5312/9333 [================>.............] - ETA: 3:14 - loss: 0.6882 - acc: 0.5422
5376/9333 [================>.............] - ETA: 3:11 - loss: 0.6881 - acc: 0.5428
5440/9333 [================>.............] - ETA: 3:08 - loss: 0.6881 - acc: 0.5423
5504/9333 [================>.............] - ETA: 3:05 - loss: 0.6882 - acc: 0.5420
5568/9333 [================>.............] - ETA: 3:01 - loss: 0.6882 - acc: 0.5422
5632/9333 [=================>............] - ETA: 2:58 - loss: 0.6881 - acc: 0.5426
5696/9333 [=================>............] - ETA: 2:55 - loss: 0.6880 - acc: 0.5421
5760/9333 [=================>............] - ETA: 2:52 - loss: 0.6880 - acc: 0.5415
5824/9333 [=================>............] - ETA: 2:49 - loss: 0.6882 - acc: 0.5405
5888/9333 [=================>............] - ETA: 2:46 - loss: 0.6881 - acc: 0.5411
5952/9333 [==================>...........] - ETA: 2:43 - loss: 0.6883 - acc: 0.5410
6016/9333 [==================>...........] - ETA: 2:40 - loss: 0.6884 - acc: 0.5409
6080/9333 [==================>...........] - ETA: 2:37 - loss: 0.6882 - acc: 0.5413
6144/9333 [==================>...........] - ETA: 2:33 - loss: 0.6883 - acc: 0.5412
6208/9333 [==================>...........] - ETA: 2:30 - loss: 0.6883 - acc: 0.5412
6272/9333 [===================>..........] - ETA: 2:27 - loss: 0.6885 - acc: 0.5400
6336/9333 [===================>..........] - ETA: 2:24 - loss: 0.6884 - acc: 0.5402
6400/9333 [===================>..........] - ETA: 2:21 - loss: 0.6883 - acc: 0.5398
6464/9333 [===================>..........] - ETA: 2:18 - loss: 0.6884 - acc: 0.5394
6528/9333 [===================>..........] - ETA: 2:15 - loss: 0.6885 - acc: 0.5395
6592/9333 [====================>.........] - ETA: 2:12 - loss: 0.6885 - acc: 0.5388
6656/9333 [====================>.........] - ETA: 2:09 - loss: 0.6885 - acc: 0.5388
6720/9333 [====================>.........] - ETA: 2:06 - loss: 0.6886 - acc: 0.5381
6784/9333 [====================>.........] - ETA: 2:03 - loss: 0.6888 - acc: 0.5376
6848/9333 [=====================>........] - ETA: 1:59 - loss: 0.6888 - acc: 0.5374
6912/9333 [=====================>........] - ETA: 1:56 - loss: 0.6889 - acc: 0.5370
6976/9333 [=====================>........] - ETA: 1:53 - loss: 0.6889 - acc: 0.5374
7040/9333 [=====================>........] - ETA: 1:50 - loss: 0.6889 - acc: 0.5372
7104/9333 [=====================>........] - ETA: 1:47 - loss: 0.6888 - acc: 0.5374
7168/9333 [======================>.......] - ETA: 1:44 - loss: 0.6890 - acc: 0.5364
7232/9333 [======================>.......] - ETA: 1:41 - loss: 0.6888 - acc: 0.5366
7296/9333 [======================>.......] - ETA: 1:38 - loss: 0.6889 - acc: 0.5358
7360/9333 [======================>.......] - ETA: 1:35 - loss: 0.6888 - acc: 0.5361
7424/9333 [======================>.......] - ETA: 1:32 - loss: 0.6888 - acc: 0.5357
7488/9333 [=======================>......] - ETA: 1:28 - loss: 0.6889 - acc: 0.5355
7552/9333 [=======================>......] - ETA: 1:25 - loss: 0.6888 - acc: 0.5355
7616/9333 [=======================>......] - ETA: 1:22 - loss: 0.6888 - acc: 0.5355
7680/9333 [=======================>......] - ETA: 1:19 - loss: 0.6886 - acc: 0.5361
7744/9333 [=======================>......] - ETA: 1:16 - loss: 0.6886 - acc: 0.5364
7808/9333 [========================>.....] - ETA: 1:13 - loss: 0.6886 - acc: 0.5361
7872/9333 [========================>.....] - ETA: 1:10 - loss: 0.6886 - acc: 0.5365
7936/9333 [========================>.....] - ETA: 1:07 - loss: 0.6883 - acc: 0.5373
8000/9333 [========================>.....] - ETA: 1:04 - loss: 0.6884 - acc: 0.5373
8064/9333 [========================>.....] - ETA: 1:01 - loss: 0.6883 - acc: 0.5371
8128/9333 [=========================>....] - ETA: 57s - loss: 0.6885 - acc: 0.5363 
8192/9333 [=========================>....] - ETA: 54s - loss: 0.6884 - acc: 0.5370
8256/9333 [=========================>....] - ETA: 51s - loss: 0.6884 - acc: 0.5371
8320/9333 [=========================>....] - ETA: 48s - loss: 0.6884 - acc: 0.5373
8384/9333 [=========================>....] - ETA: 45s - loss: 0.6883 - acc: 0.5375
8448/9333 [==========================>...] - ETA: 42s - loss: 0.6885 - acc: 0.5374
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6885 - acc: 0.5377
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6885 - acc: 0.5379
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6885 - acc: 0.5381
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6883 - acc: 0.5384
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6885 - acc: 0.5383
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6886 - acc: 0.5379
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6888 - acc: 0.5377
8960/9333 [===========================>..] - ETA: 17s - loss: 0.6888 - acc: 0.5378
9024/9333 [============================>.] - ETA: 14s - loss: 0.6887 - acc: 0.5381
9088/9333 [============================>.] - ETA: 11s - loss: 0.6887 - acc: 0.5384
9152/9333 [============================>.] - ETA: 8s - loss: 0.6889 - acc: 0.5382 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6889 - acc: 0.5381
9280/9333 [============================>.] - ETA: 2s - loss: 0.6889 - acc: 0.5377
9333/9333 [==============================] - 469s 50ms/step - loss: 0.6889 - acc: 0.5376 - val_loss: 0.6893 - val_acc: 0.5400

Epoch 00006: val_acc improved from 0.54002 to 0.54002, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window03/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 7/10

  64/9333 [..............................] - ETA: 7:40 - loss: 0.6676 - acc: 0.5625
 128/9333 [..............................] - ETA: 8:16 - loss: 0.6534 - acc: 0.6719
 192/9333 [..............................] - ETA: 7:57 - loss: 0.6632 - acc: 0.6198
 256/9333 [..............................] - ETA: 7:42 - loss: 0.6684 - acc: 0.5938
 320/9333 [>.............................] - ETA: 7:25 - loss: 0.6693 - acc: 0.5844
 384/9333 [>.............................] - ETA: 7:12 - loss: 0.6712 - acc: 0.5911
 448/9333 [>.............................] - ETA: 7:05 - loss: 0.6725 - acc: 0.5826
 512/9333 [>.............................] - ETA: 7:23 - loss: 0.6775 - acc: 0.5664
 576/9333 [>.............................] - ETA: 7:23 - loss: 0.6767 - acc: 0.5677
 640/9333 [=>............................] - ETA: 7:18 - loss: 0.6775 - acc: 0.5672
 704/9333 [=>............................] - ETA: 7:14 - loss: 0.6767 - acc: 0.5710
 768/9333 [=>............................] - ETA: 7:08 - loss: 0.6767 - acc: 0.5690
 832/9333 [=>............................] - ETA: 7:02 - loss: 0.6740 - acc: 0.5781
 896/9333 [=>............................] - ETA: 6:58 - loss: 0.6739 - acc: 0.5770
 960/9333 [==>...........................] - ETA: 6:56 - loss: 0.6772 - acc: 0.5687
1024/9333 [==>...........................] - ETA: 6:52 - loss: 0.6775 - acc: 0.5684
1088/9333 [==>...........................] - ETA: 6:47 - loss: 0.6780 - acc: 0.5680
1152/9333 [==>...........................] - ETA: 6:42 - loss: 0.6794 - acc: 0.5668
1216/9333 [==>...........................] - ETA: 6:38 - loss: 0.6806 - acc: 0.5633
1280/9333 [===>..........................] - ETA: 6:41 - loss: 0.6809 - acc: 0.5633
1344/9333 [===>..........................] - ETA: 6:38 - loss: 0.6808 - acc: 0.5670
1408/9333 [===>..........................] - ETA: 6:32 - loss: 0.6811 - acc: 0.5639
1472/9333 [===>..........................] - ETA: 6:28 - loss: 0.6801 - acc: 0.5700
1536/9333 [===>..........................] - ETA: 6:23 - loss: 0.6811 - acc: 0.5684
1600/9333 [====>.........................] - ETA: 6:23 - loss: 0.6821 - acc: 0.5656
1664/9333 [====>.........................] - ETA: 6:20 - loss: 0.6815 - acc: 0.5691
1728/9333 [====>.........................] - ETA: 6:18 - loss: 0.6819 - acc: 0.5683
1792/9333 [====>.........................] - ETA: 6:13 - loss: 0.6833 - acc: 0.5642
1856/9333 [====>.........................] - ETA: 6:07 - loss: 0.6831 - acc: 0.5636
1920/9333 [=====>........................] - ETA: 6:03 - loss: 0.6841 - acc: 0.5615
1984/9333 [=====>........................] - ETA: 6:05 - loss: 0.6850 - acc: 0.5580
2048/9333 [=====>........................] - ETA: 6:01 - loss: 0.6858 - acc: 0.5557
2112/9333 [=====>........................] - ETA: 5:58 - loss: 0.6850 - acc: 0.5582
2176/9333 [=====>........................] - ETA: 5:54 - loss: 0.6854 - acc: 0.5584
2240/9333 [======>.......................] - ETA: 5:49 - loss: 0.6861 - acc: 0.5567
2304/9333 [======>.......................] - ETA: 5:48 - loss: 0.6856 - acc: 0.5586
2368/9333 [======>.......................] - ETA: 5:45 - loss: 0.6856 - acc: 0.5587
2432/9333 [======>.......................] - ETA: 5:43 - loss: 0.6863 - acc: 0.5559
2496/9333 [=======>......................] - ETA: 5:39 - loss: 0.6864 - acc: 0.5565
2560/9333 [=======>......................] - ETA: 5:34 - loss: 0.6865 - acc: 0.5566
2624/9333 [=======>......................] - ETA: 5:29 - loss: 0.6862 - acc: 0.5556
2688/9333 [=======>......................] - ETA: 5:27 - loss: 0.6863 - acc: 0.5554
2752/9333 [=======>......................] - ETA: 5:26 - loss: 0.6866 - acc: 0.5541
2816/9333 [========>.....................] - ETA: 5:22 - loss: 0.6865 - acc: 0.5550
2880/9333 [========>.....................] - ETA: 5:19 - loss: 0.6864 - acc: 0.5552
2944/9333 [========>.....................] - ETA: 5:15 - loss: 0.6864 - acc: 0.5550
3008/9333 [========>.....................] - ETA: 5:11 - loss: 0.6864 - acc: 0.5542
3072/9333 [========>.....................] - ETA: 5:07 - loss: 0.6866 - acc: 0.5537
3136/9333 [=========>....................] - ETA: 5:05 - loss: 0.6862 - acc: 0.5552
3200/9333 [=========>....................] - ETA: 5:02 - loss: 0.6861 - acc: 0.5547
3264/9333 [=========>....................] - ETA: 4:59 - loss: 0.6861 - acc: 0.5533
3328/9333 [=========>....................] - ETA: 4:55 - loss: 0.6862 - acc: 0.5535
3392/9333 [=========>....................] - ETA: 4:51 - loss: 0.6866 - acc: 0.5528
3456/9333 [==========>...................] - ETA: 4:47 - loss: 0.6865 - acc: 0.5527
3520/9333 [==========>...................] - ETA: 4:44 - loss: 0.6868 - acc: 0.5526
3584/9333 [==========>...................] - ETA: 4:41 - loss: 0.6865 - acc: 0.5539
3648/9333 [==========>...................] - ETA: 4:37 - loss: 0.6864 - acc: 0.5543
3712/9333 [==========>...................] - ETA: 4:33 - loss: 0.6859 - acc: 0.5550
3776/9333 [===========>..................] - ETA: 4:31 - loss: 0.6859 - acc: 0.5548
3840/9333 [===========>..................] - ETA: 4:28 - loss: 0.6860 - acc: 0.5536
3904/9333 [===========>..................] - ETA: 4:26 - loss: 0.6858 - acc: 0.5533
3968/9333 [===========>..................] - ETA: 4:22 - loss: 0.6860 - acc: 0.5524
4032/9333 [===========>..................] - ETA: 4:19 - loss: 0.6864 - acc: 0.5511
4096/9333 [============>.................] - ETA: 4:15 - loss: 0.6863 - acc: 0.5496
4160/9333 [============>.................] - ETA: 4:12 - loss: 0.6863 - acc: 0.5502
4224/9333 [============>.................] - ETA: 4:10 - loss: 0.6867 - acc: 0.5483
4288/9333 [============>.................] - ETA: 4:07 - loss: 0.6869 - acc: 0.5464
4352/9333 [============>.................] - ETA: 4:04 - loss: 0.6871 - acc: 0.5460
4416/9333 [=============>................] - ETA: 4:00 - loss: 0.6870 - acc: 0.5448
4480/9333 [=============>................] - ETA: 3:56 - loss: 0.6876 - acc: 0.5420
4544/9333 [=============>................] - ETA: 3:53 - loss: 0.6877 - acc: 0.5414
4608/9333 [=============>................] - ETA: 3:51 - loss: 0.6875 - acc: 0.5421
4672/9333 [==============>...............] - ETA: 3:47 - loss: 0.6874 - acc: 0.5428
4736/9333 [==============>...............] - ETA: 3:44 - loss: 0.6876 - acc: 0.5422
4800/9333 [==============>...............] - ETA: 3:41 - loss: 0.6874 - acc: 0.5440
4864/9333 [==============>...............] - ETA: 3:38 - loss: 0.6877 - acc: 0.5430
4928/9333 [==============>...............] - ETA: 3:35 - loss: 0.6876 - acc: 0.5426
4992/9333 [===============>..............] - ETA: 3:32 - loss: 0.6875 - acc: 0.5433
5056/9333 [===============>..............] - ETA: 3:29 - loss: 0.6875 - acc: 0.5435
5120/9333 [===============>..............] - ETA: 3:26 - loss: 0.6873 - acc: 0.5443
5184/9333 [===============>..............] - ETA: 3:22 - loss: 0.6873 - acc: 0.5440
5248/9333 [===============>..............] - ETA: 3:19 - loss: 0.6875 - acc: 0.5433
5312/9333 [================>.............] - ETA: 3:15 - loss: 0.6876 - acc: 0.5429
5376/9333 [================>.............] - ETA: 3:13 - loss: 0.6877 - acc: 0.5424
5440/9333 [================>.............] - ETA: 3:10 - loss: 0.6882 - acc: 0.5401
5504/9333 [================>.............] - ETA: 3:07 - loss: 0.6884 - acc: 0.5396
5568/9333 [================>.............] - ETA: 3:04 - loss: 0.6886 - acc: 0.5384
5632/9333 [=================>............] - ETA: 3:00 - loss: 0.6886 - acc: 0.5385
5696/9333 [=================>............] - ETA: 2:57 - loss: 0.6883 - acc: 0.5384
5760/9333 [=================>............] - ETA: 2:54 - loss: 0.6883 - acc: 0.5387
5824/9333 [=================>............] - ETA: 2:51 - loss: 0.6883 - acc: 0.5385
5888/9333 [=================>............] - ETA: 2:47 - loss: 0.6882 - acc: 0.5382
5952/9333 [==================>...........] - ETA: 2:44 - loss: 0.6882 - acc: 0.5386
6016/9333 [==================>...........] - ETA: 2:41 - loss: 0.6885 - acc: 0.5369
6080/9333 [==================>...........] - ETA: 2:38 - loss: 0.6886 - acc: 0.5363
6144/9333 [==================>...........] - ETA: 2:35 - loss: 0.6885 - acc: 0.5374
6208/9333 [==================>...........] - ETA: 2:31 - loss: 0.6886 - acc: 0.5372
6272/9333 [===================>..........] - ETA: 2:28 - loss: 0.6886 - acc: 0.5371
6336/9333 [===================>..........] - ETA: 2:25 - loss: 0.6885 - acc: 0.5376
6400/9333 [===================>..........] - ETA: 2:22 - loss: 0.6888 - acc: 0.5366
6464/9333 [===================>..........] - ETA: 2:19 - loss: 0.6885 - acc: 0.5373
6528/9333 [===================>..........] - ETA: 2:16 - loss: 0.6888 - acc: 0.5358
6592/9333 [====================>.........] - ETA: 2:13 - loss: 0.6891 - acc: 0.5347
6656/9333 [====================>.........] - ETA: 2:10 - loss: 0.6890 - acc: 0.5347
6720/9333 [====================>.........] - ETA: 2:07 - loss: 0.6888 - acc: 0.5351
6784/9333 [====================>.........] - ETA: 2:04 - loss: 0.6888 - acc: 0.5351
6848/9333 [=====================>........] - ETA: 2:00 - loss: 0.6890 - acc: 0.5343
6912/9333 [=====================>........] - ETA: 1:57 - loss: 0.6891 - acc: 0.5334
6976/9333 [=====================>........] - ETA: 1:54 - loss: 0.6891 - acc: 0.5333
7040/9333 [=====================>........] - ETA: 1:51 - loss: 0.6893 - acc: 0.5327
7104/9333 [=====================>........] - ETA: 1:48 - loss: 0.6891 - acc: 0.5336
7168/9333 [======================>.......] - ETA: 1:45 - loss: 0.6892 - acc: 0.5331
7232/9333 [======================>.......] - ETA: 1:42 - loss: 0.6892 - acc: 0.5328
7296/9333 [======================>.......] - ETA: 1:39 - loss: 0.6897 - acc: 0.5317
7360/9333 [======================>.......] - ETA: 1:36 - loss: 0.6897 - acc: 0.5314
7424/9333 [======================>.......] - ETA: 1:33 - loss: 0.6895 - acc: 0.5318
7488/9333 [=======================>......] - ETA: 1:30 - loss: 0.6896 - acc: 0.5323
7552/9333 [=======================>......] - ETA: 1:26 - loss: 0.6896 - acc: 0.5327
7616/9333 [=======================>......] - ETA: 1:23 - loss: 0.6896 - acc: 0.5326
7680/9333 [=======================>......] - ETA: 1:20 - loss: 0.6898 - acc: 0.5322
7744/9333 [=======================>......] - ETA: 1:17 - loss: 0.6899 - acc: 0.5320
7808/9333 [========================>.....] - ETA: 1:14 - loss: 0.6898 - acc: 0.5324
7872/9333 [========================>.....] - ETA: 1:11 - loss: 0.6900 - acc: 0.5320
7936/9333 [========================>.....] - ETA: 1:08 - loss: 0.6900 - acc: 0.5318
8000/9333 [========================>.....] - ETA: 1:05 - loss: 0.6898 - acc: 0.5329
8064/9333 [========================>.....] - ETA: 1:01 - loss: 0.6898 - acc: 0.5329
8128/9333 [=========================>....] - ETA: 58s - loss: 0.6898 - acc: 0.5327 
8192/9333 [=========================>....] - ETA: 55s - loss: 0.6898 - acc: 0.5330
8256/9333 [=========================>....] - ETA: 52s - loss: 0.6898 - acc: 0.5326
8320/9333 [=========================>....] - ETA: 49s - loss: 0.6899 - acc: 0.5327
8384/9333 [=========================>....] - ETA: 46s - loss: 0.6897 - acc: 0.5332
8448/9333 [==========================>...] - ETA: 43s - loss: 0.6897 - acc: 0.5330
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6898 - acc: 0.5327
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6897 - acc: 0.5326
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6897 - acc: 0.5331
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6900 - acc: 0.5323
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6899 - acc: 0.5324
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6898 - acc: 0.5334
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6899 - acc: 0.5332
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6900 - acc: 0.5323
9024/9333 [============================>.] - ETA: 15s - loss: 0.6900 - acc: 0.5326
9088/9333 [============================>.] - ETA: 11s - loss: 0.6900 - acc: 0.5325
9152/9333 [============================>.] - ETA: 8s - loss: 0.6899 - acc: 0.5327 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6899 - acc: 0.5332
9280/9333 [============================>.] - ETA: 2s - loss: 0.6899 - acc: 0.5328
9333/9333 [==============================] - 472s 51ms/step - loss: 0.6898 - acc: 0.5331 - val_loss: 0.6868 - val_acc: 0.5333

Epoch 00007: val_acc did not improve from 0.54002
Epoch 8/10

  64/9333 [..............................] - ETA: 8:21 - loss: 0.6824 - acc: 0.6094
 128/9333 [..............................] - ETA: 8:42 - loss: 0.6993 - acc: 0.5469
 192/9333 [..............................] - ETA: 7:51 - loss: 0.6886 - acc: 0.5469
 256/9333 [..............................] - ETA: 7:37 - loss: 0.6868 - acc: 0.5391
 320/9333 [>.............................] - ETA: 7:26 - loss: 0.6917 - acc: 0.5281
 384/9333 [>.............................] - ETA: 7:33 - loss: 0.6966 - acc: 0.5078
 448/9333 [>.............................] - ETA: 7:25 - loss: 0.6943 - acc: 0.5201
 512/9333 [>.............................] - ETA: 7:16 - loss: 0.6906 - acc: 0.5332
 576/9333 [>.............................] - ETA: 7:07 - loss: 0.6887 - acc: 0.5347
 640/9333 [=>............................] - ETA: 7:02 - loss: 0.6871 - acc: 0.5453
 704/9333 [=>............................] - ETA: 6:52 - loss: 0.6861 - acc: 0.5469
 768/9333 [=>............................] - ETA: 6:50 - loss: 0.6863 - acc: 0.5443
 832/9333 [=>............................] - ETA: 6:49 - loss: 0.6877 - acc: 0.5409
 896/9333 [=>............................] - ETA: 6:48 - loss: 0.6862 - acc: 0.5435
 960/9333 [==>...........................] - ETA: 6:42 - loss: 0.6869 - acc: 0.5427
1024/9333 [==>...........................] - ETA: 6:36 - loss: 0.6865 - acc: 0.5420
1088/9333 [==>...........................] - ETA: 6:30 - loss: 0.6883 - acc: 0.5358
1152/9333 [==>...........................] - ETA: 6:23 - loss: 0.6879 - acc: 0.5373
1216/9333 [==>...........................] - ETA: 6:20 - loss: 0.6871 - acc: 0.5411
1280/9333 [===>..........................] - ETA: 6:18 - loss: 0.6870 - acc: 0.5430
1344/9333 [===>..........................] - ETA: 6:14 - loss: 0.6864 - acc: 0.5461
1408/9333 [===>..........................] - ETA: 6:12 - loss: 0.6855 - acc: 0.5511
1472/9333 [===>..........................] - ETA: 6:10 - loss: 0.6854 - acc: 0.5510
1536/9333 [===>..........................] - ETA: 6:06 - loss: 0.6855 - acc: 0.5514
1600/9333 [====>.........................] - ETA: 6:05 - loss: 0.6849 - acc: 0.5537
1664/9333 [====>.........................] - ETA: 6:02 - loss: 0.6842 - acc: 0.5559
1728/9333 [====>.........................] - ETA: 5:58 - loss: 0.6834 - acc: 0.5561
1792/9333 [====>.........................] - ETA: 5:55 - loss: 0.6824 - acc: 0.5586
1856/9333 [====>.........................] - ETA: 5:53 - loss: 0.6833 - acc: 0.5571
1920/9333 [=====>........................] - ETA: 5:50 - loss: 0.6847 - acc: 0.5568
1984/9333 [=====>........................] - ETA: 5:47 - loss: 0.6844 - acc: 0.5585
2048/9333 [=====>........................] - ETA: 5:45 - loss: 0.6849 - acc: 0.5562
2112/9333 [=====>........................] - ETA: 5:42 - loss: 0.6862 - acc: 0.5526
2176/9333 [=====>........................] - ETA: 5:38 - loss: 0.6853 - acc: 0.5538
2240/9333 [======>.......................] - ETA: 5:35 - loss: 0.6864 - acc: 0.5496
2304/9333 [======>.......................] - ETA: 5:33 - loss: 0.6870 - acc: 0.5490
2368/9333 [======>.......................] - ETA: 5:33 - loss: 0.6870 - acc: 0.5490
2432/9333 [======>.......................] - ETA: 5:30 - loss: 0.6875 - acc: 0.5493
2496/9333 [=======>......................] - ETA: 5:27 - loss: 0.6884 - acc: 0.5469
2560/9333 [=======>......................] - ETA: 5:23 - loss: 0.6891 - acc: 0.5426
2624/9333 [=======>......................] - ETA: 5:20 - loss: 0.6890 - acc: 0.5423
2688/9333 [=======>......................] - ETA: 5:19 - loss: 0.6885 - acc: 0.5432
2752/9333 [=======>......................] - ETA: 5:16 - loss: 0.6885 - acc: 0.5422
2816/9333 [========>.....................] - ETA: 5:12 - loss: 0.6882 - acc: 0.5430
2880/9333 [========>.....................] - ETA: 5:08 - loss: 0.6887 - acc: 0.5410
2944/9333 [========>.....................] - ETA: 5:05 - loss: 0.6886 - acc: 0.5408
3008/9333 [========>.....................] - ETA: 5:01 - loss: 0.6883 - acc: 0.5429
3072/9333 [========>.....................] - ETA: 4:57 - loss: 0.6886 - acc: 0.5407
3136/9333 [=========>....................] - ETA: 4:55 - loss: 0.6886 - acc: 0.5392
3200/9333 [=========>....................] - ETA: 4:51 - loss: 0.6888 - acc: 0.5387
3264/9333 [=========>....................] - ETA: 4:49 - loss: 0.6885 - acc: 0.5392
3328/9333 [=========>....................] - ETA: 4:46 - loss: 0.6884 - acc: 0.5397
3392/9333 [=========>....................] - ETA: 4:42 - loss: 0.6885 - acc: 0.5392
3456/9333 [==========>...................] - ETA: 4:39 - loss: 0.6883 - acc: 0.5394
3520/9333 [==========>...................] - ETA: 4:35 - loss: 0.6881 - acc: 0.5403
3584/9333 [==========>...................] - ETA: 4:32 - loss: 0.6883 - acc: 0.5388
3648/9333 [==========>...................] - ETA: 4:30 - loss: 0.6882 - acc: 0.5389
3712/9333 [==========>...................] - ETA: 4:27 - loss: 0.6882 - acc: 0.5383
3776/9333 [===========>..................] - ETA: 4:24 - loss: 0.6882 - acc: 0.5376
3840/9333 [===========>..................] - ETA: 4:21 - loss: 0.6881 - acc: 0.5372
3904/9333 [===========>..................] - ETA: 4:17 - loss: 0.6878 - acc: 0.5377
3968/9333 [===========>..................] - ETA: 4:16 - loss: 0.6881 - acc: 0.5368
4032/9333 [===========>..................] - ETA: 4:13 - loss: 0.6882 - acc: 0.5372
4096/9333 [============>.................] - ETA: 4:10 - loss: 0.6881 - acc: 0.5381
4160/9333 [============>.................] - ETA: 4:07 - loss: 0.6881 - acc: 0.5380
4224/9333 [============>.................] - ETA: 4:03 - loss: 0.6880 - acc: 0.5386
4288/9333 [============>.................] - ETA: 4:00 - loss: 0.6878 - acc: 0.5389
4352/9333 [============>.................] - ETA: 3:57 - loss: 0.6879 - acc: 0.5388
4416/9333 [=============>................] - ETA: 3:54 - loss: 0.6878 - acc: 0.5385
4480/9333 [=============>................] - ETA: 3:51 - loss: 0.6880 - acc: 0.5386
4544/9333 [=============>................] - ETA: 3:49 - loss: 0.6876 - acc: 0.5403
4608/9333 [=============>................] - ETA: 3:45 - loss: 0.6876 - acc: 0.5410
4672/9333 [==============>...............] - ETA: 3:42 - loss: 0.6876 - acc: 0.5409
4736/9333 [==============>...............] - ETA: 3:39 - loss: 0.6875 - acc: 0.5410
4800/9333 [==============>...............] - ETA: 3:36 - loss: 0.6876 - acc: 0.5404
4864/9333 [==============>...............] - ETA: 3:33 - loss: 0.6879 - acc: 0.5397
4928/9333 [==============>...............] - ETA: 3:31 - loss: 0.6876 - acc: 0.5396
4992/9333 [===============>..............] - ETA: 3:27 - loss: 0.6875 - acc: 0.5395
5056/9333 [===============>..............] - ETA: 3:24 - loss: 0.6878 - acc: 0.5392
5120/9333 [===============>..............] - ETA: 3:22 - loss: 0.6879 - acc: 0.5398
5184/9333 [===============>..............] - ETA: 3:19 - loss: 0.6878 - acc: 0.5409
5248/9333 [===============>..............] - ETA: 3:16 - loss: 0.6875 - acc: 0.5423
5312/9333 [================>.............] - ETA: 3:13 - loss: 0.6875 - acc: 0.5433
5376/9333 [================>.............] - ETA: 3:10 - loss: 0.6876 - acc: 0.5430
5440/9333 [================>.............] - ETA: 3:07 - loss: 0.6875 - acc: 0.5428
5504/9333 [================>.............] - ETA: 3:03 - loss: 0.6878 - acc: 0.5420
5568/9333 [================>.............] - ETA: 3:00 - loss: 0.6880 - acc: 0.5411
5632/9333 [=================>............] - ETA: 2:57 - loss: 0.6880 - acc: 0.5419
5696/9333 [=================>............] - ETA: 2:54 - loss: 0.6878 - acc: 0.5423
5760/9333 [=================>............] - ETA: 2:51 - loss: 0.6877 - acc: 0.5429
5824/9333 [=================>............] - ETA: 2:48 - loss: 0.6875 - acc: 0.5429
5888/9333 [=================>............] - ETA: 2:44 - loss: 0.6876 - acc: 0.5431
5952/9333 [==================>...........] - ETA: 2:41 - loss: 0.6878 - acc: 0.5425
6016/9333 [==================>...........] - ETA: 2:38 - loss: 0.6879 - acc: 0.5421
6080/9333 [==================>...........] - ETA: 2:35 - loss: 0.6879 - acc: 0.5416
6144/9333 [==================>...........] - ETA: 2:32 - loss: 0.6880 - acc: 0.5410
6208/9333 [==================>...........] - ETA: 2:29 - loss: 0.6881 - acc: 0.5412
6272/9333 [===================>..........] - ETA: 2:26 - loss: 0.6880 - acc: 0.5416
6336/9333 [===================>..........] - ETA: 2:23 - loss: 0.6881 - acc: 0.5415
6400/9333 [===================>..........] - ETA: 2:20 - loss: 0.6880 - acc: 0.5419
6464/9333 [===================>..........] - ETA: 2:17 - loss: 0.6882 - acc: 0.5421
6528/9333 [===================>..........] - ETA: 2:13 - loss: 0.6882 - acc: 0.5424
6592/9333 [====================>.........] - ETA: 2:10 - loss: 0.6882 - acc: 0.5431
6656/9333 [====================>.........] - ETA: 2:08 - loss: 0.6882 - acc: 0.5428
6720/9333 [====================>.........] - ETA: 2:05 - loss: 0.6880 - acc: 0.5437
6784/9333 [====================>.........] - ETA: 2:01 - loss: 0.6880 - acc: 0.5441
6848/9333 [=====================>........] - ETA: 1:58 - loss: 0.6881 - acc: 0.5437
6912/9333 [=====================>........] - ETA: 1:55 - loss: 0.6882 - acc: 0.5438
6976/9333 [=====================>........] - ETA: 1:52 - loss: 0.6882 - acc: 0.5442
7040/9333 [=====================>........] - ETA: 1:49 - loss: 0.6882 - acc: 0.5443
7104/9333 [=====================>........] - ETA: 1:46 - loss: 0.6883 - acc: 0.5439
7168/9333 [======================>.......] - ETA: 1:43 - loss: 0.6883 - acc: 0.5434
7232/9333 [======================>.......] - ETA: 1:40 - loss: 0.6883 - acc: 0.5433
7296/9333 [======================>.......] - ETA: 1:37 - loss: 0.6883 - acc: 0.5430
7360/9333 [======================>.......] - ETA: 1:33 - loss: 0.6884 - acc: 0.5423
7424/9333 [======================>.......] - ETA: 1:30 - loss: 0.6884 - acc: 0.5427
7488/9333 [=======================>......] - ETA: 1:27 - loss: 0.6884 - acc: 0.5426
7552/9333 [=======================>......] - ETA: 1:24 - loss: 0.6884 - acc: 0.5424
7616/9333 [=======================>......] - ETA: 1:21 - loss: 0.6883 - acc: 0.5424
7680/9333 [=======================>......] - ETA: 1:18 - loss: 0.6882 - acc: 0.5427
7744/9333 [=======================>......] - ETA: 1:15 - loss: 0.6881 - acc: 0.5433
7808/9333 [========================>.....] - ETA: 1:12 - loss: 0.6883 - acc: 0.5424
7872/9333 [========================>.....] - ETA: 1:09 - loss: 0.6885 - acc: 0.5423
7936/9333 [========================>.....] - ETA: 1:06 - loss: 0.6884 - acc: 0.5430
8000/9333 [========================>.....] - ETA: 1:03 - loss: 0.6883 - acc: 0.5426
8064/9333 [========================>.....] - ETA: 1:00 - loss: 0.6883 - acc: 0.5428
8128/9333 [=========================>....] - ETA: 57s - loss: 0.6882 - acc: 0.5426 
8192/9333 [=========================>....] - ETA: 54s - loss: 0.6882 - acc: 0.5427
8256/9333 [=========================>....] - ETA: 51s - loss: 0.6881 - acc: 0.5429
8320/9333 [=========================>....] - ETA: 48s - loss: 0.6881 - acc: 0.5425
8384/9333 [=========================>....] - ETA: 45s - loss: 0.6882 - acc: 0.5421
8448/9333 [==========================>...] - ETA: 42s - loss: 0.6882 - acc: 0.5419
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6883 - acc: 0.5418
8576/9333 [==========================>...] - ETA: 35s - loss: 0.6883 - acc: 0.5419
8640/9333 [==========================>...] - ETA: 32s - loss: 0.6881 - acc: 0.5421
8704/9333 [==========================>...] - ETA: 29s - loss: 0.6880 - acc: 0.5426
8768/9333 [===========================>..] - ETA: 26s - loss: 0.6881 - acc: 0.5422
8832/9333 [===========================>..] - ETA: 23s - loss: 0.6879 - acc: 0.5428
8896/9333 [===========================>..] - ETA: 20s - loss: 0.6878 - acc: 0.5429
8960/9333 [===========================>..] - ETA: 17s - loss: 0.6878 - acc: 0.5425
9024/9333 [============================>.] - ETA: 14s - loss: 0.6877 - acc: 0.5430
9088/9333 [============================>.] - ETA: 11s - loss: 0.6875 - acc: 0.5431
9152/9333 [============================>.] - ETA: 8s - loss: 0.6874 - acc: 0.5434 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6874 - acc: 0.5433
9280/9333 [============================>.] - ETA: 2s - loss: 0.6875 - acc: 0.5431
9333/9333 [==============================] - 462s 50ms/step - loss: 0.6876 - acc: 0.5424 - val_loss: 0.6896 - val_acc: 0.5256

Epoch 00008: val_acc did not improve from 0.54002
Epoch 9/10

  64/9333 [..............................] - ETA: 7:59 - loss: 0.6926 - acc: 0.5000
 128/9333 [..............................] - ETA: 7:20 - loss: 0.6897 - acc: 0.5234
 192/9333 [..............................] - ETA: 7:11 - loss: 0.6940 - acc: 0.5156
 256/9333 [..............................] - ETA: 6:58 - loss: 0.6940 - acc: 0.5195
 320/9333 [>.............................] - ETA: 6:54 - loss: 0.6895 - acc: 0.5344
 384/9333 [>.............................] - ETA: 6:57 - loss: 0.6904 - acc: 0.5234
 448/9333 [>.............................] - ETA: 6:53 - loss: 0.6904 - acc: 0.5312
 512/9333 [>.............................] - ETA: 6:54 - loss: 0.6900 - acc: 0.5273
 576/9333 [>.............................] - ETA: 6:59 - loss: 0.6868 - acc: 0.5399
 640/9333 [=>............................] - ETA: 6:55 - loss: 0.6854 - acc: 0.5469
 704/9333 [=>............................] - ETA: 6:50 - loss: 0.6859 - acc: 0.5469
 768/9333 [=>............................] - ETA: 6:43 - loss: 0.6853 - acc: 0.5469
 832/9333 [=>............................] - ETA: 6:37 - loss: 0.6850 - acc: 0.5505
 896/9333 [=>............................] - ETA: 6:30 - loss: 0.6870 - acc: 0.5446
 960/9333 [==>...........................] - ETA: 6:37 - loss: 0.6838 - acc: 0.5542
1024/9333 [==>...........................] - ETA: 6:33 - loss: 0.6845 - acc: 0.5518
1088/9333 [==>...........................] - ETA: 6:30 - loss: 0.6846 - acc: 0.5496
1152/9333 [==>...........................] - ETA: 6:24 - loss: 0.6842 - acc: 0.5521
1216/9333 [==>...........................] - ETA: 6:23 - loss: 0.6842 - acc: 0.5502
1280/9333 [===>..........................] - ETA: 6:18 - loss: 0.6847 - acc: 0.5477
1344/9333 [===>..........................] - ETA: 6:21 - loss: 0.6835 - acc: 0.5506
1408/9333 [===>..........................] - ETA: 6:17 - loss: 0.6831 - acc: 0.5490
1472/9333 [===>..........................] - ETA: 6:14 - loss: 0.6834 - acc: 0.5469
1536/9333 [===>..........................] - ETA: 6:12 - loss: 0.6842 - acc: 0.5456
1600/9333 [====>.........................] - ETA: 6:11 - loss: 0.6837 - acc: 0.5450
1664/9333 [====>.........................] - ETA: 6:06 - loss: 0.6848 - acc: 0.5409
1728/9333 [====>.........................] - ETA: 6:05 - loss: 0.6844 - acc: 0.5440
1792/9333 [====>.........................] - ETA: 6:01 - loss: 0.6847 - acc: 0.5430
1856/9333 [====>.........................] - ETA: 5:57 - loss: 0.6834 - acc: 0.5458
1920/9333 [=====>........................] - ETA: 5:57 - loss: 0.6850 - acc: 0.5432
1984/9333 [=====>........................] - ETA: 5:53 - loss: 0.6845 - acc: 0.5454
2048/9333 [=====>........................] - ETA: 5:48 - loss: 0.6846 - acc: 0.5444
2112/9333 [=====>........................] - ETA: 5:47 - loss: 0.6850 - acc: 0.5445
2176/9333 [=====>........................] - ETA: 5:45 - loss: 0.6849 - acc: 0.5450
2240/9333 [======>.......................] - ETA: 5:41 - loss: 0.6846 - acc: 0.5455
2304/9333 [======>.......................] - ETA: 5:38 - loss: 0.6844 - acc: 0.5486
2368/9333 [======>.......................] - ETA: 5:35 - loss: 0.6839 - acc: 0.5507
2432/9333 [======>.......................] - ETA: 5:32 - loss: 0.6846 - acc: 0.5485
2496/9333 [=======>......................] - ETA: 5:29 - loss: 0.6849 - acc: 0.5489
2560/9333 [=======>......................] - ETA: 5:25 - loss: 0.6861 - acc: 0.5461
2624/9333 [=======>......................] - ETA: 5:22 - loss: 0.6864 - acc: 0.5450
2688/9333 [=======>......................] - ETA: 5:18 - loss: 0.6869 - acc: 0.5443
2752/9333 [=======>......................] - ETA: 5:15 - loss: 0.6867 - acc: 0.5451
2816/9333 [========>.....................] - ETA: 5:15 - loss: 0.6867 - acc: 0.5444
2880/9333 [========>.....................] - ETA: 5:11 - loss: 0.6869 - acc: 0.5437
2944/9333 [========>.....................] - ETA: 5:07 - loss: 0.6872 - acc: 0.5431
3008/9333 [========>.....................] - ETA: 5:03 - loss: 0.6873 - acc: 0.5422
3072/9333 [========>.....................] - ETA: 5:00 - loss: 0.6870 - acc: 0.5439
3136/9333 [=========>....................] - ETA: 4:56 - loss: 0.6871 - acc: 0.5434
3200/9333 [=========>....................] - ETA: 4:53 - loss: 0.6875 - acc: 0.5434
3264/9333 [=========>....................] - ETA: 4:50 - loss: 0.6871 - acc: 0.5450
3328/9333 [=========>....................] - ETA: 4:47 - loss: 0.6866 - acc: 0.5475
3392/9333 [=========>....................] - ETA: 4:45 - loss: 0.6870 - acc: 0.5481
3456/9333 [==========>...................] - ETA: 4:42 - loss: 0.6868 - acc: 0.5501
3520/9333 [==========>...................] - ETA: 4:38 - loss: 0.6873 - acc: 0.5477
3584/9333 [==========>...................] - ETA: 4:35 - loss: 0.6876 - acc: 0.5466
3648/9333 [==========>...................] - ETA: 4:31 - loss: 0.6873 - acc: 0.5480
3712/9333 [==========>...................] - ETA: 4:28 - loss: 0.6879 - acc: 0.5461
3776/9333 [===========>..................] - ETA: 4:27 - loss: 0.6876 - acc: 0.5466
3840/9333 [===========>..................] - ETA: 4:24 - loss: 0.6869 - acc: 0.5484
3904/9333 [===========>..................] - ETA: 4:21 - loss: 0.6868 - acc: 0.5482
3968/9333 [===========>..................] - ETA: 4:17 - loss: 0.6866 - acc: 0.5491
4032/9333 [===========>..................] - ETA: 4:13 - loss: 0.6870 - acc: 0.5479
4096/9333 [============>.................] - ETA: 4:11 - loss: 0.6869 - acc: 0.5476
4160/9333 [============>.................] - ETA: 4:08 - loss: 0.6869 - acc: 0.5490
4224/9333 [============>.................] - ETA: 4:06 - loss: 0.6866 - acc: 0.5507
4288/9333 [============>.................] - ETA: 4:02 - loss: 0.6864 - acc: 0.5518
4352/9333 [============>.................] - ETA: 3:59 - loss: 0.6865 - acc: 0.5515
4416/9333 [=============>................] - ETA: 3:55 - loss: 0.6866 - acc: 0.5512
4480/9333 [=============>................] - ETA: 3:54 - loss: 0.6862 - acc: 0.5527
4544/9333 [=============>................] - ETA: 3:51 - loss: 0.6864 - acc: 0.5530
4608/9333 [=============>................] - ETA: 3:47 - loss: 0.6866 - acc: 0.5527
4672/9333 [==============>...............] - ETA: 3:44 - loss: 0.6867 - acc: 0.5518
4736/9333 [==============>...............] - ETA: 3:41 - loss: 0.6864 - acc: 0.5522
4800/9333 [==============>...............] - ETA: 3:37 - loss: 0.6863 - acc: 0.5515
4864/9333 [==============>...............] - ETA: 3:34 - loss: 0.6864 - acc: 0.5510
4928/9333 [==============>...............] - ETA: 3:31 - loss: 0.6864 - acc: 0.5511
4992/9333 [===============>..............] - ETA: 3:27 - loss: 0.6864 - acc: 0.5519
5056/9333 [===============>..............] - ETA: 3:24 - loss: 0.6865 - acc: 0.5520
5120/9333 [===============>..............] - ETA: 3:21 - loss: 0.6869 - acc: 0.5520
5184/9333 [===============>..............] - ETA: 3:18 - loss: 0.6870 - acc: 0.5521
5248/9333 [===============>..............] - ETA: 3:15 - loss: 0.6869 - acc: 0.5516
5312/9333 [================>.............] - ETA: 3:12 - loss: 0.6867 - acc: 0.5518
5376/9333 [================>.............] - ETA: 3:09 - loss: 0.6865 - acc: 0.5517
5440/9333 [================>.............] - ETA: 3:06 - loss: 0.6868 - acc: 0.5509
5504/9333 [================>.............] - ETA: 3:03 - loss: 0.6866 - acc: 0.5511
5568/9333 [================>.............] - ETA: 3:00 - loss: 0.6866 - acc: 0.5508
5632/9333 [=================>............] - ETA: 2:57 - loss: 0.6870 - acc: 0.5497
5696/9333 [=================>............] - ETA: 2:53 - loss: 0.6870 - acc: 0.5492
5760/9333 [=================>............] - ETA: 2:51 - loss: 0.6868 - acc: 0.5488
5824/9333 [=================>............] - ETA: 2:48 - loss: 0.6867 - acc: 0.5495
5888/9333 [=================>............] - ETA: 2:45 - loss: 0.6868 - acc: 0.5498
5952/9333 [==================>...........] - ETA: 2:41 - loss: 0.6865 - acc: 0.5499
6016/9333 [==================>...........] - ETA: 2:38 - loss: 0.6863 - acc: 0.5505
6080/9333 [==================>...........] - ETA: 2:35 - loss: 0.6867 - acc: 0.5495
6144/9333 [==================>...........] - ETA: 2:33 - loss: 0.6869 - acc: 0.5495
6208/9333 [==================>...........] - ETA: 2:30 - loss: 0.6868 - acc: 0.5503
6272/9333 [===================>..........] - ETA: 2:26 - loss: 0.6866 - acc: 0.5507
6336/9333 [===================>..........] - ETA: 2:23 - loss: 0.6867 - acc: 0.5500
6400/9333 [===================>..........] - ETA: 2:20 - loss: 0.6866 - acc: 0.5503
6464/9333 [===================>..........] - ETA: 2:17 - loss: 0.6866 - acc: 0.5503
6528/9333 [===================>..........] - ETA: 2:14 - loss: 0.6868 - acc: 0.5496
6592/9333 [====================>.........] - ETA: 2:11 - loss: 0.6867 - acc: 0.5493
6656/9333 [====================>.........] - ETA: 2:08 - loss: 0.6866 - acc: 0.5494
6720/9333 [====================>.........] - ETA: 2:05 - loss: 0.6865 - acc: 0.5500
6784/9333 [====================>.........] - ETA: 2:01 - loss: 0.6868 - acc: 0.5494
6848/9333 [=====================>........] - ETA: 1:58 - loss: 0.6869 - acc: 0.5491
6912/9333 [=====================>........] - ETA: 1:55 - loss: 0.6870 - acc: 0.5488
6976/9333 [=====================>........] - ETA: 1:52 - loss: 0.6873 - acc: 0.5482
7040/9333 [=====================>........] - ETA: 1:49 - loss: 0.6872 - acc: 0.5486
7104/9333 [=====================>........] - ETA: 1:46 - loss: 0.6872 - acc: 0.5484
7168/9333 [======================>.......] - ETA: 1:43 - loss: 0.6873 - acc: 0.5483
7232/9333 [======================>.......] - ETA: 1:40 - loss: 0.6873 - acc: 0.5476
7296/9333 [======================>.......] - ETA: 1:37 - loss: 0.6872 - acc: 0.5482
7360/9333 [======================>.......] - ETA: 1:34 - loss: 0.6872 - acc: 0.5484
7424/9333 [======================>.......] - ETA: 1:31 - loss: 0.6872 - acc: 0.5480
7488/9333 [=======================>......] - ETA: 1:28 - loss: 0.6871 - acc: 0.5485
7552/9333 [=======================>......] - ETA: 1:25 - loss: 0.6872 - acc: 0.5482
7616/9333 [=======================>......] - ETA: 1:21 - loss: 0.6874 - acc: 0.5474
7680/9333 [=======================>......] - ETA: 1:19 - loss: 0.6872 - acc: 0.5474
7744/9333 [=======================>......] - ETA: 1:16 - loss: 0.6870 - acc: 0.5484
7808/9333 [========================>.....] - ETA: 1:13 - loss: 0.6870 - acc: 0.5488
7872/9333 [========================>.....] - ETA: 1:09 - loss: 0.6871 - acc: 0.5481
7936/9333 [========================>.....] - ETA: 1:06 - loss: 0.6871 - acc: 0.5483
8000/9333 [========================>.....] - ETA: 1:03 - loss: 0.6870 - acc: 0.5481
8064/9333 [========================>.....] - ETA: 1:00 - loss: 0.6869 - acc: 0.5482
8128/9333 [=========================>....] - ETA: 57s - loss: 0.6869 - acc: 0.5482 
8192/9333 [=========================>....] - ETA: 54s - loss: 0.6870 - acc: 0.5481
8256/9333 [=========================>....] - ETA: 51s - loss: 0.6871 - acc: 0.5480
8320/9333 [=========================>....] - ETA: 48s - loss: 0.6872 - acc: 0.5477
8384/9333 [=========================>....] - ETA: 45s - loss: 0.6872 - acc: 0.5474
8448/9333 [==========================>...] - ETA: 42s - loss: 0.6870 - acc: 0.5482
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6872 - acc: 0.5471
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6873 - acc: 0.5465
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6875 - acc: 0.5461
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6874 - acc: 0.5455
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6875 - acc: 0.5454
8832/9333 [===========================>..] - ETA: 23s - loss: 0.6876 - acc: 0.5450
8896/9333 [===========================>..] - ETA: 20s - loss: 0.6875 - acc: 0.5452
8960/9333 [===========================>..] - ETA: 17s - loss: 0.6875 - acc: 0.5451
9024/9333 [============================>.] - ETA: 14s - loss: 0.6876 - acc: 0.5449
9088/9333 [============================>.] - ETA: 11s - loss: 0.6874 - acc: 0.5457
9152/9333 [============================>.] - ETA: 8s - loss: 0.6875 - acc: 0.5450 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6876 - acc: 0.5446
9280/9333 [============================>.] - ETA: 2s - loss: 0.6875 - acc: 0.5448
9333/9333 [==============================] - 464s 50ms/step - loss: 0.6873 - acc: 0.5456 - val_loss: 0.6861 - val_acc: 0.5304

Epoch 00009: val_acc did not improve from 0.54002
Epoch 10/10

  64/9333 [..............................] - ETA: 8:38 - loss: 0.7077 - acc: 0.4531
 128/9333 [..............................] - ETA: 8:07 - loss: 0.7014 - acc: 0.4922
 192/9333 [..............................] - ETA: 8:23 - loss: 0.6989 - acc: 0.5052
 256/9333 [..............................] - ETA: 8:04 - loss: 0.7008 - acc: 0.5039
 320/9333 [>.............................] - ETA: 7:46 - loss: 0.6931 - acc: 0.5188
 384/9333 [>.............................] - ETA: 7:55 - loss: 0.6967 - acc: 0.5104
 448/9333 [>.............................] - ETA: 7:40 - loss: 0.7001 - acc: 0.4978
 512/9333 [>.............................] - ETA: 7:37 - loss: 0.6966 - acc: 0.5098
 576/9333 [>.............................] - ETA: 7:30 - loss: 0.6956 - acc: 0.5191
 640/9333 [=>............................] - ETA: 7:21 - loss: 0.6925 - acc: 0.5266
 704/9333 [=>............................] - ETA: 7:11 - loss: 0.6927 - acc: 0.5256
 768/9333 [=>............................] - ETA: 7:09 - loss: 0.6910 - acc: 0.5312
 832/9333 [=>............................] - ETA: 7:04 - loss: 0.6911 - acc: 0.5252
 896/9333 [=>............................] - ETA: 6:57 - loss: 0.6916 - acc: 0.5257
 960/9333 [==>...........................] - ETA: 6:53 - loss: 0.6921 - acc: 0.5250
1024/9333 [==>...........................] - ETA: 6:45 - loss: 0.6925 - acc: 0.5205
1088/9333 [==>...........................] - ETA: 6:39 - loss: 0.6932 - acc: 0.5184
1152/9333 [==>...........................] - ETA: 6:38 - loss: 0.6924 - acc: 0.5234
1216/9333 [==>...........................] - ETA: 6:33 - loss: 0.6924 - acc: 0.5230
1280/9333 [===>..........................] - ETA: 6:29 - loss: 0.6916 - acc: 0.5297
1344/9333 [===>..........................] - ETA: 6:26 - loss: 0.6924 - acc: 0.5260
1408/9333 [===>..........................] - ETA: 6:22 - loss: 0.6924 - acc: 0.5263
1472/9333 [===>..........................] - ETA: 6:17 - loss: 0.6917 - acc: 0.5285
1536/9333 [===>..........................] - ETA: 6:13 - loss: 0.6913 - acc: 0.5293
1600/9333 [====>.........................] - ETA: 6:12 - loss: 0.6917 - acc: 0.5256
1664/9333 [====>.........................] - ETA: 6:10 - loss: 0.6907 - acc: 0.5294
1728/9333 [====>.........................] - ETA: 6:08 - loss: 0.6906 - acc: 0.5289
1792/9333 [====>.........................] - ETA: 6:03 - loss: 0.6903 - acc: 0.5301
1856/9333 [====>.........................] - ETA: 5:59 - loss: 0.6897 - acc: 0.5345
1920/9333 [=====>........................] - ETA: 5:56 - loss: 0.6892 - acc: 0.5344
1984/9333 [=====>........................] - ETA: 5:54 - loss: 0.6890 - acc: 0.5358
2048/9333 [=====>........................] - ETA: 5:52 - loss: 0.6892 - acc: 0.5342
2112/9333 [=====>........................] - ETA: 5:49 - loss: 0.6886 - acc: 0.5374
2176/9333 [=====>........................] - ETA: 5:45 - loss: 0.6887 - acc: 0.5368
2240/9333 [======>.......................] - ETA: 5:41 - loss: 0.6889 - acc: 0.5366
2304/9333 [======>.......................] - ETA: 5:37 - loss: 0.6884 - acc: 0.5386
2368/9333 [======>.......................] - ETA: 5:35 - loss: 0.6887 - acc: 0.5389
2432/9333 [======>.......................] - ETA: 5:34 - loss: 0.6885 - acc: 0.5382
2496/9333 [=======>......................] - ETA: 5:30 - loss: 0.6887 - acc: 0.5365
2560/9333 [=======>......................] - ETA: 5:26 - loss: 0.6890 - acc: 0.5336
2624/9333 [=======>......................] - ETA: 5:22 - loss: 0.6888 - acc: 0.5354
2688/9333 [=======>......................] - ETA: 5:19 - loss: 0.6889 - acc: 0.5350
2752/9333 [=======>......................] - ETA: 5:15 - loss: 0.6892 - acc: 0.5342
2816/9333 [========>.....................] - ETA: 5:13 - loss: 0.6885 - acc: 0.5366
2880/9333 [========>.....................] - ETA: 5:10 - loss: 0.6883 - acc: 0.5375
2944/9333 [========>.....................] - ETA: 5:07 - loss: 0.6883 - acc: 0.5374
3008/9333 [========>.....................] - ETA: 5:04 - loss: 0.6878 - acc: 0.5396
3072/9333 [========>.....................] - ETA: 5:00 - loss: 0.6875 - acc: 0.5430
3136/9333 [=========>....................] - ETA: 4:57 - loss: 0.6879 - acc: 0.5421
3200/9333 [=========>....................] - ETA: 4:53 - loss: 0.6879 - acc: 0.5425
3264/9333 [=========>....................] - ETA: 4:49 - loss: 0.6878 - acc: 0.5441
3328/9333 [=========>....................] - ETA: 4:49 - loss: 0.6875 - acc: 0.5448
3392/9333 [=========>....................] - ETA: 4:46 - loss: 0.6872 - acc: 0.5451
3456/9333 [==========>...................] - ETA: 4:43 - loss: 0.6872 - acc: 0.5463
3520/9333 [==========>...................] - ETA: 4:39 - loss: 0.6870 - acc: 0.5477
3584/9333 [==========>...................] - ETA: 4:36 - loss: 0.6871 - acc: 0.5494
3648/9333 [==========>...................] - ETA: 4:32 - loss: 0.6867 - acc: 0.5499
3712/9333 [==========>...................] - ETA: 4:28 - loss: 0.6871 - acc: 0.5490
3776/9333 [===========>..................] - ETA: 4:26 - loss: 0.6871 - acc: 0.5493
3840/9333 [===========>..................] - ETA: 4:23 - loss: 0.6867 - acc: 0.5513
3904/9333 [===========>..................] - ETA: 4:21 - loss: 0.6868 - acc: 0.5510
3968/9333 [===========>..................] - ETA: 4:17 - loss: 0.6867 - acc: 0.5519
4032/9333 [===========>..................] - ETA: 4:14 - loss: 0.6864 - acc: 0.5523
4096/9333 [============>.................] - ETA: 4:10 - loss: 0.6856 - acc: 0.5544
4160/9333 [============>.................] - ETA: 4:08 - loss: 0.6863 - acc: 0.5519
4224/9333 [============>.................] - ETA: 4:05 - loss: 0.6866 - acc: 0.5507
4288/9333 [============>.................] - ETA: 4:02 - loss: 0.6870 - acc: 0.5490
4352/9333 [============>.................] - ETA: 3:59 - loss: 0.6869 - acc: 0.5492
4416/9333 [=============>................] - ETA: 3:56 - loss: 0.6876 - acc: 0.5482
4480/9333 [=============>................] - ETA: 3:53 - loss: 0.6876 - acc: 0.5473
4544/9333 [=============>................] - ETA: 3:50 - loss: 0.6868 - acc: 0.5493
4608/9333 [=============>................] - ETA: 3:47 - loss: 0.6877 - acc: 0.5480
4672/9333 [==============>...............] - ETA: 3:43 - loss: 0.6872 - acc: 0.5479
4736/9333 [==============>...............] - ETA: 3:41 - loss: 0.6874 - acc: 0.5479
4800/9333 [==============>...............] - ETA: 3:38 - loss: 0.6872 - acc: 0.5483
4864/9333 [==============>...............] - ETA: 3:35 - loss: 0.6876 - acc: 0.5473
4928/9333 [==============>...............] - ETA: 3:32 - loss: 0.6875 - acc: 0.5473
4992/9333 [===============>..............] - ETA: 3:28 - loss: 0.6880 - acc: 0.5461
5056/9333 [===============>..............] - ETA: 3:25 - loss: 0.6884 - acc: 0.5449
5120/9333 [===============>..............] - ETA: 3:22 - loss: 0.6881 - acc: 0.5465
5184/9333 [===============>..............] - ETA: 3:18 - loss: 0.6882 - acc: 0.5467
5248/9333 [===============>..............] - ETA: 3:15 - loss: 0.6885 - acc: 0.5455
5312/9333 [================>.............] - ETA: 3:12 - loss: 0.6885 - acc: 0.5463
5376/9333 [================>.............] - ETA: 3:09 - loss: 0.6884 - acc: 0.5467
5440/9333 [================>.............] - ETA: 3:06 - loss: 0.6883 - acc: 0.5471
5504/9333 [================>.............] - ETA: 3:03 - loss: 0.6879 - acc: 0.5485
5568/9333 [================>.............] - ETA: 3:00 - loss: 0.6876 - acc: 0.5489
5632/9333 [=================>............] - ETA: 2:56 - loss: 0.6875 - acc: 0.5490
5696/9333 [=================>............] - ETA: 2:53 - loss: 0.6876 - acc: 0.5478
5760/9333 [=================>............] - ETA: 2:51 - loss: 0.6873 - acc: 0.5486
5824/9333 [=================>............] - ETA: 2:48 - loss: 0.6872 - acc: 0.5482
5888/9333 [=================>............] - ETA: 2:45 - loss: 0.6869 - acc: 0.5489
5952/9333 [==================>...........] - ETA: 2:41 - loss: 0.6869 - acc: 0.5491
6016/9333 [==================>...........] - ETA: 2:38 - loss: 0.6867 - acc: 0.5494
6080/9333 [==================>...........] - ETA: 2:35 - loss: 0.6866 - acc: 0.5498
6144/9333 [==================>...........] - ETA: 2:32 - loss: 0.6867 - acc: 0.5496
6208/9333 [==================>...........] - ETA: 2:29 - loss: 0.6867 - acc: 0.5496
6272/9333 [===================>..........] - ETA: 2:26 - loss: 0.6864 - acc: 0.5502
6336/9333 [===================>..........] - ETA: 2:23 - loss: 0.6865 - acc: 0.5496
6400/9333 [===================>..........] - ETA: 2:20 - loss: 0.6863 - acc: 0.5498
6464/9333 [===================>..........] - ETA: 2:17 - loss: 0.6865 - acc: 0.5492
6528/9333 [===================>..........] - ETA: 2:13 - loss: 0.6864 - acc: 0.5492
6592/9333 [====================>.........] - ETA: 2:10 - loss: 0.6864 - acc: 0.5488
6656/9333 [====================>.........] - ETA: 2:07 - loss: 0.6865 - acc: 0.5485
6720/9333 [====================>.........] - ETA: 2:04 - loss: 0.6866 - acc: 0.5479
6784/9333 [====================>.........] - ETA: 2:01 - loss: 0.6867 - acc: 0.5476
6848/9333 [=====================>........] - ETA: 1:58 - loss: 0.6866 - acc: 0.5480
6912/9333 [=====================>........] - ETA: 1:55 - loss: 0.6864 - acc: 0.5488
6976/9333 [=====================>........] - ETA: 1:52 - loss: 0.6862 - acc: 0.5499
7040/9333 [=====================>........] - ETA: 1:49 - loss: 0.6862 - acc: 0.5499
7104/9333 [=====================>........] - ETA: 1:46 - loss: 0.6863 - acc: 0.5493
7168/9333 [======================>.......] - ETA: 1:43 - loss: 0.6862 - acc: 0.5498
7232/9333 [======================>.......] - ETA: 1:40 - loss: 0.6863 - acc: 0.5501
7296/9333 [======================>.......] - ETA: 1:37 - loss: 0.6863 - acc: 0.5496
7360/9333 [======================>.......] - ETA: 1:34 - loss: 0.6863 - acc: 0.5497
7424/9333 [======================>.......] - ETA: 1:31 - loss: 0.6861 - acc: 0.5500
7488/9333 [=======================>......] - ETA: 1:28 - loss: 0.6865 - acc: 0.5487
7552/9333 [=======================>......] - ETA: 1:25 - loss: 0.6863 - acc: 0.5487
7616/9333 [=======================>......] - ETA: 1:22 - loss: 0.6864 - acc: 0.5486
7680/9333 [=======================>......] - ETA: 1:19 - loss: 0.6863 - acc: 0.5488
7744/9333 [=======================>......] - ETA: 1:16 - loss: 0.6863 - acc: 0.5492
7808/9333 [========================>.....] - ETA: 1:12 - loss: 0.6863 - acc: 0.5493
7872/9333 [========================>.....] - ETA: 1:09 - loss: 0.6862 - acc: 0.5497
7936/9333 [========================>.....] - ETA: 1:06 - loss: 0.6862 - acc: 0.5495
8000/9333 [========================>.....] - ETA: 1:03 - loss: 0.6861 - acc: 0.5497
8064/9333 [========================>.....] - ETA: 1:00 - loss: 0.6861 - acc: 0.5497
8128/9333 [=========================>....] - ETA: 57s - loss: 0.6860 - acc: 0.5502 
8192/9333 [=========================>....] - ETA: 54s - loss: 0.6860 - acc: 0.5505
8256/9333 [=========================>....] - ETA: 51s - loss: 0.6861 - acc: 0.5503
8320/9333 [=========================>....] - ETA: 48s - loss: 0.6860 - acc: 0.5502
8384/9333 [=========================>....] - ETA: 45s - loss: 0.6860 - acc: 0.5501
8448/9333 [==========================>...] - ETA: 42s - loss: 0.6859 - acc: 0.5507
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6859 - acc: 0.5505
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6857 - acc: 0.5512
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6856 - acc: 0.5512
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6857 - acc: 0.5507
8768/9333 [===========================>..] - ETA: 26s - loss: 0.6857 - acc: 0.5508
8832/9333 [===========================>..] - ETA: 23s - loss: 0.6859 - acc: 0.5505
8896/9333 [===========================>..] - ETA: 20s - loss: 0.6857 - acc: 0.5510
8960/9333 [===========================>..] - ETA: 17s - loss: 0.6859 - acc: 0.5503
9024/9333 [============================>.] - ETA: 14s - loss: 0.6858 - acc: 0.5508
9088/9333 [============================>.] - ETA: 11s - loss: 0.6859 - acc: 0.5506
9152/9333 [============================>.] - ETA: 8s - loss: 0.6860 - acc: 0.5500 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6860 - acc: 0.5502
9280/9333 [============================>.] - ETA: 2s - loss: 0.6859 - acc: 0.5506
9333/9333 [==============================] - 463s 50ms/step - loss: 0.6858 - acc: 0.5511 - val_loss: 0.6850 - val_acc: 0.5439

Epoch 00010: val_acc improved from 0.54002 to 0.54388, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window03/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4ef7526c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4ef7526c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f47246a9590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f47246a9590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f3b1462d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4f3b1462d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ef6d62190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ef6d62190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eeecf7290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eeecf7290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eeec50250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eeec50250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eeec502d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eeec502d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e404ed10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46e404ed10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4564722bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4564722bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eeeaf5d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eeeaf5d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eeea04710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eeea04710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4564722e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4564722e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef74aaa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef74aaa50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eee94c710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eee94c710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eee79a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eee79a550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eee8f4510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eee8f4510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eee94c510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eee94c510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eee8f4810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eee8f4810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eee6aaf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eee6aaf50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ee64bc210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ee64bc210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee635ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee635ba50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eee5b5d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eee5b5d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee6546750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee6546750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eee80c790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4eee80c790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ee6160d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ee6160d10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee64b6950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee64b6950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ee626fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ee626fd50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee64c61d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee64c61d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ee6067bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ee6067bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ee5e833d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ee5e833d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee615de90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee615de90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ee604eb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ee604eb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee6293fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ee6293fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ee5e6ae50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ee5e6ae50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eddb248d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eddb248d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef736ce10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef736ce10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eddd26350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eddd26350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eddb4fd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eddb4fd90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4edd8d7e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4edd8d7e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4edd846a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4edd846a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eddc29b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4eddc29b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4edd9d3310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4edd9d3310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4edd8421d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4edd8421d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4edd835b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4edd835b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ed54e7d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ed54e7d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4edd601fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4edd601fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eddd1a910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4eddd1a910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed53f1c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed53f1c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ed52920d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ed52920d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ed5335a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ed5335a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed52f8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed52f8490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ed51fe2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ed51fe2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed50bd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed50bd050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ed4fc2990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ed4fc2990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ed4eae710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ed4eae710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed4fbebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed4fbebd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ed5075a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ed5075a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed51f2c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed51f2c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ed4e5b590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ed4e5b590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eccb51090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4eccb51090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ecca6a050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ecca6a050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ed4f3cd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ed4f3cd90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed4fd7e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ed4fd7e10>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 3:04
 128/2592 [>.............................] - ETA: 1:50
 192/2592 [=>............................] - ETA: 1:27
 256/2592 [=>............................] - ETA: 1:14
 320/2592 [==>...........................] - ETA: 1:06
 384/2592 [===>..........................] - ETA: 1:01
 448/2592 [====>.........................] - ETA: 57s 
 512/2592 [====>.........................] - ETA: 55s
 576/2592 [=====>........................] - ETA: 52s
 640/2592 [======>.......................] - ETA: 48s
 704/2592 [=======>......................] - ETA: 45s
 768/2592 [=======>......................] - ETA: 43s
 832/2592 [========>.....................] - ETA: 40s
 896/2592 [=========>....................] - ETA: 38s
 960/2592 [==========>...................] - ETA: 36s
1024/2592 [==========>...................] - ETA: 34s
1088/2592 [===========>..................] - ETA: 32s
1152/2592 [============>.................] - ETA: 30s
1216/2592 [=============>................] - ETA: 29s
1280/2592 [=============>................] - ETA: 27s
1344/2592 [==============>...............] - ETA: 26s
1408/2592 [===============>..............] - ETA: 24s
1472/2592 [================>.............] - ETA: 23s
1536/2592 [================>.............] - ETA: 21s
1600/2592 [=================>............] - ETA: 20s
1664/2592 [==================>...........] - ETA: 20s
1728/2592 [===================>..........] - ETA: 18s
1792/2592 [===================>..........] - ETA: 17s
1856/2592 [====================>.........] - ETA: 15s
1920/2592 [=====================>........] - ETA: 14s
1984/2592 [=====================>........] - ETA: 12s
2048/2592 [======================>.......] - ETA: 11s
2112/2592 [=======================>......] - ETA: 10s
2176/2592 [========================>.....] - ETA: 8s 
2240/2592 [========================>.....] - ETA: 7s
2304/2592 [=========================>....] - ETA: 5s
2368/2592 [==========================>...] - ETA: 4s
2432/2592 [===========================>..] - ETA: 3s
2496/2592 [===========================>..] - ETA: 1s
2560/2592 [============================>.] - ETA: 0s
2592/2592 [==============================] - 53s 20ms/step
loss: 0.6837523086571399
acc: 0.5582561728395061
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f454410c9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f454410c9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f45440dc690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f45440dc690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a46ee790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a46ee790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48c4083bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48c4083bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ef6f56590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ef6f56590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a462b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a462b550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48c4083d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48c4083d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48c4179610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48c4179610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ef748fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ef748fb90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ef73f5bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ef73f5bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef6f56090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef6f56090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ef748f810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ef748f810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef71e8690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef71e8690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ef6fdfed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4ef6fdfed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ef7498690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4ef7498690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef6fdfa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4ef6fdfa90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ef7101790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4ef7101790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f448434bfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f448434bfd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48a423f5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48a423f5d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45245472d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45245472d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45245443d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45245443d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48a423f450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48a423f450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f452464dcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f452464dcd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4524366850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4524366850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4524210f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4524210f90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45242f9610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45242f9610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4524462090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4524462090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45242c8750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45242c8750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4524253c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4524253c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45046c60d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45046c60d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4504756490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4504756490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45245479d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45245479d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45046c3550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45046c3550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f450472b410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f450472b410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4504395e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4504395e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45044bef90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45044bef90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f450472b510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f450472b510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45043df550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45043df550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45044e31d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45044e31d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45040b3ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45040b3ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f450427da10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f450427da10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f450428c210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f450428c210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45040aad90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45040aad90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45040e8050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45040e8050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44e45606d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44e45606d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f450407d750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f450407d750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44e4671890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44e4671890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44e450ded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44e450ded0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44e43f9e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44e43f9e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44e42012d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44e42012d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44e411ca50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44e411ca50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44e4371d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44e4371d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44e430bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44e430bc50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44c47f2f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44c47f2f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44c46dbd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44c46dbd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44c4770d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44c4770d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44e42745d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44e42745d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44c4549e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44c4549e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44c47ea1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44c47ea1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44c43b0510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44c43b0510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44c4532cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44c4532cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44c47ea9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44c47ea9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44c44ab490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44c44ab490>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 1:13:38 - loss: 0.7062 - acc: 0.5312
 128/9333 [..............................] - ETA: 43:25 - loss: 0.7306 - acc: 0.5156  
 192/9333 [..............................] - ETA: 33:22 - loss: 0.7249 - acc: 0.5104
 256/9333 [..............................] - ETA: 28:12 - loss: 0.7294 - acc: 0.5117
 320/9333 [>.............................] - ETA: 24:44 - loss: 0.7522 - acc: 0.4969
 384/9333 [>.............................] - ETA: 22:34 - loss: 0.7512 - acc: 0.5052
 448/9333 [>.............................] - ETA: 21:23 - loss: 0.7577 - acc: 0.5000
 512/9333 [>.............................] - ETA: 20:15 - loss: 0.7517 - acc: 0.5059
 576/9333 [>.............................] - ETA: 19:10 - loss: 0.7511 - acc: 0.4983
 640/9333 [=>............................] - ETA: 18:19 - loss: 0.7484 - acc: 0.5016
 704/9333 [=>............................] - ETA: 17:44 - loss: 0.7541 - acc: 0.5014
 768/9333 [=>............................] - ETA: 17:05 - loss: 0.7583 - acc: 0.4948
 832/9333 [=>............................] - ETA: 16:37 - loss: 0.7537 - acc: 0.5000
 896/9333 [=>............................] - ETA: 16:15 - loss: 0.7498 - acc: 0.5067
 960/9333 [==>...........................] - ETA: 15:53 - loss: 0.7498 - acc: 0.5062
1024/9333 [==>...........................] - ETA: 15:28 - loss: 0.7467 - acc: 0.5059
1088/9333 [==>...........................] - ETA: 15:06 - loss: 0.7428 - acc: 0.5083
1152/9333 [==>...........................] - ETA: 14:49 - loss: 0.7439 - acc: 0.5061
1216/9333 [==>...........................] - ETA: 14:28 - loss: 0.7424 - acc: 0.5066
1280/9333 [===>..........................] - ETA: 14:11 - loss: 0.7408 - acc: 0.5086
1344/9333 [===>..........................] - ETA: 13:58 - loss: 0.7432 - acc: 0.5067
1408/9333 [===>..........................] - ETA: 13:46 - loss: 0.7457 - acc: 0.5043
1472/9333 [===>..........................] - ETA: 13:30 - loss: 0.7466 - acc: 0.5027
1536/9333 [===>..........................] - ETA: 13:18 - loss: 0.7461 - acc: 0.5052
1600/9333 [====>.........................] - ETA: 13:08 - loss: 0.7452 - acc: 0.5038
1664/9333 [====>.........................] - ETA: 12:56 - loss: 0.7436 - acc: 0.5066
1728/9333 [====>.........................] - ETA: 12:43 - loss: 0.7404 - acc: 0.5093
1792/9333 [====>.........................] - ETA: 12:34 - loss: 0.7395 - acc: 0.5084
1856/9333 [====>.........................] - ETA: 12:26 - loss: 0.7421 - acc: 0.5043
1920/9333 [=====>........................] - ETA: 12:14 - loss: 0.7420 - acc: 0.5042
1984/9333 [=====>........................] - ETA: 12:04 - loss: 0.7412 - acc: 0.5055
2048/9333 [=====>........................] - ETA: 11:56 - loss: 0.7407 - acc: 0.5034
2112/9333 [=====>........................] - ETA: 11:46 - loss: 0.7406 - acc: 0.5038
2176/9333 [=====>........................] - ETA: 11:33 - loss: 0.7392 - acc: 0.5037
2240/9333 [======>.......................] - ETA: 11:24 - loss: 0.7372 - acc: 0.5076
2304/9333 [======>.......................] - ETA: 11:13 - loss: 0.7367 - acc: 0.5069
2368/9333 [======>.......................] - ETA: 11:08 - loss: 0.7362 - acc: 0.5072
2432/9333 [======>.......................] - ETA: 10:59 - loss: 0.7362 - acc: 0.5066
2496/9333 [=======>......................] - ETA: 10:52 - loss: 0.7366 - acc: 0.5048
2560/9333 [=======>......................] - ETA: 10:45 - loss: 0.7369 - acc: 0.5031
2624/9333 [=======>......................] - ETA: 10:37 - loss: 0.7369 - acc: 0.5027
2688/9333 [=======>......................] - ETA: 10:30 - loss: 0.7371 - acc: 0.5015
2752/9333 [=======>......................] - ETA: 10:20 - loss: 0.7361 - acc: 0.5015
2816/9333 [========>.....................] - ETA: 10:12 - loss: 0.7359 - acc: 0.5007
2880/9333 [========>.....................] - ETA: 10:06 - loss: 0.7356 - acc: 0.5017
2944/9333 [========>.....................] - ETA: 9:58 - loss: 0.7343 - acc: 0.5037 
3008/9333 [========>.....................] - ETA: 9:53 - loss: 0.7333 - acc: 0.5050
3072/9333 [========>.....................] - ETA: 9:46 - loss: 0.7330 - acc: 0.5046
3136/9333 [=========>....................] - ETA: 9:39 - loss: 0.7322 - acc: 0.5048
3200/9333 [=========>....................] - ETA: 9:31 - loss: 0.7319 - acc: 0.5031
3264/9333 [=========>....................] - ETA: 9:24 - loss: 0.7317 - acc: 0.5018
3328/9333 [=========>....................] - ETA: 9:17 - loss: 0.7315 - acc: 0.5012
3392/9333 [=========>....................] - ETA: 9:10 - loss: 0.7311 - acc: 0.5012
3456/9333 [==========>...................] - ETA: 9:04 - loss: 0.7311 - acc: 0.5006
3520/9333 [==========>...................] - ETA: 8:58 - loss: 0.7301 - acc: 0.5017
3584/9333 [==========>...................] - ETA: 8:51 - loss: 0.7302 - acc: 0.5017
3648/9333 [==========>...................] - ETA: 8:44 - loss: 0.7304 - acc: 0.5000
3712/9333 [==========>...................] - ETA: 8:37 - loss: 0.7299 - acc: 0.5003
3776/9333 [===========>..................] - ETA: 8:30 - loss: 0.7294 - acc: 0.5013
3840/9333 [===========>..................] - ETA: 8:24 - loss: 0.7288 - acc: 0.5021
3904/9333 [===========>..................] - ETA: 8:16 - loss: 0.7290 - acc: 0.5005
3968/9333 [===========>..................] - ETA: 8:10 - loss: 0.7291 - acc: 0.5005
4032/9333 [===========>..................] - ETA: 8:04 - loss: 0.7283 - acc: 0.5017
4096/9333 [============>.................] - ETA: 7:58 - loss: 0.7277 - acc: 0.5024
4160/9333 [============>.................] - ETA: 7:51 - loss: 0.7275 - acc: 0.5034
4224/9333 [============>.................] - ETA: 7:46 - loss: 0.7273 - acc: 0.5036
4288/9333 [============>.................] - ETA: 7:39 - loss: 0.7272 - acc: 0.5026
4352/9333 [============>.................] - ETA: 7:33 - loss: 0.7264 - acc: 0.5039
4416/9333 [=============>................] - ETA: 7:26 - loss: 0.7263 - acc: 0.5029
4480/9333 [=============>................] - ETA: 7:21 - loss: 0.7263 - acc: 0.5016
4544/9333 [=============>................] - ETA: 7:15 - loss: 0.7267 - acc: 0.5000
4608/9333 [=============>................] - ETA: 7:08 - loss: 0.7259 - acc: 0.5017
4672/9333 [==============>...............] - ETA: 7:02 - loss: 0.7259 - acc: 0.5006
4736/9333 [==============>...............] - ETA: 6:57 - loss: 0.7257 - acc: 0.5000
4800/9333 [==============>...............] - ETA: 6:50 - loss: 0.7252 - acc: 0.5006
4864/9333 [==============>...............] - ETA: 6:43 - loss: 0.7249 - acc: 0.5016
4928/9333 [==============>...............] - ETA: 6:38 - loss: 0.7249 - acc: 0.5024
4992/9333 [===============>..............] - ETA: 6:32 - loss: 0.7249 - acc: 0.5032
5056/9333 [===============>..............] - ETA: 6:26 - loss: 0.7243 - acc: 0.5049
5120/9333 [===============>..............] - ETA: 6:19 - loss: 0.7242 - acc: 0.5047
5184/9333 [===============>..............] - ETA: 6:13 - loss: 0.7230 - acc: 0.5068
5248/9333 [===============>..............] - ETA: 6:07 - loss: 0.7231 - acc: 0.5074
5312/9333 [================>.............] - ETA: 6:01 - loss: 0.7230 - acc: 0.5073
5376/9333 [================>.............] - ETA: 5:55 - loss: 0.7232 - acc: 0.5065
5440/9333 [================>.............] - ETA: 5:49 - loss: 0.7228 - acc: 0.5064
5504/9333 [================>.............] - ETA: 5:43 - loss: 0.7228 - acc: 0.5055
5568/9333 [================>.............] - ETA: 5:37 - loss: 0.7220 - acc: 0.5072
5632/9333 [=================>............] - ETA: 5:31 - loss: 0.7217 - acc: 0.5080
5696/9333 [=================>............] - ETA: 5:26 - loss: 0.7211 - acc: 0.5090
5760/9333 [=================>............] - ETA: 5:20 - loss: 0.7209 - acc: 0.5085
5824/9333 [=================>............] - ETA: 5:14 - loss: 0.7208 - acc: 0.5084
5888/9333 [=================>............] - ETA: 5:08 - loss: 0.7200 - acc: 0.5097
5952/9333 [==================>...........] - ETA: 5:02 - loss: 0.7202 - acc: 0.5089
6016/9333 [==================>...........] - ETA: 4:57 - loss: 0.7202 - acc: 0.5081
6080/9333 [==================>...........] - ETA: 4:51 - loss: 0.7197 - acc: 0.5090
6144/9333 [==================>...........] - ETA: 4:45 - loss: 0.7193 - acc: 0.5096
6208/9333 [==================>...........] - ETA: 4:39 - loss: 0.7192 - acc: 0.5093
6272/9333 [===================>..........] - ETA: 4:33 - loss: 0.7189 - acc: 0.5096
6336/9333 [===================>..........] - ETA: 4:28 - loss: 0.7184 - acc: 0.5106
6400/9333 [===================>..........] - ETA: 4:22 - loss: 0.7183 - acc: 0.5103
6464/9333 [===================>..........] - ETA: 4:15 - loss: 0.7179 - acc: 0.5111
6528/9333 [===================>..........] - ETA: 4:10 - loss: 0.7178 - acc: 0.5109
6592/9333 [====================>.........] - ETA: 4:04 - loss: 0.7171 - acc: 0.5129
6656/9333 [====================>.........] - ETA: 3:58 - loss: 0.7166 - acc: 0.5138
6720/9333 [====================>.........] - ETA: 3:52 - loss: 0.7164 - acc: 0.5140
6784/9333 [====================>.........] - ETA: 3:46 - loss: 0.7161 - acc: 0.5144
6848/9333 [=====================>........] - ETA: 3:40 - loss: 0.7157 - acc: 0.5146
6912/9333 [=====================>........] - ETA: 3:34 - loss: 0.7154 - acc: 0.5150
6976/9333 [=====================>........] - ETA: 3:29 - loss: 0.7149 - acc: 0.5162
7040/9333 [=====================>........] - ETA: 3:23 - loss: 0.7146 - acc: 0.5166
7104/9333 [=====================>........] - ETA: 3:17 - loss: 0.7145 - acc: 0.5166
7168/9333 [======================>.......] - ETA: 3:11 - loss: 0.7144 - acc: 0.5166
7232/9333 [======================>.......] - ETA: 3:06 - loss: 0.7144 - acc: 0.5162
7296/9333 [======================>.......] - ETA: 3:00 - loss: 0.7147 - acc: 0.5159
7360/9333 [======================>.......] - ETA: 2:54 - loss: 0.7152 - acc: 0.5155
7424/9333 [======================>.......] - ETA: 2:48 - loss: 0.7149 - acc: 0.5160
7488/9333 [=======================>......] - ETA: 2:42 - loss: 0.7144 - acc: 0.5168
7552/9333 [=======================>......] - ETA: 2:37 - loss: 0.7141 - acc: 0.5166
7616/9333 [=======================>......] - ETA: 2:31 - loss: 0.7139 - acc: 0.5171
7680/9333 [=======================>......] - ETA: 2:25 - loss: 0.7138 - acc: 0.5177
7744/9333 [=======================>......] - ETA: 2:20 - loss: 0.7135 - acc: 0.5185
7808/9333 [========================>.....] - ETA: 2:14 - loss: 0.7134 - acc: 0.5183
7872/9333 [========================>.....] - ETA: 2:08 - loss: 0.7128 - acc: 0.5196
7936/9333 [========================>.....] - ETA: 2:03 - loss: 0.7125 - acc: 0.5198
8000/9333 [========================>.....] - ETA: 1:57 - loss: 0.7121 - acc: 0.5206
8064/9333 [========================>.....] - ETA: 1:51 - loss: 0.7121 - acc: 0.5202
8128/9333 [=========================>....] - ETA: 1:46 - loss: 0.7121 - acc: 0.5201
8192/9333 [=========================>....] - ETA: 1:40 - loss: 0.7119 - acc: 0.5205
8256/9333 [=========================>....] - ETA: 1:34 - loss: 0.7116 - acc: 0.5207
8320/9333 [=========================>....] - ETA: 1:29 - loss: 0.7115 - acc: 0.5212
8384/9333 [=========================>....] - ETA: 1:23 - loss: 0.7111 - acc: 0.5215
8448/9333 [==========================>...] - ETA: 1:18 - loss: 0.7112 - acc: 0.5211
8512/9333 [==========================>...] - ETA: 1:12 - loss: 0.7110 - acc: 0.5210
8576/9333 [==========================>...] - ETA: 1:06 - loss: 0.7109 - acc: 0.5215
8640/9333 [==========================>...] - ETA: 1:01 - loss: 0.7107 - acc: 0.5214
8704/9333 [==========================>...] - ETA: 55s - loss: 0.7109 - acc: 0.5211 
8768/9333 [===========================>..] - ETA: 49s - loss: 0.7109 - acc: 0.5213
8832/9333 [===========================>..] - ETA: 44s - loss: 0.7106 - acc: 0.5214
8896/9333 [===========================>..] - ETA: 38s - loss: 0.7103 - acc: 0.5223
8960/9333 [===========================>..] - ETA: 32s - loss: 0.7100 - acc: 0.5229
9024/9333 [============================>.] - ETA: 27s - loss: 0.7101 - acc: 0.5228
9088/9333 [============================>.] - ETA: 21s - loss: 0.7098 - acc: 0.5232
9152/9333 [============================>.] - ETA: 15s - loss: 0.7100 - acc: 0.5223
9216/9333 [============================>.] - ETA: 10s - loss: 0.7099 - acc: 0.5222
9280/9333 [============================>.] - ETA: 4s - loss: 0.7096 - acc: 0.5228 
9333/9333 [==============================] - 855s 92ms/step - loss: 0.7095 - acc: 0.5231 - val_loss: 0.6880 - val_acc: 0.5526

Epoch 00001: val_acc improved from -inf to 0.55256, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window04/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 15:31 - loss: 0.7049 - acc: 0.5156
 128/9333 [..............................] - ETA: 14:56 - loss: 0.6968 - acc: 0.5625
 192/9333 [..............................] - ETA: 13:50 - loss: 0.6986 - acc: 0.5469
 256/9333 [..............................] - ETA: 14:05 - loss: 0.6900 - acc: 0.5664
 320/9333 [>.............................] - ETA: 13:37 - loss: 0.6814 - acc: 0.5844
 384/9333 [>.............................] - ETA: 13:16 - loss: 0.6919 - acc: 0.5599
 448/9333 [>.............................] - ETA: 13:21 - loss: 0.6921 - acc: 0.5580
 512/9333 [>.............................] - ETA: 13:09 - loss: 0.6914 - acc: 0.5586
 576/9333 [>.............................] - ETA: 12:58 - loss: 0.6972 - acc: 0.5451
 640/9333 [=>............................] - ETA: 12:56 - loss: 0.7032 - acc: 0.5344
 704/9333 [=>............................] - ETA: 12:39 - loss: 0.7051 - acc: 0.5327
 768/9333 [=>............................] - ETA: 12:27 - loss: 0.7003 - acc: 0.5417
 832/9333 [=>............................] - ETA: 12:21 - loss: 0.6997 - acc: 0.5421
 896/9333 [=>............................] - ETA: 12:17 - loss: 0.7010 - acc: 0.5391
 960/9333 [==>...........................] - ETA: 12:08 - loss: 0.7014 - acc: 0.5375
1024/9333 [==>...........................] - ETA: 11:59 - loss: 0.7000 - acc: 0.5381
1088/9333 [==>...........................] - ETA: 11:57 - loss: 0.6962 - acc: 0.5441
1152/9333 [==>...........................] - ETA: 11:50 - loss: 0.6961 - acc: 0.5408
1216/9333 [==>...........................] - ETA: 11:41 - loss: 0.6966 - acc: 0.5378
1280/9333 [===>..........................] - ETA: 11:36 - loss: 0.6981 - acc: 0.5344
1344/9333 [===>..........................] - ETA: 11:31 - loss: 0.6987 - acc: 0.5290
1408/9333 [===>..........................] - ETA: 11:21 - loss: 0.7002 - acc: 0.5256
1472/9333 [===>..........................] - ETA: 11:14 - loss: 0.7010 - acc: 0.5265
1536/9333 [===>..........................] - ETA: 11:10 - loss: 0.7005 - acc: 0.5299
1600/9333 [====>.........................] - ETA: 11:03 - loss: 0.7022 - acc: 0.5281
1664/9333 [====>.........................] - ETA: 10:57 - loss: 0.7024 - acc: 0.5270
1728/9333 [====>.........................] - ETA: 10:52 - loss: 0.7017 - acc: 0.5284
1792/9333 [====>.........................] - ETA: 10:48 - loss: 0.7022 - acc: 0.5240
1856/9333 [====>.........................] - ETA: 10:40 - loss: 0.7019 - acc: 0.5248
1920/9333 [=====>........................] - ETA: 10:38 - loss: 0.7021 - acc: 0.5240
1984/9333 [=====>........................] - ETA: 10:32 - loss: 0.7024 - acc: 0.5257
2048/9333 [=====>........................] - ETA: 10:24 - loss: 0.7022 - acc: 0.5259
2112/9333 [=====>........................] - ETA: 10:19 - loss: 0.7018 - acc: 0.5260
2176/9333 [=====>........................] - ETA: 10:13 - loss: 0.7019 - acc: 0.5271
2240/9333 [======>.......................] - ETA: 10:05 - loss: 0.7021 - acc: 0.5250
2304/9333 [======>.......................] - ETA: 9:56 - loss: 0.7026 - acc: 0.5252 
2368/9333 [======>.......................] - ETA: 9:49 - loss: 0.7023 - acc: 0.5258
2432/9333 [======>.......................] - ETA: 9:41 - loss: 0.7026 - acc: 0.5247
2496/9333 [=======>......................] - ETA: 9:32 - loss: 0.7020 - acc: 0.5256
2560/9333 [=======>......................] - ETA: 9:25 - loss: 0.7018 - acc: 0.5258
2624/9333 [=======>......................] - ETA: 9:18 - loss: 0.7015 - acc: 0.5259
2688/9333 [=======>......................] - ETA: 9:11 - loss: 0.7008 - acc: 0.5279
2752/9333 [=======>......................] - ETA: 9:05 - loss: 0.7002 - acc: 0.5273
2816/9333 [========>.....................] - ETA: 8:57 - loss: 0.6999 - acc: 0.5270
2880/9333 [========>.....................] - ETA: 8:50 - loss: 0.6997 - acc: 0.5267
2944/9333 [========>.....................] - ETA: 8:43 - loss: 0.6998 - acc: 0.5255
3008/9333 [========>.....................] - ETA: 8:36 - loss: 0.6992 - acc: 0.5273
3072/9333 [========>.....................] - ETA: 8:29 - loss: 0.6995 - acc: 0.5254
3136/9333 [=========>....................] - ETA: 8:22 - loss: 0.6994 - acc: 0.5255
3200/9333 [=========>....................] - ETA: 8:15 - loss: 0.6999 - acc: 0.5238
3264/9333 [=========>....................] - ETA: 8:09 - loss: 0.6996 - acc: 0.5254
3328/9333 [=========>....................] - ETA: 8:03 - loss: 0.6994 - acc: 0.5246
3392/9333 [=========>....................] - ETA: 7:55 - loss: 0.6992 - acc: 0.5242
3456/9333 [==========>...................] - ETA: 7:49 - loss: 0.6994 - acc: 0.5226
3520/9333 [==========>...................] - ETA: 7:43 - loss: 0.6996 - acc: 0.5222
3584/9333 [==========>...................] - ETA: 7:37 - loss: 0.6998 - acc: 0.5206
3648/9333 [==========>...................] - ETA: 7:31 - loss: 0.6997 - acc: 0.5211
3712/9333 [==========>...................] - ETA: 7:25 - loss: 0.6995 - acc: 0.5202
3776/9333 [===========>..................] - ETA: 7:18 - loss: 0.6998 - acc: 0.5185
3840/9333 [===========>..................] - ETA: 7:12 - loss: 0.6993 - acc: 0.5203
3904/9333 [===========>..................] - ETA: 7:07 - loss: 0.6991 - acc: 0.5200
3968/9333 [===========>..................] - ETA: 7:01 - loss: 0.6992 - acc: 0.5184
4032/9333 [===========>..................] - ETA: 6:55 - loss: 0.6991 - acc: 0.5198
4096/9333 [============>.................] - ETA: 6:49 - loss: 0.6988 - acc: 0.5210
4160/9333 [============>.................] - ETA: 6:44 - loss: 0.6984 - acc: 0.5214
4224/9333 [============>.................] - ETA: 6:38 - loss: 0.6984 - acc: 0.5211
4288/9333 [============>.................] - ETA: 6:32 - loss: 0.6977 - acc: 0.5226
4352/9333 [============>.................] - ETA: 6:27 - loss: 0.6976 - acc: 0.5227
4416/9333 [=============>................] - ETA: 6:21 - loss: 0.6980 - acc: 0.5215
4480/9333 [=============>................] - ETA: 6:16 - loss: 0.6981 - acc: 0.5210
4544/9333 [=============>................] - ETA: 6:10 - loss: 0.6984 - acc: 0.5211
4608/9333 [=============>................] - ETA: 6:04 - loss: 0.6983 - acc: 0.5215
4672/9333 [==============>...............] - ETA: 5:59 - loss: 0.6989 - acc: 0.5197
4736/9333 [==============>...............] - ETA: 5:53 - loss: 0.6988 - acc: 0.5201
4800/9333 [==============>...............] - ETA: 5:48 - loss: 0.6984 - acc: 0.5210
4864/9333 [==============>...............] - ETA: 5:42 - loss: 0.6985 - acc: 0.5216
4928/9333 [==============>...............] - ETA: 5:37 - loss: 0.6984 - acc: 0.5211
4992/9333 [===============>..............] - ETA: 5:32 - loss: 0.6983 - acc: 0.5212
5056/9333 [===============>..............] - ETA: 5:27 - loss: 0.6985 - acc: 0.5214
5120/9333 [===============>..............] - ETA: 5:21 - loss: 0.6985 - acc: 0.5203
5184/9333 [===============>..............] - ETA: 5:16 - loss: 0.6984 - acc: 0.5216
5248/9333 [===============>..............] - ETA: 5:11 - loss: 0.6984 - acc: 0.5219
5312/9333 [================>.............] - ETA: 5:06 - loss: 0.6984 - acc: 0.5220
5376/9333 [================>.............] - ETA: 5:01 - loss: 0.6985 - acc: 0.5208
5440/9333 [================>.............] - ETA: 4:56 - loss: 0.6984 - acc: 0.5210
5504/9333 [================>.............] - ETA: 4:50 - loss: 0.6985 - acc: 0.5203
5568/9333 [================>.............] - ETA: 4:45 - loss: 0.6985 - acc: 0.5201
5632/9333 [=================>............] - ETA: 4:40 - loss: 0.6988 - acc: 0.5190
5696/9333 [=================>............] - ETA: 4:35 - loss: 0.6985 - acc: 0.5197
5760/9333 [=================>............] - ETA: 4:30 - loss: 0.6981 - acc: 0.5203
5824/9333 [=================>............] - ETA: 4:25 - loss: 0.6977 - acc: 0.5213
5888/9333 [=================>............] - ETA: 4:19 - loss: 0.6976 - acc: 0.5222
5952/9333 [==================>...........] - ETA: 4:14 - loss: 0.6978 - acc: 0.5218
6016/9333 [==================>...........] - ETA: 4:09 - loss: 0.6979 - acc: 0.5226
6080/9333 [==================>...........] - ETA: 4:04 - loss: 0.6979 - acc: 0.5225
6144/9333 [==================>...........] - ETA: 3:59 - loss: 0.6977 - acc: 0.5233
6208/9333 [==================>...........] - ETA: 3:55 - loss: 0.6973 - acc: 0.5245
6272/9333 [===================>..........] - ETA: 3:50 - loss: 0.6973 - acc: 0.5242
6336/9333 [===================>..........] - ETA: 3:44 - loss: 0.6972 - acc: 0.5245
6400/9333 [===================>..........] - ETA: 3:39 - loss: 0.6972 - acc: 0.5244
6464/9333 [===================>..........] - ETA: 3:35 - loss: 0.6973 - acc: 0.5243
6528/9333 [===================>..........] - ETA: 3:29 - loss: 0.6973 - acc: 0.5245
6592/9333 [====================>.........] - ETA: 3:24 - loss: 0.6975 - acc: 0.5238
6656/9333 [====================>.........] - ETA: 3:20 - loss: 0.6974 - acc: 0.5237
6720/9333 [====================>.........] - ETA: 3:14 - loss: 0.6972 - acc: 0.5243
6784/9333 [====================>.........] - ETA: 3:09 - loss: 0.6972 - acc: 0.5245
6848/9333 [=====================>........] - ETA: 3:05 - loss: 0.6972 - acc: 0.5239
6912/9333 [=====================>........] - ETA: 3:00 - loss: 0.6974 - acc: 0.5233
6976/9333 [=====================>........] - ETA: 2:55 - loss: 0.6975 - acc: 0.5232
7040/9333 [=====================>........] - ETA: 2:50 - loss: 0.6976 - acc: 0.5227
7104/9333 [=====================>........] - ETA: 2:45 - loss: 0.6974 - acc: 0.5232
7168/9333 [======================>.......] - ETA: 2:41 - loss: 0.6974 - acc: 0.5226
7232/9333 [======================>.......] - ETA: 2:36 - loss: 0.6973 - acc: 0.5232
7296/9333 [======================>.......] - ETA: 2:31 - loss: 0.6970 - acc: 0.5245
7360/9333 [======================>.......] - ETA: 2:26 - loss: 0.6971 - acc: 0.5246
7424/9333 [======================>.......] - ETA: 2:21 - loss: 0.6971 - acc: 0.5241
7488/9333 [=======================>......] - ETA: 2:16 - loss: 0.6972 - acc: 0.5235
7552/9333 [=======================>......] - ETA: 2:11 - loss: 0.6971 - acc: 0.5234
7616/9333 [=======================>......] - ETA: 2:07 - loss: 0.6973 - acc: 0.5227
7680/9333 [=======================>......] - ETA: 2:02 - loss: 0.6973 - acc: 0.5221
7744/9333 [=======================>......] - ETA: 1:57 - loss: 0.6972 - acc: 0.5222
7808/9333 [========================>.....] - ETA: 1:52 - loss: 0.6971 - acc: 0.5220
7872/9333 [========================>.....] - ETA: 1:48 - loss: 0.6970 - acc: 0.5220
7936/9333 [========================>.....] - ETA: 1:43 - loss: 0.6969 - acc: 0.5224
8000/9333 [========================>.....] - ETA: 1:38 - loss: 0.6969 - acc: 0.5226
8064/9333 [========================>.....] - ETA: 1:33 - loss: 0.6969 - acc: 0.5227
8128/9333 [=========================>....] - ETA: 1:29 - loss: 0.6968 - acc: 0.5225
8192/9333 [=========================>....] - ETA: 1:24 - loss: 0.6969 - acc: 0.5221
8256/9333 [=========================>....] - ETA: 1:19 - loss: 0.6968 - acc: 0.5223
8320/9333 [=========================>....] - ETA: 1:14 - loss: 0.6968 - acc: 0.5220
8384/9333 [=========================>....] - ETA: 1:10 - loss: 0.6969 - acc: 0.5212
8448/9333 [==========================>...] - ETA: 1:05 - loss: 0.6971 - acc: 0.5215
8512/9333 [==========================>...] - ETA: 1:00 - loss: 0.6970 - acc: 0.5211
8576/9333 [==========================>...] - ETA: 55s - loss: 0.6970 - acc: 0.5216 
8640/9333 [==========================>...] - ETA: 51s - loss: 0.6971 - acc: 0.5207
8704/9333 [==========================>...] - ETA: 46s - loss: 0.6971 - acc: 0.5203
8768/9333 [===========================>..] - ETA: 41s - loss: 0.6971 - acc: 0.5195
8832/9333 [===========================>..] - ETA: 36s - loss: 0.6973 - acc: 0.5191
8896/9333 [===========================>..] - ETA: 32s - loss: 0.6975 - acc: 0.5188
8960/9333 [===========================>..] - ETA: 27s - loss: 0.6976 - acc: 0.5184
9024/9333 [============================>.] - ETA: 22s - loss: 0.6973 - acc: 0.5189
9088/9333 [============================>.] - ETA: 18s - loss: 0.6975 - acc: 0.5184
9152/9333 [============================>.] - ETA: 13s - loss: 0.6975 - acc: 0.5189
9216/9333 [============================>.] - ETA: 8s - loss: 0.6975 - acc: 0.5191 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6974 - acc: 0.5193
9333/9333 [==============================] - 710s 76ms/step - loss: 0.6973 - acc: 0.5193 - val_loss: 0.6874 - val_acc: 0.5477

Epoch 00002: val_acc did not improve from 0.55256
Epoch 3/10

  64/9333 [..............................] - ETA: 9:56 - loss: 0.7044 - acc: 0.5312
 128/9333 [..............................] - ETA: 10:40 - loss: 0.7070 - acc: 0.5000
 192/9333 [..............................] - ETA: 10:35 - loss: 0.7045 - acc: 0.5104
 256/9333 [..............................] - ETA: 10:52 - loss: 0.7064 - acc: 0.4844
 320/9333 [>.............................] - ETA: 10:55 - loss: 0.7034 - acc: 0.5031
 384/9333 [>.............................] - ETA: 10:31 - loss: 0.7010 - acc: 0.5182
 448/9333 [>.............................] - ETA: 10:31 - loss: 0.7028 - acc: 0.5022
 512/9333 [>.............................] - ETA: 10:22 - loss: 0.6991 - acc: 0.5117
 576/9333 [>.............................] - ETA: 10:22 - loss: 0.6989 - acc: 0.5122
 640/9333 [=>............................] - ETA: 10:09 - loss: 0.6998 - acc: 0.5172
 704/9333 [=>............................] - ETA: 10:07 - loss: 0.6973 - acc: 0.5256
 768/9333 [=>............................] - ETA: 10:04 - loss: 0.6972 - acc: 0.5234
 832/9333 [=>............................] - ETA: 10:01 - loss: 0.6960 - acc: 0.5240
 896/9333 [=>............................] - ETA: 9:59 - loss: 0.6952 - acc: 0.5234 
 960/9333 [==>...........................] - ETA: 9:52 - loss: 0.6947 - acc: 0.5260
1024/9333 [==>...........................] - ETA: 9:51 - loss: 0.6948 - acc: 0.5254
1088/9333 [==>...........................] - ETA: 9:42 - loss: 0.6957 - acc: 0.5202
1152/9333 [==>...........................] - ETA: 9:34 - loss: 0.6924 - acc: 0.5312
1216/9333 [==>...........................] - ETA: 9:29 - loss: 0.6905 - acc: 0.5378
1280/9333 [===>..........................] - ETA: 9:24 - loss: 0.6906 - acc: 0.5375
1344/9333 [===>..........................] - ETA: 9:18 - loss: 0.6917 - acc: 0.5357
1408/9333 [===>..........................] - ETA: 9:12 - loss: 0.6920 - acc: 0.5341
1472/9333 [===>..........................] - ETA: 9:07 - loss: 0.6934 - acc: 0.5319
1536/9333 [===>..........................] - ETA: 9:00 - loss: 0.6944 - acc: 0.5306
1600/9333 [====>.........................] - ETA: 8:53 - loss: 0.6954 - acc: 0.5275
1664/9333 [====>.........................] - ETA: 8:48 - loss: 0.6957 - acc: 0.5258
1728/9333 [====>.........................] - ETA: 8:45 - loss: 0.6955 - acc: 0.5266
1792/9333 [====>.........................] - ETA: 8:42 - loss: 0.6956 - acc: 0.5273
1856/9333 [====>.........................] - ETA: 8:37 - loss: 0.6945 - acc: 0.5318
1920/9333 [=====>........................] - ETA: 8:33 - loss: 0.6944 - acc: 0.5323
1984/9333 [=====>........................] - ETA: 8:29 - loss: 0.6932 - acc: 0.5343
2048/9333 [=====>........................] - ETA: 8:25 - loss: 0.6931 - acc: 0.5327
2112/9333 [=====>........................] - ETA: 8:22 - loss: 0.6916 - acc: 0.5350
2176/9333 [=====>........................] - ETA: 8:16 - loss: 0.6921 - acc: 0.5335
2240/9333 [======>.......................] - ETA: 8:12 - loss: 0.6920 - acc: 0.5344
2304/9333 [======>.......................] - ETA: 8:05 - loss: 0.6912 - acc: 0.5369
2368/9333 [======>.......................] - ETA: 8:03 - loss: 0.6917 - acc: 0.5359
2432/9333 [======>.......................] - ETA: 7:57 - loss: 0.6918 - acc: 0.5345
2496/9333 [=======>......................] - ETA: 7:52 - loss: 0.6925 - acc: 0.5329
2560/9333 [=======>......................] - ETA: 7:47 - loss: 0.6920 - acc: 0.5340
2624/9333 [=======>......................] - ETA: 7:43 - loss: 0.6926 - acc: 0.5320
2688/9333 [=======>......................] - ETA: 7:38 - loss: 0.6924 - acc: 0.5335
2752/9333 [=======>......................] - ETA: 7:34 - loss: 0.6922 - acc: 0.5338
2816/9333 [========>.....................] - ETA: 7:29 - loss: 0.6923 - acc: 0.5344
2880/9333 [========>.....................] - ETA: 7:25 - loss: 0.6924 - acc: 0.5340
2944/9333 [========>.....................] - ETA: 7:20 - loss: 0.6924 - acc: 0.5357
3008/9333 [========>.....................] - ETA: 7:17 - loss: 0.6927 - acc: 0.5352
3072/9333 [========>.....................] - ETA: 7:12 - loss: 0.6926 - acc: 0.5339
3136/9333 [=========>....................] - ETA: 7:09 - loss: 0.6931 - acc: 0.5325
3200/9333 [=========>....................] - ETA: 7:04 - loss: 0.6930 - acc: 0.5322
3264/9333 [=========>....................] - ETA: 6:59 - loss: 0.6932 - acc: 0.5306
3328/9333 [=========>....................] - ETA: 6:55 - loss: 0.6927 - acc: 0.5322
3392/9333 [=========>....................] - ETA: 6:50 - loss: 0.6924 - acc: 0.5342
3456/9333 [==========>...................] - ETA: 6:46 - loss: 0.6928 - acc: 0.5339
3520/9333 [==========>...................] - ETA: 6:42 - loss: 0.6932 - acc: 0.5318
3584/9333 [==========>...................] - ETA: 6:37 - loss: 0.6931 - acc: 0.5315
3648/9333 [==========>...................] - ETA: 6:33 - loss: 0.6935 - acc: 0.5299
3712/9333 [==========>...................] - ETA: 6:28 - loss: 0.6932 - acc: 0.5310
3776/9333 [===========>..................] - ETA: 6:24 - loss: 0.6930 - acc: 0.5302
3840/9333 [===========>..................] - ETA: 6:19 - loss: 0.6930 - acc: 0.5315
3904/9333 [===========>..................] - ETA: 6:15 - loss: 0.6929 - acc: 0.5318
3968/9333 [===========>..................] - ETA: 6:11 - loss: 0.6928 - acc: 0.5315
4032/9333 [===========>..................] - ETA: 6:07 - loss: 0.6930 - acc: 0.5312
4096/9333 [============>.................] - ETA: 6:02 - loss: 0.6929 - acc: 0.5305
4160/9333 [============>.................] - ETA: 5:58 - loss: 0.6930 - acc: 0.5291
4224/9333 [============>.................] - ETA: 5:53 - loss: 0.6931 - acc: 0.5289
4288/9333 [============>.................] - ETA: 5:49 - loss: 0.6929 - acc: 0.5294
4352/9333 [============>.................] - ETA: 5:44 - loss: 0.6931 - acc: 0.5283
4416/9333 [=============>................] - ETA: 5:40 - loss: 0.6933 - acc: 0.5272
4480/9333 [=============>................] - ETA: 5:35 - loss: 0.6933 - acc: 0.5275
4544/9333 [=============>................] - ETA: 5:31 - loss: 0.6935 - acc: 0.5262
4608/9333 [=============>................] - ETA: 5:26 - loss: 0.6942 - acc: 0.5256
4672/9333 [==============>...............] - ETA: 5:22 - loss: 0.6941 - acc: 0.5257
4736/9333 [==============>...............] - ETA: 5:17 - loss: 0.6939 - acc: 0.5264
4800/9333 [==============>...............] - ETA: 5:12 - loss: 0.6937 - acc: 0.5265
4864/9333 [==============>...............] - ETA: 5:08 - loss: 0.6936 - acc: 0.5263
4928/9333 [==============>...............] - ETA: 5:04 - loss: 0.6936 - acc: 0.5262
4992/9333 [===============>..............] - ETA: 4:59 - loss: 0.6936 - acc: 0.5260
5056/9333 [===============>..............] - ETA: 4:55 - loss: 0.6936 - acc: 0.5257
5120/9333 [===============>..............] - ETA: 4:50 - loss: 0.6937 - acc: 0.5250
5184/9333 [===============>..............] - ETA: 4:46 - loss: 0.6939 - acc: 0.5243
5248/9333 [===============>..............] - ETA: 4:41 - loss: 0.6937 - acc: 0.5257
5312/9333 [================>.............] - ETA: 4:37 - loss: 0.6937 - acc: 0.5250
5376/9333 [================>.............] - ETA: 4:32 - loss: 0.6939 - acc: 0.5249
5440/9333 [================>.............] - ETA: 4:28 - loss: 0.6938 - acc: 0.5257
5504/9333 [================>.............] - ETA: 4:23 - loss: 0.6939 - acc: 0.5251
5568/9333 [================>.............] - ETA: 4:19 - loss: 0.6941 - acc: 0.5235
5632/9333 [=================>............] - ETA: 4:14 - loss: 0.6942 - acc: 0.5227
5696/9333 [=================>............] - ETA: 4:10 - loss: 0.6944 - acc: 0.5218
5760/9333 [=================>............] - ETA: 4:05 - loss: 0.6944 - acc: 0.5219
5824/9333 [=================>............] - ETA: 4:01 - loss: 0.6945 - acc: 0.5211
5888/9333 [=================>............] - ETA: 3:57 - loss: 0.6943 - acc: 0.5222
5952/9333 [==================>...........] - ETA: 3:52 - loss: 0.6943 - acc: 0.5228
6016/9333 [==================>...........] - ETA: 3:48 - loss: 0.6942 - acc: 0.5231
6080/9333 [==================>...........] - ETA: 3:44 - loss: 0.6943 - acc: 0.5234
6144/9333 [==================>...........] - ETA: 3:39 - loss: 0.6944 - acc: 0.5234
6208/9333 [==================>...........] - ETA: 3:35 - loss: 0.6942 - acc: 0.5240
6272/9333 [===================>..........] - ETA: 3:30 - loss: 0.6942 - acc: 0.5242
6336/9333 [===================>..........] - ETA: 3:26 - loss: 0.6942 - acc: 0.5246
6400/9333 [===================>..........] - ETA: 3:22 - loss: 0.6942 - acc: 0.5247
6464/9333 [===================>..........] - ETA: 3:17 - loss: 0.6942 - acc: 0.5246
6528/9333 [===================>..........] - ETA: 3:13 - loss: 0.6941 - acc: 0.5251
6592/9333 [====================>.........] - ETA: 3:08 - loss: 0.6940 - acc: 0.5259
6656/9333 [====================>.........] - ETA: 3:04 - loss: 0.6938 - acc: 0.5266
6720/9333 [====================>.........] - ETA: 3:00 - loss: 0.6936 - acc: 0.5277
6784/9333 [====================>.........] - ETA: 2:55 - loss: 0.6936 - acc: 0.5274
6848/9333 [=====================>........] - ETA: 2:51 - loss: 0.6935 - acc: 0.5275
6912/9333 [=====================>........] - ETA: 2:47 - loss: 0.6935 - acc: 0.5272
6976/9333 [=====================>........] - ETA: 2:42 - loss: 0.6937 - acc: 0.5267
7040/9333 [=====================>........] - ETA: 2:37 - loss: 0.6935 - acc: 0.5267
7104/9333 [=====================>........] - ETA: 2:33 - loss: 0.6935 - acc: 0.5267
7168/9333 [======================>.......] - ETA: 2:28 - loss: 0.6935 - acc: 0.5271
7232/9333 [======================>.......] - ETA: 2:24 - loss: 0.6936 - acc: 0.5268
7296/9333 [======================>.......] - ETA: 2:20 - loss: 0.6936 - acc: 0.5267
7360/9333 [======================>.......] - ETA: 2:15 - loss: 0.6934 - acc: 0.5276
7424/9333 [======================>.......] - ETA: 2:11 - loss: 0.6933 - acc: 0.5286
7488/9333 [=======================>......] - ETA: 2:06 - loss: 0.6936 - acc: 0.5282
7552/9333 [=======================>......] - ETA: 2:02 - loss: 0.6936 - acc: 0.5283
7616/9333 [=======================>......] - ETA: 1:57 - loss: 0.6936 - acc: 0.5277
7680/9333 [=======================>......] - ETA: 1:53 - loss: 0.6937 - acc: 0.5272
7744/9333 [=======================>......] - ETA: 1:49 - loss: 0.6937 - acc: 0.5272
7808/9333 [========================>.....] - ETA: 1:44 - loss: 0.6938 - acc: 0.5274
7872/9333 [========================>.....] - ETA: 1:40 - loss: 0.6934 - acc: 0.5281
7936/9333 [========================>.....] - ETA: 1:36 - loss: 0.6933 - acc: 0.5289
8000/9333 [========================>.....] - ETA: 1:31 - loss: 0.6932 - acc: 0.5294
8064/9333 [========================>.....] - ETA: 1:27 - loss: 0.6931 - acc: 0.5293
8128/9333 [=========================>....] - ETA: 1:22 - loss: 0.6930 - acc: 0.5294
8192/9333 [=========================>....] - ETA: 1:18 - loss: 0.6929 - acc: 0.5297
8256/9333 [=========================>....] - ETA: 1:14 - loss: 0.6927 - acc: 0.5308
8320/9333 [=========================>....] - ETA: 1:09 - loss: 0.6929 - acc: 0.5303
8384/9333 [=========================>....] - ETA: 1:05 - loss: 0.6929 - acc: 0.5302
8448/9333 [==========================>...] - ETA: 1:00 - loss: 0.6930 - acc: 0.5299
8512/9333 [==========================>...] - ETA: 56s - loss: 0.6932 - acc: 0.5294 
8576/9333 [==========================>...] - ETA: 52s - loss: 0.6931 - acc: 0.5294
8640/9333 [==========================>...] - ETA: 47s - loss: 0.6929 - acc: 0.5301
8704/9333 [==========================>...] - ETA: 43s - loss: 0.6929 - acc: 0.5303
8768/9333 [===========================>..] - ETA: 38s - loss: 0.6929 - acc: 0.5307
8832/9333 [===========================>..] - ETA: 34s - loss: 0.6927 - acc: 0.5310
8896/9333 [===========================>..] - ETA: 30s - loss: 0.6927 - acc: 0.5309
8960/9333 [===========================>..] - ETA: 25s - loss: 0.6927 - acc: 0.5305
9024/9333 [============================>.] - ETA: 21s - loss: 0.6927 - acc: 0.5303
9088/9333 [============================>.] - ETA: 16s - loss: 0.6925 - acc: 0.5305
9152/9333 [============================>.] - ETA: 12s - loss: 0.6926 - acc: 0.5302
9216/9333 [============================>.] - ETA: 8s - loss: 0.6924 - acc: 0.5305 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6923 - acc: 0.5306
9333/9333 [==============================] - 665s 71ms/step - loss: 0.6922 - acc: 0.5307 - val_loss: 0.6887 - val_acc: 0.5313

Epoch 00003: val_acc did not improve from 0.55256
Epoch 4/10

  64/9333 [..............................] - ETA: 10:03 - loss: 0.6731 - acc: 0.6094
 128/9333 [..............................] - ETA: 9:51 - loss: 0.6886 - acc: 0.5156 
 192/9333 [..............................] - ETA: 10:01 - loss: 0.6977 - acc: 0.4844
 256/9333 [..............................] - ETA: 10:29 - loss: 0.6952 - acc: 0.5156
 320/9333 [>.............................] - ETA: 10:22 - loss: 0.6889 - acc: 0.5531
 384/9333 [>.............................] - ETA: 10:26 - loss: 0.6855 - acc: 0.5547
 448/9333 [>.............................] - ETA: 10:20 - loss: 0.6870 - acc: 0.5446
 512/9333 [>.............................] - ETA: 10:33 - loss: 0.6898 - acc: 0.5332
 576/9333 [>.............................] - ETA: 10:25 - loss: 0.6900 - acc: 0.5434
 640/9333 [=>............................] - ETA: 10:20 - loss: 0.6920 - acc: 0.5281
 704/9333 [=>............................] - ETA: 10:07 - loss: 0.6913 - acc: 0.5355
 768/9333 [=>............................] - ETA: 10:07 - loss: 0.6927 - acc: 0.5286
 832/9333 [=>............................] - ETA: 9:56 - loss: 0.6930 - acc: 0.5264 
 896/9333 [=>............................] - ETA: 9:53 - loss: 0.6937 - acc: 0.5212
 960/9333 [==>...........................] - ETA: 9:46 - loss: 0.6936 - acc: 0.5198
1024/9333 [==>...........................] - ETA: 9:44 - loss: 0.6941 - acc: 0.5166
1088/9333 [==>...........................] - ETA: 9:38 - loss: 0.6940 - acc: 0.5175
1152/9333 [==>...........................] - ETA: 9:29 - loss: 0.6948 - acc: 0.5078
1216/9333 [==>...........................] - ETA: 9:25 - loss: 0.6949 - acc: 0.5090
1280/9333 [===>..........................] - ETA: 9:22 - loss: 0.6942 - acc: 0.5117
1344/9333 [===>..........................] - ETA: 9:15 - loss: 0.6932 - acc: 0.5134
1408/9333 [===>..........................] - ETA: 9:14 - loss: 0.6924 - acc: 0.5178
1472/9333 [===>..........................] - ETA: 9:12 - loss: 0.6926 - acc: 0.5163
1536/9333 [===>..........................] - ETA: 9:07 - loss: 0.6939 - acc: 0.5124
1600/9333 [====>.........................] - ETA: 9:02 - loss: 0.6934 - acc: 0.5144
1664/9333 [====>.........................] - ETA: 8:57 - loss: 0.6922 - acc: 0.5180
1728/9333 [====>.........................] - ETA: 8:53 - loss: 0.6922 - acc: 0.5168
1792/9333 [====>.........................] - ETA: 8:47 - loss: 0.6915 - acc: 0.5223
1856/9333 [====>.........................] - ETA: 8:42 - loss: 0.6915 - acc: 0.5226
1920/9333 [=====>........................] - ETA: 8:38 - loss: 0.6912 - acc: 0.5240
1984/9333 [=====>........................] - ETA: 8:33 - loss: 0.6916 - acc: 0.5247
2048/9333 [=====>........................] - ETA: 8:29 - loss: 0.6913 - acc: 0.5244
2112/9333 [=====>........................] - ETA: 8:25 - loss: 0.6906 - acc: 0.5260
2176/9333 [=====>........................] - ETA: 8:21 - loss: 0.6903 - acc: 0.5280
2240/9333 [======>.......................] - ETA: 8:16 - loss: 0.6894 - acc: 0.5308
2304/9333 [======>.......................] - ETA: 8:12 - loss: 0.6894 - acc: 0.5317
2368/9333 [======>.......................] - ETA: 8:08 - loss: 0.6897 - acc: 0.5317
2432/9333 [======>.......................] - ETA: 8:02 - loss: 0.6893 - acc: 0.5345
2496/9333 [=======>......................] - ETA: 7:57 - loss: 0.6893 - acc: 0.5329
2560/9333 [=======>......................] - ETA: 7:52 - loss: 0.6895 - acc: 0.5316
2624/9333 [=======>......................] - ETA: 7:49 - loss: 0.6906 - acc: 0.5290
2688/9333 [=======>......................] - ETA: 7:44 - loss: 0.6903 - acc: 0.5294
2752/9333 [=======>......................] - ETA: 7:39 - loss: 0.6902 - acc: 0.5305
2816/9333 [========>.....................] - ETA: 7:34 - loss: 0.6907 - acc: 0.5298
2880/9333 [========>.....................] - ETA: 7:30 - loss: 0.6903 - acc: 0.5326
2944/9333 [========>.....................] - ETA: 7:26 - loss: 0.6907 - acc: 0.5319
3008/9333 [========>.....................] - ETA: 7:22 - loss: 0.6911 - acc: 0.5306
3072/9333 [========>.....................] - ETA: 7:18 - loss: 0.6912 - acc: 0.5309
3136/9333 [=========>....................] - ETA: 7:13 - loss: 0.6911 - acc: 0.5319
3200/9333 [=========>....................] - ETA: 7:10 - loss: 0.6916 - acc: 0.5306
3264/9333 [=========>....................] - ETA: 7:09 - loss: 0.6911 - acc: 0.5312
3328/9333 [=========>....................] - ETA: 7:05 - loss: 0.6911 - acc: 0.5306
3392/9333 [=========>....................] - ETA: 7:03 - loss: 0.6908 - acc: 0.5304
3456/9333 [==========>...................] - ETA: 7:00 - loss: 0.6903 - acc: 0.5333
3520/9333 [==========>...................] - ETA: 6:58 - loss: 0.6907 - acc: 0.5324
3584/9333 [==========>...................] - ETA: 6:54 - loss: 0.6909 - acc: 0.5326
3648/9333 [==========>...................] - ETA: 6:50 - loss: 0.6911 - acc: 0.5318
3712/9333 [==========>...................] - ETA: 6:46 - loss: 0.6908 - acc: 0.5329
3776/9333 [===========>..................] - ETA: 6:42 - loss: 0.6910 - acc: 0.5328
3840/9333 [===========>..................] - ETA: 6:38 - loss: 0.6907 - acc: 0.5344
3904/9333 [===========>..................] - ETA: 6:35 - loss: 0.6907 - acc: 0.5338
3968/9333 [===========>..................] - ETA: 6:32 - loss: 0.6912 - acc: 0.5323
4032/9333 [===========>..................] - ETA: 6:28 - loss: 0.6914 - acc: 0.5315
4096/9333 [============>.................] - ETA: 6:24 - loss: 0.6917 - acc: 0.5310
4160/9333 [============>.................] - ETA: 6:21 - loss: 0.6915 - acc: 0.5322
4224/9333 [============>.................] - ETA: 6:16 - loss: 0.6914 - acc: 0.5334
4288/9333 [============>.................] - ETA: 6:12 - loss: 0.6913 - acc: 0.5340
4352/9333 [============>.................] - ETA: 6:07 - loss: 0.6916 - acc: 0.5326
4416/9333 [=============>................] - ETA: 6:04 - loss: 0.6918 - acc: 0.5317
4480/9333 [=============>................] - ETA: 6:00 - loss: 0.6915 - acc: 0.5330
4544/9333 [=============>................] - ETA: 5:56 - loss: 0.6914 - acc: 0.5332
4608/9333 [=============>................] - ETA: 5:51 - loss: 0.6914 - acc: 0.5332
4672/9333 [==============>...............] - ETA: 5:47 - loss: 0.6915 - acc: 0.5325
4736/9333 [==============>...............] - ETA: 5:43 - loss: 0.6912 - acc: 0.5340
4800/9333 [==============>...............] - ETA: 5:38 - loss: 0.6914 - acc: 0.5329
4864/9333 [==============>...............] - ETA: 5:34 - loss: 0.6915 - acc: 0.5325
4928/9333 [==============>...............] - ETA: 5:31 - loss: 0.6914 - acc: 0.5327
4992/9333 [===============>..............] - ETA: 5:26 - loss: 0.6917 - acc: 0.5321
5056/9333 [===============>..............] - ETA: 5:22 - loss: 0.6917 - acc: 0.5328
5120/9333 [===============>..............] - ETA: 5:17 - loss: 0.6918 - acc: 0.5328
5184/9333 [===============>..............] - ETA: 5:13 - loss: 0.6918 - acc: 0.5341
5248/9333 [===============>..............] - ETA: 5:08 - loss: 0.6919 - acc: 0.5341
5312/9333 [================>.............] - ETA: 5:04 - loss: 0.6919 - acc: 0.5348
5376/9333 [================>.............] - ETA: 4:59 - loss: 0.6917 - acc: 0.5353
5440/9333 [================>.............] - ETA: 4:56 - loss: 0.6915 - acc: 0.5357
5504/9333 [================>.............] - ETA: 4:52 - loss: 0.6911 - acc: 0.5374
5568/9333 [================>.............] - ETA: 4:48 - loss: 0.6914 - acc: 0.5365
5632/9333 [=================>............] - ETA: 4:45 - loss: 0.6916 - acc: 0.5360
5696/9333 [=================>............] - ETA: 4:41 - loss: 0.6917 - acc: 0.5353
5760/9333 [=================>............] - ETA: 4:36 - loss: 0.6917 - acc: 0.5351
5824/9333 [=================>............] - ETA: 4:31 - loss: 0.6917 - acc: 0.5354
5888/9333 [=================>............] - ETA: 4:27 - loss: 0.6920 - acc: 0.5345
5952/9333 [==================>...........] - ETA: 4:23 - loss: 0.6920 - acc: 0.5346
6016/9333 [==================>...........] - ETA: 4:19 - loss: 0.6918 - acc: 0.5351
6080/9333 [==================>...........] - ETA: 4:14 - loss: 0.6920 - acc: 0.5345
6144/9333 [==================>...........] - ETA: 4:11 - loss: 0.6920 - acc: 0.5342
6208/9333 [==================>...........] - ETA: 4:06 - loss: 0.6921 - acc: 0.5330
6272/9333 [===================>..........] - ETA: 4:01 - loss: 0.6918 - acc: 0.5340
6336/9333 [===================>..........] - ETA: 3:57 - loss: 0.6916 - acc: 0.5341
6400/9333 [===================>..........] - ETA: 3:53 - loss: 0.6916 - acc: 0.5342
6464/9333 [===================>..........] - ETA: 3:48 - loss: 0.6916 - acc: 0.5342
6528/9333 [===================>..........] - ETA: 3:44 - loss: 0.6915 - acc: 0.5343
6592/9333 [====================>.........] - ETA: 3:39 - loss: 0.6912 - acc: 0.5347
6656/9333 [====================>.........] - ETA: 3:35 - loss: 0.6912 - acc: 0.5344
6720/9333 [====================>.........] - ETA: 3:30 - loss: 0.6915 - acc: 0.5330
6784/9333 [====================>.........] - ETA: 3:25 - loss: 0.6914 - acc: 0.5330
6848/9333 [=====================>........] - ETA: 3:21 - loss: 0.6916 - acc: 0.5327
6912/9333 [=====================>........] - ETA: 3:16 - loss: 0.6916 - acc: 0.5328
6976/9333 [=====================>........] - ETA: 3:11 - loss: 0.6915 - acc: 0.5328
7040/9333 [=====================>........] - ETA: 3:06 - loss: 0.6912 - acc: 0.5337
7104/9333 [=====================>........] - ETA: 3:01 - loss: 0.6911 - acc: 0.5336
7168/9333 [======================>.......] - ETA: 2:56 - loss: 0.6910 - acc: 0.5339
7232/9333 [======================>.......] - ETA: 2:51 - loss: 0.6908 - acc: 0.5350
7296/9333 [======================>.......] - ETA: 2:47 - loss: 0.6909 - acc: 0.5350
7360/9333 [======================>.......] - ETA: 2:42 - loss: 0.6911 - acc: 0.5346
7424/9333 [======================>.......] - ETA: 2:37 - loss: 0.6912 - acc: 0.5349
7488/9333 [=======================>......] - ETA: 2:32 - loss: 0.6912 - acc: 0.5345
7552/9333 [=======================>......] - ETA: 2:27 - loss: 0.6913 - acc: 0.5350
7616/9333 [=======================>......] - ETA: 2:22 - loss: 0.6911 - acc: 0.5356
7680/9333 [=======================>......] - ETA: 2:16 - loss: 0.6912 - acc: 0.5350
7744/9333 [=======================>......] - ETA: 2:11 - loss: 0.6912 - acc: 0.5345
7808/9333 [========================>.....] - ETA: 2:06 - loss: 0.6911 - acc: 0.5345
7872/9333 [========================>.....] - ETA: 2:01 - loss: 0.6912 - acc: 0.5343
7936/9333 [========================>.....] - ETA: 1:56 - loss: 0.6909 - acc: 0.5357
8000/9333 [========================>.....] - ETA: 1:51 - loss: 0.6910 - acc: 0.5354
8064/9333 [========================>.....] - ETA: 1:46 - loss: 0.6910 - acc: 0.5352
8128/9333 [=========================>....] - ETA: 1:40 - loss: 0.6910 - acc: 0.5351
8192/9333 [=========================>....] - ETA: 1:35 - loss: 0.6912 - acc: 0.5343
8256/9333 [=========================>....] - ETA: 1:30 - loss: 0.6912 - acc: 0.5344
8320/9333 [=========================>....] - ETA: 1:25 - loss: 0.6911 - acc: 0.5340
8384/9333 [=========================>....] - ETA: 1:20 - loss: 0.6910 - acc: 0.5340
8448/9333 [==========================>...] - ETA: 1:14 - loss: 0.6911 - acc: 0.5337
8512/9333 [==========================>...] - ETA: 1:09 - loss: 0.6911 - acc: 0.5341
8576/9333 [==========================>...] - ETA: 1:04 - loss: 0.6912 - acc: 0.5338
8640/9333 [==========================>...] - ETA: 58s - loss: 0.6914 - acc: 0.5337 
8704/9333 [==========================>...] - ETA: 53s - loss: 0.6914 - acc: 0.5338
8768/9333 [===========================>..] - ETA: 48s - loss: 0.6913 - acc: 0.5342
8832/9333 [===========================>..] - ETA: 42s - loss: 0.6914 - acc: 0.5340
8896/9333 [===========================>..] - ETA: 37s - loss: 0.6913 - acc: 0.5339
8960/9333 [===========================>..] - ETA: 31s - loss: 0.6914 - acc: 0.5338
9024/9333 [============================>.] - ETA: 26s - loss: 0.6913 - acc: 0.5339
9088/9333 [============================>.] - ETA: 20s - loss: 0.6912 - acc: 0.5337
9152/9333 [============================>.] - ETA: 15s - loss: 0.6913 - acc: 0.5331
9216/9333 [============================>.] - ETA: 9s - loss: 0.6914 - acc: 0.5322 
9280/9333 [============================>.] - ETA: 4s - loss: 0.6913 - acc: 0.5325
9333/9333 [==============================] - 832s 89ms/step - loss: 0.6914 - acc: 0.5323 - val_loss: 0.6875 - val_acc: 0.5458

Epoch 00004: val_acc did not improve from 0.55256
Epoch 5/10

  64/9333 [..............................] - ETA: 17:42 - loss: 0.6788 - acc: 0.5625
 128/9333 [..............................] - ETA: 17:36 - loss: 0.6800 - acc: 0.5625
 192/9333 [..............................] - ETA: 17:10 - loss: 0.6932 - acc: 0.5000
 256/9333 [..............................] - ETA: 16:22 - loss: 0.6915 - acc: 0.5078
 320/9333 [>.............................] - ETA: 16:07 - loss: 0.6932 - acc: 0.5125
 384/9333 [>.............................] - ETA: 15:38 - loss: 0.6917 - acc: 0.5130
 448/9333 [>.............................] - ETA: 15:48 - loss: 0.6902 - acc: 0.5246
 512/9333 [>.............................] - ETA: 15:49 - loss: 0.6893 - acc: 0.5332
 576/9333 [>.............................] - ETA: 15:31 - loss: 0.6920 - acc: 0.5312
 640/9333 [=>............................] - ETA: 15:08 - loss: 0.6908 - acc: 0.5359
 704/9333 [=>............................] - ETA: 15:05 - loss: 0.6891 - acc: 0.5341
 768/9333 [=>............................] - ETA: 14:54 - loss: 0.6892 - acc: 0.5365
 832/9333 [=>............................] - ETA: 14:37 - loss: 0.6885 - acc: 0.5421
 896/9333 [=>............................] - ETA: 14:26 - loss: 0.6888 - acc: 0.5379
 960/9333 [==>...........................] - ETA: 14:08 - loss: 0.6876 - acc: 0.5427
1024/9333 [==>...........................] - ETA: 13:57 - loss: 0.6886 - acc: 0.5400
1088/9333 [==>...........................] - ETA: 13:52 - loss: 0.6894 - acc: 0.5414
1152/9333 [==>...........................] - ETA: 13:44 - loss: 0.6914 - acc: 0.5356
1216/9333 [==>...........................] - ETA: 13:35 - loss: 0.6932 - acc: 0.5288
1280/9333 [===>..........................] - ETA: 13:31 - loss: 0.6926 - acc: 0.5273
1344/9333 [===>..........................] - ETA: 13:21 - loss: 0.6925 - acc: 0.5290
1408/9333 [===>..........................] - ETA: 13:12 - loss: 0.6933 - acc: 0.5263
1472/9333 [===>..........................] - ETA: 13:04 - loss: 0.6926 - acc: 0.5279
1536/9333 [===>..........................] - ETA: 12:52 - loss: 0.6925 - acc: 0.5280
1600/9333 [====>.........................] - ETA: 12:48 - loss: 0.6922 - acc: 0.5300
1664/9333 [====>.........................] - ETA: 12:39 - loss: 0.6932 - acc: 0.5246
1728/9333 [====>.........................] - ETA: 12:33 - loss: 0.6932 - acc: 0.5237
1792/9333 [====>.........................] - ETA: 12:26 - loss: 0.6935 - acc: 0.5229
1856/9333 [====>.........................] - ETA: 12:18 - loss: 0.6938 - acc: 0.5232
1920/9333 [=====>........................] - ETA: 12:14 - loss: 0.6930 - acc: 0.5276
1984/9333 [=====>........................] - ETA: 12:08 - loss: 0.6925 - acc: 0.5287
2048/9333 [=====>........................] - ETA: 12:02 - loss: 0.6925 - acc: 0.5298
2112/9333 [=====>........................] - ETA: 11:55 - loss: 0.6923 - acc: 0.5298
2176/9333 [=====>........................] - ETA: 11:51 - loss: 0.6924 - acc: 0.5276
2240/9333 [======>.......................] - ETA: 11:44 - loss: 0.6926 - acc: 0.5263
2304/9333 [======>.......................] - ETA: 11:37 - loss: 0.6925 - acc: 0.5282
2368/9333 [======>.......................] - ETA: 11:29 - loss: 0.6933 - acc: 0.5241
2432/9333 [======>.......................] - ETA: 11:22 - loss: 0.6921 - acc: 0.5288
2496/9333 [=======>......................] - ETA: 11:16 - loss: 0.6920 - acc: 0.5296
2560/9333 [=======>......................] - ETA: 11:08 - loss: 0.6919 - acc: 0.5305
2624/9333 [=======>......................] - ETA: 11:04 - loss: 0.6922 - acc: 0.5297
2688/9333 [=======>......................] - ETA: 10:58 - loss: 0.6926 - acc: 0.5279
2752/9333 [=======>......................] - ETA: 10:51 - loss: 0.6927 - acc: 0.5283
2816/9333 [========>.....................] - ETA: 10:43 - loss: 0.6925 - acc: 0.5312
2880/9333 [========>.....................] - ETA: 10:39 - loss: 0.6929 - acc: 0.5299
2944/9333 [========>.....................] - ETA: 10:32 - loss: 0.6927 - acc: 0.5285
3008/9333 [========>.....................] - ETA: 10:25 - loss: 0.6928 - acc: 0.5279
3072/9333 [========>.....................] - ETA: 10:17 - loss: 0.6933 - acc: 0.5267
3136/9333 [=========>....................] - ETA: 10:12 - loss: 0.6932 - acc: 0.5274
3200/9333 [=========>....................] - ETA: 10:06 - loss: 0.6931 - acc: 0.5275
3264/9333 [=========>....................] - ETA: 9:58 - loss: 0.6932 - acc: 0.5270 
3328/9333 [=========>....................] - ETA: 9:51 - loss: 0.6931 - acc: 0.5264
3392/9333 [=========>....................] - ETA: 9:45 - loss: 0.6928 - acc: 0.5259
3456/9333 [==========>...................] - ETA: 9:38 - loss: 0.6933 - acc: 0.5240
3520/9333 [==========>...................] - ETA: 9:31 - loss: 0.6933 - acc: 0.5239
3584/9333 [==========>...................] - ETA: 9:24 - loss: 0.6932 - acc: 0.5254
3648/9333 [==========>...................] - ETA: 9:19 - loss: 0.6927 - acc: 0.5269
3712/9333 [==========>...................] - ETA: 9:12 - loss: 0.6921 - acc: 0.5302
3776/9333 [===========>..................] - ETA: 9:04 - loss: 0.6918 - acc: 0.5315
3840/9333 [===========>..................] - ETA: 8:59 - loss: 0.6916 - acc: 0.5312
3904/9333 [===========>..................] - ETA: 8:52 - loss: 0.6919 - acc: 0.5305
3968/9333 [===========>..................] - ETA: 8:46 - loss: 0.6921 - acc: 0.5297
4032/9333 [===========>..................] - ETA: 8:41 - loss: 0.6921 - acc: 0.5300
4096/9333 [============>.................] - ETA: 8:35 - loss: 0.6921 - acc: 0.5298
4160/9333 [============>.................] - ETA: 8:29 - loss: 0.6920 - acc: 0.5293
4224/9333 [============>.................] - ETA: 8:22 - loss: 0.6918 - acc: 0.5308
4288/9333 [============>.................] - ETA: 8:16 - loss: 0.6919 - acc: 0.5299
4352/9333 [============>.................] - ETA: 8:10 - loss: 0.6919 - acc: 0.5294
4416/9333 [=============>................] - ETA: 8:04 - loss: 0.6918 - acc: 0.5299
4480/9333 [=============>................] - ETA: 7:57 - loss: 0.6912 - acc: 0.5319
4544/9333 [=============>................] - ETA: 7:51 - loss: 0.6912 - acc: 0.5319
4608/9333 [=============>................] - ETA: 7:45 - loss: 0.6915 - acc: 0.5302
4672/9333 [==============>...............] - ETA: 7:38 - loss: 0.6911 - acc: 0.5321
4736/9333 [==============>...............] - ETA: 7:32 - loss: 0.6910 - acc: 0.5319
4800/9333 [==============>...............] - ETA: 7:26 - loss: 0.6910 - acc: 0.5323
4864/9333 [==============>...............] - ETA: 7:19 - loss: 0.6909 - acc: 0.5315
4928/9333 [==============>...............] - ETA: 7:13 - loss: 0.6907 - acc: 0.5319
4992/9333 [===============>..............] - ETA: 7:06 - loss: 0.6907 - acc: 0.5312
5056/9333 [===============>..............] - ETA: 7:00 - loss: 0.6907 - acc: 0.5318
5120/9333 [===============>..............] - ETA: 6:53 - loss: 0.6908 - acc: 0.5309
5184/9333 [===============>..............] - ETA: 6:46 - loss: 0.6910 - acc: 0.5301
5248/9333 [===============>..............] - ETA: 6:41 - loss: 0.6910 - acc: 0.5295
5312/9333 [================>.............] - ETA: 6:35 - loss: 0.6909 - acc: 0.5292
5376/9333 [================>.............] - ETA: 6:28 - loss: 0.6909 - acc: 0.5290
5440/9333 [================>.............] - ETA: 6:21 - loss: 0.6907 - acc: 0.5303
5504/9333 [================>.............] - ETA: 6:15 - loss: 0.6909 - acc: 0.5296
5568/9333 [================>.............] - ETA: 6:09 - loss: 0.6908 - acc: 0.5300
5632/9333 [=================>............] - ETA: 6:02 - loss: 0.6909 - acc: 0.5298
5696/9333 [=================>............] - ETA: 5:56 - loss: 0.6909 - acc: 0.5312
5760/9333 [=================>............] - ETA: 5:49 - loss: 0.6910 - acc: 0.5304
5824/9333 [=================>............] - ETA: 5:43 - loss: 0.6910 - acc: 0.5311
5888/9333 [=================>............] - ETA: 5:36 - loss: 0.6910 - acc: 0.5306
5952/9333 [==================>...........] - ETA: 5:31 - loss: 0.6911 - acc: 0.5304
6016/9333 [==================>...........] - ETA: 5:25 - loss: 0.6907 - acc: 0.5319
6080/9333 [==================>...........] - ETA: 5:20 - loss: 0.6905 - acc: 0.5329
6144/9333 [==================>...........] - ETA: 5:15 - loss: 0.6904 - acc: 0.5332
6208/9333 [==================>...........] - ETA: 5:09 - loss: 0.6905 - acc: 0.5322
6272/9333 [===================>..........] - ETA: 5:04 - loss: 0.6903 - acc: 0.5330
6336/9333 [===================>..........] - ETA: 4:59 - loss: 0.6906 - acc: 0.5316
6400/9333 [===================>..........] - ETA: 4:54 - loss: 0.6909 - acc: 0.5311
6464/9333 [===================>..........] - ETA: 4:48 - loss: 0.6913 - acc: 0.5300
6528/9333 [===================>..........] - ETA: 4:43 - loss: 0.6911 - acc: 0.5305
6592/9333 [====================>.........] - ETA: 4:37 - loss: 0.6910 - acc: 0.5306
6656/9333 [====================>.........] - ETA: 4:32 - loss: 0.6909 - acc: 0.5314
6720/9333 [====================>.........] - ETA: 4:26 - loss: 0.6906 - acc: 0.5324
6784/9333 [====================>.........] - ETA: 4:20 - loss: 0.6907 - acc: 0.5321
6848/9333 [=====================>........] - ETA: 4:15 - loss: 0.6908 - acc: 0.5321
6912/9333 [=====================>........] - ETA: 4:09 - loss: 0.6907 - acc: 0.5315
6976/9333 [=====================>........] - ETA: 4:03 - loss: 0.6906 - acc: 0.5317
7040/9333 [=====================>........] - ETA: 3:57 - loss: 0.6906 - acc: 0.5321
7104/9333 [=====================>........] - ETA: 3:51 - loss: 0.6906 - acc: 0.5325
7168/9333 [======================>.......] - ETA: 3:45 - loss: 0.6904 - acc: 0.5325
7232/9333 [======================>.......] - ETA: 3:39 - loss: 0.6903 - acc: 0.5329
7296/9333 [======================>.......] - ETA: 3:33 - loss: 0.6905 - acc: 0.5323
7360/9333 [======================>.......] - ETA: 3:27 - loss: 0.6905 - acc: 0.5325
7424/9333 [======================>.......] - ETA: 3:21 - loss: 0.6905 - acc: 0.5321
7488/9333 [=======================>......] - ETA: 3:15 - loss: 0.6902 - acc: 0.5325
7552/9333 [=======================>......] - ETA: 3:08 - loss: 0.6902 - acc: 0.5318
7616/9333 [=======================>......] - ETA: 3:02 - loss: 0.6902 - acc: 0.5314
7680/9333 [=======================>......] - ETA: 2:55 - loss: 0.6901 - acc: 0.5318
7744/9333 [=======================>......] - ETA: 2:49 - loss: 0.6900 - acc: 0.5324
7808/9333 [========================>.....] - ETA: 2:43 - loss: 0.6899 - acc: 0.5332
7872/9333 [========================>.....] - ETA: 2:36 - loss: 0.6898 - acc: 0.5334
7936/9333 [========================>.....] - ETA: 2:29 - loss: 0.6900 - acc: 0.5330
8000/9333 [========================>.....] - ETA: 2:23 - loss: 0.6899 - acc: 0.5336
8064/9333 [========================>.....] - ETA: 2:16 - loss: 0.6899 - acc: 0.5335
8128/9333 [=========================>....] - ETA: 2:10 - loss: 0.6899 - acc: 0.5337
8192/9333 [=========================>....] - ETA: 2:03 - loss: 0.6898 - acc: 0.5338
8256/9333 [=========================>....] - ETA: 1:56 - loss: 0.6897 - acc: 0.5337
8320/9333 [=========================>....] - ETA: 1:50 - loss: 0.6897 - acc: 0.5335
8384/9333 [=========================>....] - ETA: 1:43 - loss: 0.6895 - acc: 0.5339
8448/9333 [==========================>...] - ETA: 1:36 - loss: 0.6894 - acc: 0.5342
8512/9333 [==========================>...] - ETA: 1:29 - loss: 0.6893 - acc: 0.5347
8576/9333 [==========================>...] - ETA: 1:22 - loss: 0.6893 - acc: 0.5345
8640/9333 [==========================>...] - ETA: 1:16 - loss: 0.6893 - acc: 0.5347
8704/9333 [==========================>...] - ETA: 1:09 - loss: 0.6892 - acc: 0.5347
8768/9333 [===========================>..] - ETA: 1:02 - loss: 0.6894 - acc: 0.5341
8832/9333 [===========================>..] - ETA: 55s - loss: 0.6894 - acc: 0.5340 
8896/9333 [===========================>..] - ETA: 48s - loss: 0.6894 - acc: 0.5342
8960/9333 [===========================>..] - ETA: 41s - loss: 0.6893 - acc: 0.5349
9024/9333 [============================>.] - ETA: 34s - loss: 0.6895 - acc: 0.5345
9088/9333 [============================>.] - ETA: 27s - loss: 0.6895 - acc: 0.5349
9152/9333 [============================>.] - ETA: 20s - loss: 0.6895 - acc: 0.5345
9216/9333 [============================>.] - ETA: 13s - loss: 0.6895 - acc: 0.5343
9280/9333 [============================>.] - ETA: 5s - loss: 0.6895 - acc: 0.5338 
9333/9333 [==============================] - 1086s 116ms/step - loss: 0.6896 - acc: 0.5337 - val_loss: 0.6887 - val_acc: 0.5400

Epoch 00005: val_acc did not improve from 0.55256
Epoch 6/10

  64/9333 [..............................] - ETA: 22:00 - loss: 0.6907 - acc: 0.5000
 128/9333 [..............................] - ETA: 21:44 - loss: 0.6852 - acc: 0.4766
 192/9333 [..............................] - ETA: 20:59 - loss: 0.6831 - acc: 0.5052
 256/9333 [..............................] - ETA: 20:30 - loss: 0.6838 - acc: 0.5352
 320/9333 [>.............................] - ETA: 20:31 - loss: 0.6867 - acc: 0.5312
 384/9333 [>.............................] - ETA: 20:29 - loss: 0.6845 - acc: 0.5469
 448/9333 [>.............................] - ETA: 20:04 - loss: 0.6834 - acc: 0.5446
 512/9333 [>.............................] - ETA: 19:55 - loss: 0.6834 - acc: 0.5508
 576/9333 [>.............................] - ETA: 19:50 - loss: 0.6857 - acc: 0.5434
 640/9333 [=>............................] - ETA: 19:39 - loss: 0.6841 - acc: 0.5484
 704/9333 [=>............................] - ETA: 19:23 - loss: 0.6834 - acc: 0.5526
 768/9333 [=>............................] - ETA: 19:10 - loss: 0.6833 - acc: 0.5521
 832/9333 [=>............................] - ETA: 18:59 - loss: 0.6843 - acc: 0.5481
 896/9333 [=>............................] - ETA: 18:43 - loss: 0.6862 - acc: 0.5435
 960/9333 [==>...........................] - ETA: 18:35 - loss: 0.6863 - acc: 0.5437
1024/9333 [==>...........................] - ETA: 18:31 - loss: 0.6852 - acc: 0.5479
1088/9333 [==>...........................] - ETA: 18:22 - loss: 0.6869 - acc: 0.5404
1152/9333 [==>...........................] - ETA: 18:10 - loss: 0.6861 - acc: 0.5443
1216/9333 [==>...........................] - ETA: 18:02 - loss: 0.6850 - acc: 0.5469
1280/9333 [===>..........................] - ETA: 17:55 - loss: 0.6850 - acc: 0.5492
1344/9333 [===>..........................] - ETA: 17:44 - loss: 0.6837 - acc: 0.5528
1408/9333 [===>..........................] - ETA: 17:37 - loss: 0.6835 - acc: 0.5554
1472/9333 [===>..........................] - ETA: 17:28 - loss: 0.6830 - acc: 0.5571
1536/9333 [===>..........................] - ETA: 17:20 - loss: 0.6825 - acc: 0.5579
1600/9333 [====>.........................] - ETA: 17:09 - loss: 0.6819 - acc: 0.5594
1664/9333 [====>.........................] - ETA: 17:02 - loss: 0.6816 - acc: 0.5607
1728/9333 [====>.........................] - ETA: 16:52 - loss: 0.6817 - acc: 0.5602
1792/9333 [====>.........................] - ETA: 16:40 - loss: 0.6817 - acc: 0.5592
1856/9333 [====>.........................] - ETA: 16:28 - loss: 0.6825 - acc: 0.5587
1920/9333 [=====>........................] - ETA: 16:22 - loss: 0.6831 - acc: 0.5573
1984/9333 [=====>........................] - ETA: 16:16 - loss: 0.6824 - acc: 0.5595
2048/9333 [=====>........................] - ETA: 16:09 - loss: 0.6822 - acc: 0.5601
2112/9333 [=====>........................] - ETA: 16:00 - loss: 0.6828 - acc: 0.5597
2176/9333 [=====>........................] - ETA: 15:52 - loss: 0.6829 - acc: 0.5588
2240/9333 [======>.......................] - ETA: 15:41 - loss: 0.6846 - acc: 0.5567
2304/9333 [======>.......................] - ETA: 15:31 - loss: 0.6851 - acc: 0.5547
2368/9333 [======>.......................] - ETA: 15:22 - loss: 0.6837 - acc: 0.5600
2432/9333 [======>.......................] - ETA: 15:14 - loss: 0.6834 - acc: 0.5613
2496/9333 [=======>......................] - ETA: 15:03 - loss: 0.6838 - acc: 0.5609
2560/9333 [=======>......................] - ETA: 14:55 - loss: 0.6839 - acc: 0.5617
2624/9333 [=======>......................] - ETA: 14:49 - loss: 0.6844 - acc: 0.5598
2688/9333 [=======>......................] - ETA: 14:39 - loss: 0.6858 - acc: 0.5569
2752/9333 [=======>......................] - ETA: 14:32 - loss: 0.6861 - acc: 0.5563
2816/9333 [========>.....................] - ETA: 14:22 - loss: 0.6859 - acc: 0.5565
2880/9333 [========>.....................] - ETA: 14:13 - loss: 0.6860 - acc: 0.5563
2944/9333 [========>.....................] - ETA: 14:03 - loss: 0.6860 - acc: 0.5574
3008/9333 [========>.....................] - ETA: 13:55 - loss: 0.6853 - acc: 0.5592
3072/9333 [========>.....................] - ETA: 13:46 - loss: 0.6857 - acc: 0.5589
3136/9333 [=========>....................] - ETA: 13:37 - loss: 0.6851 - acc: 0.5599
3200/9333 [=========>....................] - ETA: 13:28 - loss: 0.6851 - acc: 0.5597
3264/9333 [=========>....................] - ETA: 13:19 - loss: 0.6855 - acc: 0.5582
3328/9333 [=========>....................] - ETA: 13:10 - loss: 0.6854 - acc: 0.5586
3392/9333 [=========>....................] - ETA: 13:02 - loss: 0.6857 - acc: 0.5566
3456/9333 [==========>...................] - ETA: 12:54 - loss: 0.6859 - acc: 0.5556
3520/9333 [==========>...................] - ETA: 12:46 - loss: 0.6861 - acc: 0.5543
3584/9333 [==========>...................] - ETA: 12:37 - loss: 0.6860 - acc: 0.5555
3648/9333 [==========>...................] - ETA: 12:28 - loss: 0.6860 - acc: 0.5546
3712/9333 [==========>...................] - ETA: 12:20 - loss: 0.6863 - acc: 0.5541
3776/9333 [===========>..................] - ETA: 12:12 - loss: 0.6866 - acc: 0.5530
3840/9333 [===========>..................] - ETA: 12:03 - loss: 0.6865 - acc: 0.5536
3904/9333 [===========>..................] - ETA: 11:54 - loss: 0.6866 - acc: 0.5538
3968/9333 [===========>..................] - ETA: 11:47 - loss: 0.6870 - acc: 0.5517
4032/9333 [===========>..................] - ETA: 11:37 - loss: 0.6872 - acc: 0.5508
4096/9333 [============>.................] - ETA: 11:28 - loss: 0.6875 - acc: 0.5500
4160/9333 [============>.................] - ETA: 11:21 - loss: 0.6872 - acc: 0.5507
4224/9333 [============>.................] - ETA: 11:13 - loss: 0.6870 - acc: 0.5516
4288/9333 [============>.................] - ETA: 11:04 - loss: 0.6873 - acc: 0.5506
4352/9333 [============>.................] - ETA: 10:55 - loss: 0.6872 - acc: 0.5503
4416/9333 [=============>................] - ETA: 10:47 - loss: 0.6873 - acc: 0.5507
4480/9333 [=============>................] - ETA: 10:39 - loss: 0.6872 - acc: 0.5518
4544/9333 [=============>................] - ETA: 10:30 - loss: 0.6871 - acc: 0.5526
4608/9333 [=============>................] - ETA: 10:21 - loss: 0.6871 - acc: 0.5525
4672/9333 [==============>...............] - ETA: 10:14 - loss: 0.6872 - acc: 0.5522
4736/9333 [==============>...............] - ETA: 10:06 - loss: 0.6872 - acc: 0.5519
4800/9333 [==============>...............] - ETA: 9:57 - loss: 0.6870 - acc: 0.5525 
4864/9333 [==============>...............] - ETA: 9:50 - loss: 0.6872 - acc: 0.5520
4928/9333 [==============>...............] - ETA: 9:41 - loss: 0.6870 - acc: 0.5528
4992/9333 [===============>..............] - ETA: 9:32 - loss: 0.6867 - acc: 0.5537
5056/9333 [===============>..............] - ETA: 9:23 - loss: 0.6868 - acc: 0.5536
5120/9333 [===============>..............] - ETA: 9:14 - loss: 0.6870 - acc: 0.5521
5184/9333 [===============>..............] - ETA: 9:06 - loss: 0.6872 - acc: 0.5503
5248/9333 [===============>..............] - ETA: 8:58 - loss: 0.6867 - acc: 0.5524
5312/9333 [================>.............] - ETA: 8:50 - loss: 0.6866 - acc: 0.5523
5376/9333 [================>.............] - ETA: 8:41 - loss: 0.6868 - acc: 0.5510
5440/9333 [================>.............] - ETA: 8:32 - loss: 0.6870 - acc: 0.5506
5504/9333 [================>.............] - ETA: 8:23 - loss: 0.6868 - acc: 0.5516
5568/9333 [================>.............] - ETA: 8:14 - loss: 0.6872 - acc: 0.5510
5632/9333 [=================>............] - ETA: 8:06 - loss: 0.6871 - acc: 0.5510
5696/9333 [=================>............] - ETA: 7:57 - loss: 0.6869 - acc: 0.5511
5760/9333 [=================>............] - ETA: 7:49 - loss: 0.6867 - acc: 0.5514
5824/9333 [=================>............] - ETA: 7:40 - loss: 0.6866 - acc: 0.5519
5888/9333 [=================>............] - ETA: 7:31 - loss: 0.6866 - acc: 0.5515
5952/9333 [==================>...........] - ETA: 7:22 - loss: 0.6867 - acc: 0.5504
6016/9333 [==================>...........] - ETA: 7:14 - loss: 0.6864 - acc: 0.5515
6080/9333 [==================>...........] - ETA: 7:05 - loss: 0.6865 - acc: 0.5513
6144/9333 [==================>...........] - ETA: 6:57 - loss: 0.6867 - acc: 0.5505
6208/9333 [==================>...........] - ETA: 6:48 - loss: 0.6869 - acc: 0.5501
6272/9333 [===================>..........] - ETA: 6:40 - loss: 0.6870 - acc: 0.5494
6336/9333 [===================>..........] - ETA: 6:31 - loss: 0.6870 - acc: 0.5492
6400/9333 [===================>..........] - ETA: 6:23 - loss: 0.6871 - acc: 0.5491
6464/9333 [===================>..........] - ETA: 6:15 - loss: 0.6871 - acc: 0.5490
6528/9333 [===================>..........] - ETA: 6:06 - loss: 0.6871 - acc: 0.5486
6592/9333 [====================>.........] - ETA: 5:58 - loss: 0.6869 - acc: 0.5493
6656/9333 [====================>.........] - ETA: 5:49 - loss: 0.6869 - acc: 0.5494
6720/9333 [====================>.........] - ETA: 5:41 - loss: 0.6868 - acc: 0.5494
6784/9333 [====================>.........] - ETA: 5:33 - loss: 0.6867 - acc: 0.5501
6848/9333 [=====================>........] - ETA: 5:24 - loss: 0.6864 - acc: 0.5504
6912/9333 [=====================>........] - ETA: 5:16 - loss: 0.6868 - acc: 0.5492
6976/9333 [=====================>........] - ETA: 5:07 - loss: 0.6866 - acc: 0.5492
7040/9333 [=====================>........] - ETA: 4:59 - loss: 0.6867 - acc: 0.5484
7104/9333 [=====================>........] - ETA: 4:51 - loss: 0.6867 - acc: 0.5491
7168/9333 [======================>.......] - ETA: 4:42 - loss: 0.6867 - acc: 0.5495
7232/9333 [======================>.......] - ETA: 4:34 - loss: 0.6867 - acc: 0.5494
7296/9333 [======================>.......] - ETA: 4:25 - loss: 0.6867 - acc: 0.5489
7360/9333 [======================>.......] - ETA: 4:17 - loss: 0.6866 - acc: 0.5493
7424/9333 [======================>.......] - ETA: 4:09 - loss: 0.6866 - acc: 0.5488
7488/9333 [=======================>......] - ETA: 4:00 - loss: 0.6867 - acc: 0.5481
7552/9333 [=======================>......] - ETA: 3:52 - loss: 0.6866 - acc: 0.5481
7616/9333 [=======================>......] - ETA: 3:43 - loss: 0.6865 - acc: 0.5481
7680/9333 [=======================>......] - ETA: 3:35 - loss: 0.6863 - acc: 0.5488
7744/9333 [=======================>......] - ETA: 3:26 - loss: 0.6861 - acc: 0.5492
7808/9333 [========================>.....] - ETA: 3:18 - loss: 0.6859 - acc: 0.5498
7872/9333 [========================>.....] - ETA: 3:10 - loss: 0.6860 - acc: 0.5494
7936/9333 [========================>.....] - ETA: 3:01 - loss: 0.6862 - acc: 0.5490
8000/9333 [========================>.....] - ETA: 2:53 - loss: 0.6862 - acc: 0.5490
8064/9333 [========================>.....] - ETA: 2:44 - loss: 0.6864 - acc: 0.5487
8128/9333 [=========================>....] - ETA: 2:36 - loss: 0.6866 - acc: 0.5480
8192/9333 [=========================>....] - ETA: 2:28 - loss: 0.6864 - acc: 0.5492
8256/9333 [=========================>....] - ETA: 2:19 - loss: 0.6864 - acc: 0.5492
8320/9333 [=========================>....] - ETA: 2:11 - loss: 0.6864 - acc: 0.5492
8384/9333 [=========================>....] - ETA: 2:02 - loss: 0.6866 - acc: 0.5483
8448/9333 [==========================>...] - ETA: 1:54 - loss: 0.6868 - acc: 0.5481
8512/9333 [==========================>...] - ETA: 1:46 - loss: 0.6866 - acc: 0.5480
8576/9333 [==========================>...] - ETA: 1:37 - loss: 0.6864 - acc: 0.5482
8640/9333 [==========================>...] - ETA: 1:29 - loss: 0.6863 - acc: 0.5484
8704/9333 [==========================>...] - ETA: 1:21 - loss: 0.6864 - acc: 0.5478
8768/9333 [===========================>..] - ETA: 1:13 - loss: 0.6865 - acc: 0.5474
8832/9333 [===========================>..] - ETA: 1:04 - loss: 0.6866 - acc: 0.5468
8896/9333 [===========================>..] - ETA: 56s - loss: 0.6865 - acc: 0.5471 
8960/9333 [===========================>..] - ETA: 48s - loss: 0.6865 - acc: 0.5467
9024/9333 [============================>.] - ETA: 39s - loss: 0.6867 - acc: 0.5461
9088/9333 [============================>.] - ETA: 31s - loss: 0.6867 - acc: 0.5465
9152/9333 [============================>.] - ETA: 23s - loss: 0.6869 - acc: 0.5457
9216/9333 [============================>.] - ETA: 15s - loss: 0.6869 - acc: 0.5456
9280/9333 [============================>.] - ETA: 6s - loss: 0.6869 - acc: 0.5457 
9333/9333 [==============================] - 1234s 132ms/step - loss: 0.6869 - acc: 0.5458 - val_loss: 0.6888 - val_acc: 0.5207

Epoch 00006: val_acc did not improve from 0.55256
Epoch 7/10

  64/9333 [..............................] - ETA: 19:08 - loss: 0.6969 - acc: 0.5312
 128/9333 [..............................] - ETA: 18:17 - loss: 0.6904 - acc: 0.5391
 192/9333 [..............................] - ETA: 17:47 - loss: 0.6874 - acc: 0.5521
 256/9333 [..............................] - ETA: 17:43 - loss: 0.6899 - acc: 0.5508
 320/9333 [>.............................] - ETA: 17:16 - loss: 0.6899 - acc: 0.5500
 384/9333 [>.............................] - ETA: 17:08 - loss: 0.6908 - acc: 0.5391
 448/9333 [>.............................] - ETA: 17:03 - loss: 0.6912 - acc: 0.5424
 512/9333 [>.............................] - ETA: 17:05 - loss: 0.6909 - acc: 0.5371
 576/9333 [>.............................] - ETA: 16:58 - loss: 0.6937 - acc: 0.5243
 640/9333 [=>............................] - ETA: 16:37 - loss: 0.6915 - acc: 0.5375
 704/9333 [=>............................] - ETA: 16:29 - loss: 0.6915 - acc: 0.5327
 768/9333 [=>............................] - ETA: 16:19 - loss: 0.6898 - acc: 0.5378
 832/9333 [=>............................] - ETA: 16:10 - loss: 0.6888 - acc: 0.5445
 896/9333 [=>............................] - ETA: 16:00 - loss: 0.6881 - acc: 0.5525
 960/9333 [==>...........................] - ETA: 15:50 - loss: 0.6870 - acc: 0.5563
1024/9333 [==>...........................] - ETA: 15:42 - loss: 0.6885 - acc: 0.5498
1088/9333 [==>...........................] - ETA: 15:29 - loss: 0.6882 - acc: 0.5524
1152/9333 [==>...........................] - ETA: 15:20 - loss: 0.6873 - acc: 0.5521
1216/9333 [==>...........................] - ETA: 15:17 - loss: 0.6879 - acc: 0.5493
1280/9333 [===>..........................] - ETA: 15:09 - loss: 0.6890 - acc: 0.5500
1344/9333 [===>..........................] - ETA: 15:01 - loss: 0.6898 - acc: 0.5461
1408/9333 [===>..........................] - ETA: 14:56 - loss: 0.6892 - acc: 0.5469
1472/9333 [===>..........................] - ETA: 14:48 - loss: 0.6899 - acc: 0.5442
1536/9333 [===>..........................] - ETA: 14:41 - loss: 0.6889 - acc: 0.5443
1600/9333 [====>.........................] - ETA: 14:35 - loss: 0.6882 - acc: 0.5469
1664/9333 [====>.........................] - ETA: 14:27 - loss: 0.6890 - acc: 0.5439
1728/9333 [====>.........................] - ETA: 14:20 - loss: 0.6896 - acc: 0.5428
1792/9333 [====>.........................] - ETA: 14:12 - loss: 0.6887 - acc: 0.5463
1856/9333 [====>.........................] - ETA: 14:02 - loss: 0.6882 - acc: 0.5474
1920/9333 [=====>........................] - ETA: 13:54 - loss: 0.6881 - acc: 0.5464
1984/9333 [=====>........................] - ETA: 13:46 - loss: 0.6877 - acc: 0.5464
2048/9333 [=====>........................] - ETA: 13:41 - loss: 0.6876 - acc: 0.5479
2112/9333 [=====>........................] - ETA: 13:33 - loss: 0.6878 - acc: 0.5464
2176/9333 [=====>........................] - ETA: 13:25 - loss: 0.6875 - acc: 0.5492
2240/9333 [======>.......................] - ETA: 13:18 - loss: 0.6873 - acc: 0.5496
2304/9333 [======>.......................] - ETA: 13:10 - loss: 0.6866 - acc: 0.5503
2368/9333 [======>.......................] - ETA: 13:03 - loss: 0.6865 - acc: 0.5503
2432/9333 [======>.......................] - ETA: 12:56 - loss: 0.6864 - acc: 0.5502
2496/9333 [=======>......................] - ETA: 12:49 - loss: 0.6862 - acc: 0.5509
2560/9333 [=======>......................] - ETA: 12:42 - loss: 0.6862 - acc: 0.5516
2624/9333 [=======>......................] - ETA: 12:34 - loss: 0.6868 - acc: 0.5495
2688/9333 [=======>......................] - ETA: 12:29 - loss: 0.6863 - acc: 0.5513
2752/9333 [=======>......................] - ETA: 12:22 - loss: 0.6868 - acc: 0.5501
2816/9333 [========>.....................] - ETA: 12:13 - loss: 0.6868 - acc: 0.5483
2880/9333 [========>.....................] - ETA: 12:08 - loss: 0.6867 - acc: 0.5490
2944/9333 [========>.....................] - ETA: 12:00 - loss: 0.6869 - acc: 0.5486
3008/9333 [========>.....................] - ETA: 11:52 - loss: 0.6865 - acc: 0.5502
3072/9333 [========>.....................] - ETA: 11:45 - loss: 0.6863 - acc: 0.5495
3136/9333 [=========>....................] - ETA: 11:37 - loss: 0.6860 - acc: 0.5494
3200/9333 [=========>....................] - ETA: 11:31 - loss: 0.6854 - acc: 0.5519
3264/9333 [=========>....................] - ETA: 11:23 - loss: 0.6853 - acc: 0.5521
3328/9333 [=========>....................] - ETA: 11:16 - loss: 0.6847 - acc: 0.5532
3392/9333 [=========>....................] - ETA: 11:09 - loss: 0.6847 - acc: 0.5540
3456/9333 [==========>...................] - ETA: 11:02 - loss: 0.6847 - acc: 0.5550
3520/9333 [==========>...................] - ETA: 10:55 - loss: 0.6852 - acc: 0.5540
3584/9333 [==========>...................] - ETA: 10:48 - loss: 0.6849 - acc: 0.5558
3648/9333 [==========>...................] - ETA: 10:40 - loss: 0.6850 - acc: 0.5559
3712/9333 [==========>...................] - ETA: 10:34 - loss: 0.6848 - acc: 0.5566
3776/9333 [===========>..................] - ETA: 10:27 - loss: 0.6851 - acc: 0.5561
3840/9333 [===========>..................] - ETA: 10:20 - loss: 0.6854 - acc: 0.5555
3904/9333 [===========>..................] - ETA: 10:13 - loss: 0.6856 - acc: 0.5553
3968/9333 [===========>..................] - ETA: 10:05 - loss: 0.6867 - acc: 0.5532
4032/9333 [===========>..................] - ETA: 9:58 - loss: 0.6866 - acc: 0.5536 
4096/9333 [============>.................] - ETA: 9:51 - loss: 0.6864 - acc: 0.5535
4160/9333 [============>.................] - ETA: 9:43 - loss: 0.6865 - acc: 0.5524
4224/9333 [============>.................] - ETA: 9:37 - loss: 0.6869 - acc: 0.5511
4288/9333 [============>.................] - ETA: 9:29 - loss: 0.6863 - acc: 0.5527
4352/9333 [============>.................] - ETA: 9:22 - loss: 0.6866 - acc: 0.5517
4416/9333 [=============>................] - ETA: 9:15 - loss: 0.6865 - acc: 0.5521
4480/9333 [=============>................] - ETA: 9:07 - loss: 0.6866 - acc: 0.5516
4544/9333 [=============>................] - ETA: 9:00 - loss: 0.6865 - acc: 0.5515
4608/9333 [=============>................] - ETA: 8:53 - loss: 0.6864 - acc: 0.5516
4672/9333 [==============>...............] - ETA: 8:46 - loss: 0.6861 - acc: 0.5531
4736/9333 [==============>...............] - ETA: 8:38 - loss: 0.6856 - acc: 0.5549
4800/9333 [==============>...............] - ETA: 8:31 - loss: 0.6859 - acc: 0.5550
4864/9333 [==============>...............] - ETA: 8:24 - loss: 0.6862 - acc: 0.5547
4928/9333 [==============>...............] - ETA: 8:16 - loss: 0.6856 - acc: 0.5564
4992/9333 [===============>..............] - ETA: 8:09 - loss: 0.6855 - acc: 0.5563
5056/9333 [===============>..............] - ETA: 8:02 - loss: 0.6858 - acc: 0.5554
5120/9333 [===============>..............] - ETA: 7:55 - loss: 0.6858 - acc: 0.5559
5184/9333 [===============>..............] - ETA: 7:48 - loss: 0.6858 - acc: 0.5561
5248/9333 [===============>..............] - ETA: 7:40 - loss: 0.6856 - acc: 0.5572
5312/9333 [================>.............] - ETA: 7:33 - loss: 0.6853 - acc: 0.5578
5376/9333 [================>.............] - ETA: 7:26 - loss: 0.6854 - acc: 0.5573
5440/9333 [================>.............] - ETA: 7:19 - loss: 0.6852 - acc: 0.5577
5504/9333 [================>.............] - ETA: 7:12 - loss: 0.6851 - acc: 0.5580
5568/9333 [================>.............] - ETA: 7:04 - loss: 0.6855 - acc: 0.5571
5632/9333 [=================>............] - ETA: 6:56 - loss: 0.6862 - acc: 0.5561
5696/9333 [=================>............] - ETA: 6:50 - loss: 0.6862 - acc: 0.5567
5760/9333 [=================>............] - ETA: 6:42 - loss: 0.6861 - acc: 0.5569
5824/9333 [=================>............] - ETA: 6:35 - loss: 0.6863 - acc: 0.5561
5888/9333 [=================>............] - ETA: 6:27 - loss: 0.6865 - acc: 0.5552
5952/9333 [==================>...........] - ETA: 6:20 - loss: 0.6865 - acc: 0.5549
6016/9333 [==================>...........] - ETA: 6:13 - loss: 0.6862 - acc: 0.5552
6080/9333 [==================>...........] - ETA: 6:06 - loss: 0.6862 - acc: 0.5546
6144/9333 [==================>...........] - ETA: 5:58 - loss: 0.6862 - acc: 0.5550
6208/9333 [==================>...........] - ETA: 5:52 - loss: 0.6861 - acc: 0.5551
6272/9333 [===================>..........] - ETA: 5:45 - loss: 0.6861 - acc: 0.5552
6336/9333 [===================>..........] - ETA: 5:37 - loss: 0.6863 - acc: 0.5545
6400/9333 [===================>..........] - ETA: 5:30 - loss: 0.6866 - acc: 0.5548
6464/9333 [===================>..........] - ETA: 5:23 - loss: 0.6866 - acc: 0.5548
6528/9333 [===================>..........] - ETA: 5:16 - loss: 0.6868 - acc: 0.5536
6592/9333 [====================>.........] - ETA: 5:09 - loss: 0.6869 - acc: 0.5535
6656/9333 [====================>.........] - ETA: 5:01 - loss: 0.6866 - acc: 0.5539
6720/9333 [====================>.........] - ETA: 4:54 - loss: 0.6865 - acc: 0.5540
6784/9333 [====================>.........] - ETA: 4:47 - loss: 0.6865 - acc: 0.5538
6848/9333 [=====================>........] - ETA: 4:40 - loss: 0.6866 - acc: 0.5533
6912/9333 [=====================>........] - ETA: 4:33 - loss: 0.6867 - acc: 0.5530
6976/9333 [=====================>........] - ETA: 4:26 - loss: 0.6867 - acc: 0.5529
7040/9333 [=====================>........] - ETA: 4:18 - loss: 0.6867 - acc: 0.5526
7104/9333 [=====================>........] - ETA: 4:11 - loss: 0.6868 - acc: 0.5521
7168/9333 [======================>.......] - ETA: 4:04 - loss: 0.6867 - acc: 0.5523
7232/9333 [======================>.......] - ETA: 3:56 - loss: 0.6866 - acc: 0.5532
7296/9333 [======================>.......] - ETA: 3:49 - loss: 0.6865 - acc: 0.5537
7360/9333 [======================>.......] - ETA: 3:42 - loss: 0.6866 - acc: 0.5537
7424/9333 [======================>.......] - ETA: 3:35 - loss: 0.6866 - acc: 0.5536
7488/9333 [=======================>......] - ETA: 3:27 - loss: 0.6866 - acc: 0.5541
7552/9333 [=======================>......] - ETA: 3:20 - loss: 0.6865 - acc: 0.5547
7616/9333 [=======================>......] - ETA: 3:13 - loss: 0.6863 - acc: 0.5550
7680/9333 [=======================>......] - ETA: 3:06 - loss: 0.6864 - acc: 0.5555
7744/9333 [=======================>......] - ETA: 2:58 - loss: 0.6862 - acc: 0.5559
7808/9333 [========================>.....] - ETA: 2:51 - loss: 0.6861 - acc: 0.5561
7872/9333 [========================>.....] - ETA: 2:44 - loss: 0.6861 - acc: 0.5563
7936/9333 [========================>.....] - ETA: 2:37 - loss: 0.6861 - acc: 0.5567
8000/9333 [========================>.....] - ETA: 2:30 - loss: 0.6859 - acc: 0.5573
8064/9333 [========================>.....] - ETA: 2:22 - loss: 0.6858 - acc: 0.5572
8128/9333 [=========================>....] - ETA: 2:15 - loss: 0.6859 - acc: 0.5570
8192/9333 [=========================>....] - ETA: 2:08 - loss: 0.6861 - acc: 0.5563
8256/9333 [=========================>....] - ETA: 2:01 - loss: 0.6861 - acc: 0.5562
8320/9333 [=========================>....] - ETA: 1:53 - loss: 0.6859 - acc: 0.5570
8384/9333 [=========================>....] - ETA: 1:46 - loss: 0.6862 - acc: 0.5562
8448/9333 [==========================>...] - ETA: 1:39 - loss: 0.6860 - acc: 0.5569
8512/9333 [==========================>...] - ETA: 1:32 - loss: 0.6862 - acc: 0.5562
8576/9333 [==========================>...] - ETA: 1:25 - loss: 0.6860 - acc: 0.5567
8640/9333 [==========================>...] - ETA: 1:17 - loss: 0.6859 - acc: 0.5572
8704/9333 [==========================>...] - ETA: 1:10 - loss: 0.6858 - acc: 0.5574
8768/9333 [===========================>..] - ETA: 1:03 - loss: 0.6858 - acc: 0.5575
8832/9333 [===========================>..] - ETA: 56s - loss: 0.6860 - acc: 0.5565 
8896/9333 [===========================>..] - ETA: 49s - loss: 0.6860 - acc: 0.5569
8960/9333 [===========================>..] - ETA: 41s - loss: 0.6860 - acc: 0.5570
9024/9333 [============================>.] - ETA: 34s - loss: 0.6860 - acc: 0.5571
9088/9333 [============================>.] - ETA: 27s - loss: 0.6862 - acc: 0.5564
9152/9333 [============================>.] - ETA: 20s - loss: 0.6862 - acc: 0.5561
9216/9333 [============================>.] - ETA: 13s - loss: 0.6862 - acc: 0.5561
9280/9333 [============================>.] - ETA: 5s - loss: 0.6863 - acc: 0.5559 
9333/9333 [==============================] - 1084s 116ms/step - loss: 0.6862 - acc: 0.5562 - val_loss: 0.6905 - val_acc: 0.5477

Epoch 00007: val_acc did not improve from 0.55256
Epoch 8/10

  64/9333 [..............................] - ETA: 17:05 - loss: 0.7201 - acc: 0.4844
 128/9333 [..............................] - ETA: 17:19 - loss: 0.6957 - acc: 0.5000
 192/9333 [..............................] - ETA: 17:06 - loss: 0.6970 - acc: 0.5052
 256/9333 [..............................] - ETA: 16:58 - loss: 0.7125 - acc: 0.4883
 320/9333 [>.............................] - ETA: 16:57 - loss: 0.7056 - acc: 0.4938
 384/9333 [>.............................] - ETA: 16:38 - loss: 0.7025 - acc: 0.5052
 448/9333 [>.............................] - ETA: 16:45 - loss: 0.7040 - acc: 0.4978
 512/9333 [>.............................] - ETA: 16:33 - loss: 0.7035 - acc: 0.4922
 576/9333 [>.............................] - ETA: 16:24 - loss: 0.7042 - acc: 0.4948
 640/9333 [=>............................] - ETA: 16:20 - loss: 0.7026 - acc: 0.5031
 704/9333 [=>............................] - ETA: 16:12 - loss: 0.6997 - acc: 0.5128
 768/9333 [=>............................] - ETA: 16:05 - loss: 0.6996 - acc: 0.5104
 832/9333 [=>............................] - ETA: 15:59 - loss: 0.6968 - acc: 0.5168
 896/9333 [=>............................] - ETA: 15:55 - loss: 0.6940 - acc: 0.5257
 960/9333 [==>...........................] - ETA: 15:47 - loss: 0.6923 - acc: 0.5250
1024/9333 [==>...........................] - ETA: 15:40 - loss: 0.6926 - acc: 0.5195
1088/9333 [==>...........................] - ETA: 15:33 - loss: 0.6924 - acc: 0.5193
1152/9333 [==>...........................] - ETA: 15:27 - loss: 0.6919 - acc: 0.5234
1216/9333 [==>...........................] - ETA: 15:16 - loss: 0.6933 - acc: 0.5214
1280/9333 [===>..........................] - ETA: 15:07 - loss: 0.6924 - acc: 0.5227
1344/9333 [===>..........................] - ETA: 15:00 - loss: 0.6919 - acc: 0.5260
1408/9333 [===>..........................] - ETA: 14:54 - loss: 0.6930 - acc: 0.5249
1472/9333 [===>..........................] - ETA: 14:45 - loss: 0.6926 - acc: 0.5265
1536/9333 [===>..........................] - ETA: 14:37 - loss: 0.6927 - acc: 0.5267
1600/9333 [====>.........................] - ETA: 14:28 - loss: 0.6919 - acc: 0.5325
1664/9333 [====>.........................] - ETA: 14:21 - loss: 0.6921 - acc: 0.5306
1728/9333 [====>.........................] - ETA: 14:12 - loss: 0.6917 - acc: 0.5318
1792/9333 [====>.........................] - ETA: 14:06 - loss: 0.6915 - acc: 0.5335
1856/9333 [====>.........................] - ETA: 14:00 - loss: 0.6910 - acc: 0.5350
1920/9333 [=====>........................] - ETA: 13:51 - loss: 0.6904 - acc: 0.5391
1984/9333 [=====>........................] - ETA: 13:43 - loss: 0.6899 - acc: 0.5403
2048/9333 [=====>........................] - ETA: 13:36 - loss: 0.6894 - acc: 0.5430
2112/9333 [=====>........................] - ETA: 13:29 - loss: 0.6888 - acc: 0.5450
2176/9333 [=====>........................] - ETA: 13:21 - loss: 0.6883 - acc: 0.5441
2240/9333 [======>.......................] - ETA: 13:16 - loss: 0.6878 - acc: 0.5451
2304/9333 [======>.......................] - ETA: 13:09 - loss: 0.6872 - acc: 0.5477
2368/9333 [======>.......................] - ETA: 13:02 - loss: 0.6878 - acc: 0.5448
2432/9333 [======>.......................] - ETA: 12:55 - loss: 0.6876 - acc: 0.5461
2496/9333 [=======>......................] - ETA: 12:48 - loss: 0.6883 - acc: 0.5453
2560/9333 [=======>......................] - ETA: 12:41 - loss: 0.6889 - acc: 0.5430
2624/9333 [=======>......................] - ETA: 12:33 - loss: 0.6890 - acc: 0.5431
2688/9333 [=======>......................] - ETA: 12:26 - loss: 0.6883 - acc: 0.5450
2752/9333 [=======>......................] - ETA: 12:20 - loss: 0.6887 - acc: 0.5432
2816/9333 [========>.....................] - ETA: 12:12 - loss: 0.6880 - acc: 0.5462
2880/9333 [========>.....................] - ETA: 12:06 - loss: 0.6877 - acc: 0.5465
2944/9333 [========>.....................] - ETA: 11:59 - loss: 0.6884 - acc: 0.5448
3008/9333 [========>.....................] - ETA: 11:51 - loss: 0.6883 - acc: 0.5469
3072/9333 [========>.....................] - ETA: 11:43 - loss: 0.6892 - acc: 0.5439
3136/9333 [=========>....................] - ETA: 11:35 - loss: 0.6893 - acc: 0.5446
3200/9333 [=========>....................] - ETA: 11:28 - loss: 0.6893 - acc: 0.5447
3264/9333 [=========>....................] - ETA: 11:22 - loss: 0.6890 - acc: 0.5460
3328/9333 [=========>....................] - ETA: 11:15 - loss: 0.6894 - acc: 0.5445
3392/9333 [=========>....................] - ETA: 11:08 - loss: 0.6888 - acc: 0.5466
3456/9333 [==========>...................] - ETA: 11:01 - loss: 0.6888 - acc: 0.5466
3520/9333 [==========>...................] - ETA: 10:53 - loss: 0.6886 - acc: 0.5474
3584/9333 [==========>...................] - ETA: 10:45 - loss: 0.6881 - acc: 0.5480
3648/9333 [==========>...................] - ETA: 10:39 - loss: 0.6879 - acc: 0.5485
3712/9333 [==========>...................] - ETA: 10:32 - loss: 0.6878 - acc: 0.5482
3776/9333 [===========>..................] - ETA: 10:25 - loss: 0.6871 - acc: 0.5501
3840/9333 [===========>..................] - ETA: 10:17 - loss: 0.6871 - acc: 0.5492
3904/9333 [===========>..................] - ETA: 10:10 - loss: 0.6874 - acc: 0.5487
3968/9333 [===========>..................] - ETA: 10:02 - loss: 0.6874 - acc: 0.5484
4032/9333 [===========>..................] - ETA: 9:55 - loss: 0.6872 - acc: 0.5486 
4096/9333 [============>.................] - ETA: 9:48 - loss: 0.6867 - acc: 0.5500
4160/9333 [============>.................] - ETA: 9:42 - loss: 0.6869 - acc: 0.5486
4224/9333 [============>.................] - ETA: 9:34 - loss: 0.6868 - acc: 0.5485
4288/9333 [============>.................] - ETA: 9:26 - loss: 0.6867 - acc: 0.5487
4352/9333 [============>.................] - ETA: 9:19 - loss: 0.6868 - acc: 0.5476
4416/9333 [=============>................] - ETA: 9:12 - loss: 0.6871 - acc: 0.5462
4480/9333 [=============>................] - ETA: 9:05 - loss: 0.6869 - acc: 0.5471
4544/9333 [=============>................] - ETA: 8:57 - loss: 0.6871 - acc: 0.5469
4608/9333 [=============>................] - ETA: 8:51 - loss: 0.6871 - acc: 0.5473
4672/9333 [==============>...............] - ETA: 8:43 - loss: 0.6871 - acc: 0.5473
4736/9333 [==============>...............] - ETA: 8:36 - loss: 0.6869 - acc: 0.5486
4800/9333 [==============>...............] - ETA: 8:29 - loss: 0.6868 - acc: 0.5494
4864/9333 [==============>...............] - ETA: 8:22 - loss: 0.6863 - acc: 0.5502
4928/9333 [==============>...............] - ETA: 8:15 - loss: 0.6869 - acc: 0.5489
4992/9333 [===============>..............] - ETA: 8:07 - loss: 0.6868 - acc: 0.5503
5056/9333 [===============>..............] - ETA: 8:00 - loss: 0.6867 - acc: 0.5502
5120/9333 [===============>..............] - ETA: 7:52 - loss: 0.6862 - acc: 0.5518
5184/9333 [===============>..............] - ETA: 7:45 - loss: 0.6865 - acc: 0.5505
5248/9333 [===============>..............] - ETA: 7:38 - loss: 0.6865 - acc: 0.5507
5312/9333 [================>.............] - ETA: 7:30 - loss: 0.6867 - acc: 0.5503
5376/9333 [================>.............] - ETA: 7:23 - loss: 0.6869 - acc: 0.5502
5440/9333 [================>.............] - ETA: 7:15 - loss: 0.6868 - acc: 0.5511
5504/9333 [================>.............] - ETA: 7:08 - loss: 0.6872 - acc: 0.5500
5568/9333 [================>.............] - ETA: 7:01 - loss: 0.6871 - acc: 0.5508
5632/9333 [=================>............] - ETA: 6:54 - loss: 0.6869 - acc: 0.5513
5696/9333 [=================>............] - ETA: 6:47 - loss: 0.6865 - acc: 0.5525
5760/9333 [=================>............] - ETA: 6:39 - loss: 0.6864 - acc: 0.5531
5824/9333 [=================>............] - ETA: 6:32 - loss: 0.6865 - acc: 0.5522
5888/9333 [=================>............] - ETA: 6:25 - loss: 0.6866 - acc: 0.5521
5952/9333 [==================>...........] - ETA: 6:18 - loss: 0.6865 - acc: 0.5526
6016/9333 [==================>...........] - ETA: 6:11 - loss: 0.6865 - acc: 0.5525
6080/9333 [==================>...........] - ETA: 6:04 - loss: 0.6864 - acc: 0.5530
6144/9333 [==================>...........] - ETA: 5:56 - loss: 0.6861 - acc: 0.5526
6208/9333 [==================>...........] - ETA: 5:49 - loss: 0.6864 - acc: 0.5512
6272/9333 [===================>..........] - ETA: 5:42 - loss: 0.6864 - acc: 0.5505
6336/9333 [===================>..........] - ETA: 5:34 - loss: 0.6865 - acc: 0.5507
6400/9333 [===================>..........] - ETA: 5:27 - loss: 0.6867 - acc: 0.5505
6464/9333 [===================>..........] - ETA: 5:20 - loss: 0.6867 - acc: 0.5503
6528/9333 [===================>..........] - ETA: 5:12 - loss: 0.6863 - acc: 0.5521
6592/9333 [====================>.........] - ETA: 5:05 - loss: 0.6862 - acc: 0.5523
6656/9333 [====================>.........] - ETA: 4:58 - loss: 0.6861 - acc: 0.5524
6720/9333 [====================>.........] - ETA: 4:51 - loss: 0.6860 - acc: 0.5534
6784/9333 [====================>.........] - ETA: 4:44 - loss: 0.6858 - acc: 0.5537
6848/9333 [=====================>........] - ETA: 4:36 - loss: 0.6859 - acc: 0.5536
6912/9333 [=====================>........] - ETA: 4:29 - loss: 0.6861 - acc: 0.5528
6976/9333 [=====================>........] - ETA: 4:22 - loss: 0.6859 - acc: 0.5535
7040/9333 [=====================>........] - ETA: 4:15 - loss: 0.6860 - acc: 0.5521
7104/9333 [=====================>........] - ETA: 4:08 - loss: 0.6861 - acc: 0.5522
7168/9333 [======================>.......] - ETA: 4:00 - loss: 0.6862 - acc: 0.5519
7232/9333 [======================>.......] - ETA: 3:53 - loss: 0.6861 - acc: 0.5523
7296/9333 [======================>.......] - ETA: 3:46 - loss: 0.6861 - acc: 0.5521
7360/9333 [======================>.......] - ETA: 3:39 - loss: 0.6860 - acc: 0.5522
7424/9333 [======================>.......] - ETA: 3:32 - loss: 0.6860 - acc: 0.5525
7488/9333 [=======================>......] - ETA: 3:24 - loss: 0.6859 - acc: 0.5530
7552/9333 [=======================>......] - ETA: 3:17 - loss: 0.6860 - acc: 0.5527
7616/9333 [=======================>......] - ETA: 3:10 - loss: 0.6862 - acc: 0.5529
7680/9333 [=======================>......] - ETA: 3:03 - loss: 0.6862 - acc: 0.5527
7744/9333 [=======================>......] - ETA: 2:56 - loss: 0.6860 - acc: 0.5535
7808/9333 [========================>.....] - ETA: 2:49 - loss: 0.6860 - acc: 0.5532
7872/9333 [========================>.....] - ETA: 2:42 - loss: 0.6860 - acc: 0.5535
7936/9333 [========================>.....] - ETA: 2:35 - loss: 0.6862 - acc: 0.5536
8000/9333 [========================>.....] - ETA: 2:27 - loss: 0.6858 - acc: 0.5545
8064/9333 [========================>.....] - ETA: 2:20 - loss: 0.6856 - acc: 0.5551
8128/9333 [=========================>....] - ETA: 2:13 - loss: 0.6858 - acc: 0.5544
8192/9333 [=========================>....] - ETA: 2:06 - loss: 0.6860 - acc: 0.5538
8256/9333 [=========================>....] - ETA: 1:59 - loss: 0.6859 - acc: 0.5539
8320/9333 [=========================>....] - ETA: 1:52 - loss: 0.6858 - acc: 0.5544
8384/9333 [=========================>....] - ETA: 1:45 - loss: 0.6858 - acc: 0.5549
8448/9333 [==========================>...] - ETA: 1:38 - loss: 0.6857 - acc: 0.5553
8512/9333 [==========================>...] - ETA: 1:31 - loss: 0.6857 - acc: 0.5556
8576/9333 [==========================>...] - ETA: 1:23 - loss: 0.6860 - acc: 0.5550
8640/9333 [==========================>...] - ETA: 1:16 - loss: 0.6859 - acc: 0.5551
8704/9333 [==========================>...] - ETA: 1:09 - loss: 0.6859 - acc: 0.5553
8768/9333 [===========================>..] - ETA: 1:02 - loss: 0.6859 - acc: 0.5554
8832/9333 [===========================>..] - ETA: 55s - loss: 0.6859 - acc: 0.5556 
8896/9333 [===========================>..] - ETA: 48s - loss: 0.6858 - acc: 0.5558
8960/9333 [===========================>..] - ETA: 41s - loss: 0.6857 - acc: 0.5560
9024/9333 [============================>.] - ETA: 34s - loss: 0.6855 - acc: 0.5566
9088/9333 [============================>.] - ETA: 27s - loss: 0.6854 - acc: 0.5572
9152/9333 [============================>.] - ETA: 20s - loss: 0.6854 - acc: 0.5570
9216/9333 [============================>.] - ETA: 12s - loss: 0.6855 - acc: 0.5569
9280/9333 [============================>.] - ETA: 5s - loss: 0.6856 - acc: 0.5570 
9333/9333 [==============================] - 1070s 115ms/step - loss: 0.6856 - acc: 0.5572 - val_loss: 0.6857 - val_acc: 0.5419

Epoch 00008: val_acc did not improve from 0.55256
Epoch 9/10

  64/9333 [..............................] - ETA: 16:22 - loss: 0.6813 - acc: 0.6719
 128/9333 [..............................] - ETA: 16:17 - loss: 0.6848 - acc: 0.6094
 192/9333 [..............................] - ETA: 16:54 - loss: 0.6779 - acc: 0.5938
 256/9333 [..............................] - ETA: 16:40 - loss: 0.6862 - acc: 0.5664
 320/9333 [>.............................] - ETA: 16:25 - loss: 0.6900 - acc: 0.5500
 384/9333 [>.............................] - ETA: 16:14 - loss: 0.6907 - acc: 0.5495
 448/9333 [>.............................] - ETA: 16:01 - loss: 0.6899 - acc: 0.5446
 512/9333 [>.............................] - ETA: 15:57 - loss: 0.6863 - acc: 0.5547
 576/9333 [>.............................] - ETA: 15:50 - loss: 0.6857 - acc: 0.5538
 640/9333 [=>............................] - ETA: 15:39 - loss: 0.6854 - acc: 0.5578
 704/9333 [=>............................] - ETA: 15:32 - loss: 0.6857 - acc: 0.5568
 768/9333 [=>............................] - ETA: 15:20 - loss: 0.6880 - acc: 0.5521
 832/9333 [=>............................] - ETA: 15:17 - loss: 0.6888 - acc: 0.5493
 896/9333 [=>............................] - ETA: 15:10 - loss: 0.6890 - acc: 0.5513
 960/9333 [==>...........................] - ETA: 15:00 - loss: 0.6885 - acc: 0.5521
1024/9333 [==>...........................] - ETA: 14:57 - loss: 0.6879 - acc: 0.5566
1088/9333 [==>...........................] - ETA: 14:50 - loss: 0.6860 - acc: 0.5625
1152/9333 [==>...........................] - ETA: 14:45 - loss: 0.6853 - acc: 0.5634
1216/9333 [==>...........................] - ETA: 14:34 - loss: 0.6836 - acc: 0.5707
1280/9333 [===>..........................] - ETA: 14:27 - loss: 0.6817 - acc: 0.5734
1344/9333 [===>..........................] - ETA: 14:20 - loss: 0.6829 - acc: 0.5685
1408/9333 [===>..........................] - ETA: 14:12 - loss: 0.6829 - acc: 0.5682
1472/9333 [===>..........................] - ETA: 14:07 - loss: 0.6838 - acc: 0.5645
1536/9333 [===>..........................] - ETA: 14:01 - loss: 0.6833 - acc: 0.5671
1600/9333 [====>.........................] - ETA: 13:55 - loss: 0.6849 - acc: 0.5625
1664/9333 [====>.........................] - ETA: 13:48 - loss: 0.6851 - acc: 0.5619
1728/9333 [====>.........................] - ETA: 13:42 - loss: 0.6852 - acc: 0.5613
1792/9333 [====>.........................] - ETA: 13:35 - loss: 0.6853 - acc: 0.5603
1856/9333 [====>.........................] - ETA: 13:28 - loss: 0.6859 - acc: 0.5603
1920/9333 [=====>........................] - ETA: 13:22 - loss: 0.6857 - acc: 0.5620
1984/9333 [=====>........................] - ETA: 13:14 - loss: 0.6863 - acc: 0.5600
2048/9333 [=====>........................] - ETA: 13:08 - loss: 0.6864 - acc: 0.5591
2112/9333 [=====>........................] - ETA: 13:03 - loss: 0.6857 - acc: 0.5601
2176/9333 [=====>........................] - ETA: 12:56 - loss: 0.6859 - acc: 0.5593
2240/9333 [======>.......................] - ETA: 12:48 - loss: 0.6862 - acc: 0.5554
2304/9333 [======>.......................] - ETA: 12:40 - loss: 0.6861 - acc: 0.5569
2368/9333 [======>.......................] - ETA: 12:32 - loss: 0.6856 - acc: 0.5574
2432/9333 [======>.......................] - ETA: 12:26 - loss: 0.6854 - acc: 0.5588
2496/9333 [=======>......................] - ETA: 12:20 - loss: 0.6859 - acc: 0.5565
2560/9333 [=======>......................] - ETA: 12:13 - loss: 0.6853 - acc: 0.5578
2624/9333 [=======>......................] - ETA: 12:06 - loss: 0.6850 - acc: 0.5583
2688/9333 [=======>......................] - ETA: 12:00 - loss: 0.6847 - acc: 0.5588
2752/9333 [=======>......................] - ETA: 11:52 - loss: 0.6843 - acc: 0.5600
2816/9333 [========>.....................] - ETA: 11:45 - loss: 0.6847 - acc: 0.5582
2880/9333 [========>.....................] - ETA: 11:38 - loss: 0.6844 - acc: 0.5594
2944/9333 [========>.....................] - ETA: 11:30 - loss: 0.6845 - acc: 0.5588
3008/9333 [========>.....................] - ETA: 11:25 - loss: 0.6847 - acc: 0.5588
3072/9333 [========>.....................] - ETA: 11:18 - loss: 0.6854 - acc: 0.5570
3136/9333 [=========>....................] - ETA: 11:11 - loss: 0.6851 - acc: 0.5577
3200/9333 [=========>....................] - ETA: 11:04 - loss: 0.6850 - acc: 0.5581
3264/9333 [=========>....................] - ETA: 10:57 - loss: 0.6847 - acc: 0.5582
3328/9333 [=========>....................] - ETA: 10:51 - loss: 0.6847 - acc: 0.5586
3392/9333 [=========>....................] - ETA: 10:44 - loss: 0.6846 - acc: 0.5587
3456/9333 [==========>...................] - ETA: 10:36 - loss: 0.6855 - acc: 0.5558
3520/9333 [==========>...................] - ETA: 10:29 - loss: 0.6854 - acc: 0.5551
3584/9333 [==========>...................] - ETA: 10:22 - loss: 0.6857 - acc: 0.5541
3648/9333 [==========>...................] - ETA: 10:16 - loss: 0.6853 - acc: 0.5559
3712/9333 [==========>...................] - ETA: 10:10 - loss: 0.6856 - acc: 0.5547
3776/9333 [===========>..................] - ETA: 10:03 - loss: 0.6859 - acc: 0.5548
3840/9333 [===========>..................] - ETA: 9:56 - loss: 0.6860 - acc: 0.5542 
3904/9333 [===========>..................] - ETA: 9:49 - loss: 0.6858 - acc: 0.5538
3968/9333 [===========>..................] - ETA: 9:42 - loss: 0.6858 - acc: 0.5532
4032/9333 [===========>..................] - ETA: 9:35 - loss: 0.6859 - acc: 0.5528
4096/9333 [============>.................] - ETA: 9:28 - loss: 0.6859 - acc: 0.5530
4160/9333 [============>.................] - ETA: 9:21 - loss: 0.6856 - acc: 0.5538
4224/9333 [============>.................] - ETA: 9:14 - loss: 0.6858 - acc: 0.5542
4288/9333 [============>.................] - ETA: 9:08 - loss: 0.6856 - acc: 0.5550
4352/9333 [============>.................] - ETA: 9:01 - loss: 0.6857 - acc: 0.5547
4416/9333 [=============>................] - ETA: 8:54 - loss: 0.6859 - acc: 0.5532
4480/9333 [=============>................] - ETA: 8:47 - loss: 0.6864 - acc: 0.5527
4544/9333 [=============>................] - ETA: 8:40 - loss: 0.6861 - acc: 0.5535
4608/9333 [=============>................] - ETA: 8:33 - loss: 0.6860 - acc: 0.5536
4672/9333 [==============>...............] - ETA: 8:25 - loss: 0.6860 - acc: 0.5537
4736/9333 [==============>...............] - ETA: 8:18 - loss: 0.6861 - acc: 0.5532
4800/9333 [==============>...............] - ETA: 8:11 - loss: 0.6860 - acc: 0.5544
4864/9333 [==============>...............] - ETA: 8:05 - loss: 0.6860 - acc: 0.5547
4928/9333 [==============>...............] - ETA: 7:58 - loss: 0.6859 - acc: 0.5558
4992/9333 [===============>..............] - ETA: 7:51 - loss: 0.6860 - acc: 0.5555
5056/9333 [===============>..............] - ETA: 7:44 - loss: 0.6862 - acc: 0.5544
5120/9333 [===============>..............] - ETA: 7:37 - loss: 0.6863 - acc: 0.5543
5184/9333 [===============>..............] - ETA: 7:30 - loss: 0.6863 - acc: 0.5538
5248/9333 [===============>..............] - ETA: 7:24 - loss: 0.6865 - acc: 0.5526
5312/9333 [================>.............] - ETA: 7:17 - loss: 0.6865 - acc: 0.5527
5376/9333 [================>.............] - ETA: 7:10 - loss: 0.6865 - acc: 0.5530
5440/9333 [================>.............] - ETA: 7:03 - loss: 0.6862 - acc: 0.5544
5504/9333 [================>.............] - ETA: 6:56 - loss: 0.6862 - acc: 0.5545
5568/9333 [================>.............] - ETA: 6:49 - loss: 0.6864 - acc: 0.5533
5632/9333 [=================>............] - ETA: 6:42 - loss: 0.6864 - acc: 0.5531
5696/9333 [=================>............] - ETA: 6:35 - loss: 0.6866 - acc: 0.5523
5760/9333 [=================>............] - ETA: 6:28 - loss: 0.6866 - acc: 0.5528
5824/9333 [=================>............] - ETA: 6:21 - loss: 0.6864 - acc: 0.5539
5888/9333 [=================>............] - ETA: 6:14 - loss: 0.6863 - acc: 0.5542
5952/9333 [==================>...........] - ETA: 6:07 - loss: 0.6863 - acc: 0.5538
6016/9333 [==================>...........] - ETA: 6:00 - loss: 0.6863 - acc: 0.5532
6080/9333 [==================>...........] - ETA: 5:53 - loss: 0.6863 - acc: 0.5531
6144/9333 [==================>...........] - ETA: 5:46 - loss: 0.6861 - acc: 0.5535
6208/9333 [==================>...........] - ETA: 5:39 - loss: 0.6861 - acc: 0.5540
6272/9333 [===================>..........] - ETA: 5:32 - loss: 0.6863 - acc: 0.5534
6336/9333 [===================>..........] - ETA: 5:25 - loss: 0.6862 - acc: 0.5538
6400/9333 [===================>..........] - ETA: 5:18 - loss: 0.6858 - acc: 0.5544
6464/9333 [===================>..........] - ETA: 5:11 - loss: 0.6858 - acc: 0.5548
6528/9333 [===================>..........] - ETA: 5:04 - loss: 0.6859 - acc: 0.5542
6592/9333 [====================>.........] - ETA: 4:57 - loss: 0.6857 - acc: 0.5548
6656/9333 [====================>.........] - ETA: 4:50 - loss: 0.6857 - acc: 0.5544
6720/9333 [====================>.........] - ETA: 4:43 - loss: 0.6858 - acc: 0.5543
6784/9333 [====================>.........] - ETA: 4:36 - loss: 0.6857 - acc: 0.5545
6848/9333 [=====================>........] - ETA: 4:29 - loss: 0.6857 - acc: 0.5543
6912/9333 [=====================>........] - ETA: 4:22 - loss: 0.6861 - acc: 0.5527
6976/9333 [=====================>........] - ETA: 4:15 - loss: 0.6860 - acc: 0.5533
7040/9333 [=====================>........] - ETA: 4:08 - loss: 0.6857 - acc: 0.5543
7104/9333 [=====================>........] - ETA: 4:01 - loss: 0.6855 - acc: 0.5549
7168/9333 [======================>.......] - ETA: 3:55 - loss: 0.6856 - acc: 0.5548
7232/9333 [======================>.......] - ETA: 3:48 - loss: 0.6855 - acc: 0.5542
7296/9333 [======================>.......] - ETA: 3:41 - loss: 0.6854 - acc: 0.5546
7360/9333 [======================>.......] - ETA: 3:34 - loss: 0.6855 - acc: 0.5546
7424/9333 [======================>.......] - ETA: 3:27 - loss: 0.6855 - acc: 0.5546
7488/9333 [=======================>......] - ETA: 3:20 - loss: 0.6854 - acc: 0.5544
7552/9333 [=======================>......] - ETA: 3:13 - loss: 0.6856 - acc: 0.5544
7616/9333 [=======================>......] - ETA: 3:06 - loss: 0.6856 - acc: 0.5546
7680/9333 [=======================>......] - ETA: 2:59 - loss: 0.6855 - acc: 0.5544
7744/9333 [=======================>......] - ETA: 2:52 - loss: 0.6852 - acc: 0.5553
7808/9333 [========================>.....] - ETA: 2:45 - loss: 0.6850 - acc: 0.5557
7872/9333 [========================>.....] - ETA: 2:38 - loss: 0.6850 - acc: 0.5561
7936/9333 [========================>.....] - ETA: 2:31 - loss: 0.6850 - acc: 0.5558
8000/9333 [========================>.....] - ETA: 2:24 - loss: 0.6851 - acc: 0.5555
8064/9333 [========================>.....] - ETA: 2:17 - loss: 0.6852 - acc: 0.5552
8128/9333 [=========================>....] - ETA: 2:10 - loss: 0.6853 - acc: 0.5543
8192/9333 [=========================>....] - ETA: 2:03 - loss: 0.6852 - acc: 0.5540
8256/9333 [=========================>....] - ETA: 1:56 - loss: 0.6854 - acc: 0.5537
8320/9333 [=========================>....] - ETA: 1:50 - loss: 0.6854 - acc: 0.5537
8384/9333 [=========================>....] - ETA: 1:43 - loss: 0.6854 - acc: 0.5536
8448/9333 [==========================>...] - ETA: 1:36 - loss: 0.6853 - acc: 0.5536
8512/9333 [==========================>...] - ETA: 1:29 - loss: 0.6852 - acc: 0.5538
8576/9333 [==========================>...] - ETA: 1:22 - loss: 0.6852 - acc: 0.5538
8640/9333 [==========================>...] - ETA: 1:15 - loss: 0.6851 - acc: 0.5539
8704/9333 [==========================>...] - ETA: 1:08 - loss: 0.6850 - acc: 0.5542
8768/9333 [===========================>..] - ETA: 1:01 - loss: 0.6850 - acc: 0.5546
8832/9333 [===========================>..] - ETA: 54s - loss: 0.6851 - acc: 0.5543 
8896/9333 [===========================>..] - ETA: 47s - loss: 0.6849 - acc: 0.5550
8960/9333 [===========================>..] - ETA: 40s - loss: 0.6852 - acc: 0.5544
9024/9333 [============================>.] - ETA: 33s - loss: 0.6851 - acc: 0.5540
9088/9333 [============================>.] - ETA: 26s - loss: 0.6850 - acc: 0.5540
9152/9333 [============================>.] - ETA: 19s - loss: 0.6850 - acc: 0.5539
9216/9333 [============================>.] - ETA: 12s - loss: 0.6850 - acc: 0.5541
9280/9333 [============================>.] - ETA: 5s - loss: 0.6851 - acc: 0.5541 
9333/9333 [==============================] - 1050s 113ms/step - loss: 0.6848 - acc: 0.5548 - val_loss: 0.6871 - val_acc: 0.5468

Epoch 00009: val_acc did not improve from 0.55256
Epoch 10/10

  64/9333 [..............................] - ETA: 17:03 - loss: 0.6866 - acc: 0.6250
 128/9333 [..............................] - ETA: 16:32 - loss: 0.7098 - acc: 0.5312
 192/9333 [..............................] - ETA: 16:16 - loss: 0.7063 - acc: 0.5312
 256/9333 [..............................] - ETA: 16:36 - loss: 0.7037 - acc: 0.5391
 320/9333 [>.............................] - ETA: 16:37 - loss: 0.7056 - acc: 0.5281
 384/9333 [>.............................] - ETA: 16:25 - loss: 0.7043 - acc: 0.5260
 448/9333 [>.............................] - ETA: 16:33 - loss: 0.7021 - acc: 0.5335
 512/9333 [>.............................] - ETA: 16:19 - loss: 0.6985 - acc: 0.5410
 576/9333 [>.............................] - ETA: 16:10 - loss: 0.6939 - acc: 0.5521
 640/9333 [=>............................] - ETA: 16:01 - loss: 0.6915 - acc: 0.5594
 704/9333 [=>............................] - ETA: 15:54 - loss: 0.6917 - acc: 0.5526
 768/9333 [=>............................] - ETA: 15:44 - loss: 0.6909 - acc: 0.5508
 832/9333 [=>............................] - ETA: 15:33 - loss: 0.6890 - acc: 0.5565
 896/9333 [=>............................] - ETA: 15:29 - loss: 0.6888 - acc: 0.5569
 960/9333 [==>...........................] - ETA: 15:18 - loss: 0.6885 - acc: 0.5583
1024/9333 [==>...........................] - ETA: 15:13 - loss: 0.6888 - acc: 0.5605
1088/9333 [==>...........................] - ETA: 15:04 - loss: 0.6892 - acc: 0.5597
1152/9333 [==>...........................] - ETA: 14:56 - loss: 0.6893 - acc: 0.5564
1216/9333 [==>...........................] - ETA: 14:52 - loss: 0.6900 - acc: 0.5535
1280/9333 [===>..........................] - ETA: 14:46 - loss: 0.6901 - acc: 0.5516
1344/9333 [===>..........................] - ETA: 14:39 - loss: 0.6904 - acc: 0.5476
1408/9333 [===>..........................] - ETA: 14:31 - loss: 0.6906 - acc: 0.5490
1472/9333 [===>..........................] - ETA: 14:23 - loss: 0.6894 - acc: 0.5516
1536/9333 [===>..........................] - ETA: 14:16 - loss: 0.6895 - acc: 0.5495
1600/9333 [====>.........................] - ETA: 14:10 - loss: 0.6903 - acc: 0.5444
1664/9333 [====>.........................] - ETA: 14:03 - loss: 0.6901 - acc: 0.5427
1728/9333 [====>.........................] - ETA: 13:59 - loss: 0.6895 - acc: 0.5422
1792/9333 [====>.........................] - ETA: 13:52 - loss: 0.6891 - acc: 0.5413
1856/9333 [====>.........................] - ETA: 13:44 - loss: 0.6886 - acc: 0.5415
1920/9333 [=====>........................] - ETA: 13:37 - loss: 0.6882 - acc: 0.5411
1984/9333 [=====>........................] - ETA: 13:30 - loss: 0.6879 - acc: 0.5413
2048/9333 [=====>........................] - ETA: 13:25 - loss: 0.6889 - acc: 0.5361
2112/9333 [=====>........................] - ETA: 13:17 - loss: 0.6897 - acc: 0.5341
2176/9333 [=====>........................] - ETA: 13:12 - loss: 0.6895 - acc: 0.5368
2240/9333 [======>.......................] - ETA: 13:06 - loss: 0.6897 - acc: 0.5379
2304/9333 [======>.......................] - ETA: 12:57 - loss: 0.6898 - acc: 0.5369
2368/9333 [======>.......................] - ETA: 12:51 - loss: 0.6897 - acc: 0.5367
2432/9333 [======>.......................] - ETA: 12:44 - loss: 0.6893 - acc: 0.5391
2496/9333 [=======>......................] - ETA: 12:37 - loss: 0.6891 - acc: 0.5393
2560/9333 [=======>......................] - ETA: 12:30 - loss: 0.6889 - acc: 0.5402
2624/9333 [=======>......................] - ETA: 12:22 - loss: 0.6890 - acc: 0.5393
2688/9333 [=======>......................] - ETA: 12:15 - loss: 0.6884 - acc: 0.5406
2752/9333 [=======>......................] - ETA: 12:09 - loss: 0.6890 - acc: 0.5389
2816/9333 [========>.....................] - ETA: 12:01 - loss: 0.6892 - acc: 0.5384
2880/9333 [========>.....................] - ETA: 11:53 - loss: 0.6886 - acc: 0.5396
2944/9333 [========>.....................] - ETA: 11:46 - loss: 0.6892 - acc: 0.5377
3008/9333 [========>.....................] - ETA: 11:39 - loss: 0.6891 - acc: 0.5372
3072/9333 [========>.....................] - ETA: 11:33 - loss: 0.6896 - acc: 0.5352
3136/9333 [=========>....................] - ETA: 11:25 - loss: 0.6902 - acc: 0.5332
3200/9333 [=========>....................] - ETA: 11:19 - loss: 0.6899 - acc: 0.5344
3264/9333 [=========>....................] - ETA: 11:11 - loss: 0.6895 - acc: 0.5349
3328/9333 [=========>....................] - ETA: 11:05 - loss: 0.6893 - acc: 0.5358
3392/9333 [=========>....................] - ETA: 10:58 - loss: 0.6890 - acc: 0.5357
3456/9333 [==========>...................] - ETA: 10:51 - loss: 0.6890 - acc: 0.5359
3520/9333 [==========>...................] - ETA: 10:43 - loss: 0.6890 - acc: 0.5361
3584/9333 [==========>...................] - ETA: 10:36 - loss: 0.6890 - acc: 0.5366
3648/9333 [==========>...................] - ETA: 10:30 - loss: 0.6891 - acc: 0.5356
3712/9333 [==========>...................] - ETA: 10:21 - loss: 0.6892 - acc: 0.5364
3776/9333 [===========>..................] - ETA: 10:14 - loss: 0.6891 - acc: 0.5360
3840/9333 [===========>..................] - ETA: 10:07 - loss: 0.6890 - acc: 0.5365
3904/9333 [===========>..................] - ETA: 10:00 - loss: 0.6890 - acc: 0.5364
3968/9333 [===========>..................] - ETA: 9:53 - loss: 0.6886 - acc: 0.5381 
4032/9333 [===========>..................] - ETA: 9:46 - loss: 0.6891 - acc: 0.5372
4096/9333 [============>.................] - ETA: 9:38 - loss: 0.6890 - acc: 0.5371
4160/9333 [============>.................] - ETA: 9:31 - loss: 0.6890 - acc: 0.5373
4224/9333 [============>.................] - ETA: 9:24 - loss: 0.6888 - acc: 0.5381
4288/9333 [============>.................] - ETA: 9:17 - loss: 0.6890 - acc: 0.5385
4352/9333 [============>.................] - ETA: 9:10 - loss: 0.6893 - acc: 0.5375
4416/9333 [=============>................] - ETA: 9:03 - loss: 0.6893 - acc: 0.5376
4480/9333 [=============>................] - ETA: 8:56 - loss: 0.6890 - acc: 0.5386
4544/9333 [=============>................] - ETA: 8:48 - loss: 0.6886 - acc: 0.5398
4608/9333 [=============>................] - ETA: 8:41 - loss: 0.6885 - acc: 0.5397
4672/9333 [==============>...............] - ETA: 8:34 - loss: 0.6886 - acc: 0.5396
4736/9333 [==============>...............] - ETA: 8:27 - loss: 0.6886 - acc: 0.5399
4800/9333 [==============>...............] - ETA: 8:19 - loss: 0.6884 - acc: 0.5402
4864/9333 [==============>...............] - ETA: 8:12 - loss: 0.6887 - acc: 0.5399
4928/9333 [==============>...............] - ETA: 8:05 - loss: 0.6886 - acc: 0.5404
4992/9333 [===============>..............] - ETA: 7:58 - loss: 0.6887 - acc: 0.5397
5056/9333 [===============>..............] - ETA: 7:51 - loss: 0.6890 - acc: 0.5382
5120/9333 [===============>..............] - ETA: 7:44 - loss: 0.6885 - acc: 0.5396
5184/9333 [===============>..............] - ETA: 7:36 - loss: 0.6884 - acc: 0.5405
5248/9333 [===============>..............] - ETA: 7:29 - loss: 0.6882 - acc: 0.5413
5312/9333 [================>.............] - ETA: 7:23 - loss: 0.6883 - acc: 0.5414
5376/9333 [================>.............] - ETA: 7:15 - loss: 0.6880 - acc: 0.5424
5440/9333 [================>.............] - ETA: 7:08 - loss: 0.6880 - acc: 0.5425
5504/9333 [================>.............] - ETA: 7:01 - loss: 0.6880 - acc: 0.5423
5568/9333 [================>.............] - ETA: 6:54 - loss: 0.6879 - acc: 0.5426
5632/9333 [=================>............] - ETA: 6:47 - loss: 0.6878 - acc: 0.5431
5696/9333 [=================>............] - ETA: 6:40 - loss: 0.6880 - acc: 0.5430
5760/9333 [=================>............] - ETA: 6:33 - loss: 0.6877 - acc: 0.5441
5824/9333 [=================>............] - ETA: 6:26 - loss: 0.6876 - acc: 0.5450
5888/9333 [=================>............] - ETA: 6:19 - loss: 0.6873 - acc: 0.5457
5952/9333 [==================>...........] - ETA: 6:12 - loss: 0.6870 - acc: 0.5462
6016/9333 [==================>...........] - ETA: 6:05 - loss: 0.6870 - acc: 0.5465
6080/9333 [==================>...........] - ETA: 5:58 - loss: 0.6868 - acc: 0.5470
6144/9333 [==================>...........] - ETA: 5:51 - loss: 0.6868 - acc: 0.5469
6208/9333 [==================>...........] - ETA: 5:44 - loss: 0.6873 - acc: 0.5456
6272/9333 [===================>..........] - ETA: 5:37 - loss: 0.6872 - acc: 0.5458
6336/9333 [===================>..........] - ETA: 5:30 - loss: 0.6874 - acc: 0.5451
6400/9333 [===================>..........] - ETA: 5:22 - loss: 0.6875 - acc: 0.5447
6464/9333 [===================>..........] - ETA: 5:15 - loss: 0.6874 - acc: 0.5453
6528/9333 [===================>..........] - ETA: 5:08 - loss: 0.6873 - acc: 0.5460
6592/9333 [====================>.........] - ETA: 5:01 - loss: 0.6873 - acc: 0.5455
6656/9333 [====================>.........] - ETA: 4:54 - loss: 0.6873 - acc: 0.5457
6720/9333 [====================>.........] - ETA: 4:47 - loss: 0.6876 - acc: 0.5451
6784/9333 [====================>.........] - ETA: 4:40 - loss: 0.6878 - acc: 0.5445
6848/9333 [=====================>........] - ETA: 4:33 - loss: 0.6880 - acc: 0.5442
6912/9333 [=====================>........] - ETA: 4:26 - loss: 0.6883 - acc: 0.5437
6976/9333 [=====================>........] - ETA: 4:19 - loss: 0.6882 - acc: 0.5436
7040/9333 [=====================>........] - ETA: 4:12 - loss: 0.6879 - acc: 0.5445
7104/9333 [=====================>........] - ETA: 4:05 - loss: 0.6877 - acc: 0.5445
7168/9333 [======================>.......] - ETA: 3:57 - loss: 0.6879 - acc: 0.5446
7232/9333 [======================>.......] - ETA: 3:50 - loss: 0.6879 - acc: 0.5447
7296/9333 [======================>.......] - ETA: 3:43 - loss: 0.6882 - acc: 0.5437
7360/9333 [======================>.......] - ETA: 3:36 - loss: 0.6883 - acc: 0.5429
7424/9333 [======================>.......] - ETA: 3:29 - loss: 0.6883 - acc: 0.5427
7488/9333 [=======================>......] - ETA: 3:22 - loss: 0.6883 - acc: 0.5431
7552/9333 [=======================>......] - ETA: 3:15 - loss: 0.6880 - acc: 0.5438
7616/9333 [=======================>......] - ETA: 3:08 - loss: 0.6880 - acc: 0.5440
7680/9333 [=======================>......] - ETA: 3:01 - loss: 0.6877 - acc: 0.5447
7744/9333 [=======================>......] - ETA: 2:54 - loss: 0.6876 - acc: 0.5446
7808/9333 [========================>.....] - ETA: 2:47 - loss: 0.6877 - acc: 0.5443
7872/9333 [========================>.....] - ETA: 2:40 - loss: 0.6876 - acc: 0.5445
7936/9333 [========================>.....] - ETA: 2:32 - loss: 0.6873 - acc: 0.5455
8000/9333 [========================>.....] - ETA: 2:25 - loss: 0.6873 - acc: 0.5459
8064/9333 [========================>.....] - ETA: 2:18 - loss: 0.6873 - acc: 0.5455
8128/9333 [=========================>....] - ETA: 2:11 - loss: 0.6871 - acc: 0.5459
8192/9333 [=========================>....] - ETA: 2:04 - loss: 0.6871 - acc: 0.5460
8256/9333 [=========================>....] - ETA: 1:57 - loss: 0.6872 - acc: 0.5458
8320/9333 [=========================>....] - ETA: 1:50 - loss: 0.6872 - acc: 0.5463
8384/9333 [=========================>....] - ETA: 1:43 - loss: 0.6874 - acc: 0.5457
8448/9333 [==========================>...] - ETA: 1:36 - loss: 0.6875 - acc: 0.5456
8512/9333 [==========================>...] - ETA: 1:29 - loss: 0.6876 - acc: 0.5451
8576/9333 [==========================>...] - ETA: 1:22 - loss: 0.6875 - acc: 0.5450
8640/9333 [==========================>...] - ETA: 1:15 - loss: 0.6874 - acc: 0.5455
8704/9333 [==========================>...] - ETA: 1:08 - loss: 0.6868 - acc: 0.5476
8768/9333 [===========================>..] - ETA: 1:01 - loss: 0.6868 - acc: 0.5476
8832/9333 [===========================>..] - ETA: 54s - loss: 0.6868 - acc: 0.5474 
8896/9333 [===========================>..] - ETA: 47s - loss: 0.6867 - acc: 0.5479
8960/9333 [===========================>..] - ETA: 40s - loss: 0.6866 - acc: 0.5481
9024/9333 [============================>.] - ETA: 33s - loss: 0.6866 - acc: 0.5485
9088/9333 [============================>.] - ETA: 26s - loss: 0.6866 - acc: 0.5483
9152/9333 [============================>.] - ETA: 19s - loss: 0.6865 - acc: 0.5484
9216/9333 [============================>.] - ETA: 12s - loss: 0.6868 - acc: 0.5474
9280/9333 [============================>.] - ETA: 5s - loss: 0.6868 - acc: 0.5480 
9333/9333 [==============================] - 1058s 113ms/step - loss: 0.6868 - acc: 0.5482 - val_loss: 0.6856 - val_acc: 0.5439

Epoch 00010: val_acc did not improve from 0.55256
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f48c422f950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f48c422f950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f48c40dcd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f48c40dcd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48c4184710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48c4184710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48a4244b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48a4244b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43a4155390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43a4155390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a40e1810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a40e1810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48a4244bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48a4244bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a413d210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a413d210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48a4270690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48a4270690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48a4155b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48a4155b10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a42aa190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a42aa190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45247931d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45247931d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44bc7e8b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44bc7e8b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48847da490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48847da490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4884480c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4884480c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44bc504110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44bc504110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45440ec310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45440ec310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48c4089110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48c4089110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48841f9e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48841f9e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4884164e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4884164e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44e45f0f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44e45f0f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48843528d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48843528d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48841675d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48841675d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4864723a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4864723a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48645c8990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48645c8990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44c47e85d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44c47e85d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4864723d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4864723d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f486462f750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f486462f750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48644e13d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48644e13d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48642ecd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48642ecd90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48644057d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48644057d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48840722d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48840722d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48642dd890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48642dd890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4864086390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4864086390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f484474f3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f484474f3d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48640a1710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48640a1710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48645c4c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48645c4c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4844672dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4844672dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f484454be90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f484454be90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48640ab2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48640ab2d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48445c9e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48445c9e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f484454b1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f484454b1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f484430c510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f484430c510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f484426fd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f484426fd10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4844114150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4844114150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48444110d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48444110d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f484423c890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f484423c890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48440c40d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48440c40d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4824691c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4824691c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48245f7990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48245f7990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48247268d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48247268d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4824691a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4824691a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f484410eb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f484410eb10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48243b6650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48243b6650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f482429c6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f482429c6d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48245f2950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48245f2950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48243b6ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48243b6ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f482431ced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f482431ced0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48240ab290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48240ab290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4804700290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4804700290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48240aba10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48240aba10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f482404ccd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f482404ccd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4824245ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4824245ed0>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 6:17
 128/2592 [>.............................] - ETA: 3:44
 192/2592 [=>............................] - ETA: 2:52
 256/2592 [=>............................] - ETA: 2:26
 320/2592 [==>...........................] - ETA: 2:11
 384/2592 [===>..........................] - ETA: 2:00
 448/2592 [====>.........................] - ETA: 1:50
 512/2592 [====>.........................] - ETA: 1:41
 576/2592 [=====>........................] - ETA: 1:35
 640/2592 [======>.......................] - ETA: 1:30
 704/2592 [=======>......................] - ETA: 1:25
 768/2592 [=======>......................] - ETA: 1:21
 832/2592 [========>.....................] - ETA: 1:16
 896/2592 [=========>....................] - ETA: 1:12
 960/2592 [==========>...................] - ETA: 1:08
1024/2592 [==========>...................] - ETA: 1:05
1088/2592 [===========>..................] - ETA: 1:01
1152/2592 [============>.................] - ETA: 58s 
1216/2592 [=============>................] - ETA: 55s
1280/2592 [=============>................] - ETA: 52s
1344/2592 [==============>...............] - ETA: 49s
1408/2592 [===============>..............] - ETA: 47s
1472/2592 [================>.............] - ETA: 44s
1536/2592 [================>.............] - ETA: 41s
1600/2592 [=================>............] - ETA: 39s
1664/2592 [==================>...........] - ETA: 36s
1728/2592 [===================>..........] - ETA: 33s
1792/2592 [===================>..........] - ETA: 30s
1856/2592 [====================>.........] - ETA: 28s
1920/2592 [=====================>........] - ETA: 25s
1984/2592 [=====================>........] - ETA: 23s
2048/2592 [======================>.......] - ETA: 20s
2112/2592 [=======================>......] - ETA: 18s
2176/2592 [========================>.....] - ETA: 15s
2240/2592 [========================>.....] - ETA: 13s
2304/2592 [=========================>....] - ETA: 10s
2368/2592 [==========================>...] - ETA: 8s 
2432/2592 [===========================>..] - ETA: 6s
2496/2592 [===========================>..] - ETA: 3s
2560/2592 [============================>.] - ETA: 1s
2592/2592 [==============================] - 98s 38ms/step
loss: 0.6928660994694557
acc: 0.5281635802469136
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f434c2c78d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f434c2c78d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f434c2b8e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f434c2b8e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a4297c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a4297c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47c43b4b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47c43b4b10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f434c247510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f434c247510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47c440dbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47c440dbd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47c43c57d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47c43c57d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a43e4cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a43e4cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47c4424410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47c4424410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48c40bd110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f48c40bd110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a43303d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a43303d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47c43e6dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47c43e6dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a4788990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48a4788990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48c40ac990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f48c40ac990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f434c1ccb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f434c1ccb10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48c40ac250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48c40ac250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48c40ace50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f48c40ace50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4284737e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4284737e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f434c080b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f434c080b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f432470a450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f432470a450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f432460f990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f432460f990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f434c080450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f434c080450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4324793d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4324793d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4324585a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4324585a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4324423890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4324423890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f432432ddd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f432432ddd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f434c075210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f434c075210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f432460fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f432460fd50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f43241dded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f43241dded0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43240f14d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43240f14d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f431c78d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f431c78d850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43241ddd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43241ddd10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4324421b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4324421b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f431c6b5650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f431c6b5650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f431c5a1f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f431c5a1f90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f432454b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f432454b0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f431c6b5d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f431c6b5d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f432414a6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f432414a6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f431c3eced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f431c3eced0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f431c3545d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f431c3545d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f431c58f9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f431c58f9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f431c3ec6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f431c3ec6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f431c441190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f431c441190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f431c094610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f431c094610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f431c064c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f431c064c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f431c33be50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f431c33be50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f431c31a590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f431c31a590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42e870ad10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42e870ad10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42e84c3890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42e84c3890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42e84e3b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42e84e3b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42e8451450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42e8451450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42e87a6210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42e87a6210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42e83ebb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42e83ebb10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42e817a4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42e817a4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42e80e0a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42e80e0a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42e8214e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42e8214e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42e817a590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42e817a590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42c47523d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42c47523d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42e81e3590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42e81e3590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42c4697290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42c4697290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42c446dd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42c446dd10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42e820ddd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42e820ddd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42c45ca690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42c45ca690>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 1:07:30 - loss: 0.7931 - acc: 0.4844
 128/9333 [..............................] - ETA: 39:57 - loss: 0.8193 - acc: 0.4062  
 192/9333 [..............................] - ETA: 30:41 - loss: 0.7604 - acc: 0.4844
 256/9333 [..............................] - ETA: 26:23 - loss: 0.7508 - acc: 0.5000
 320/9333 [>.............................] - ETA: 23:29 - loss: 0.7569 - acc: 0.4969
 384/9333 [>.............................] - ETA: 21:39 - loss: 0.7493 - acc: 0.5026
 448/9333 [>.............................] - ETA: 20:19 - loss: 0.7535 - acc: 0.4978
 512/9333 [>.............................] - ETA: 19:15 - loss: 0.7517 - acc: 0.4961
 576/9333 [>.............................] - ETA: 18:25 - loss: 0.7522 - acc: 0.4931
 640/9333 [=>............................] - ETA: 17:46 - loss: 0.7471 - acc: 0.4969
 704/9333 [=>............................] - ETA: 17:22 - loss: 0.7446 - acc: 0.4972
 768/9333 [=>............................] - ETA: 16:49 - loss: 0.7390 - acc: 0.5065
 832/9333 [=>............................] - ETA: 16:22 - loss: 0.7353 - acc: 0.5084
 896/9333 [=>............................] - ETA: 15:55 - loss: 0.7265 - acc: 0.5190
 960/9333 [==>...........................] - ETA: 15:38 - loss: 0.7281 - acc: 0.5146
1024/9333 [==>...........................] - ETA: 15:16 - loss: 0.7245 - acc: 0.5166
1088/9333 [==>...........................] - ETA: 14:55 - loss: 0.7282 - acc: 0.5147
1152/9333 [==>...........................] - ETA: 14:37 - loss: 0.7294 - acc: 0.5130
1216/9333 [==>...........................] - ETA: 14:26 - loss: 0.7294 - acc: 0.5107
1280/9333 [===>..........................] - ETA: 14:14 - loss: 0.7278 - acc: 0.5141
1344/9333 [===>..........................] - ETA: 13:57 - loss: 0.7266 - acc: 0.5171
1408/9333 [===>..........................] - ETA: 13:42 - loss: 0.7267 - acc: 0.5192
1472/9333 [===>..........................] - ETA: 13:33 - loss: 0.7290 - acc: 0.5183
1536/9333 [===>..........................] - ETA: 13:20 - loss: 0.7303 - acc: 0.5189
1600/9333 [====>.........................] - ETA: 13:08 - loss: 0.7304 - acc: 0.5194
1664/9333 [====>.........................] - ETA: 12:55 - loss: 0.7300 - acc: 0.5210
1728/9333 [====>.........................] - ETA: 12:42 - loss: 0.7306 - acc: 0.5197
1792/9333 [====>.........................] - ETA: 12:32 - loss: 0.7297 - acc: 0.5218
1856/9333 [====>.........................] - ETA: 12:21 - loss: 0.7297 - acc: 0.5216
1920/9333 [=====>........................] - ETA: 12:11 - loss: 0.7291 - acc: 0.5208
1984/9333 [=====>........................] - ETA: 12:03 - loss: 0.7290 - acc: 0.5202
2048/9333 [=====>........................] - ETA: 11:53 - loss: 0.7303 - acc: 0.5171
2112/9333 [=====>........................] - ETA: 11:43 - loss: 0.7274 - acc: 0.5199
2176/9333 [=====>........................] - ETA: 11:33 - loss: 0.7269 - acc: 0.5216
2240/9333 [======>.......................] - ETA: 11:26 - loss: 0.7264 - acc: 0.5210
2304/9333 [======>.......................] - ETA: 11:19 - loss: 0.7257 - acc: 0.5213
2368/9333 [======>.......................] - ETA: 11:10 - loss: 0.7255 - acc: 0.5215
2432/9333 [======>.......................] - ETA: 11:01 - loss: 0.7261 - acc: 0.5193
2496/9333 [=======>......................] - ETA: 10:52 - loss: 0.7269 - acc: 0.5172
2560/9333 [=======>......................] - ETA: 10:44 - loss: 0.7264 - acc: 0.5180
2624/9333 [=======>......................] - ETA: 10:37 - loss: 0.7263 - acc: 0.5171
2688/9333 [=======>......................] - ETA: 10:29 - loss: 0.7256 - acc: 0.5171
2752/9333 [=======>......................] - ETA: 10:23 - loss: 0.7248 - acc: 0.5189
2816/9333 [========>.....................] - ETA: 10:16 - loss: 0.7242 - acc: 0.5192
2880/9333 [========>.....................] - ETA: 10:08 - loss: 0.7243 - acc: 0.5181
2944/9333 [========>.....................] - ETA: 10:00 - loss: 0.7245 - acc: 0.5194
3008/9333 [========>.....................] - ETA: 9:53 - loss: 0.7238 - acc: 0.5199 
3072/9333 [========>.....................] - ETA: 9:45 - loss: 0.7243 - acc: 0.5195
3136/9333 [=========>....................] - ETA: 9:38 - loss: 0.7246 - acc: 0.5182
3200/9333 [=========>....................] - ETA: 9:31 - loss: 0.7238 - acc: 0.5188
3264/9333 [=========>....................] - ETA: 9:23 - loss: 0.7239 - acc: 0.5165
3328/9333 [=========>....................] - ETA: 9:16 - loss: 0.7235 - acc: 0.5180
3392/9333 [=========>....................] - ETA: 9:09 - loss: 0.7230 - acc: 0.5186
3456/9333 [==========>...................] - ETA: 9:02 - loss: 0.7226 - acc: 0.5182
3520/9333 [==========>...................] - ETA: 8:56 - loss: 0.7225 - acc: 0.5179
3584/9333 [==========>...................] - ETA: 8:48 - loss: 0.7233 - acc: 0.5165
3648/9333 [==========>...................] - ETA: 8:42 - loss: 0.7228 - acc: 0.5167
3712/9333 [==========>...................] - ETA: 8:35 - loss: 0.7226 - acc: 0.5162
3776/9333 [===========>..................] - ETA: 8:28 - loss: 0.7223 - acc: 0.5167
3840/9333 [===========>..................] - ETA: 8:23 - loss: 0.7212 - acc: 0.5185
3904/9333 [===========>..................] - ETA: 8:16 - loss: 0.7210 - acc: 0.5187
3968/9333 [===========>..................] - ETA: 8:09 - loss: 0.7204 - acc: 0.5179
4032/9333 [===========>..................] - ETA: 8:03 - loss: 0.7205 - acc: 0.5179
4096/9333 [============>.................] - ETA: 7:56 - loss: 0.7201 - acc: 0.5181
4160/9333 [============>.................] - ETA: 7:50 - loss: 0.7198 - acc: 0.5190
4224/9333 [============>.................] - ETA: 7:43 - loss: 0.7196 - acc: 0.5189
4288/9333 [============>.................] - ETA: 7:37 - loss: 0.7201 - acc: 0.5184
4352/9333 [============>.................] - ETA: 7:31 - loss: 0.7207 - acc: 0.5177
4416/9333 [=============>................] - ETA: 7:25 - loss: 0.7202 - acc: 0.5172
4480/9333 [=============>................] - ETA: 7:18 - loss: 0.7202 - acc: 0.5170
4544/9333 [=============>................] - ETA: 7:12 - loss: 0.7206 - acc: 0.5163
4608/9333 [=============>................] - ETA: 7:06 - loss: 0.7198 - acc: 0.5169
4672/9333 [==============>...............] - ETA: 7:00 - loss: 0.7196 - acc: 0.5178
4736/9333 [==============>...............] - ETA: 6:54 - loss: 0.7195 - acc: 0.5169
4800/9333 [==============>...............] - ETA: 6:47 - loss: 0.7191 - acc: 0.5167
4864/9333 [==============>...............] - ETA: 6:41 - loss: 0.7189 - acc: 0.5183
4928/9333 [==============>...............] - ETA: 6:35 - loss: 0.7191 - acc: 0.5177
4992/9333 [===============>..............] - ETA: 6:29 - loss: 0.7191 - acc: 0.5178
5056/9333 [===============>..............] - ETA: 6:23 - loss: 0.7192 - acc: 0.5174
5120/9333 [===============>..............] - ETA: 6:17 - loss: 0.7190 - acc: 0.5186
5184/9333 [===============>..............] - ETA: 6:11 - loss: 0.7188 - acc: 0.5187
5248/9333 [===============>..............] - ETA: 6:05 - loss: 0.7183 - acc: 0.5198
5312/9333 [================>.............] - ETA: 5:59 - loss: 0.7181 - acc: 0.5198
5376/9333 [================>.............] - ETA: 5:52 - loss: 0.7176 - acc: 0.5210
5440/9333 [================>.............] - ETA: 5:46 - loss: 0.7181 - acc: 0.5199
5504/9333 [================>.............] - ETA: 5:40 - loss: 0.7183 - acc: 0.5193
5568/9333 [================>.............] - ETA: 5:34 - loss: 0.7180 - acc: 0.5199
5632/9333 [=================>............] - ETA: 5:28 - loss: 0.7177 - acc: 0.5199
5696/9333 [=================>............] - ETA: 5:22 - loss: 0.7175 - acc: 0.5204
5760/9333 [=================>............] - ETA: 5:17 - loss: 0.7175 - acc: 0.5203
5824/9333 [=================>............] - ETA: 5:11 - loss: 0.7171 - acc: 0.5209
5888/9333 [=================>............] - ETA: 5:05 - loss: 0.7171 - acc: 0.5214
5952/9333 [==================>...........] - ETA: 4:59 - loss: 0.7180 - acc: 0.5198
6016/9333 [==================>...........] - ETA: 4:53 - loss: 0.7176 - acc: 0.5203
6080/9333 [==================>...........] - ETA: 4:47 - loss: 0.7174 - acc: 0.5202
6144/9333 [==================>...........] - ETA: 4:42 - loss: 0.7172 - acc: 0.5207
6208/9333 [==================>...........] - ETA: 4:36 - loss: 0.7172 - acc: 0.5206
6272/9333 [===================>..........] - ETA: 4:30 - loss: 0.7169 - acc: 0.5201
6336/9333 [===================>..........] - ETA: 4:25 - loss: 0.7171 - acc: 0.5197
6400/9333 [===================>..........] - ETA: 4:19 - loss: 0.7169 - acc: 0.5197
6464/9333 [===================>..........] - ETA: 4:13 - loss: 0.7168 - acc: 0.5189
6528/9333 [===================>..........] - ETA: 4:07 - loss: 0.7172 - acc: 0.5175
6592/9333 [====================>.........] - ETA: 4:01 - loss: 0.7171 - acc: 0.5170
6656/9333 [====================>.........] - ETA: 3:56 - loss: 0.7171 - acc: 0.5170
6720/9333 [====================>.........] - ETA: 3:50 - loss: 0.7168 - acc: 0.5167
6784/9333 [====================>.........] - ETA: 3:44 - loss: 0.7164 - acc: 0.5174
6848/9333 [=====================>........] - ETA: 3:38 - loss: 0.7163 - acc: 0.5175
6912/9333 [=====================>........] - ETA: 3:33 - loss: 0.7163 - acc: 0.5172
6976/9333 [=====================>........] - ETA: 3:27 - loss: 0.7160 - acc: 0.5175
7040/9333 [=====================>........] - ETA: 3:21 - loss: 0.7156 - acc: 0.5186
7104/9333 [=====================>........] - ETA: 3:16 - loss: 0.7153 - acc: 0.5189
7168/9333 [======================>.......] - ETA: 3:10 - loss: 0.7151 - acc: 0.5180
7232/9333 [======================>.......] - ETA: 3:04 - loss: 0.7149 - acc: 0.5187
7296/9333 [======================>.......] - ETA: 2:59 - loss: 0.7149 - acc: 0.5189
7360/9333 [======================>.......] - ETA: 2:53 - loss: 0.7146 - acc: 0.5197
7424/9333 [======================>.......] - ETA: 2:47 - loss: 0.7149 - acc: 0.5190
7488/9333 [=======================>......] - ETA: 2:42 - loss: 0.7148 - acc: 0.5191
7552/9333 [=======================>......] - ETA: 2:36 - loss: 0.7146 - acc: 0.5188
7616/9333 [=======================>......] - ETA: 2:30 - loss: 0.7146 - acc: 0.5188
7680/9333 [=======================>......] - ETA: 2:25 - loss: 0.7142 - acc: 0.5198
7744/9333 [=======================>......] - ETA: 2:19 - loss: 0.7143 - acc: 0.5191
7808/9333 [========================>.....] - ETA: 2:13 - loss: 0.7140 - acc: 0.5191
7872/9333 [========================>.....] - ETA: 2:08 - loss: 0.7140 - acc: 0.5191
7936/9333 [========================>.....] - ETA: 2:02 - loss: 0.7139 - acc: 0.5186
8000/9333 [========================>.....] - ETA: 1:56 - loss: 0.7139 - acc: 0.5190
8064/9333 [========================>.....] - ETA: 1:51 - loss: 0.7140 - acc: 0.5184
8128/9333 [=========================>....] - ETA: 1:45 - loss: 0.7137 - acc: 0.5181
8192/9333 [=========================>....] - ETA: 1:39 - loss: 0.7136 - acc: 0.5190
8256/9333 [=========================>....] - ETA: 1:34 - loss: 0.7134 - acc: 0.5195
8320/9333 [=========================>....] - ETA: 1:28 - loss: 0.7133 - acc: 0.5200
8384/9333 [=========================>....] - ETA: 1:23 - loss: 0.7128 - acc: 0.5200
8448/9333 [==========================>...] - ETA: 1:17 - loss: 0.7127 - acc: 0.5199
8512/9333 [==========================>...] - ETA: 1:11 - loss: 0.7124 - acc: 0.5206
8576/9333 [==========================>...] - ETA: 1:06 - loss: 0.7124 - acc: 0.5205
8640/9333 [==========================>...] - ETA: 1:00 - loss: 0.7123 - acc: 0.5201
8704/9333 [==========================>...] - ETA: 54s - loss: 0.7122 - acc: 0.5201 
8768/9333 [===========================>..] - ETA: 49s - loss: 0.7123 - acc: 0.5201
8832/9333 [===========================>..] - ETA: 43s - loss: 0.7124 - acc: 0.5197
8896/9333 [===========================>..] - ETA: 38s - loss: 0.7122 - acc: 0.5198
8960/9333 [===========================>..] - ETA: 32s - loss: 0.7123 - acc: 0.5194
9024/9333 [============================>.] - ETA: 26s - loss: 0.7121 - acc: 0.5194
9088/9333 [============================>.] - ETA: 21s - loss: 0.7119 - acc: 0.5197
9152/9333 [============================>.] - ETA: 15s - loss: 0.7119 - acc: 0.5199
9216/9333 [============================>.] - ETA: 10s - loss: 0.7116 - acc: 0.5201
9280/9333 [============================>.] - ETA: 4s - loss: 0.7117 - acc: 0.5191 
9333/9333 [==============================] - 846s 91ms/step - loss: 0.7115 - acc: 0.5194 - val_loss: 0.6913 - val_acc: 0.5265

Epoch 00001: val_acc improved from -inf to 0.52652, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window05/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 14:41 - loss: 0.7061 - acc: 0.5000
 128/9333 [..............................] - ETA: 13:33 - loss: 0.7134 - acc: 0.4922
 192/9333 [..............................] - ETA: 13:17 - loss: 0.7021 - acc: 0.5312
 256/9333 [..............................] - ETA: 13:17 - loss: 0.7006 - acc: 0.5234
 320/9333 [>.............................] - ETA: 12:52 - loss: 0.6995 - acc: 0.5281
 384/9333 [>.............................] - ETA: 13:00 - loss: 0.7076 - acc: 0.4974
 448/9333 [>.............................] - ETA: 12:48 - loss: 0.7050 - acc: 0.5089
 512/9333 [>.............................] - ETA: 12:35 - loss: 0.7035 - acc: 0.5098
 576/9333 [>.............................] - ETA: 12:25 - loss: 0.6994 - acc: 0.5191
 640/9333 [=>............................] - ETA: 12:17 - loss: 0.7021 - acc: 0.5078
 704/9333 [=>............................] - ETA: 12:13 - loss: 0.6976 - acc: 0.5185
 768/9333 [=>............................] - ETA: 12:10 - loss: 0.6954 - acc: 0.5208
 832/9333 [=>............................] - ETA: 12:09 - loss: 0.6955 - acc: 0.5204
 896/9333 [=>............................] - ETA: 12:04 - loss: 0.6945 - acc: 0.5234
 960/9333 [==>...........................] - ETA: 11:55 - loss: 0.6958 - acc: 0.5229
1024/9333 [==>...........................] - ETA: 11:51 - loss: 0.6953 - acc: 0.5215
1088/9333 [==>...........................] - ETA: 11:49 - loss: 0.6943 - acc: 0.5276
1152/9333 [==>...........................] - ETA: 11:44 - loss: 0.6936 - acc: 0.5278
1216/9333 [==>...........................] - ETA: 11:39 - loss: 0.6947 - acc: 0.5247
1280/9333 [===>..........................] - ETA: 11:33 - loss: 0.6948 - acc: 0.5219
1344/9333 [===>..........................] - ETA: 11:26 - loss: 0.6935 - acc: 0.5253
1408/9333 [===>..........................] - ETA: 11:22 - loss: 0.6950 - acc: 0.5213
1472/9333 [===>..........................] - ETA: 11:14 - loss: 0.6959 - acc: 0.5204
1536/9333 [===>..........................] - ETA: 11:09 - loss: 0.6962 - acc: 0.5202
1600/9333 [====>.........................] - ETA: 11:02 - loss: 0.6973 - acc: 0.5156
1664/9333 [====>.........................] - ETA: 10:53 - loss: 0.6972 - acc: 0.5180
1728/9333 [====>.........................] - ETA: 10:47 - loss: 0.6968 - acc: 0.5203
1792/9333 [====>.........................] - ETA: 10:44 - loss: 0.6959 - acc: 0.5218
1856/9333 [====>.........................] - ETA: 10:37 - loss: 0.6963 - acc: 0.5199
1920/9333 [=====>........................] - ETA: 10:33 - loss: 0.6958 - acc: 0.5208
1984/9333 [=====>........................] - ETA: 10:28 - loss: 0.6960 - acc: 0.5217
2048/9333 [=====>........................] - ETA: 10:23 - loss: 0.6956 - acc: 0.5220
2112/9333 [=====>........................] - ETA: 10:16 - loss: 0.6953 - acc: 0.5241
2176/9333 [=====>........................] - ETA: 10:10 - loss: 0.6952 - acc: 0.5262
2240/9333 [======>.......................] - ETA: 10:05 - loss: 0.6952 - acc: 0.5268
2304/9333 [======>.......................] - ETA: 9:58 - loss: 0.6958 - acc: 0.5239 
2368/9333 [======>.......................] - ETA: 9:52 - loss: 0.6953 - acc: 0.5249
2432/9333 [======>.......................] - ETA: 9:46 - loss: 0.6960 - acc: 0.5230
2496/9333 [=======>......................] - ETA: 9:40 - loss: 0.6954 - acc: 0.5248
2560/9333 [=======>......................] - ETA: 9:35 - loss: 0.6962 - acc: 0.5227
2624/9333 [=======>......................] - ETA: 9:31 - loss: 0.6960 - acc: 0.5236
2688/9333 [=======>......................] - ETA: 9:24 - loss: 0.6961 - acc: 0.5234
2752/9333 [=======>......................] - ETA: 9:18 - loss: 0.6965 - acc: 0.5236
2816/9333 [========>.....................] - ETA: 9:13 - loss: 0.6971 - acc: 0.5227
2880/9333 [========>.....................] - ETA: 9:07 - loss: 0.6979 - acc: 0.5201
2944/9333 [========>.....................] - ETA: 9:01 - loss: 0.6978 - acc: 0.5207
3008/9333 [========>.....................] - ETA: 8:55 - loss: 0.6980 - acc: 0.5206
3072/9333 [========>.....................] - ETA: 8:51 - loss: 0.6982 - acc: 0.5202
3136/9333 [=========>....................] - ETA: 8:44 - loss: 0.6983 - acc: 0.5207
3200/9333 [=========>....................] - ETA: 8:38 - loss: 0.6983 - acc: 0.5209
3264/9333 [=========>....................] - ETA: 8:32 - loss: 0.6988 - acc: 0.5196
3328/9333 [=========>....................] - ETA: 8:27 - loss: 0.6994 - acc: 0.5174
3392/9333 [=========>....................] - ETA: 8:21 - loss: 0.6994 - acc: 0.5174
3456/9333 [==========>...................] - ETA: 8:16 - loss: 0.6982 - acc: 0.5188
3520/9333 [==========>...................] - ETA: 8:09 - loss: 0.6989 - acc: 0.5168
3584/9333 [==========>...................] - ETA: 8:05 - loss: 0.6988 - acc: 0.5170
3648/9333 [==========>...................] - ETA: 8:01 - loss: 0.6992 - acc: 0.5154
3712/9333 [==========>...................] - ETA: 7:56 - loss: 0.6988 - acc: 0.5148
3776/9333 [===========>..................] - ETA: 7:49 - loss: 0.6986 - acc: 0.5154
3840/9333 [===========>..................] - ETA: 7:44 - loss: 0.6985 - acc: 0.5154
3904/9333 [===========>..................] - ETA: 7:39 - loss: 0.6984 - acc: 0.5154
3968/9333 [===========>..................] - ETA: 7:33 - loss: 0.6979 - acc: 0.5171
4032/9333 [===========>..................] - ETA: 7:29 - loss: 0.6976 - acc: 0.5176
4096/9333 [============>.................] - ETA: 7:23 - loss: 0.6981 - acc: 0.5166
4160/9333 [============>.................] - ETA: 7:18 - loss: 0.6984 - acc: 0.5166
4224/9333 [============>.................] - ETA: 7:12 - loss: 0.6985 - acc: 0.5159
4288/9333 [============>.................] - ETA: 7:07 - loss: 0.6991 - acc: 0.5138
4352/9333 [============>.................] - ETA: 7:01 - loss: 0.6988 - acc: 0.5147
4416/9333 [=============>................] - ETA: 6:56 - loss: 0.6990 - acc: 0.5152
4480/9333 [=============>................] - ETA: 6:50 - loss: 0.6990 - acc: 0.5150
4544/9333 [=============>................] - ETA: 6:44 - loss: 0.6992 - acc: 0.5143
4608/9333 [=============>................] - ETA: 6:39 - loss: 0.6988 - acc: 0.5152
4672/9333 [==============>...............] - ETA: 6:33 - loss: 0.6985 - acc: 0.5165
4736/9333 [==============>...............] - ETA: 6:27 - loss: 0.6983 - acc: 0.5167
4800/9333 [==============>...............] - ETA: 6:23 - loss: 0.6987 - acc: 0.5160
4864/9333 [==============>...............] - ETA: 6:17 - loss: 0.6985 - acc: 0.5167
4928/9333 [==============>...............] - ETA: 6:11 - loss: 0.6985 - acc: 0.5166
4992/9333 [===============>..............] - ETA: 6:05 - loss: 0.6986 - acc: 0.5162
5056/9333 [===============>..............] - ETA: 6:00 - loss: 0.6988 - acc: 0.5154
5120/9333 [===============>..............] - ETA: 5:55 - loss: 0.6987 - acc: 0.5160
5184/9333 [===============>..............] - ETA: 5:50 - loss: 0.6992 - acc: 0.5137
5248/9333 [===============>..............] - ETA: 5:44 - loss: 0.6993 - acc: 0.5128
5312/9333 [================>.............] - ETA: 5:38 - loss: 0.6993 - acc: 0.5124
5376/9333 [================>.............] - ETA: 5:33 - loss: 0.6995 - acc: 0.5106
5440/9333 [================>.............] - ETA: 5:28 - loss: 0.6994 - acc: 0.5105
5504/9333 [================>.............] - ETA: 5:22 - loss: 0.6994 - acc: 0.5105
5568/9333 [================>.............] - ETA: 5:17 - loss: 0.6993 - acc: 0.5097
5632/9333 [=================>............] - ETA: 5:11 - loss: 0.6993 - acc: 0.5096
5696/9333 [=================>............] - ETA: 5:05 - loss: 0.6992 - acc: 0.5104
5760/9333 [=================>............] - ETA: 5:00 - loss: 0.6992 - acc: 0.5101
5824/9333 [=================>............] - ETA: 4:54 - loss: 0.6991 - acc: 0.5101
5888/9333 [=================>............] - ETA: 4:48 - loss: 0.6992 - acc: 0.5095
5952/9333 [==================>...........] - ETA: 4:43 - loss: 0.6995 - acc: 0.5087
6016/9333 [==================>...........] - ETA: 4:38 - loss: 0.6994 - acc: 0.5095
6080/9333 [==================>...........] - ETA: 4:32 - loss: 0.6995 - acc: 0.5092
6144/9333 [==================>...........] - ETA: 4:27 - loss: 0.6997 - acc: 0.5085
6208/9333 [==================>...........] - ETA: 4:21 - loss: 0.6995 - acc: 0.5092
6272/9333 [===================>..........] - ETA: 4:16 - loss: 0.6992 - acc: 0.5102
6336/9333 [===================>..........] - ETA: 4:11 - loss: 0.6992 - acc: 0.5106
6400/9333 [===================>..........] - ETA: 4:05 - loss: 0.6990 - acc: 0.5112
6464/9333 [===================>..........] - ETA: 4:00 - loss: 0.6988 - acc: 0.5121
6528/9333 [===================>..........] - ETA: 3:54 - loss: 0.6988 - acc: 0.5126
6592/9333 [====================>.........] - ETA: 3:49 - loss: 0.6990 - acc: 0.5123
6656/9333 [====================>.........] - ETA: 3:44 - loss: 0.6989 - acc: 0.5128
6720/9333 [====================>.........] - ETA: 3:38 - loss: 0.6988 - acc: 0.5132
6784/9333 [====================>.........] - ETA: 3:33 - loss: 0.6988 - acc: 0.5131
6848/9333 [=====================>........] - ETA: 3:27 - loss: 0.6985 - acc: 0.5131
6912/9333 [=====================>........] - ETA: 3:21 - loss: 0.6982 - acc: 0.5140
6976/9333 [=====================>........] - ETA: 3:16 - loss: 0.6981 - acc: 0.5142
7040/9333 [=====================>........] - ETA: 3:10 - loss: 0.6981 - acc: 0.5142
7104/9333 [=====================>........] - ETA: 3:05 - loss: 0.6982 - acc: 0.5139
7168/9333 [======================>.......] - ETA: 3:00 - loss: 0.6983 - acc: 0.5140
7232/9333 [======================>.......] - ETA: 2:54 - loss: 0.6983 - acc: 0.5137
7296/9333 [======================>.......] - ETA: 2:49 - loss: 0.6982 - acc: 0.5144
7360/9333 [======================>.......] - ETA: 2:43 - loss: 0.6981 - acc: 0.5149
7424/9333 [======================>.......] - ETA: 2:37 - loss: 0.6980 - acc: 0.5151
7488/9333 [=======================>......] - ETA: 2:32 - loss: 0.6981 - acc: 0.5152
7552/9333 [=======================>......] - ETA: 2:27 - loss: 0.6980 - acc: 0.5158
7616/9333 [=======================>......] - ETA: 2:21 - loss: 0.6984 - acc: 0.5151
7680/9333 [=======================>......] - ETA: 2:16 - loss: 0.6982 - acc: 0.5158
7744/9333 [=======================>......] - ETA: 2:11 - loss: 0.6983 - acc: 0.5147
7808/9333 [========================>.....] - ETA: 2:05 - loss: 0.6983 - acc: 0.5150
7872/9333 [========================>.....] - ETA: 2:00 - loss: 0.6982 - acc: 0.5152
7936/9333 [========================>.....] - ETA: 1:54 - loss: 0.6982 - acc: 0.5151
8000/9333 [========================>.....] - ETA: 1:49 - loss: 0.6983 - acc: 0.5145
8064/9333 [========================>.....] - ETA: 1:44 - loss: 0.6984 - acc: 0.5150
8128/9333 [=========================>....] - ETA: 1:39 - loss: 0.6983 - acc: 0.5155
8192/9333 [=========================>....] - ETA: 1:33 - loss: 0.6984 - acc: 0.5151
8256/9333 [=========================>....] - ETA: 1:28 - loss: 0.6983 - acc: 0.5157
8320/9333 [=========================>....] - ETA: 1:23 - loss: 0.6982 - acc: 0.5160
8384/9333 [=========================>....] - ETA: 1:17 - loss: 0.6984 - acc: 0.5154
8448/9333 [==========================>...] - ETA: 1:12 - loss: 0.6985 - acc: 0.5154
8512/9333 [==========================>...] - ETA: 1:07 - loss: 0.6983 - acc: 0.5161
8576/9333 [==========================>...] - ETA: 1:02 - loss: 0.6985 - acc: 0.5149
8640/9333 [==========================>...] - ETA: 56s - loss: 0.6984 - acc: 0.5152 
8704/9333 [==========================>...] - ETA: 51s - loss: 0.6983 - acc: 0.5153
8768/9333 [===========================>..] - ETA: 46s - loss: 0.6982 - acc: 0.5151
8832/9333 [===========================>..] - ETA: 40s - loss: 0.6982 - acc: 0.5151
8896/9333 [===========================>..] - ETA: 35s - loss: 0.6982 - acc: 0.5142
8960/9333 [===========================>..] - ETA: 30s - loss: 0.6984 - acc: 0.5137
9024/9333 [============================>.] - ETA: 25s - loss: 0.6982 - acc: 0.5141
9088/9333 [============================>.] - ETA: 20s - loss: 0.6983 - acc: 0.5140
9152/9333 [============================>.] - ETA: 14s - loss: 0.6981 - acc: 0.5148
9216/9333 [============================>.] - ETA: 9s - loss: 0.6982 - acc: 0.5148 
9280/9333 [============================>.] - ETA: 4s - loss: 0.6982 - acc: 0.5147
9333/9333 [==============================] - 788s 84ms/step - loss: 0.6982 - acc: 0.5143 - val_loss: 0.6884 - val_acc: 0.5429

Epoch 00002: val_acc improved from 0.52652 to 0.54291, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window05/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 3/10

  64/9333 [..............................] - ETA: 11:23 - loss: 0.6920 - acc: 0.5156
 128/9333 [..............................] - ETA: 11:08 - loss: 0.6884 - acc: 0.5234
 192/9333 [..............................] - ETA: 10:44 - loss: 0.6867 - acc: 0.5052
 256/9333 [..............................] - ETA: 10:56 - loss: 0.6888 - acc: 0.5156
 320/9333 [>.............................] - ETA: 10:48 - loss: 0.6913 - acc: 0.5094
 384/9333 [>.............................] - ETA: 10:35 - loss: 0.6944 - acc: 0.5052
 448/9333 [>.............................] - ETA: 10:42 - loss: 0.6946 - acc: 0.5045
 512/9333 [>.............................] - ETA: 10:33 - loss: 0.6961 - acc: 0.4980
 576/9333 [>.............................] - ETA: 10:36 - loss: 0.6981 - acc: 0.4913
 640/9333 [=>............................] - ETA: 10:32 - loss: 0.7002 - acc: 0.4891
 704/9333 [=>............................] - ETA: 10:27 - loss: 0.7003 - acc: 0.4872
 768/9333 [=>............................] - ETA: 10:15 - loss: 0.6993 - acc: 0.4909
 832/9333 [=>............................] - ETA: 10:15 - loss: 0.6975 - acc: 0.4952
 896/9333 [=>............................] - ETA: 10:15 - loss: 0.6984 - acc: 0.4955
 960/9333 [==>...........................] - ETA: 10:05 - loss: 0.6983 - acc: 0.4979
1024/9333 [==>...........................] - ETA: 10:02 - loss: 0.6979 - acc: 0.5000
1088/9333 [==>...........................] - ETA: 9:58 - loss: 0.6983 - acc: 0.5009 
1152/9333 [==>...........................] - ETA: 9:55 - loss: 0.6985 - acc: 0.5000
1216/9333 [==>...........................] - ETA: 9:49 - loss: 0.6992 - acc: 0.4959
1280/9333 [===>..........................] - ETA: 9:46 - loss: 0.6984 - acc: 0.4969
1344/9333 [===>..........................] - ETA: 9:38 - loss: 0.6981 - acc: 0.4993
1408/9333 [===>..........................] - ETA: 9:32 - loss: 0.6984 - acc: 0.4979
1472/9333 [===>..........................] - ETA: 9:32 - loss: 0.6977 - acc: 0.5041
1536/9333 [===>..........................] - ETA: 9:29 - loss: 0.6985 - acc: 0.4987
1600/9333 [====>.........................] - ETA: 9:25 - loss: 0.6989 - acc: 0.4981
1664/9333 [====>.........................] - ETA: 9:18 - loss: 0.6994 - acc: 0.4964
1728/9333 [====>.........................] - ETA: 9:16 - loss: 0.6990 - acc: 0.5000
1792/9333 [====>.........................] - ETA: 9:10 - loss: 0.6993 - acc: 0.4989
1856/9333 [====>.........................] - ETA: 9:04 - loss: 0.6994 - acc: 0.4978
1920/9333 [=====>........................] - ETA: 8:59 - loss: 0.6985 - acc: 0.5005
1984/9333 [=====>........................] - ETA: 8:52 - loss: 0.6987 - acc: 0.4995
2048/9333 [=====>........................] - ETA: 8:49 - loss: 0.6994 - acc: 0.4980
2112/9333 [=====>........................] - ETA: 8:46 - loss: 0.6993 - acc: 0.5000
2176/9333 [=====>........................] - ETA: 8:39 - loss: 0.6993 - acc: 0.4982
2240/9333 [======>.......................] - ETA: 8:34 - loss: 0.6989 - acc: 0.5000
2304/9333 [======>.......................] - ETA: 8:31 - loss: 0.6987 - acc: 0.5000
2368/9333 [======>.......................] - ETA: 8:26 - loss: 0.6989 - acc: 0.5004
2432/9333 [======>.......................] - ETA: 8:20 - loss: 0.6985 - acc: 0.5037
2496/9333 [=======>......................] - ETA: 8:17 - loss: 0.6982 - acc: 0.5056
2560/9333 [=======>......................] - ETA: 8:12 - loss: 0.6978 - acc: 0.5059
2624/9333 [=======>......................] - ETA: 8:07 - loss: 0.6972 - acc: 0.5084
2688/9333 [=======>......................] - ETA: 8:03 - loss: 0.6969 - acc: 0.5104
2752/9333 [=======>......................] - ETA: 7:58 - loss: 0.6971 - acc: 0.5080
2816/9333 [========>.....................] - ETA: 7:54 - loss: 0.6974 - acc: 0.5064
2880/9333 [========>.....................] - ETA: 7:51 - loss: 0.6970 - acc: 0.5066
2944/9333 [========>.....................] - ETA: 7:48 - loss: 0.6970 - acc: 0.5078
3008/9333 [========>.....................] - ETA: 7:44 - loss: 0.6970 - acc: 0.5083
3072/9333 [========>.....................] - ETA: 7:40 - loss: 0.6963 - acc: 0.5120
3136/9333 [=========>....................] - ETA: 7:36 - loss: 0.6959 - acc: 0.5137
3200/9333 [=========>....................] - ETA: 7:31 - loss: 0.6957 - acc: 0.5138
3264/9333 [=========>....................] - ETA: 7:26 - loss: 0.6963 - acc: 0.5116
3328/9333 [=========>....................] - ETA: 7:19 - loss: 0.6960 - acc: 0.5123
3392/9333 [=========>....................] - ETA: 7:12 - loss: 0.6958 - acc: 0.5133
3456/9333 [==========>...................] - ETA: 7:04 - loss: 0.6958 - acc: 0.5130
3520/9333 [==========>...................] - ETA: 6:57 - loss: 0.6955 - acc: 0.5139
3584/9333 [==========>...................] - ETA: 6:50 - loss: 0.6952 - acc: 0.5153
3648/9333 [==========>...................] - ETA: 6:44 - loss: 0.6958 - acc: 0.5134
3712/9333 [==========>...................] - ETA: 6:37 - loss: 0.6959 - acc: 0.5137
3776/9333 [===========>..................] - ETA: 6:30 - loss: 0.6961 - acc: 0.5132
3840/9333 [===========>..................] - ETA: 6:24 - loss: 0.6957 - acc: 0.5141
3904/9333 [===========>..................] - ETA: 6:17 - loss: 0.6960 - acc: 0.5131
3968/9333 [===========>..................] - ETA: 6:11 - loss: 0.6959 - acc: 0.5129
4032/9333 [===========>..................] - ETA: 6:05 - loss: 0.6961 - acc: 0.5112
4096/9333 [============>.................] - ETA: 5:58 - loss: 0.6960 - acc: 0.5100
4160/9333 [============>.................] - ETA: 5:53 - loss: 0.6960 - acc: 0.5096
4224/9333 [============>.................] - ETA: 5:47 - loss: 0.6956 - acc: 0.5114
4288/9333 [============>.................] - ETA: 5:42 - loss: 0.6956 - acc: 0.5119
4352/9333 [============>.................] - ETA: 5:38 - loss: 0.6956 - acc: 0.5113
4416/9333 [=============>................] - ETA: 5:32 - loss: 0.6959 - acc: 0.5111
4480/9333 [=============>................] - ETA: 5:27 - loss: 0.6956 - acc: 0.5121
4544/9333 [=============>................] - ETA: 5:23 - loss: 0.6958 - acc: 0.5112
4608/9333 [=============>................] - ETA: 5:17 - loss: 0.6956 - acc: 0.5119
4672/9333 [==============>...............] - ETA: 5:13 - loss: 0.6959 - acc: 0.5107
4736/9333 [==============>...............] - ETA: 5:09 - loss: 0.6956 - acc: 0.5118
4800/9333 [==============>...............] - ETA: 5:04 - loss: 0.6954 - acc: 0.5127
4864/9333 [==============>...............] - ETA: 4:59 - loss: 0.6955 - acc: 0.5121
4928/9333 [==============>...............] - ETA: 4:54 - loss: 0.6954 - acc: 0.5118
4992/9333 [===============>..............] - ETA: 4:48 - loss: 0.6954 - acc: 0.5112
5056/9333 [===============>..............] - ETA: 4:43 - loss: 0.6954 - acc: 0.5113
5120/9333 [===============>..............] - ETA: 4:38 - loss: 0.6956 - acc: 0.5104
5184/9333 [===============>..............] - ETA: 4:33 - loss: 0.6959 - acc: 0.5100
5248/9333 [===============>..............] - ETA: 4:29 - loss: 0.6957 - acc: 0.5107
5312/9333 [================>.............] - ETA: 4:24 - loss: 0.6956 - acc: 0.5104
5376/9333 [================>.............] - ETA: 4:19 - loss: 0.6956 - acc: 0.5108
5440/9333 [================>.............] - ETA: 4:15 - loss: 0.6956 - acc: 0.5105
5504/9333 [================>.............] - ETA: 4:10 - loss: 0.6957 - acc: 0.5107
5568/9333 [================>.............] - ETA: 4:06 - loss: 0.6953 - acc: 0.5128
5632/9333 [=================>............] - ETA: 4:01 - loss: 0.6954 - acc: 0.5123
5696/9333 [=================>............] - ETA: 3:56 - loss: 0.6954 - acc: 0.5119
5760/9333 [=================>............] - ETA: 3:52 - loss: 0.6952 - acc: 0.5125
5824/9333 [=================>............] - ETA: 3:47 - loss: 0.6956 - acc: 0.5113
5888/9333 [=================>............] - ETA: 3:43 - loss: 0.6956 - acc: 0.5117
5952/9333 [==================>...........] - ETA: 3:39 - loss: 0.6958 - acc: 0.5114
6016/9333 [==================>...........] - ETA: 3:34 - loss: 0.6956 - acc: 0.5116
6080/9333 [==================>...........] - ETA: 3:30 - loss: 0.6955 - acc: 0.5125
6144/9333 [==================>...........] - ETA: 3:25 - loss: 0.6956 - acc: 0.5125
6208/9333 [==================>...........] - ETA: 3:21 - loss: 0.6959 - acc: 0.5116
6272/9333 [===================>..........] - ETA: 3:17 - loss: 0.6962 - acc: 0.5105
6336/9333 [===================>..........] - ETA: 3:12 - loss: 0.6963 - acc: 0.5104
6400/9333 [===================>..........] - ETA: 3:08 - loss: 0.6962 - acc: 0.5102
6464/9333 [===================>..........] - ETA: 3:04 - loss: 0.6963 - acc: 0.5099
6528/9333 [===================>..........] - ETA: 2:59 - loss: 0.6963 - acc: 0.5098
6592/9333 [====================>.........] - ETA: 2:55 - loss: 0.6964 - acc: 0.5102
6656/9333 [====================>.........] - ETA: 2:51 - loss: 0.6964 - acc: 0.5107
6720/9333 [====================>.........] - ETA: 2:46 - loss: 0.6963 - acc: 0.5112
6784/9333 [====================>.........] - ETA: 2:42 - loss: 0.6964 - acc: 0.5108
6848/9333 [=====================>........] - ETA: 2:38 - loss: 0.6961 - acc: 0.5120
6912/9333 [=====================>........] - ETA: 2:34 - loss: 0.6962 - acc: 0.5122
6976/9333 [=====================>........] - ETA: 2:30 - loss: 0.6959 - acc: 0.5129
7040/9333 [=====================>........] - ETA: 2:26 - loss: 0.6960 - acc: 0.5132
7104/9333 [=====================>........] - ETA: 2:21 - loss: 0.6962 - acc: 0.5130
7168/9333 [======================>.......] - ETA: 2:17 - loss: 0.6961 - acc: 0.5138
7232/9333 [======================>.......] - ETA: 2:13 - loss: 0.6963 - acc: 0.5134
7296/9333 [======================>.......] - ETA: 2:09 - loss: 0.6964 - acc: 0.5130
7360/9333 [======================>.......] - ETA: 2:04 - loss: 0.6966 - acc: 0.5130
7424/9333 [======================>.......] - ETA: 2:00 - loss: 0.6965 - acc: 0.5136
7488/9333 [=======================>......] - ETA: 1:56 - loss: 0.6966 - acc: 0.5132
7552/9333 [=======================>......] - ETA: 1:52 - loss: 0.6966 - acc: 0.5128
7616/9333 [=======================>......] - ETA: 1:48 - loss: 0.6965 - acc: 0.5126
7680/9333 [=======================>......] - ETA: 1:44 - loss: 0.6966 - acc: 0.5122
7744/9333 [=======================>......] - ETA: 1:40 - loss: 0.6966 - acc: 0.5121
7808/9333 [========================>.....] - ETA: 1:35 - loss: 0.6967 - acc: 0.5113
7872/9333 [========================>.....] - ETA: 1:31 - loss: 0.6969 - acc: 0.5104
7936/9333 [========================>.....] - ETA: 1:27 - loss: 0.6971 - acc: 0.5093
8000/9333 [========================>.....] - ETA: 1:23 - loss: 0.6972 - acc: 0.5085
8064/9333 [========================>.....] - ETA: 1:19 - loss: 0.6973 - acc: 0.5083
8128/9333 [=========================>....] - ETA: 1:15 - loss: 0.6972 - acc: 0.5084
8192/9333 [=========================>....] - ETA: 1:11 - loss: 0.6972 - acc: 0.5085
8256/9333 [=========================>....] - ETA: 1:07 - loss: 0.6973 - acc: 0.5082
8320/9333 [=========================>....] - ETA: 1:03 - loss: 0.6971 - acc: 0.5090
8384/9333 [=========================>....] - ETA: 59s - loss: 0.6970 - acc: 0.5095 
8448/9333 [==========================>...] - ETA: 54s - loss: 0.6970 - acc: 0.5095
8512/9333 [==========================>...] - ETA: 51s - loss: 0.6970 - acc: 0.5094
8576/9333 [==========================>...] - ETA: 47s - loss: 0.6970 - acc: 0.5092
8640/9333 [==========================>...] - ETA: 42s - loss: 0.6970 - acc: 0.5091
8704/9333 [==========================>...] - ETA: 38s - loss: 0.6970 - acc: 0.5094
8768/9333 [===========================>..] - ETA: 35s - loss: 0.6971 - acc: 0.5084
8832/9333 [===========================>..] - ETA: 31s - loss: 0.6970 - acc: 0.5093
8896/9333 [===========================>..] - ETA: 27s - loss: 0.6969 - acc: 0.5092
8960/9333 [===========================>..] - ETA: 23s - loss: 0.6968 - acc: 0.5097
9024/9333 [============================>.] - ETA: 19s - loss: 0.6969 - acc: 0.5093
9088/9333 [============================>.] - ETA: 15s - loss: 0.6968 - acc: 0.5094
9152/9333 [============================>.] - ETA: 11s - loss: 0.6967 - acc: 0.5104
9216/9333 [============================>.] - ETA: 7s - loss: 0.6969 - acc: 0.5094 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6969 - acc: 0.5094
9333/9333 [==============================] - 601s 64ms/step - loss: 0.6968 - acc: 0.5098 - val_loss: 0.6888 - val_acc: 0.5448

Epoch 00003: val_acc improved from 0.54291 to 0.54484, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window05/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 4/10

  64/9333 [..............................] - ETA: 8:13 - loss: 0.6940 - acc: 0.4844
 128/9333 [..............................] - ETA: 8:33 - loss: 0.6894 - acc: 0.5234
 192/9333 [..............................] - ETA: 8:13 - loss: 0.6916 - acc: 0.5260
 256/9333 [..............................] - ETA: 8:05 - loss: 0.6920 - acc: 0.5234
 320/9333 [>.............................] - ETA: 8:15 - loss: 0.6914 - acc: 0.5219
 384/9333 [>.............................] - ETA: 8:29 - loss: 0.6891 - acc: 0.5286
 448/9333 [>.............................] - ETA: 8:31 - loss: 0.6883 - acc: 0.5335
 512/9333 [>.............................] - ETA: 8:28 - loss: 0.6882 - acc: 0.5352
 576/9333 [>.............................] - ETA: 8:19 - loss: 0.6877 - acc: 0.5382
 640/9333 [=>............................] - ETA: 8:18 - loss: 0.6885 - acc: 0.5375
 704/9333 [=>............................] - ETA: 8:10 - loss: 0.6873 - acc: 0.5426
 768/9333 [=>............................] - ETA: 8:06 - loss: 0.6877 - acc: 0.5404
 832/9333 [=>............................] - ETA: 8:00 - loss: 0.6875 - acc: 0.5433
 896/9333 [=>............................] - ETA: 7:57 - loss: 0.6885 - acc: 0.5357
 960/9333 [==>...........................] - ETA: 7:56 - loss: 0.6884 - acc: 0.5354
1024/9333 [==>...........................] - ETA: 7:52 - loss: 0.6869 - acc: 0.5410
1088/9333 [==>...........................] - ETA: 7:50 - loss: 0.6885 - acc: 0.5377
1152/9333 [==>...........................] - ETA: 7:47 - loss: 0.6908 - acc: 0.5347
1216/9333 [==>...........................] - ETA: 7:44 - loss: 0.6909 - acc: 0.5329
1280/9333 [===>..........................] - ETA: 7:40 - loss: 0.6924 - acc: 0.5297
1344/9333 [===>..........................] - ETA: 7:38 - loss: 0.6915 - acc: 0.5335
1408/9333 [===>..........................] - ETA: 7:36 - loss: 0.6904 - acc: 0.5348
1472/9333 [===>..........................] - ETA: 7:33 - loss: 0.6898 - acc: 0.5353
1536/9333 [===>..........................] - ETA: 7:30 - loss: 0.6904 - acc: 0.5326
1600/9333 [====>.........................] - ETA: 7:28 - loss: 0.6910 - acc: 0.5294
1664/9333 [====>.........................] - ETA: 7:23 - loss: 0.6906 - acc: 0.5331
1728/9333 [====>.........................] - ETA: 7:19 - loss: 0.6912 - acc: 0.5312
1792/9333 [====>.........................] - ETA: 7:14 - loss: 0.6916 - acc: 0.5312
1856/9333 [====>.........................] - ETA: 7:12 - loss: 0.6912 - acc: 0.5323
1920/9333 [=====>........................] - ETA: 7:09 - loss: 0.6901 - acc: 0.5380
1984/9333 [=====>........................] - ETA: 7:03 - loss: 0.6899 - acc: 0.5373
2048/9333 [=====>........................] - ETA: 6:58 - loss: 0.6899 - acc: 0.5371
2112/9333 [=====>........................] - ETA: 6:56 - loss: 0.6892 - acc: 0.5407
2176/9333 [=====>........................] - ETA: 6:52 - loss: 0.6889 - acc: 0.5404
2240/9333 [======>.......................] - ETA: 6:49 - loss: 0.6885 - acc: 0.5429
2304/9333 [======>.......................] - ETA: 6:45 - loss: 0.6880 - acc: 0.5456
2368/9333 [======>.......................] - ETA: 6:41 - loss: 0.6878 - acc: 0.5469
2432/9333 [======>.......................] - ETA: 6:39 - loss: 0.6874 - acc: 0.5481
2496/9333 [=======>......................] - ETA: 6:36 - loss: 0.6870 - acc: 0.5493
2560/9333 [=======>......................] - ETA: 6:32 - loss: 0.6877 - acc: 0.5480
2624/9333 [=======>......................] - ETA: 6:28 - loss: 0.6878 - acc: 0.5469
2688/9333 [=======>......................] - ETA: 6:24 - loss: 0.6888 - acc: 0.5439
2752/9333 [=======>......................] - ETA: 6:19 - loss: 0.6890 - acc: 0.5429
2816/9333 [========>.....................] - ETA: 6:15 - loss: 0.6897 - acc: 0.5408
2880/9333 [========>.....................] - ETA: 6:11 - loss: 0.6890 - acc: 0.5434
2944/9333 [========>.....................] - ETA: 6:10 - loss: 0.6886 - acc: 0.5435
3008/9333 [========>.....................] - ETA: 6:06 - loss: 0.6892 - acc: 0.5416
3072/9333 [========>.....................] - ETA: 6:03 - loss: 0.6896 - acc: 0.5397
3136/9333 [=========>....................] - ETA: 5:58 - loss: 0.6901 - acc: 0.5386
3200/9333 [=========>....................] - ETA: 5:55 - loss: 0.6898 - acc: 0.5391
3264/9333 [=========>....................] - ETA: 5:52 - loss: 0.6892 - acc: 0.5411
3328/9333 [=========>....................] - ETA: 5:48 - loss: 0.6888 - acc: 0.5430
3392/9333 [=========>....................] - ETA: 5:45 - loss: 0.6888 - acc: 0.5427
3456/9333 [==========>...................] - ETA: 5:42 - loss: 0.6889 - acc: 0.5417
3520/9333 [==========>...................] - ETA: 5:38 - loss: 0.6889 - acc: 0.5415
3584/9333 [==========>...................] - ETA: 5:34 - loss: 0.6890 - acc: 0.5399
3648/9333 [==========>...................] - ETA: 5:29 - loss: 0.6893 - acc: 0.5376
3712/9333 [==========>...................] - ETA: 5:25 - loss: 0.6896 - acc: 0.5372
3776/9333 [===========>..................] - ETA: 5:21 - loss: 0.6900 - acc: 0.5373
3840/9333 [===========>..................] - ETA: 5:18 - loss: 0.6898 - acc: 0.5385
3904/9333 [===========>..................] - ETA: 5:14 - loss: 0.6897 - acc: 0.5392
3968/9333 [===========>..................] - ETA: 5:11 - loss: 0.6895 - acc: 0.5401
4032/9333 [===========>..................] - ETA: 5:08 - loss: 0.6899 - acc: 0.5392
4096/9333 [============>.................] - ETA: 5:03 - loss: 0.6897 - acc: 0.5396
4160/9333 [============>.................] - ETA: 4:59 - loss: 0.6899 - acc: 0.5375
4224/9333 [============>.................] - ETA: 4:55 - loss: 0.6896 - acc: 0.5393
4288/9333 [============>.................] - ETA: 4:52 - loss: 0.6895 - acc: 0.5394
4352/9333 [============>.................] - ETA: 4:49 - loss: 0.6895 - acc: 0.5402
4416/9333 [=============>................] - ETA: 4:45 - loss: 0.6895 - acc: 0.5408
4480/9333 [=============>................] - ETA: 4:41 - loss: 0.6894 - acc: 0.5411
4544/9333 [=============>................] - ETA: 4:37 - loss: 0.6894 - acc: 0.5414
4608/9333 [=============>................] - ETA: 4:32 - loss: 0.6894 - acc: 0.5408
4672/9333 [==============>...............] - ETA: 4:29 - loss: 0.6895 - acc: 0.5407
4736/9333 [==============>...............] - ETA: 4:24 - loss: 0.6892 - acc: 0.5414
4800/9333 [==============>...............] - ETA: 4:21 - loss: 0.6893 - acc: 0.5408
4864/9333 [==============>...............] - ETA: 4:18 - loss: 0.6895 - acc: 0.5411
4928/9333 [==============>...............] - ETA: 4:14 - loss: 0.6898 - acc: 0.5402
4992/9333 [===============>..............] - ETA: 4:10 - loss: 0.6899 - acc: 0.5401
5056/9333 [===============>..............] - ETA: 4:05 - loss: 0.6898 - acc: 0.5392
5120/9333 [===============>..............] - ETA: 4:02 - loss: 0.6897 - acc: 0.5398
5184/9333 [===============>..............] - ETA: 3:58 - loss: 0.6898 - acc: 0.5397
5248/9333 [===============>..............] - ETA: 3:54 - loss: 0.6902 - acc: 0.5393
5312/9333 [================>.............] - ETA: 3:50 - loss: 0.6901 - acc: 0.5386
5376/9333 [================>.............] - ETA: 3:47 - loss: 0.6901 - acc: 0.5394
5440/9333 [================>.............] - ETA: 3:44 - loss: 0.6900 - acc: 0.5395
5504/9333 [================>.............] - ETA: 3:40 - loss: 0.6899 - acc: 0.5400
5568/9333 [================>.............] - ETA: 3:36 - loss: 0.6901 - acc: 0.5399
5632/9333 [=================>............] - ETA: 3:33 - loss: 0.6901 - acc: 0.5412
5696/9333 [=================>............] - ETA: 3:29 - loss: 0.6901 - acc: 0.5407
5760/9333 [=================>............] - ETA: 3:26 - loss: 0.6899 - acc: 0.5420
5824/9333 [=================>............] - ETA: 3:22 - loss: 0.6900 - acc: 0.5419
5888/9333 [=================>............] - ETA: 3:19 - loss: 0.6900 - acc: 0.5414
5952/9333 [==================>...........] - ETA: 3:15 - loss: 0.6900 - acc: 0.5418
6016/9333 [==================>...........] - ETA: 3:12 - loss: 0.6902 - acc: 0.5411
6080/9333 [==================>...........] - ETA: 3:08 - loss: 0.6902 - acc: 0.5411
6144/9333 [==================>...........] - ETA: 3:04 - loss: 0.6904 - acc: 0.5410
6208/9333 [==================>...........] - ETA: 3:01 - loss: 0.6906 - acc: 0.5398
6272/9333 [===================>..........] - ETA: 2:57 - loss: 0.6906 - acc: 0.5397
6336/9333 [===================>..........] - ETA: 2:53 - loss: 0.6905 - acc: 0.5399
6400/9333 [===================>..........] - ETA: 2:50 - loss: 0.6905 - acc: 0.5389
6464/9333 [===================>..........] - ETA: 2:46 - loss: 0.6905 - acc: 0.5391
6528/9333 [===================>..........] - ETA: 2:43 - loss: 0.6905 - acc: 0.5395
6592/9333 [====================>.........] - ETA: 2:39 - loss: 0.6903 - acc: 0.5393
6656/9333 [====================>.........] - ETA: 2:35 - loss: 0.6904 - acc: 0.5383
6720/9333 [====================>.........] - ETA: 2:31 - loss: 0.6906 - acc: 0.5375
6784/9333 [====================>.........] - ETA: 2:28 - loss: 0.6906 - acc: 0.5370
6848/9333 [=====================>........] - ETA: 2:24 - loss: 0.6904 - acc: 0.5377
6912/9333 [=====================>........] - ETA: 2:20 - loss: 0.6903 - acc: 0.5379
6976/9333 [=====================>........] - ETA: 2:17 - loss: 0.6905 - acc: 0.5376
7040/9333 [=====================>........] - ETA: 2:13 - loss: 0.6907 - acc: 0.5365
7104/9333 [=====================>........] - ETA: 2:09 - loss: 0.6908 - acc: 0.5365
7168/9333 [======================>.......] - ETA: 2:06 - loss: 0.6908 - acc: 0.5361
7232/9333 [======================>.......] - ETA: 2:02 - loss: 0.6910 - acc: 0.5344
7296/9333 [======================>.......] - ETA: 1:58 - loss: 0.6911 - acc: 0.5341
7360/9333 [======================>.......] - ETA: 1:54 - loss: 0.6912 - acc: 0.5340
7424/9333 [======================>.......] - ETA: 1:51 - loss: 0.6914 - acc: 0.5337
7488/9333 [=======================>......] - ETA: 1:47 - loss: 0.6914 - acc: 0.5334
7552/9333 [=======================>......] - ETA: 1:43 - loss: 0.6914 - acc: 0.5334
7616/9333 [=======================>......] - ETA: 1:40 - loss: 0.6914 - acc: 0.5335
7680/9333 [=======================>......] - ETA: 1:36 - loss: 0.6915 - acc: 0.5333
7744/9333 [=======================>......] - ETA: 1:32 - loss: 0.6915 - acc: 0.5337
7808/9333 [========================>.....] - ETA: 1:29 - loss: 0.6914 - acc: 0.5341
7872/9333 [========================>.....] - ETA: 1:25 - loss: 0.6913 - acc: 0.5347
7936/9333 [========================>.....] - ETA: 1:21 - loss: 0.6913 - acc: 0.5343
8000/9333 [========================>.....] - ETA: 1:17 - loss: 0.6913 - acc: 0.5346
8064/9333 [========================>.....] - ETA: 1:14 - loss: 0.6912 - acc: 0.5350
8128/9333 [=========================>....] - ETA: 1:10 - loss: 0.6914 - acc: 0.5346
8192/9333 [=========================>....] - ETA: 1:06 - loss: 0.6914 - acc: 0.5347
8256/9333 [=========================>....] - ETA: 1:02 - loss: 0.6914 - acc: 0.5349
8320/9333 [=========================>....] - ETA: 59s - loss: 0.6913 - acc: 0.5346 
8384/9333 [=========================>....] - ETA: 55s - loss: 0.6914 - acc: 0.5340
8448/9333 [==========================>...] - ETA: 51s - loss: 0.6914 - acc: 0.5342
8512/9333 [==========================>...] - ETA: 47s - loss: 0.6915 - acc: 0.5337
8576/9333 [==========================>...] - ETA: 44s - loss: 0.6917 - acc: 0.5328
8640/9333 [==========================>...] - ETA: 40s - loss: 0.6915 - acc: 0.5336
8704/9333 [==========================>...] - ETA: 36s - loss: 0.6916 - acc: 0.5334
8768/9333 [===========================>..] - ETA: 32s - loss: 0.6915 - acc: 0.5336
8832/9333 [===========================>..] - ETA: 29s - loss: 0.6914 - acc: 0.5343
8896/9333 [===========================>..] - ETA: 25s - loss: 0.6914 - acc: 0.5338
8960/9333 [===========================>..] - ETA: 21s - loss: 0.6915 - acc: 0.5339
9024/9333 [============================>.] - ETA: 18s - loss: 0.6915 - acc: 0.5339
9088/9333 [============================>.] - ETA: 14s - loss: 0.6917 - acc: 0.5329
9152/9333 [============================>.] - ETA: 10s - loss: 0.6917 - acc: 0.5328
9216/9333 [============================>.] - ETA: 6s - loss: 0.6918 - acc: 0.5332 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6919 - acc: 0.5330
9333/9333 [==============================] - 566s 61ms/step - loss: 0.6919 - acc: 0.5327 - val_loss: 0.6859 - val_acc: 0.5593

Epoch 00004: val_acc improved from 0.54484 to 0.55931, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window05/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 5/10

  64/9333 [..............................] - ETA: 10:07 - loss: 0.6932 - acc: 0.5625
 128/9333 [..............................] - ETA: 9:36 - loss: 0.6908 - acc: 0.5547 
 192/9333 [..............................] - ETA: 9:04 - loss: 0.6923 - acc: 0.5312
 256/9333 [..............................] - ETA: 8:54 - loss: 0.6862 - acc: 0.5664
 320/9333 [>.............................] - ETA: 8:49 - loss: 0.6871 - acc: 0.5625
 384/9333 [>.............................] - ETA: 8:51 - loss: 0.6902 - acc: 0.5391
 448/9333 [>.............................] - ETA: 8:51 - loss: 0.6931 - acc: 0.5268
 512/9333 [>.............................] - ETA: 8:45 - loss: 0.6930 - acc: 0.5293
 576/9333 [>.............................] - ETA: 8:39 - loss: 0.6946 - acc: 0.5330
 640/9333 [=>............................] - ETA: 8:31 - loss: 0.6945 - acc: 0.5312
 704/9333 [=>............................] - ETA: 8:26 - loss: 0.6958 - acc: 0.5270
 768/9333 [=>............................] - ETA: 8:18 - loss: 0.6947 - acc: 0.5339
 832/9333 [=>............................] - ETA: 8:12 - loss: 0.6949 - acc: 0.5312
 896/9333 [=>............................] - ETA: 8:17 - loss: 0.6950 - acc: 0.5301
 960/9333 [==>...........................] - ETA: 8:21 - loss: 0.6947 - acc: 0.5302
1024/9333 [==>...........................] - ETA: 8:13 - loss: 0.6944 - acc: 0.5322
1088/9333 [==>...........................] - ETA: 8:05 - loss: 0.6939 - acc: 0.5331
1152/9333 [==>...........................] - ETA: 8:01 - loss: 0.6940 - acc: 0.5295
1216/9333 [==>...........................] - ETA: 7:56 - loss: 0.6935 - acc: 0.5345
1280/9333 [===>..........................] - ETA: 7:49 - loss: 0.6938 - acc: 0.5328
1344/9333 [===>..........................] - ETA: 7:46 - loss: 0.6930 - acc: 0.5387
1408/9333 [===>..........................] - ETA: 7:40 - loss: 0.6939 - acc: 0.5327
1472/9333 [===>..........................] - ETA: 7:36 - loss: 0.6944 - acc: 0.5265
1536/9333 [===>..........................] - ETA: 7:33 - loss: 0.6946 - acc: 0.5228
1600/9333 [====>.........................] - ETA: 7:28 - loss: 0.6939 - acc: 0.5250
1664/9333 [====>.........................] - ETA: 7:27 - loss: 0.6938 - acc: 0.5240
1728/9333 [====>.........................] - ETA: 7:21 - loss: 0.6938 - acc: 0.5231
1792/9333 [====>.........................] - ETA: 7:16 - loss: 0.6940 - acc: 0.5234
1856/9333 [====>.........................] - ETA: 7:13 - loss: 0.6946 - acc: 0.5221
1920/9333 [=====>........................] - ETA: 7:08 - loss: 0.6949 - acc: 0.5193
1984/9333 [=====>........................] - ETA: 7:04 - loss: 0.6944 - acc: 0.5207
2048/9333 [=====>........................] - ETA: 7:01 - loss: 0.6944 - acc: 0.5205
2112/9333 [=====>........................] - ETA: 6:57 - loss: 0.6950 - acc: 0.5180
2176/9333 [=====>........................] - ETA: 6:51 - loss: 0.6952 - acc: 0.5170
2240/9333 [======>.......................] - ETA: 6:47 - loss: 0.6955 - acc: 0.5165
2304/9333 [======>.......................] - ETA: 6:44 - loss: 0.6954 - acc: 0.5148
2368/9333 [======>.......................] - ETA: 6:39 - loss: 0.6951 - acc: 0.5165
2432/9333 [======>.......................] - ETA: 6:34 - loss: 0.6949 - acc: 0.5185
2496/9333 [=======>......................] - ETA: 6:29 - loss: 0.6942 - acc: 0.5204
2560/9333 [=======>......................] - ETA: 6:26 - loss: 0.6937 - acc: 0.5230
2624/9333 [=======>......................] - ETA: 6:23 - loss: 0.6934 - acc: 0.5240
2688/9333 [=======>......................] - ETA: 6:18 - loss: 0.6938 - acc: 0.5212
2752/9333 [=======>......................] - ETA: 6:13 - loss: 0.6937 - acc: 0.5222
2816/9333 [========>.....................] - ETA: 6:10 - loss: 0.6934 - acc: 0.5231
2880/9333 [========>.....................] - ETA: 6:06 - loss: 0.6933 - acc: 0.5260
2944/9333 [========>.....................] - ETA: 6:02 - loss: 0.6936 - acc: 0.5234
3008/9333 [========>.....................] - ETA: 5:57 - loss: 0.6935 - acc: 0.5233
3072/9333 [========>.....................] - ETA: 5:53 - loss: 0.6932 - acc: 0.5234
3136/9333 [=========>....................] - ETA: 5:50 - loss: 0.6928 - acc: 0.5242
3200/9333 [=========>....................] - ETA: 5:47 - loss: 0.6930 - acc: 0.5228
3264/9333 [=========>....................] - ETA: 5:44 - loss: 0.6933 - acc: 0.5211
3328/9333 [=========>....................] - ETA: 5:40 - loss: 0.6934 - acc: 0.5198
3392/9333 [=========>....................] - ETA: 5:35 - loss: 0.6934 - acc: 0.5195
3456/9333 [==========>...................] - ETA: 5:31 - loss: 0.6926 - acc: 0.5220
3520/9333 [==========>...................] - ETA: 5:29 - loss: 0.6929 - acc: 0.5202
3584/9333 [==========>...................] - ETA: 5:25 - loss: 0.6924 - acc: 0.5212
3648/9333 [==========>...................] - ETA: 5:20 - loss: 0.6925 - acc: 0.5211
3712/9333 [==========>...................] - ETA: 5:16 - loss: 0.6923 - acc: 0.5216
3776/9333 [===========>..................] - ETA: 5:12 - loss: 0.6922 - acc: 0.5225
3840/9333 [===========>..................] - ETA: 5:09 - loss: 0.6922 - acc: 0.5234
3904/9333 [===========>..................] - ETA: 5:05 - loss: 0.6924 - acc: 0.5225
3968/9333 [===========>..................] - ETA: 5:02 - loss: 0.6924 - acc: 0.5229
4032/9333 [===========>..................] - ETA: 4:58 - loss: 0.6922 - acc: 0.5236
4096/9333 [============>.................] - ETA: 4:54 - loss: 0.6920 - acc: 0.5247
4160/9333 [============>.................] - ETA: 4:51 - loss: 0.6921 - acc: 0.5245
4224/9333 [============>.................] - ETA: 4:48 - loss: 0.6925 - acc: 0.5239
4288/9333 [============>.................] - ETA: 4:44 - loss: 0.6930 - acc: 0.5222
4352/9333 [============>.................] - ETA: 4:40 - loss: 0.6930 - acc: 0.5218
4416/9333 [=============>................] - ETA: 4:36 - loss: 0.6929 - acc: 0.5222
4480/9333 [=============>................] - ETA: 4:32 - loss: 0.6932 - acc: 0.5217
4544/9333 [=============>................] - ETA: 4:29 - loss: 0.6933 - acc: 0.5211
4608/9333 [=============>................] - ETA: 4:25 - loss: 0.6936 - acc: 0.5200
4672/9333 [==============>...............] - ETA: 4:21 - loss: 0.6935 - acc: 0.5205
4736/9333 [==============>...............] - ETA: 4:18 - loss: 0.6934 - acc: 0.5207
4800/9333 [==============>...............] - ETA: 4:15 - loss: 0.6931 - acc: 0.5217
4864/9333 [==============>...............] - ETA: 4:11 - loss: 0.6930 - acc: 0.5220
4928/9333 [==============>...............] - ETA: 4:07 - loss: 0.6930 - acc: 0.5219
4992/9333 [===============>..............] - ETA: 4:03 - loss: 0.6931 - acc: 0.5218
5056/9333 [===============>..............] - ETA: 3:59 - loss: 0.6931 - acc: 0.5212
5120/9333 [===============>..............] - ETA: 3:55 - loss: 0.6934 - acc: 0.5207
5184/9333 [===============>..............] - ETA: 3:52 - loss: 0.6930 - acc: 0.5214
5248/9333 [===============>..............] - ETA: 3:48 - loss: 0.6930 - acc: 0.5212
5312/9333 [================>.............] - ETA: 3:45 - loss: 0.6928 - acc: 0.5216
5376/9333 [================>.............] - ETA: 3:41 - loss: 0.6927 - acc: 0.5216
5440/9333 [================>.............] - ETA: 3:38 - loss: 0.6925 - acc: 0.5222
5504/9333 [================>.............] - ETA: 3:34 - loss: 0.6926 - acc: 0.5214
5568/9333 [================>.............] - ETA: 3:30 - loss: 0.6926 - acc: 0.5226
5632/9333 [=================>............] - ETA: 3:27 - loss: 0.6925 - acc: 0.5225
5696/9333 [=================>............] - ETA: 3:24 - loss: 0.6925 - acc: 0.5225
5760/9333 [=================>............] - ETA: 3:20 - loss: 0.6925 - acc: 0.5224
5824/9333 [=================>............] - ETA: 3:16 - loss: 0.6922 - acc: 0.5240
5888/9333 [=================>............] - ETA: 3:13 - loss: 0.6922 - acc: 0.5246
5952/9333 [==================>...........] - ETA: 3:09 - loss: 0.6921 - acc: 0.5245
6016/9333 [==================>...........] - ETA: 3:05 - loss: 0.6922 - acc: 0.5238
6080/9333 [==================>...........] - ETA: 3:02 - loss: 0.6923 - acc: 0.5232
6144/9333 [==================>...........] - ETA: 2:58 - loss: 0.6923 - acc: 0.5234
6208/9333 [==================>...........] - ETA: 2:55 - loss: 0.6921 - acc: 0.5237
6272/9333 [===================>..........] - ETA: 2:51 - loss: 0.6921 - acc: 0.5241
6336/9333 [===================>..........] - ETA: 2:47 - loss: 0.6920 - acc: 0.5251
6400/9333 [===================>..........] - ETA: 2:44 - loss: 0.6917 - acc: 0.5258
6464/9333 [===================>..........] - ETA: 2:40 - loss: 0.6915 - acc: 0.5265
6528/9333 [===================>..........] - ETA: 2:36 - loss: 0.6916 - acc: 0.5260
6592/9333 [====================>.........] - ETA: 2:33 - loss: 0.6917 - acc: 0.5261
6656/9333 [====================>.........] - ETA: 2:29 - loss: 0.6917 - acc: 0.5266
6720/9333 [====================>.........] - ETA: 2:25 - loss: 0.6914 - acc: 0.5271
6784/9333 [====================>.........] - ETA: 2:22 - loss: 0.6915 - acc: 0.5268
6848/9333 [=====================>........] - ETA: 2:18 - loss: 0.6914 - acc: 0.5270
6912/9333 [=====================>........] - ETA: 2:15 - loss: 0.6914 - acc: 0.5266
6976/9333 [=====================>........] - ETA: 2:11 - loss: 0.6916 - acc: 0.5257
7040/9333 [=====================>........] - ETA: 2:07 - loss: 0.6915 - acc: 0.5259
7104/9333 [=====================>........] - ETA: 2:04 - loss: 0.6915 - acc: 0.5253
7168/9333 [======================>.......] - ETA: 2:00 - loss: 0.6915 - acc: 0.5250
7232/9333 [======================>.......] - ETA: 1:56 - loss: 0.6915 - acc: 0.5250
7296/9333 [======================>.......] - ETA: 1:53 - loss: 0.6915 - acc: 0.5249
7360/9333 [======================>.......] - ETA: 1:49 - loss: 0.6914 - acc: 0.5251
7424/9333 [======================>.......] - ETA: 1:46 - loss: 0.6912 - acc: 0.5259
7488/9333 [=======================>......] - ETA: 1:42 - loss: 0.6913 - acc: 0.5259
7552/9333 [=======================>......] - ETA: 1:39 - loss: 0.6911 - acc: 0.5267
7616/9333 [=======================>......] - ETA: 1:35 - loss: 0.6911 - acc: 0.5265
7680/9333 [=======================>......] - ETA: 1:31 - loss: 0.6912 - acc: 0.5271
7744/9333 [=======================>......] - ETA: 1:28 - loss: 0.6911 - acc: 0.5270
7808/9333 [========================>.....] - ETA: 1:24 - loss: 0.6910 - acc: 0.5274
7872/9333 [========================>.....] - ETA: 1:21 - loss: 0.6911 - acc: 0.5276
7936/9333 [========================>.....] - ETA: 1:17 - loss: 0.6909 - acc: 0.5289
8000/9333 [========================>.....] - ETA: 1:14 - loss: 0.6910 - acc: 0.5291
8064/9333 [========================>.....] - ETA: 1:10 - loss: 0.6908 - acc: 0.5293
8128/9333 [=========================>....] - ETA: 1:06 - loss: 0.6910 - acc: 0.5284
8192/9333 [=========================>....] - ETA: 1:03 - loss: 0.6909 - acc: 0.5284
8256/9333 [=========================>....] - ETA: 59s - loss: 0.6907 - acc: 0.5287 
8320/9333 [=========================>....] - ETA: 56s - loss: 0.6908 - acc: 0.5287
8384/9333 [=========================>....] - ETA: 52s - loss: 0.6908 - acc: 0.5286
8448/9333 [==========================>...] - ETA: 48s - loss: 0.6908 - acc: 0.5289
8512/9333 [==========================>...] - ETA: 45s - loss: 0.6908 - acc: 0.5290
8576/9333 [==========================>...] - ETA: 41s - loss: 0.6909 - acc: 0.5288
8640/9333 [==========================>...] - ETA: 38s - loss: 0.6907 - acc: 0.5296
8704/9333 [==========================>...] - ETA: 34s - loss: 0.6906 - acc: 0.5298
8768/9333 [===========================>..] - ETA: 31s - loss: 0.6907 - acc: 0.5294
8832/9333 [===========================>..] - ETA: 27s - loss: 0.6907 - acc: 0.5296
8896/9333 [===========================>..] - ETA: 23s - loss: 0.6908 - acc: 0.5290
8960/9333 [===========================>..] - ETA: 20s - loss: 0.6908 - acc: 0.5290
9024/9333 [============================>.] - ETA: 16s - loss: 0.6908 - acc: 0.5288
9088/9333 [============================>.] - ETA: 13s - loss: 0.6908 - acc: 0.5295
9152/9333 [============================>.] - ETA: 9s - loss: 0.6909 - acc: 0.5293 
9216/9333 [============================>.] - ETA: 6s - loss: 0.6910 - acc: 0.5293
9280/9333 [============================>.] - ETA: 2s - loss: 0.6912 - acc: 0.5286
9333/9333 [==============================] - 530s 57ms/step - loss: 0.6912 - acc: 0.5283 - val_loss: 0.6881 - val_acc: 0.5419

Epoch 00005: val_acc did not improve from 0.55931
Epoch 6/10

  64/9333 [..............................] - ETA: 7:35 - loss: 0.7079 - acc: 0.3906
 128/9333 [..............................] - ETA: 7:09 - loss: 0.7000 - acc: 0.4766
 192/9333 [..............................] - ETA: 7:06 - loss: 0.6983 - acc: 0.4948
 256/9333 [..............................] - ETA: 7:30 - loss: 0.6974 - acc: 0.5039
 320/9333 [>.............................] - ETA: 7:24 - loss: 0.6945 - acc: 0.5188
 384/9333 [>.............................] - ETA: 7:13 - loss: 0.6953 - acc: 0.4974
 448/9333 [>.............................] - ETA: 7:05 - loss: 0.6955 - acc: 0.5000
 512/9333 [>.............................] - ETA: 7:02 - loss: 0.6945 - acc: 0.5059
 576/9333 [>.............................] - ETA: 6:51 - loss: 0.6904 - acc: 0.5278
 640/9333 [=>............................] - ETA: 6:45 - loss: 0.6898 - acc: 0.5312
 704/9333 [=>............................] - ETA: 6:42 - loss: 0.6881 - acc: 0.5341
 768/9333 [=>............................] - ETA: 6:36 - loss: 0.6897 - acc: 0.5286
 832/9333 [=>............................] - ETA: 6:31 - loss: 0.6899 - acc: 0.5276
 896/9333 [=>............................] - ETA: 6:25 - loss: 0.6900 - acc: 0.5324
 960/9333 [==>...........................] - ETA: 6:25 - loss: 0.6885 - acc: 0.5385
1024/9333 [==>...........................] - ETA: 6:20 - loss: 0.6882 - acc: 0.5400
1088/9333 [==>...........................] - ETA: 6:15 - loss: 0.6879 - acc: 0.5404
1152/9333 [==>...........................] - ETA: 6:11 - loss: 0.6890 - acc: 0.5356
1216/9333 [==>...........................] - ETA: 6:09 - loss: 0.6906 - acc: 0.5312
1280/9333 [===>..........................] - ETA: 6:04 - loss: 0.6901 - acc: 0.5320
1344/9333 [===>..........................] - ETA: 6:05 - loss: 0.6901 - acc: 0.5327
1408/9333 [===>..........................] - ETA: 6:00 - loss: 0.6900 - acc: 0.5298
1472/9333 [===>..........................] - ETA: 6:00 - loss: 0.6896 - acc: 0.5306
1536/9333 [===>..........................] - ETA: 5:57 - loss: 0.6895 - acc: 0.5332
1600/9333 [====>.........................] - ETA: 5:56 - loss: 0.6893 - acc: 0.5337
1664/9333 [====>.........................] - ETA: 5:52 - loss: 0.6901 - acc: 0.5300
1728/9333 [====>.........................] - ETA: 5:48 - loss: 0.6896 - acc: 0.5341
1792/9333 [====>.........................] - ETA: 5:44 - loss: 0.6893 - acc: 0.5352
1856/9333 [====>.........................] - ETA: 5:43 - loss: 0.6897 - acc: 0.5350
1920/9333 [=====>........................] - ETA: 5:38 - loss: 0.6904 - acc: 0.5349
1984/9333 [=====>........................] - ETA: 5:34 - loss: 0.6897 - acc: 0.5363
2048/9333 [=====>........................] - ETA: 5:30 - loss: 0.6898 - acc: 0.5361
2112/9333 [=====>........................] - ETA: 5:28 - loss: 0.6901 - acc: 0.5355
2176/9333 [=====>........................] - ETA: 5:25 - loss: 0.6901 - acc: 0.5354
2240/9333 [======>.......................] - ETA: 5:22 - loss: 0.6902 - acc: 0.5357
2304/9333 [======>.......................] - ETA: 5:18 - loss: 0.6899 - acc: 0.5365
2368/9333 [======>.......................] - ETA: 5:14 - loss: 0.6904 - acc: 0.5334
2432/9333 [======>.......................] - ETA: 5:14 - loss: 0.6902 - acc: 0.5333
2496/9333 [=======>......................] - ETA: 5:13 - loss: 0.6899 - acc: 0.5357
2560/9333 [=======>......................] - ETA: 5:13 - loss: 0.6902 - acc: 0.5336
2624/9333 [=======>......................] - ETA: 5:11 - loss: 0.6901 - acc: 0.5362
2688/9333 [=======>......................] - ETA: 5:09 - loss: 0.6899 - acc: 0.5379
2752/9333 [=======>......................] - ETA: 5:08 - loss: 0.6905 - acc: 0.5360
2816/9333 [========>.....................] - ETA: 5:07 - loss: 0.6904 - acc: 0.5369
2880/9333 [========>.....................] - ETA: 5:05 - loss: 0.6901 - acc: 0.5382
2944/9333 [========>.....................] - ETA: 5:04 - loss: 0.6903 - acc: 0.5384
3008/9333 [========>.....................] - ETA: 5:03 - loss: 0.6908 - acc: 0.5366
3072/9333 [========>.....................] - ETA: 5:02 - loss: 0.6905 - acc: 0.5365
3136/9333 [=========>....................] - ETA: 5:00 - loss: 0.6903 - acc: 0.5370
3200/9333 [=========>....................] - ETA: 4:58 - loss: 0.6903 - acc: 0.5369
3264/9333 [=========>....................] - ETA: 4:55 - loss: 0.6899 - acc: 0.5380
3328/9333 [=========>....................] - ETA: 4:54 - loss: 0.6903 - acc: 0.5370
3392/9333 [=========>....................] - ETA: 4:53 - loss: 0.6907 - acc: 0.5354
3456/9333 [==========>...................] - ETA: 4:51 - loss: 0.6909 - acc: 0.5347
3520/9333 [==========>...................] - ETA: 4:50 - loss: 0.6908 - acc: 0.5349
3584/9333 [==========>...................] - ETA: 4:49 - loss: 0.6907 - acc: 0.5357
3648/9333 [==========>...................] - ETA: 4:46 - loss: 0.6904 - acc: 0.5362
3712/9333 [==========>...................] - ETA: 4:44 - loss: 0.6909 - acc: 0.5358
3776/9333 [===========>..................] - ETA: 4:42 - loss: 0.6905 - acc: 0.5371
3840/9333 [===========>..................] - ETA: 4:40 - loss: 0.6907 - acc: 0.5367
3904/9333 [===========>..................] - ETA: 4:38 - loss: 0.6906 - acc: 0.5377
3968/9333 [===========>..................] - ETA: 4:36 - loss: 0.6909 - acc: 0.5365
4032/9333 [===========>..................] - ETA: 4:33 - loss: 0.6909 - acc: 0.5360
4096/9333 [============>.................] - ETA: 4:30 - loss: 0.6910 - acc: 0.5356
4160/9333 [============>.................] - ETA: 4:28 - loss: 0.6912 - acc: 0.5349
4224/9333 [============>.................] - ETA: 4:25 - loss: 0.6910 - acc: 0.5365
4288/9333 [============>.................] - ETA: 4:22 - loss: 0.6911 - acc: 0.5361
4352/9333 [============>.................] - ETA: 4:20 - loss: 0.6909 - acc: 0.5368
4416/9333 [=============>................] - ETA: 4:17 - loss: 0.6910 - acc: 0.5365
4480/9333 [=============>................] - ETA: 4:16 - loss: 0.6908 - acc: 0.5377
4544/9333 [=============>................] - ETA: 4:15 - loss: 0.6906 - acc: 0.5385
4608/9333 [=============>................] - ETA: 4:13 - loss: 0.6905 - acc: 0.5393
4672/9333 [==============>...............] - ETA: 4:11 - loss: 0.6904 - acc: 0.5398
4736/9333 [==============>...............] - ETA: 4:09 - loss: 0.6904 - acc: 0.5397
4800/9333 [==============>...............] - ETA: 4:07 - loss: 0.6902 - acc: 0.5398
4864/9333 [==============>...............] - ETA: 4:05 - loss: 0.6900 - acc: 0.5407
4928/9333 [==============>...............] - ETA: 4:02 - loss: 0.6900 - acc: 0.5414
4992/9333 [===============>..............] - ETA: 4:00 - loss: 0.6898 - acc: 0.5413
5056/9333 [===============>..............] - ETA: 3:58 - loss: 0.6894 - acc: 0.5431
5120/9333 [===============>..............] - ETA: 3:55 - loss: 0.6894 - acc: 0.5432
5184/9333 [===============>..............] - ETA: 3:53 - loss: 0.6895 - acc: 0.5421
5248/9333 [===============>..............] - ETA: 3:50 - loss: 0.6895 - acc: 0.5423
5312/9333 [================>.............] - ETA: 3:48 - loss: 0.6896 - acc: 0.5416
5376/9333 [================>.............] - ETA: 3:45 - loss: 0.6893 - acc: 0.5422
5440/9333 [================>.............] - ETA: 3:43 - loss: 0.6893 - acc: 0.5421
5504/9333 [================>.............] - ETA: 3:39 - loss: 0.6892 - acc: 0.5420
5568/9333 [================>.............] - ETA: 3:37 - loss: 0.6891 - acc: 0.5417
5632/9333 [=================>............] - ETA: 3:33 - loss: 0.6895 - acc: 0.5410
5696/9333 [=================>............] - ETA: 3:30 - loss: 0.6897 - acc: 0.5400
5760/9333 [=================>............] - ETA: 3:27 - loss: 0.6897 - acc: 0.5401
5824/9333 [=================>............] - ETA: 3:24 - loss: 0.6896 - acc: 0.5404
5888/9333 [=================>............] - ETA: 3:21 - loss: 0.6900 - acc: 0.5394
5952/9333 [==================>...........] - ETA: 3:17 - loss: 0.6901 - acc: 0.5390
6016/9333 [==================>...........] - ETA: 3:14 - loss: 0.6901 - acc: 0.5389
6080/9333 [==================>...........] - ETA: 3:11 - loss: 0.6900 - acc: 0.5395
6144/9333 [==================>...........] - ETA: 3:08 - loss: 0.6900 - acc: 0.5397
6208/9333 [==================>...........] - ETA: 3:05 - loss: 0.6901 - acc: 0.5387
6272/9333 [===================>..........] - ETA: 3:01 - loss: 0.6901 - acc: 0.5392
6336/9333 [===================>..........] - ETA: 2:58 - loss: 0.6901 - acc: 0.5393
6400/9333 [===================>..........] - ETA: 2:55 - loss: 0.6902 - acc: 0.5392
6464/9333 [===================>..........] - ETA: 2:51 - loss: 0.6900 - acc: 0.5401
6528/9333 [===================>..........] - ETA: 2:48 - loss: 0.6900 - acc: 0.5400
6592/9333 [====================>.........] - ETA: 2:44 - loss: 0.6899 - acc: 0.5397
6656/9333 [====================>.........] - ETA: 2:41 - loss: 0.6900 - acc: 0.5392
6720/9333 [====================>.........] - ETA: 2:37 - loss: 0.6901 - acc: 0.5388
6784/9333 [====================>.........] - ETA: 2:34 - loss: 0.6902 - acc: 0.5385
6848/9333 [=====================>........] - ETA: 2:30 - loss: 0.6901 - acc: 0.5393
6912/9333 [=====================>........] - ETA: 2:27 - loss: 0.6902 - acc: 0.5388
6976/9333 [=====================>........] - ETA: 2:23 - loss: 0.6901 - acc: 0.5394
7040/9333 [=====================>........] - ETA: 2:19 - loss: 0.6900 - acc: 0.5392
7104/9333 [=====================>........] - ETA: 2:16 - loss: 0.6900 - acc: 0.5397
7168/9333 [======================>.......] - ETA: 2:12 - loss: 0.6900 - acc: 0.5400
7232/9333 [======================>.......] - ETA: 2:08 - loss: 0.6899 - acc: 0.5397
7296/9333 [======================>.......] - ETA: 2:05 - loss: 0.6898 - acc: 0.5403
7360/9333 [======================>.......] - ETA: 2:01 - loss: 0.6897 - acc: 0.5409
7424/9333 [======================>.......] - ETA: 1:57 - loss: 0.6897 - acc: 0.5407
7488/9333 [=======================>......] - ETA: 1:53 - loss: 0.6896 - acc: 0.5405
7552/9333 [=======================>......] - ETA: 1:49 - loss: 0.6897 - acc: 0.5405
7616/9333 [=======================>......] - ETA: 1:46 - loss: 0.6896 - acc: 0.5410
7680/9333 [=======================>......] - ETA: 1:42 - loss: 0.6894 - acc: 0.5414
7744/9333 [=======================>......] - ETA: 1:38 - loss: 0.6892 - acc: 0.5435
7808/9333 [========================>.....] - ETA: 1:34 - loss: 0.6892 - acc: 0.5435
7872/9333 [========================>.....] - ETA: 1:30 - loss: 0.6892 - acc: 0.5434
7936/9333 [========================>.....] - ETA: 1:26 - loss: 0.6892 - acc: 0.5435
8000/9333 [========================>.....] - ETA: 1:23 - loss: 0.6896 - acc: 0.5423
8064/9333 [========================>.....] - ETA: 1:19 - loss: 0.6897 - acc: 0.5423
8128/9333 [=========================>....] - ETA: 1:15 - loss: 0.6896 - acc: 0.5421
8192/9333 [=========================>....] - ETA: 1:11 - loss: 0.6898 - acc: 0.5416
8256/9333 [=========================>....] - ETA: 1:07 - loss: 0.6897 - acc: 0.5420
8320/9333 [=========================>....] - ETA: 1:03 - loss: 0.6895 - acc: 0.5427
8384/9333 [=========================>....] - ETA: 59s - loss: 0.6899 - acc: 0.5415 
8448/9333 [==========================>...] - ETA: 55s - loss: 0.6897 - acc: 0.5417
8512/9333 [==========================>...] - ETA: 51s - loss: 0.6897 - acc: 0.5418
8576/9333 [==========================>...] - ETA: 47s - loss: 0.6897 - acc: 0.5413
8640/9333 [==========================>...] - ETA: 43s - loss: 0.6898 - acc: 0.5413
8704/9333 [==========================>...] - ETA: 39s - loss: 0.6898 - acc: 0.5416
8768/9333 [===========================>..] - ETA: 35s - loss: 0.6898 - acc: 0.5414
8832/9333 [===========================>..] - ETA: 31s - loss: 0.6899 - acc: 0.5410
8896/9333 [===========================>..] - ETA: 27s - loss: 0.6899 - acc: 0.5409
8960/9333 [===========================>..] - ETA: 23s - loss: 0.6898 - acc: 0.5415
9024/9333 [============================>.] - ETA: 19s - loss: 0.6897 - acc: 0.5416
9088/9333 [============================>.] - ETA: 15s - loss: 0.6897 - acc: 0.5418
9152/9333 [============================>.] - ETA: 11s - loss: 0.6897 - acc: 0.5422
9216/9333 [============================>.] - ETA: 7s - loss: 0.6897 - acc: 0.5423 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6894 - acc: 0.5433
9333/9333 [==============================] - 624s 67ms/step - loss: 0.6893 - acc: 0.5439 - val_loss: 0.6839 - val_acc: 0.5554

Epoch 00006: val_acc did not improve from 0.55931
Epoch 7/10

  64/9333 [..............................] - ETA: 11:59 - loss: 0.6968 - acc: 0.4844
 128/9333 [..............................] - ETA: 11:19 - loss: 0.6896 - acc: 0.5234
 192/9333 [..............................] - ETA: 11:16 - loss: 0.6854 - acc: 0.5521
 256/9333 [..............................] - ETA: 11:22 - loss: 0.6844 - acc: 0.5469
 320/9333 [>.............................] - ETA: 11:15 - loss: 0.6840 - acc: 0.5406
 384/9333 [>.............................] - ETA: 11:19 - loss: 0.6855 - acc: 0.5365
 448/9333 [>.............................] - ETA: 11:10 - loss: 0.6853 - acc: 0.5469
 512/9333 [>.............................] - ETA: 11:05 - loss: 0.6821 - acc: 0.5566
 576/9333 [>.............................] - ETA: 10:52 - loss: 0.6853 - acc: 0.5486
 640/9333 [=>............................] - ETA: 10:46 - loss: 0.6863 - acc: 0.5484
 704/9333 [=>............................] - ETA: 10:43 - loss: 0.6832 - acc: 0.5568
 768/9333 [=>............................] - ETA: 10:39 - loss: 0.6845 - acc: 0.5547
 832/9333 [=>............................] - ETA: 10:37 - loss: 0.6843 - acc: 0.5613
 896/9333 [=>............................] - ETA: 10:29 - loss: 0.6844 - acc: 0.5592
 960/9333 [==>...........................] - ETA: 10:27 - loss: 0.6850 - acc: 0.5573
1024/9333 [==>...........................] - ETA: 10:22 - loss: 0.6846 - acc: 0.5557
1088/9333 [==>...........................] - ETA: 10:17 - loss: 0.6844 - acc: 0.5533
1152/9333 [==>...........................] - ETA: 10:12 - loss: 0.6841 - acc: 0.5503
1216/9333 [==>...........................] - ETA: 10:08 - loss: 0.6856 - acc: 0.5461
1280/9333 [===>..........................] - ETA: 10:05 - loss: 0.6856 - acc: 0.5437
1344/9333 [===>..........................] - ETA: 10:02 - loss: 0.6871 - acc: 0.5409
1408/9333 [===>..........................] - ETA: 9:56 - loss: 0.6866 - acc: 0.5412 
1472/9333 [===>..........................] - ETA: 9:49 - loss: 0.6866 - acc: 0.5442
1536/9333 [===>..........................] - ETA: 9:44 - loss: 0.6865 - acc: 0.5456
1600/9333 [====>.........................] - ETA: 9:39 - loss: 0.6869 - acc: 0.5463
1664/9333 [====>.........................] - ETA: 9:34 - loss: 0.6869 - acc: 0.5463
1728/9333 [====>.........................] - ETA: 9:28 - loss: 0.6881 - acc: 0.5417
1792/9333 [====>.........................] - ETA: 9:23 - loss: 0.6880 - acc: 0.5413
1856/9333 [====>.........................] - ETA: 9:17 - loss: 0.6872 - acc: 0.5436
1920/9333 [=====>........................] - ETA: 9:16 - loss: 0.6865 - acc: 0.5448
1984/9333 [=====>........................] - ETA: 9:14 - loss: 0.6879 - acc: 0.5423
2048/9333 [=====>........................] - ETA: 9:10 - loss: 0.6875 - acc: 0.5420
2112/9333 [=====>........................] - ETA: 9:05 - loss: 0.6878 - acc: 0.5417
2176/9333 [=====>........................] - ETA: 9:00 - loss: 0.6878 - acc: 0.5414
2240/9333 [======>.......................] - ETA: 8:54 - loss: 0.6882 - acc: 0.5406
2304/9333 [======>.......................] - ETA: 8:50 - loss: 0.6880 - acc: 0.5399
2368/9333 [======>.......................] - ETA: 8:44 - loss: 0.6869 - acc: 0.5435
2432/9333 [======>.......................] - ETA: 8:39 - loss: 0.6864 - acc: 0.5452
2496/9333 [=======>......................] - ETA: 8:32 - loss: 0.6862 - acc: 0.5473
2560/9333 [=======>......................] - ETA: 8:25 - loss: 0.6857 - acc: 0.5477
2624/9333 [=======>......................] - ETA: 8:17 - loss: 0.6855 - acc: 0.5492
2688/9333 [=======>......................] - ETA: 8:10 - loss: 0.6852 - acc: 0.5502
2752/9333 [=======>......................] - ETA: 8:04 - loss: 0.6857 - acc: 0.5483
2816/9333 [========>.....................] - ETA: 7:57 - loss: 0.6858 - acc: 0.5479
2880/9333 [========>.....................] - ETA: 7:50 - loss: 0.6862 - acc: 0.5448
2944/9333 [========>.....................] - ETA: 7:45 - loss: 0.6858 - acc: 0.5459
3008/9333 [========>.....................] - ETA: 7:38 - loss: 0.6861 - acc: 0.5452
3072/9333 [========>.....................] - ETA: 7:34 - loss: 0.6865 - acc: 0.5459
3136/9333 [=========>....................] - ETA: 7:29 - loss: 0.6875 - acc: 0.5430
3200/9333 [=========>....................] - ETA: 7:23 - loss: 0.6877 - acc: 0.5428
3264/9333 [=========>....................] - ETA: 7:17 - loss: 0.6877 - acc: 0.5438
3328/9333 [=========>....................] - ETA: 7:10 - loss: 0.6875 - acc: 0.5430
3392/9333 [=========>....................] - ETA: 7:04 - loss: 0.6873 - acc: 0.5422
3456/9333 [==========>...................] - ETA: 7:00 - loss: 0.6879 - acc: 0.5408
3520/9333 [==========>...................] - ETA: 6:54 - loss: 0.6879 - acc: 0.5409
3584/9333 [==========>...................] - ETA: 6:49 - loss: 0.6879 - acc: 0.5393
3648/9333 [==========>...................] - ETA: 6:44 - loss: 0.6882 - acc: 0.5381
3712/9333 [==========>...................] - ETA: 6:38 - loss: 0.6883 - acc: 0.5374
3776/9333 [===========>..................] - ETA: 6:33 - loss: 0.6882 - acc: 0.5376
3840/9333 [===========>..................] - ETA: 6:28 - loss: 0.6883 - acc: 0.5378
3904/9333 [===========>..................] - ETA: 6:23 - loss: 0.6883 - acc: 0.5377
3968/9333 [===========>..................] - ETA: 6:17 - loss: 0.6886 - acc: 0.5373
4032/9333 [===========>..................] - ETA: 6:12 - loss: 0.6888 - acc: 0.5367
4096/9333 [============>.................] - ETA: 6:07 - loss: 0.6888 - acc: 0.5369
4160/9333 [============>.................] - ETA: 6:02 - loss: 0.6885 - acc: 0.5382
4224/9333 [============>.................] - ETA: 5:57 - loss: 0.6882 - acc: 0.5393
4288/9333 [============>.................] - ETA: 5:52 - loss: 0.6881 - acc: 0.5403
4352/9333 [============>.................] - ETA: 5:47 - loss: 0.6882 - acc: 0.5404
4416/9333 [=============>................] - ETA: 5:42 - loss: 0.6882 - acc: 0.5401
4480/9333 [=============>................] - ETA: 5:37 - loss: 0.6883 - acc: 0.5386
4544/9333 [=============>................] - ETA: 5:32 - loss: 0.6885 - acc: 0.5376
4608/9333 [=============>................] - ETA: 5:27 - loss: 0.6883 - acc: 0.5384
4672/9333 [==============>...............] - ETA: 5:22 - loss: 0.6884 - acc: 0.5377
4736/9333 [==============>...............] - ETA: 5:17 - loss: 0.6883 - acc: 0.5386
4800/9333 [==============>...............] - ETA: 5:13 - loss: 0.6883 - acc: 0.5375
4864/9333 [==============>...............] - ETA: 5:08 - loss: 0.6883 - acc: 0.5374
4928/9333 [==============>...............] - ETA: 5:03 - loss: 0.6882 - acc: 0.5381
4992/9333 [===============>..............] - ETA: 4:58 - loss: 0.6884 - acc: 0.5375
5056/9333 [===============>..............] - ETA: 4:54 - loss: 0.6884 - acc: 0.5378
5120/9333 [===============>..............] - ETA: 4:49 - loss: 0.6884 - acc: 0.5373
5184/9333 [===============>..............] - ETA: 4:45 - loss: 0.6884 - acc: 0.5367
5248/9333 [===============>..............] - ETA: 4:39 - loss: 0.6878 - acc: 0.5383
5312/9333 [================>.............] - ETA: 4:35 - loss: 0.6881 - acc: 0.5371
5376/9333 [================>.............] - ETA: 4:30 - loss: 0.6882 - acc: 0.5370
5440/9333 [================>.............] - ETA: 4:26 - loss: 0.6883 - acc: 0.5360
5504/9333 [================>.............] - ETA: 4:21 - loss: 0.6883 - acc: 0.5362
5568/9333 [================>.............] - ETA: 4:16 - loss: 0.6884 - acc: 0.5354
5632/9333 [=================>............] - ETA: 4:11 - loss: 0.6883 - acc: 0.5359
5696/9333 [=================>............] - ETA: 4:07 - loss: 0.6882 - acc: 0.5360
5760/9333 [=================>............] - ETA: 4:02 - loss: 0.6882 - acc: 0.5365
5824/9333 [=================>............] - ETA: 3:57 - loss: 0.6879 - acc: 0.5378
5888/9333 [=================>............] - ETA: 3:53 - loss: 0.6879 - acc: 0.5379
5952/9333 [==================>...........] - ETA: 3:48 - loss: 0.6880 - acc: 0.5378
6016/9333 [==================>...........] - ETA: 3:44 - loss: 0.6878 - acc: 0.5381
6080/9333 [==================>...........] - ETA: 3:39 - loss: 0.6880 - acc: 0.5383
6144/9333 [==================>...........] - ETA: 3:34 - loss: 0.6880 - acc: 0.5387
6208/9333 [==================>...........] - ETA: 3:30 - loss: 0.6879 - acc: 0.5390
6272/9333 [===================>..........] - ETA: 3:25 - loss: 0.6881 - acc: 0.5378
6336/9333 [===================>..........] - ETA: 3:21 - loss: 0.6882 - acc: 0.5376
6400/9333 [===================>..........] - ETA: 3:16 - loss: 0.6883 - acc: 0.5378
6464/9333 [===================>..........] - ETA: 3:12 - loss: 0.6883 - acc: 0.5384
6528/9333 [===================>..........] - ETA: 3:07 - loss: 0.6878 - acc: 0.5406
6592/9333 [====================>.........] - ETA: 3:03 - loss: 0.6875 - acc: 0.5414
6656/9333 [====================>.........] - ETA: 2:59 - loss: 0.6877 - acc: 0.5409
6720/9333 [====================>.........] - ETA: 2:54 - loss: 0.6878 - acc: 0.5400
6784/9333 [====================>.........] - ETA: 2:50 - loss: 0.6875 - acc: 0.5408
6848/9333 [=====================>........] - ETA: 2:45 - loss: 0.6878 - acc: 0.5402
6912/9333 [=====================>........] - ETA: 2:41 - loss: 0.6876 - acc: 0.5411
6976/9333 [=====================>........] - ETA: 2:36 - loss: 0.6876 - acc: 0.5410
7040/9333 [=====================>........] - ETA: 2:32 - loss: 0.6878 - acc: 0.5405
7104/9333 [=====================>........] - ETA: 2:28 - loss: 0.6878 - acc: 0.5408
7168/9333 [======================>.......] - ETA: 2:24 - loss: 0.6877 - acc: 0.5414
7232/9333 [======================>.......] - ETA: 2:19 - loss: 0.6876 - acc: 0.5418
7296/9333 [======================>.......] - ETA: 2:15 - loss: 0.6876 - acc: 0.5418
7360/9333 [======================>.......] - ETA: 2:11 - loss: 0.6879 - acc: 0.5409
7424/9333 [======================>.......] - ETA: 2:06 - loss: 0.6879 - acc: 0.5405
7488/9333 [=======================>......] - ETA: 2:02 - loss: 0.6879 - acc: 0.5406
7552/9333 [=======================>......] - ETA: 1:58 - loss: 0.6880 - acc: 0.5403
7616/9333 [=======================>......] - ETA: 1:53 - loss: 0.6878 - acc: 0.5412
7680/9333 [=======================>......] - ETA: 1:49 - loss: 0.6880 - acc: 0.5398
7744/9333 [=======================>......] - ETA: 1:45 - loss: 0.6879 - acc: 0.5400
7808/9333 [========================>.....] - ETA: 1:40 - loss: 0.6882 - acc: 0.5396
7872/9333 [========================>.....] - ETA: 1:36 - loss: 0.6880 - acc: 0.5396
7936/9333 [========================>.....] - ETA: 1:32 - loss: 0.6877 - acc: 0.5404
8000/9333 [========================>.....] - ETA: 1:28 - loss: 0.6877 - acc: 0.5406
8064/9333 [========================>.....] - ETA: 1:23 - loss: 0.6878 - acc: 0.5410
8128/9333 [=========================>....] - ETA: 1:19 - loss: 0.6879 - acc: 0.5404
8192/9333 [=========================>....] - ETA: 1:15 - loss: 0.6881 - acc: 0.5403
8256/9333 [=========================>....] - ETA: 1:11 - loss: 0.6881 - acc: 0.5402
8320/9333 [=========================>....] - ETA: 1:06 - loss: 0.6880 - acc: 0.5403
8384/9333 [=========================>....] - ETA: 1:02 - loss: 0.6880 - acc: 0.5400
8448/9333 [==========================>...] - ETA: 58s - loss: 0.6882 - acc: 0.5391 
8512/9333 [==========================>...] - ETA: 54s - loss: 0.6880 - acc: 0.5394
8576/9333 [==========================>...] - ETA: 49s - loss: 0.6881 - acc: 0.5389
8640/9333 [==========================>...] - ETA: 45s - loss: 0.6883 - acc: 0.5384
8704/9333 [==========================>...] - ETA: 41s - loss: 0.6882 - acc: 0.5393
8768/9333 [===========================>..] - ETA: 37s - loss: 0.6882 - acc: 0.5389
8832/9333 [===========================>..] - ETA: 32s - loss: 0.6882 - acc: 0.5388
8896/9333 [===========================>..] - ETA: 28s - loss: 0.6882 - acc: 0.5387
8960/9333 [===========================>..] - ETA: 24s - loss: 0.6881 - acc: 0.5391
9024/9333 [============================>.] - ETA: 20s - loss: 0.6881 - acc: 0.5392
9088/9333 [============================>.] - ETA: 16s - loss: 0.6882 - acc: 0.5390
9152/9333 [============================>.] - ETA: 11s - loss: 0.6883 - acc: 0.5389
9216/9333 [============================>.] - ETA: 7s - loss: 0.6884 - acc: 0.5390 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6883 - acc: 0.5394
9333/9333 [==============================] - 636s 68ms/step - loss: 0.6884 - acc: 0.5385 - val_loss: 0.6856 - val_acc: 0.5410

Epoch 00007: val_acc did not improve from 0.55931
Epoch 8/10

  64/9333 [..............................] - ETA: 9:02 - loss: 0.6920 - acc: 0.4531
 128/9333 [..............................] - ETA: 9:04 - loss: 0.6929 - acc: 0.4766
 192/9333 [..............................] - ETA: 8:30 - loss: 0.6930 - acc: 0.4792
 256/9333 [..............................] - ETA: 8:53 - loss: 0.6925 - acc: 0.4922
 320/9333 [>.............................] - ETA: 9:09 - loss: 0.6910 - acc: 0.4969
 384/9333 [>.............................] - ETA: 9:07 - loss: 0.6914 - acc: 0.5078
 448/9333 [>.............................] - ETA: 8:55 - loss: 0.6923 - acc: 0.5045
 512/9333 [>.............................] - ETA: 8:56 - loss: 0.6921 - acc: 0.5020
 576/9333 [>.............................] - ETA: 9:04 - loss: 0.6909 - acc: 0.5035
 640/9333 [=>............................] - ETA: 9:03 - loss: 0.6907 - acc: 0.5078
 704/9333 [=>............................] - ETA: 8:58 - loss: 0.6908 - acc: 0.5085
 768/9333 [=>............................] - ETA: 8:51 - loss: 0.6895 - acc: 0.5143
 832/9333 [=>............................] - ETA: 8:41 - loss: 0.6890 - acc: 0.5192
 896/9333 [=>............................] - ETA: 8:38 - loss: 0.6887 - acc: 0.5212
 960/9333 [==>...........................] - ETA: 8:33 - loss: 0.6880 - acc: 0.5240
1024/9333 [==>...........................] - ETA: 8:29 - loss: 0.6880 - acc: 0.5244
1088/9333 [==>...........................] - ETA: 8:26 - loss: 0.6867 - acc: 0.5322
1152/9333 [==>...........................] - ETA: 8:22 - loss: 0.6884 - acc: 0.5286
1216/9333 [==>...........................] - ETA: 8:16 - loss: 0.6871 - acc: 0.5337
1280/9333 [===>..........................] - ETA: 8:12 - loss: 0.6883 - acc: 0.5312
1344/9333 [===>..........................] - ETA: 8:06 - loss: 0.6881 - acc: 0.5320
1408/9333 [===>..........................] - ETA: 8:02 - loss: 0.6877 - acc: 0.5334
1472/9333 [===>..........................] - ETA: 7:57 - loss: 0.6866 - acc: 0.5367
1536/9333 [===>..........................] - ETA: 7:53 - loss: 0.6863 - acc: 0.5371
1600/9333 [====>.........................] - ETA: 7:47 - loss: 0.6868 - acc: 0.5356
1664/9333 [====>.........................] - ETA: 7:43 - loss: 0.6866 - acc: 0.5373
1728/9333 [====>.........................] - ETA: 7:38 - loss: 0.6855 - acc: 0.5376
1792/9333 [====>.........................] - ETA: 7:34 - loss: 0.6852 - acc: 0.5396
1856/9333 [====>.........................] - ETA: 7:31 - loss: 0.6845 - acc: 0.5431
1920/9333 [=====>........................] - ETA: 7:26 - loss: 0.6846 - acc: 0.5427
1984/9333 [=====>........................] - ETA: 7:21 - loss: 0.6848 - acc: 0.5439
2048/9333 [=====>........................] - ETA: 7:16 - loss: 0.6849 - acc: 0.5435
2112/9333 [=====>........................] - ETA: 7:12 - loss: 0.6850 - acc: 0.5455
2176/9333 [=====>........................] - ETA: 7:08 - loss: 0.6853 - acc: 0.5446
2240/9333 [======>.......................] - ETA: 7:03 - loss: 0.6863 - acc: 0.5406
2304/9333 [======>.......................] - ETA: 6:59 - loss: 0.6861 - acc: 0.5417
2368/9333 [======>.......................] - ETA: 6:56 - loss: 0.6869 - acc: 0.5389
2432/9333 [======>.......................] - ETA: 6:51 - loss: 0.6868 - acc: 0.5382
2496/9333 [=======>......................] - ETA: 6:49 - loss: 0.6872 - acc: 0.5369
2560/9333 [=======>......................] - ETA: 6:46 - loss: 0.6869 - acc: 0.5375
2624/9333 [=======>......................] - ETA: 6:43 - loss: 0.6864 - acc: 0.5393
2688/9333 [=======>......................] - ETA: 6:38 - loss: 0.6865 - acc: 0.5391
2752/9333 [=======>......................] - ETA: 6:35 - loss: 0.6862 - acc: 0.5400
2816/9333 [========>.....................] - ETA: 6:29 - loss: 0.6855 - acc: 0.5437
2880/9333 [========>.....................] - ETA: 6:28 - loss: 0.6857 - acc: 0.5431
2944/9333 [========>.....................] - ETA: 6:23 - loss: 0.6857 - acc: 0.5438
3008/9333 [========>.....................] - ETA: 6:19 - loss: 0.6857 - acc: 0.5442
3072/9333 [========>.....................] - ETA: 6:15 - loss: 0.6859 - acc: 0.5433
3136/9333 [=========>....................] - ETA: 6:11 - loss: 0.6858 - acc: 0.5430
3200/9333 [=========>....................] - ETA: 6:07 - loss: 0.6854 - acc: 0.5431
3264/9333 [=========>....................] - ETA: 6:04 - loss: 0.6853 - acc: 0.5453
3328/9333 [=========>....................] - ETA: 6:00 - loss: 0.6847 - acc: 0.5469
3392/9333 [=========>....................] - ETA: 5:57 - loss: 0.6853 - acc: 0.5469
3456/9333 [==========>...................] - ETA: 5:53 - loss: 0.6853 - acc: 0.5475
3520/9333 [==========>...................] - ETA: 5:49 - loss: 0.6855 - acc: 0.5469
3584/9333 [==========>...................] - ETA: 5:46 - loss: 0.6856 - acc: 0.5458
3648/9333 [==========>...................] - ETA: 5:42 - loss: 0.6860 - acc: 0.5452
3712/9333 [==========>...................] - ETA: 5:38 - loss: 0.6864 - acc: 0.5445
3776/9333 [===========>..................] - ETA: 5:34 - loss: 0.6859 - acc: 0.5458
3840/9333 [===========>..................] - ETA: 5:30 - loss: 0.6858 - acc: 0.5466
3904/9333 [===========>..................] - ETA: 5:26 - loss: 0.6866 - acc: 0.5443
3968/9333 [===========>..................] - ETA: 5:22 - loss: 0.6869 - acc: 0.5436
4032/9333 [===========>..................] - ETA: 5:18 - loss: 0.6872 - acc: 0.5417
4096/9333 [============>.................] - ETA: 5:14 - loss: 0.6873 - acc: 0.5410
4160/9333 [============>.................] - ETA: 5:10 - loss: 0.6874 - acc: 0.5409
4224/9333 [============>.................] - ETA: 5:06 - loss: 0.6880 - acc: 0.5395
4288/9333 [============>.................] - ETA: 5:03 - loss: 0.6879 - acc: 0.5399
4352/9333 [============>.................] - ETA: 4:59 - loss: 0.6882 - acc: 0.5400
4416/9333 [=============>................] - ETA: 4:55 - loss: 0.6883 - acc: 0.5408
4480/9333 [=============>................] - ETA: 4:51 - loss: 0.6886 - acc: 0.5397
4544/9333 [=============>................] - ETA: 4:47 - loss: 0.6886 - acc: 0.5387
4608/9333 [=============>................] - ETA: 4:44 - loss: 0.6885 - acc: 0.5395
4672/9333 [==============>...............] - ETA: 4:40 - loss: 0.6886 - acc: 0.5394
4736/9333 [==============>...............] - ETA: 4:36 - loss: 0.6888 - acc: 0.5393
4800/9333 [==============>...............] - ETA: 4:32 - loss: 0.6886 - acc: 0.5406
4864/9333 [==============>...............] - ETA: 4:29 - loss: 0.6885 - acc: 0.5405
4928/9333 [==============>...............] - ETA: 4:25 - loss: 0.6885 - acc: 0.5406
4992/9333 [===============>..............] - ETA: 4:21 - loss: 0.6885 - acc: 0.5409
5056/9333 [===============>..............] - ETA: 4:16 - loss: 0.6882 - acc: 0.5421
5120/9333 [===============>..............] - ETA: 4:12 - loss: 0.6882 - acc: 0.5416
5184/9333 [===============>..............] - ETA: 4:08 - loss: 0.6881 - acc: 0.5424
5248/9333 [===============>..............] - ETA: 4:04 - loss: 0.6880 - acc: 0.5429
5312/9333 [================>.............] - ETA: 4:00 - loss: 0.6882 - acc: 0.5427
5376/9333 [================>.............] - ETA: 3:56 - loss: 0.6883 - acc: 0.5422
5440/9333 [================>.............] - ETA: 3:52 - loss: 0.6884 - acc: 0.5421
5504/9333 [================>.............] - ETA: 3:48 - loss: 0.6886 - acc: 0.5416
5568/9333 [================>.............] - ETA: 3:45 - loss: 0.6883 - acc: 0.5422
5632/9333 [=================>............] - ETA: 3:41 - loss: 0.6881 - acc: 0.5426
5696/9333 [=================>............] - ETA: 3:37 - loss: 0.6881 - acc: 0.5428
5760/9333 [=================>............] - ETA: 3:33 - loss: 0.6885 - acc: 0.5422
5824/9333 [=================>............] - ETA: 3:29 - loss: 0.6886 - acc: 0.5417
5888/9333 [=================>............] - ETA: 3:25 - loss: 0.6885 - acc: 0.5414
5952/9333 [==================>...........] - ETA: 3:21 - loss: 0.6886 - acc: 0.5420
6016/9333 [==================>...........] - ETA: 3:17 - loss: 0.6884 - acc: 0.5421
6080/9333 [==================>...........] - ETA: 3:13 - loss: 0.6884 - acc: 0.5421
6144/9333 [==================>...........] - ETA: 3:09 - loss: 0.6885 - acc: 0.5428
6208/9333 [==================>...........] - ETA: 3:05 - loss: 0.6884 - acc: 0.5432
6272/9333 [===================>..........] - ETA: 3:01 - loss: 0.6884 - acc: 0.5429
6336/9333 [===================>..........] - ETA: 2:57 - loss: 0.6886 - acc: 0.5426
6400/9333 [===================>..........] - ETA: 2:53 - loss: 0.6886 - acc: 0.5427
6464/9333 [===================>..........] - ETA: 2:49 - loss: 0.6885 - acc: 0.5429
6528/9333 [===================>..........] - ETA: 2:46 - loss: 0.6884 - acc: 0.5432
6592/9333 [====================>.........] - ETA: 2:42 - loss: 0.6886 - acc: 0.5423
6656/9333 [====================>.........] - ETA: 2:38 - loss: 0.6885 - acc: 0.5428
6720/9333 [====================>.........] - ETA: 2:34 - loss: 0.6887 - acc: 0.5427
6784/9333 [====================>.........] - ETA: 2:30 - loss: 0.6886 - acc: 0.5426
6848/9333 [=====================>........] - ETA: 2:26 - loss: 0.6887 - acc: 0.5423
6912/9333 [=====================>........] - ETA: 2:22 - loss: 0.6887 - acc: 0.5418
6976/9333 [=====================>........] - ETA: 2:19 - loss: 0.6886 - acc: 0.5421
7040/9333 [=====================>........] - ETA: 2:15 - loss: 0.6889 - acc: 0.5413
7104/9333 [=====================>........] - ETA: 2:11 - loss: 0.6888 - acc: 0.5412
7168/9333 [======================>.......] - ETA: 2:07 - loss: 0.6889 - acc: 0.5409
7232/9333 [======================>.......] - ETA: 2:03 - loss: 0.6890 - acc: 0.5407
7296/9333 [======================>.......] - ETA: 1:59 - loss: 0.6888 - acc: 0.5413
7360/9333 [======================>.......] - ETA: 1:56 - loss: 0.6889 - acc: 0.5410
7424/9333 [======================>.......] - ETA: 1:52 - loss: 0.6889 - acc: 0.5409
7488/9333 [=======================>......] - ETA: 1:48 - loss: 0.6889 - acc: 0.5413
7552/9333 [=======================>......] - ETA: 1:44 - loss: 0.6887 - acc: 0.5422
7616/9333 [=======================>......] - ETA: 1:40 - loss: 0.6889 - acc: 0.5416
7680/9333 [=======================>......] - ETA: 1:37 - loss: 0.6887 - acc: 0.5421
7744/9333 [=======================>......] - ETA: 1:33 - loss: 0.6887 - acc: 0.5424
7808/9333 [========================>.....] - ETA: 1:29 - loss: 0.6886 - acc: 0.5429
7872/9333 [========================>.....] - ETA: 1:25 - loss: 0.6886 - acc: 0.5432
7936/9333 [========================>.....] - ETA: 1:21 - loss: 0.6886 - acc: 0.5430
8000/9333 [========================>.....] - ETA: 1:18 - loss: 0.6885 - acc: 0.5433
8064/9333 [========================>.....] - ETA: 1:14 - loss: 0.6886 - acc: 0.5425
8128/9333 [=========================>....] - ETA: 1:10 - loss: 0.6886 - acc: 0.5421
8192/9333 [=========================>....] - ETA: 1:06 - loss: 0.6887 - acc: 0.5415
8256/9333 [=========================>....] - ETA: 1:03 - loss: 0.6886 - acc: 0.5414
8320/9333 [=========================>....] - ETA: 59s - loss: 0.6886 - acc: 0.5413 
8384/9333 [=========================>....] - ETA: 55s - loss: 0.6884 - acc: 0.5422
8448/9333 [==========================>...] - ETA: 51s - loss: 0.6881 - acc: 0.5436
8512/9333 [==========================>...] - ETA: 48s - loss: 0.6882 - acc: 0.5436
8576/9333 [==========================>...] - ETA: 44s - loss: 0.6882 - acc: 0.5431
8640/9333 [==========================>...] - ETA: 40s - loss: 0.6884 - acc: 0.5422
8704/9333 [==========================>...] - ETA: 37s - loss: 0.6883 - acc: 0.5429
8768/9333 [===========================>..] - ETA: 33s - loss: 0.6882 - acc: 0.5433
8832/9333 [===========================>..] - ETA: 29s - loss: 0.6883 - acc: 0.5435
8896/9333 [===========================>..] - ETA: 25s - loss: 0.6882 - acc: 0.5442
8960/9333 [===========================>..] - ETA: 22s - loss: 0.6882 - acc: 0.5442
9024/9333 [============================>.] - ETA: 18s - loss: 0.6883 - acc: 0.5436
9088/9333 [============================>.] - ETA: 14s - loss: 0.6883 - acc: 0.5430
9152/9333 [============================>.] - ETA: 10s - loss: 0.6885 - acc: 0.5431
9216/9333 [============================>.] - ETA: 6s - loss: 0.6885 - acc: 0.5433 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6886 - acc: 0.5427
9333/9333 [==============================] - 585s 63ms/step - loss: 0.6887 - acc: 0.5425 - val_loss: 0.6839 - val_acc: 0.5516

Epoch 00008: val_acc did not improve from 0.55931
Epoch 9/10

  64/9333 [..............................] - ETA: 12:18 - loss: 0.6898 - acc: 0.5156
 128/9333 [..............................] - ETA: 12:09 - loss: 0.6915 - acc: 0.5156
 192/9333 [..............................] - ETA: 11:49 - loss: 0.6925 - acc: 0.5156
 256/9333 [..............................] - ETA: 11:34 - loss: 0.6875 - acc: 0.5312
 320/9333 [>.............................] - ETA: 11:23 - loss: 0.6898 - acc: 0.5375
 384/9333 [>.............................] - ETA: 11:20 - loss: 0.6855 - acc: 0.5599
 448/9333 [>.............................] - ETA: 11:17 - loss: 0.6869 - acc: 0.5536
 512/9333 [>.............................] - ETA: 11:10 - loss: 0.6882 - acc: 0.5371
 576/9333 [>.............................] - ETA: 11:08 - loss: 0.6893 - acc: 0.5365
 640/9333 [=>............................] - ETA: 11:06 - loss: 0.6874 - acc: 0.5453
 704/9333 [=>............................] - ETA: 10:54 - loss: 0.6891 - acc: 0.5369
 768/9333 [=>............................] - ETA: 10:44 - loss: 0.6889 - acc: 0.5378
 832/9333 [=>............................] - ETA: 10:37 - loss: 0.6883 - acc: 0.5409
 896/9333 [=>............................] - ETA: 10:32 - loss: 0.6891 - acc: 0.5368
 960/9333 [==>...........................] - ETA: 10:25 - loss: 0.6887 - acc: 0.5385
1024/9333 [==>...........................] - ETA: 10:24 - loss: 0.6873 - acc: 0.5469
1088/9333 [==>...........................] - ETA: 10:19 - loss: 0.6866 - acc: 0.5496
1152/9333 [==>...........................] - ETA: 10:14 - loss: 0.6862 - acc: 0.5512
1216/9333 [==>...........................] - ETA: 10:09 - loss: 0.6871 - acc: 0.5485
1280/9333 [===>..........................] - ETA: 10:02 - loss: 0.6880 - acc: 0.5445
1344/9333 [===>..........................] - ETA: 9:56 - loss: 0.6884 - acc: 0.5454 
1408/9333 [===>..........................] - ETA: 9:51 - loss: 0.6883 - acc: 0.5447
1472/9333 [===>..........................] - ETA: 9:44 - loss: 0.6877 - acc: 0.5482
1536/9333 [===>..........................] - ETA: 9:39 - loss: 0.6875 - acc: 0.5469
1600/9333 [====>.........................] - ETA: 9:32 - loss: 0.6880 - acc: 0.5437
1664/9333 [====>.........................] - ETA: 9:27 - loss: 0.6879 - acc: 0.5421
1728/9333 [====>.........................] - ETA: 9:21 - loss: 0.6880 - acc: 0.5428
1792/9333 [====>.........................] - ETA: 9:17 - loss: 0.6872 - acc: 0.5480
1856/9333 [====>.........................] - ETA: 9:12 - loss: 0.6877 - acc: 0.5447
1920/9333 [=====>........................] - ETA: 9:06 - loss: 0.6874 - acc: 0.5474
1984/9333 [=====>........................] - ETA: 9:00 - loss: 0.6882 - acc: 0.5444
2048/9333 [=====>........................] - ETA: 8:55 - loss: 0.6875 - acc: 0.5464
2112/9333 [=====>........................] - ETA: 8:51 - loss: 0.6880 - acc: 0.5455
2176/9333 [=====>........................] - ETA: 8:46 - loss: 0.6879 - acc: 0.5478
2240/9333 [======>.......................] - ETA: 8:40 - loss: 0.6882 - acc: 0.5460
2304/9333 [======>.......................] - ETA: 8:36 - loss: 0.6882 - acc: 0.5469
2368/9333 [======>.......................] - ETA: 8:31 - loss: 0.6884 - acc: 0.5473
2432/9333 [======>.......................] - ETA: 8:26 - loss: 0.6878 - acc: 0.5481
2496/9333 [=======>......................] - ETA: 8:21 - loss: 0.6879 - acc: 0.5489
2560/9333 [=======>......................] - ETA: 8:13 - loss: 0.6882 - acc: 0.5465
2624/9333 [=======>......................] - ETA: 8:07 - loss: 0.6879 - acc: 0.5488
2688/9333 [=======>......................] - ETA: 8:00 - loss: 0.6877 - acc: 0.5495
2752/9333 [=======>......................] - ETA: 7:54 - loss: 0.6880 - acc: 0.5480
2816/9333 [========>.....................] - ETA: 7:47 - loss: 0.6882 - acc: 0.5479
2880/9333 [========>.....................] - ETA: 7:41 - loss: 0.6883 - acc: 0.5462
2944/9333 [========>.....................] - ETA: 7:36 - loss: 0.6883 - acc: 0.5465
3008/9333 [========>.....................] - ETA: 7:31 - loss: 0.6885 - acc: 0.5469
3072/9333 [========>.....................] - ETA: 7:25 - loss: 0.6888 - acc: 0.5452
3136/9333 [=========>....................] - ETA: 7:19 - loss: 0.6891 - acc: 0.5443
3200/9333 [=========>....................] - ETA: 7:15 - loss: 0.6892 - acc: 0.5428
3264/9333 [=========>....................] - ETA: 7:10 - loss: 0.6889 - acc: 0.5423
3328/9333 [=========>....................] - ETA: 7:05 - loss: 0.6892 - acc: 0.5409
3392/9333 [=========>....................] - ETA: 6:59 - loss: 0.6896 - acc: 0.5401
3456/9333 [==========>...................] - ETA: 6:53 - loss: 0.6897 - acc: 0.5391
3520/9333 [==========>...................] - ETA: 6:48 - loss: 0.6898 - acc: 0.5398
3584/9333 [==========>...................] - ETA: 6:43 - loss: 0.6898 - acc: 0.5388
3648/9333 [==========>...................] - ETA: 6:37 - loss: 0.6897 - acc: 0.5392
3712/9333 [==========>...................] - ETA: 6:32 - loss: 0.6896 - acc: 0.5391
3776/9333 [===========>..................] - ETA: 6:27 - loss: 0.6899 - acc: 0.5373
3840/9333 [===========>..................] - ETA: 6:23 - loss: 0.6896 - acc: 0.5375
3904/9333 [===========>..................] - ETA: 6:17 - loss: 0.6897 - acc: 0.5374
3968/9333 [===========>..................] - ETA: 6:12 - loss: 0.6894 - acc: 0.5388
4032/9333 [===========>..................] - ETA: 6:07 - loss: 0.6891 - acc: 0.5402
4096/9333 [============>.................] - ETA: 6:01 - loss: 0.6889 - acc: 0.5413
4160/9333 [============>.................] - ETA: 5:56 - loss: 0.6882 - acc: 0.5437
4224/9333 [============>.................] - ETA: 5:52 - loss: 0.6880 - acc: 0.5450
4288/9333 [============>.................] - ETA: 5:47 - loss: 0.6883 - acc: 0.5448
4352/9333 [============>.................] - ETA: 5:42 - loss: 0.6880 - acc: 0.5455
4416/9333 [=============>................] - ETA: 5:37 - loss: 0.6882 - acc: 0.5451
4480/9333 [=============>................] - ETA: 5:32 - loss: 0.6875 - acc: 0.5469
4544/9333 [=============>................] - ETA: 5:27 - loss: 0.6869 - acc: 0.5478
4608/9333 [=============>................] - ETA: 5:22 - loss: 0.6871 - acc: 0.5469
4672/9333 [==============>...............] - ETA: 5:17 - loss: 0.6873 - acc: 0.5462
4736/9333 [==============>...............] - ETA: 5:12 - loss: 0.6875 - acc: 0.5454
4800/9333 [==============>...............] - ETA: 5:07 - loss: 0.6870 - acc: 0.5463
4864/9333 [==============>...............] - ETA: 5:03 - loss: 0.6875 - acc: 0.5454
4928/9333 [==============>...............] - ETA: 4:58 - loss: 0.6872 - acc: 0.5457
4992/9333 [===============>..............] - ETA: 4:53 - loss: 0.6872 - acc: 0.5455
5056/9333 [===============>..............] - ETA: 4:49 - loss: 0.6877 - acc: 0.5451
5120/9333 [===============>..............] - ETA: 4:44 - loss: 0.6875 - acc: 0.5459
5184/9333 [===============>..............] - ETA: 4:40 - loss: 0.6879 - acc: 0.5451
5248/9333 [===============>..............] - ETA: 4:35 - loss: 0.6879 - acc: 0.5455
5312/9333 [================>.............] - ETA: 4:30 - loss: 0.6877 - acc: 0.5463
5376/9333 [================>.............] - ETA: 4:25 - loss: 0.6873 - acc: 0.5478
5440/9333 [================>.............] - ETA: 4:20 - loss: 0.6871 - acc: 0.5483
5504/9333 [================>.............] - ETA: 4:15 - loss: 0.6871 - acc: 0.5487
5568/9333 [================>.............] - ETA: 4:11 - loss: 0.6869 - acc: 0.5496
5632/9333 [=================>............] - ETA: 4:06 - loss: 0.6868 - acc: 0.5495
5696/9333 [=================>............] - ETA: 4:01 - loss: 0.6866 - acc: 0.5497
5760/9333 [=================>............] - ETA: 3:57 - loss: 0.6865 - acc: 0.5503
5824/9333 [=================>............] - ETA: 3:52 - loss: 0.6865 - acc: 0.5505
5888/9333 [=================>............] - ETA: 3:47 - loss: 0.6866 - acc: 0.5503
5952/9333 [==================>...........] - ETA: 3:43 - loss: 0.6867 - acc: 0.5499
6016/9333 [==================>...........] - ETA: 3:38 - loss: 0.6867 - acc: 0.5504
6080/9333 [==================>...........] - ETA: 3:33 - loss: 0.6866 - acc: 0.5510
6144/9333 [==================>...........] - ETA: 3:29 - loss: 0.6867 - acc: 0.5505
6208/9333 [==================>...........] - ETA: 3:25 - loss: 0.6866 - acc: 0.5507
6272/9333 [===================>..........] - ETA: 3:20 - loss: 0.6867 - acc: 0.5509
6336/9333 [===================>..........] - ETA: 3:16 - loss: 0.6866 - acc: 0.5510
6400/9333 [===================>..........] - ETA: 3:11 - loss: 0.6865 - acc: 0.5513
6464/9333 [===================>..........] - ETA: 3:07 - loss: 0.6866 - acc: 0.5507
6528/9333 [===================>..........] - ETA: 3:02 - loss: 0.6866 - acc: 0.5509
6592/9333 [====================>.........] - ETA: 2:58 - loss: 0.6865 - acc: 0.5508
6656/9333 [====================>.........] - ETA: 2:54 - loss: 0.6865 - acc: 0.5509
6720/9333 [====================>.........] - ETA: 2:49 - loss: 0.6868 - acc: 0.5503
6784/9333 [====================>.........] - ETA: 2:45 - loss: 0.6865 - acc: 0.5507
6848/9333 [=====================>........] - ETA: 2:41 - loss: 0.6863 - acc: 0.5507
6912/9333 [=====================>........] - ETA: 2:36 - loss: 0.6862 - acc: 0.5508
6976/9333 [=====================>........] - ETA: 2:32 - loss: 0.6863 - acc: 0.5510
7040/9333 [=====================>........] - ETA: 2:27 - loss: 0.6865 - acc: 0.5500
7104/9333 [=====================>........] - ETA: 2:23 - loss: 0.6862 - acc: 0.5507
7168/9333 [======================>.......] - ETA: 2:19 - loss: 0.6865 - acc: 0.5501
7232/9333 [======================>.......] - ETA: 2:14 - loss: 0.6865 - acc: 0.5502
7296/9333 [======================>.......] - ETA: 2:10 - loss: 0.6864 - acc: 0.5506
7360/9333 [======================>.......] - ETA: 2:06 - loss: 0.6860 - acc: 0.5514
7424/9333 [======================>.......] - ETA: 2:02 - loss: 0.6860 - acc: 0.5516
7488/9333 [=======================>......] - ETA: 1:57 - loss: 0.6860 - acc: 0.5514
7552/9333 [=======================>......] - ETA: 1:53 - loss: 0.6865 - acc: 0.5505
7616/9333 [=======================>......] - ETA: 1:49 - loss: 0.6867 - acc: 0.5498
7680/9333 [=======================>......] - ETA: 1:45 - loss: 0.6869 - acc: 0.5493
7744/9333 [=======================>......] - ETA: 1:41 - loss: 0.6869 - acc: 0.5487
7808/9333 [========================>.....] - ETA: 1:37 - loss: 0.6869 - acc: 0.5484
7872/9333 [========================>.....] - ETA: 1:33 - loss: 0.6868 - acc: 0.5490
7936/9333 [========================>.....] - ETA: 1:29 - loss: 0.6870 - acc: 0.5488
8000/9333 [========================>.....] - ETA: 1:25 - loss: 0.6869 - acc: 0.5487
8064/9333 [========================>.....] - ETA: 1:21 - loss: 0.6871 - acc: 0.5479
8128/9333 [=========================>....] - ETA: 1:17 - loss: 0.6872 - acc: 0.5476
8192/9333 [=========================>....] - ETA: 1:13 - loss: 0.6873 - acc: 0.5469
8256/9333 [=========================>....] - ETA: 1:09 - loss: 0.6874 - acc: 0.5466
8320/9333 [=========================>....] - ETA: 1:05 - loss: 0.6874 - acc: 0.5466
8384/9333 [=========================>....] - ETA: 1:01 - loss: 0.6874 - acc: 0.5464
8448/9333 [==========================>...] - ETA: 56s - loss: 0.6875 - acc: 0.5459 
8512/9333 [==========================>...] - ETA: 52s - loss: 0.6874 - acc: 0.5468
8576/9333 [==========================>...] - ETA: 48s - loss: 0.6873 - acc: 0.5471
8640/9333 [==========================>...] - ETA: 44s - loss: 0.6873 - acc: 0.5475
8704/9333 [==========================>...] - ETA: 40s - loss: 0.6873 - acc: 0.5476
8768/9333 [===========================>..] - ETA: 36s - loss: 0.6873 - acc: 0.5484
8832/9333 [===========================>..] - ETA: 32s - loss: 0.6875 - acc: 0.5465
8896/9333 [===========================>..] - ETA: 28s - loss: 0.6875 - acc: 0.5464
8960/9333 [===========================>..] - ETA: 24s - loss: 0.6874 - acc: 0.5470
9024/9333 [============================>.] - ETA: 19s - loss: 0.6873 - acc: 0.5477
9088/9333 [============================>.] - ETA: 15s - loss: 0.6873 - acc: 0.5472
9152/9333 [============================>.] - ETA: 11s - loss: 0.6873 - acc: 0.5470
9216/9333 [============================>.] - ETA: 7s - loss: 0.6873 - acc: 0.5469 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6873 - acc: 0.5474
9333/9333 [==============================] - 629s 67ms/step - loss: 0.6872 - acc: 0.5476 - val_loss: 0.6851 - val_acc: 0.5593

Epoch 00009: val_acc improved from 0.55931 to 0.55931, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window05/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 10/10

  64/9333 [..............................] - ETA: 9:59 - loss: 0.6768 - acc: 0.6250
 128/9333 [..............................] - ETA: 10:18 - loss: 0.6788 - acc: 0.5938
 192/9333 [..............................] - ETA: 9:58 - loss: 0.6782 - acc: 0.5781 
 256/9333 [..............................] - ETA: 10:06 - loss: 0.6856 - acc: 0.5547
 320/9333 [>.............................] - ETA: 9:58 - loss: 0.6850 - acc: 0.5625 
 384/9333 [>.............................] - ETA: 10:08 - loss: 0.6896 - acc: 0.5469
 448/9333 [>.............................] - ETA: 10:12 - loss: 0.6911 - acc: 0.5312
 512/9333 [>.............................] - ETA: 10:04 - loss: 0.6894 - acc: 0.5312
 576/9333 [>.............................] - ETA: 9:59 - loss: 0.6896 - acc: 0.5295 
 640/9333 [=>............................] - ETA: 9:59 - loss: 0.6901 - acc: 0.5234
 704/9333 [=>............................] - ETA: 9:57 - loss: 0.6868 - acc: 0.5369
 768/9333 [=>............................] - ETA: 9:47 - loss: 0.6871 - acc: 0.5339
 832/9333 [=>............................] - ETA: 9:40 - loss: 0.6866 - acc: 0.5325
 896/9333 [=>............................] - ETA: 9:39 - loss: 0.6860 - acc: 0.5324
 960/9333 [==>...........................] - ETA: 9:34 - loss: 0.6870 - acc: 0.5260
1024/9333 [==>...........................] - ETA: 9:29 - loss: 0.6869 - acc: 0.5293
1088/9333 [==>...........................] - ETA: 9:22 - loss: 0.6859 - acc: 0.5368
1152/9333 [==>...........................] - ETA: 9:16 - loss: 0.6874 - acc: 0.5295
1216/9333 [==>...........................] - ETA: 9:13 - loss: 0.6864 - acc: 0.5321
1280/9333 [===>..........................] - ETA: 9:15 - loss: 0.6865 - acc: 0.5336
1344/9333 [===>..........................] - ETA: 9:13 - loss: 0.6864 - acc: 0.5312
1408/9333 [===>..........................] - ETA: 9:12 - loss: 0.6861 - acc: 0.5348
1472/9333 [===>..........................] - ETA: 9:10 - loss: 0.6862 - acc: 0.5333
1536/9333 [===>..........................] - ETA: 9:10 - loss: 0.6859 - acc: 0.5332
1600/9333 [====>.........................] - ETA: 9:06 - loss: 0.6856 - acc: 0.5337
1664/9333 [====>.........................] - ETA: 9:04 - loss: 0.6863 - acc: 0.5312
1728/9333 [====>.........................] - ETA: 9:02 - loss: 0.6851 - acc: 0.5341
1792/9333 [====>.........................] - ETA: 9:01 - loss: 0.6852 - acc: 0.5368
1856/9333 [====>.........................] - ETA: 8:58 - loss: 0.6847 - acc: 0.5388
1920/9333 [=====>........................] - ETA: 8:55 - loss: 0.6849 - acc: 0.5380
1984/9333 [=====>........................] - ETA: 8:54 - loss: 0.6847 - acc: 0.5403
2048/9333 [=====>........................] - ETA: 8:50 - loss: 0.6840 - acc: 0.5435
2112/9333 [=====>........................] - ETA: 8:48 - loss: 0.6823 - acc: 0.5492
2176/9333 [=====>........................] - ETA: 8:43 - loss: 0.6826 - acc: 0.5501
2240/9333 [======>.......................] - ETA: 8:41 - loss: 0.6831 - acc: 0.5487
2304/9333 [======>.......................] - ETA: 8:38 - loss: 0.6823 - acc: 0.5521
2368/9333 [======>.......................] - ETA: 8:33 - loss: 0.6826 - acc: 0.5507
2432/9333 [======>.......................] - ETA: 8:29 - loss: 0.6826 - acc: 0.5502
2496/9333 [=======>......................] - ETA: 8:26 - loss: 0.6840 - acc: 0.5477
2560/9333 [=======>......................] - ETA: 8:22 - loss: 0.6846 - acc: 0.5473
2624/9333 [=======>......................] - ETA: 8:18 - loss: 0.6849 - acc: 0.5465
2688/9333 [=======>......................] - ETA: 8:13 - loss: 0.6844 - acc: 0.5484
2752/9333 [=======>......................] - ETA: 8:08 - loss: 0.6844 - acc: 0.5494
2816/9333 [========>.....................] - ETA: 8:05 - loss: 0.6842 - acc: 0.5515
2880/9333 [========>.....................] - ETA: 8:00 - loss: 0.6846 - acc: 0.5521
2944/9333 [========>.....................] - ETA: 7:57 - loss: 0.6847 - acc: 0.5520
3008/9333 [========>.....................] - ETA: 7:54 - loss: 0.6851 - acc: 0.5499
3072/9333 [========>.....................] - ETA: 7:49 - loss: 0.6853 - acc: 0.5495
3136/9333 [=========>....................] - ETA: 7:45 - loss: 0.6850 - acc: 0.5494
3200/9333 [=========>....................] - ETA: 7:41 - loss: 0.6848 - acc: 0.5503
3264/9333 [=========>....................] - ETA: 7:37 - loss: 0.6855 - acc: 0.5478
3328/9333 [=========>....................] - ETA: 7:33 - loss: 0.6855 - acc: 0.5478
3392/9333 [=========>....................] - ETA: 7:29 - loss: 0.6850 - acc: 0.5498
3456/9333 [==========>...................] - ETA: 7:25 - loss: 0.6849 - acc: 0.5498
3520/9333 [==========>...................] - ETA: 7:21 - loss: 0.6848 - acc: 0.5497
3584/9333 [==========>...................] - ETA: 7:16 - loss: 0.6845 - acc: 0.5502
3648/9333 [==========>...................] - ETA: 7:11 - loss: 0.6845 - acc: 0.5513
3712/9333 [==========>...................] - ETA: 7:07 - loss: 0.6850 - acc: 0.5504
3776/9333 [===========>..................] - ETA: 7:03 - loss: 0.6843 - acc: 0.5522
3840/9333 [===========>..................] - ETA: 6:58 - loss: 0.6845 - acc: 0.5510
3904/9333 [===========>..................] - ETA: 6:53 - loss: 0.6847 - acc: 0.5502
3968/9333 [===========>..................] - ETA: 6:49 - loss: 0.6845 - acc: 0.5507
4032/9333 [===========>..................] - ETA: 6:44 - loss: 0.6846 - acc: 0.5501
4096/9333 [============>.................] - ETA: 6:39 - loss: 0.6847 - acc: 0.5496
4160/9333 [============>.................] - ETA: 6:35 - loss: 0.6841 - acc: 0.5514
4224/9333 [============>.................] - ETA: 6:30 - loss: 0.6842 - acc: 0.5492
4288/9333 [============>.................] - ETA: 6:25 - loss: 0.6842 - acc: 0.5499
4352/9333 [============>.................] - ETA: 6:21 - loss: 0.6840 - acc: 0.5508
4416/9333 [=============>................] - ETA: 6:16 - loss: 0.6843 - acc: 0.5498
4480/9333 [=============>................] - ETA: 6:12 - loss: 0.6844 - acc: 0.5493
4544/9333 [=============>................] - ETA: 6:07 - loss: 0.6845 - acc: 0.5500
4608/9333 [=============>................] - ETA: 6:02 - loss: 0.6844 - acc: 0.5501
4672/9333 [==============>...............] - ETA: 5:58 - loss: 0.6846 - acc: 0.5490
4736/9333 [==============>...............] - ETA: 5:53 - loss: 0.6846 - acc: 0.5496
4800/9333 [==============>...............] - ETA: 5:48 - loss: 0.6847 - acc: 0.5496
4864/9333 [==============>...............] - ETA: 5:43 - loss: 0.6847 - acc: 0.5495
4928/9333 [==============>...............] - ETA: 5:39 - loss: 0.6845 - acc: 0.5501
4992/9333 [===============>..............] - ETA: 5:34 - loss: 0.6843 - acc: 0.5497
5056/9333 [===============>..............] - ETA: 5:29 - loss: 0.6840 - acc: 0.5504
5120/9333 [===============>..............] - ETA: 5:25 - loss: 0.6842 - acc: 0.5494
5184/9333 [===============>..............] - ETA: 5:19 - loss: 0.6844 - acc: 0.5490
5248/9333 [===============>..............] - ETA: 5:15 - loss: 0.6846 - acc: 0.5484
5312/9333 [================>.............] - ETA: 5:10 - loss: 0.6847 - acc: 0.5482
5376/9333 [================>.............] - ETA: 5:05 - loss: 0.6849 - acc: 0.5476
5440/9333 [================>.............] - ETA: 5:00 - loss: 0.6850 - acc: 0.5474
5504/9333 [================>.............] - ETA: 4:55 - loss: 0.6848 - acc: 0.5480
5568/9333 [================>.............] - ETA: 4:50 - loss: 0.6846 - acc: 0.5487
5632/9333 [=================>............] - ETA: 4:45 - loss: 0.6844 - acc: 0.5501
5696/9333 [=================>............] - ETA: 4:41 - loss: 0.6846 - acc: 0.5502
5760/9333 [=================>............] - ETA: 4:35 - loss: 0.6849 - acc: 0.5488
5824/9333 [=================>............] - ETA: 4:31 - loss: 0.6851 - acc: 0.5482
5888/9333 [=================>............] - ETA: 4:26 - loss: 0.6850 - acc: 0.5481
5952/9333 [==================>...........] - ETA: 4:21 - loss: 0.6855 - acc: 0.5467
6016/9333 [==================>...........] - ETA: 4:16 - loss: 0.6857 - acc: 0.5457
6080/9333 [==================>...........] - ETA: 4:11 - loss: 0.6856 - acc: 0.5462
6144/9333 [==================>...........] - ETA: 4:06 - loss: 0.6857 - acc: 0.5454
6208/9333 [==================>...........] - ETA: 4:02 - loss: 0.6856 - acc: 0.5454
6272/9333 [===================>..........] - ETA: 3:56 - loss: 0.6856 - acc: 0.5458
6336/9333 [===================>..........] - ETA: 3:52 - loss: 0.6857 - acc: 0.5455
6400/9333 [===================>..........] - ETA: 3:47 - loss: 0.6858 - acc: 0.5448
6464/9333 [===================>..........] - ETA: 3:42 - loss: 0.6858 - acc: 0.5449
6528/9333 [===================>..........] - ETA: 3:37 - loss: 0.6858 - acc: 0.5450
6592/9333 [====================>.........] - ETA: 3:32 - loss: 0.6861 - acc: 0.5448
6656/9333 [====================>.........] - ETA: 3:27 - loss: 0.6862 - acc: 0.5445
6720/9333 [====================>.........] - ETA: 3:22 - loss: 0.6862 - acc: 0.5443
6784/9333 [====================>.........] - ETA: 3:17 - loss: 0.6865 - acc: 0.5429
6848/9333 [=====================>........] - ETA: 3:13 - loss: 0.6868 - acc: 0.5419
6912/9333 [=====================>........] - ETA: 3:08 - loss: 0.6868 - acc: 0.5418
6976/9333 [=====================>........] - ETA: 3:03 - loss: 0.6868 - acc: 0.5426
7040/9333 [=====================>........] - ETA: 2:58 - loss: 0.6867 - acc: 0.5429
7104/9333 [=====================>........] - ETA: 2:53 - loss: 0.6868 - acc: 0.5422
7168/9333 [======================>.......] - ETA: 2:48 - loss: 0.6869 - acc: 0.5419
7232/9333 [======================>.......] - ETA: 2:43 - loss: 0.6871 - acc: 0.5409
7296/9333 [======================>.......] - ETA: 2:38 - loss: 0.6872 - acc: 0.5406
7360/9333 [======================>.......] - ETA: 2:33 - loss: 0.6871 - acc: 0.5412
7424/9333 [======================>.......] - ETA: 2:28 - loss: 0.6872 - acc: 0.5407
7488/9333 [=======================>......] - ETA: 2:23 - loss: 0.6871 - acc: 0.5409
7552/9333 [=======================>......] - ETA: 2:18 - loss: 0.6871 - acc: 0.5407
7616/9333 [=======================>......] - ETA: 2:13 - loss: 0.6871 - acc: 0.5408
7680/9333 [=======================>......] - ETA: 2:08 - loss: 0.6870 - acc: 0.5415
7744/9333 [=======================>......] - ETA: 2:03 - loss: 0.6871 - acc: 0.5409
7808/9333 [========================>.....] - ETA: 1:58 - loss: 0.6872 - acc: 0.5411
7872/9333 [========================>.....] - ETA: 1:53 - loss: 0.6873 - acc: 0.5399
7936/9333 [========================>.....] - ETA: 1:48 - loss: 0.6872 - acc: 0.5402
8000/9333 [========================>.....] - ETA: 1:43 - loss: 0.6872 - acc: 0.5400
8064/9333 [========================>.....] - ETA: 1:38 - loss: 0.6872 - acc: 0.5398
8128/9333 [=========================>....] - ETA: 1:33 - loss: 0.6871 - acc: 0.5397
8192/9333 [=========================>....] - ETA: 1:28 - loss: 0.6871 - acc: 0.5403
8256/9333 [=========================>....] - ETA: 1:23 - loss: 0.6871 - acc: 0.5396
8320/9333 [=========================>....] - ETA: 1:18 - loss: 0.6871 - acc: 0.5393
8384/9333 [=========================>....] - ETA: 1:13 - loss: 0.6871 - acc: 0.5392
8448/9333 [==========================>...] - ETA: 1:09 - loss: 0.6871 - acc: 0.5389
8512/9333 [==========================>...] - ETA: 1:04 - loss: 0.6869 - acc: 0.5402
8576/9333 [==========================>...] - ETA: 59s - loss: 0.6869 - acc: 0.5405 
8640/9333 [==========================>...] - ETA: 54s - loss: 0.6867 - acc: 0.5411
8704/9333 [==========================>...] - ETA: 49s - loss: 0.6866 - acc: 0.5417
8768/9333 [===========================>..] - ETA: 44s - loss: 0.6864 - acc: 0.5427
8832/9333 [===========================>..] - ETA: 39s - loss: 0.6864 - acc: 0.5428
8896/9333 [===========================>..] - ETA: 34s - loss: 0.6866 - acc: 0.5429
8960/9333 [===========================>..] - ETA: 29s - loss: 0.6865 - acc: 0.5431
9024/9333 [============================>.] - ETA: 24s - loss: 0.6865 - acc: 0.5438
9088/9333 [============================>.] - ETA: 19s - loss: 0.6864 - acc: 0.5438
9152/9333 [============================>.] - ETA: 14s - loss: 0.6863 - acc: 0.5440
9216/9333 [============================>.] - ETA: 9s - loss: 0.6864 - acc: 0.5441 
9280/9333 [============================>.] - ETA: 4s - loss: 0.6865 - acc: 0.5436
9333/9333 [==============================] - 758s 81ms/step - loss: 0.6865 - acc: 0.5433 - val_loss: 0.6839 - val_acc: 0.5574

Epoch 00010: val_acc did not improve from 0.55931
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f47c4727210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f47c4727210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f47c46cffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f47c46cffd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f434c0fb490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f434c0fb490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47a8733110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47a8733110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47a8619690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47a8619690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a83c6490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a83c6490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47a8733890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47a8733890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a86da990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a86da990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47a83809d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47a83809d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47a83a0750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47a83a0750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a84362d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a84362d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47a8380510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47a8380510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a8347f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a8347f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42c43906d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42c43906d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47a8129e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47a8129e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a8168050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a8168050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47a82d73d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47a82d73d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a8121690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47a8121690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47a8170250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47a8170250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47845dbad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47845dbad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f478447a9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f478447a9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47a823add0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47a823add0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47845cc710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47845cc710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4784660e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4784660e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47842abad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47842abad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4784361650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4784361650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47845d34d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47845d34d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47842ab750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47842ab750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f478408f110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f478408f110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47647eb850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47647eb850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f476474f2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f476474f2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f478408f890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f478408f890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4784175e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4784175e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46840eb110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46840eb110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4664738a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4664738a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46840eb650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46840eb650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f478407ba10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f478407ba10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46840eb9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46840eb9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46647070d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46647070d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46644247d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46644247d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f434c219f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f434c219f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46645f7f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46645f7f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46643d1310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46643d1310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46643d4210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46643d4210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46640c8550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f46640c8550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4664424b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4664424b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46641d6890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46641d6890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46407b7c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46407b7c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4640688ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4640688ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4640637dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4640637dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46640b9850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46640b9850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4640688210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4640688210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46405a94d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46405a94d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46403684d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f46403684d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f464024fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f464024fd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4640174290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4640174290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4640454a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4640454a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46641e3a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46641e3a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f464004e390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f464004e390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4628733850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4628733850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46285c16d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f46285c16d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46286dd350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f46286dd350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4640097810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4640097810>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 6:43
 128/2592 [>.............................] - ETA: 3:51
 192/2592 [=>............................] - ETA: 2:51
 256/2592 [=>............................] - ETA: 2:20
 320/2592 [==>...........................] - ETA: 2:00
 384/2592 [===>..........................] - ETA: 1:47
 448/2592 [====>.........................] - ETA: 1:37
 512/2592 [====>.........................] - ETA: 1:29
 576/2592 [=====>........................] - ETA: 1:23
 640/2592 [======>.......................] - ETA: 1:18
 704/2592 [=======>......................] - ETA: 1:13
 768/2592 [=======>......................] - ETA: 1:09
 832/2592 [========>.....................] - ETA: 1:06
 896/2592 [=========>....................] - ETA: 1:02
 960/2592 [==========>...................] - ETA: 59s 
1024/2592 [==========>...................] - ETA: 55s
1088/2592 [===========>..................] - ETA: 52s
1152/2592 [============>.................] - ETA: 50s
1216/2592 [=============>................] - ETA: 47s
1280/2592 [=============>................] - ETA: 44s
1344/2592 [==============>...............] - ETA: 42s
1408/2592 [===============>..............] - ETA: 40s
1472/2592 [================>.............] - ETA: 37s
1536/2592 [================>.............] - ETA: 35s
1600/2592 [=================>............] - ETA: 33s
1664/2592 [==================>...........] - ETA: 30s
1728/2592 [===================>..........] - ETA: 28s
1792/2592 [===================>..........] - ETA: 26s
1856/2592 [====================>.........] - ETA: 24s
1920/2592 [=====================>........] - ETA: 21s
1984/2592 [=====================>........] - ETA: 19s
2048/2592 [======================>.......] - ETA: 17s
2112/2592 [=======================>......] - ETA: 15s
2176/2592 [========================>.....] - ETA: 13s
2240/2592 [========================>.....] - ETA: 11s
2304/2592 [=========================>....] - ETA: 9s 
2368/2592 [==========================>...] - ETA: 7s
2432/2592 [===========================>..] - ETA: 5s
2496/2592 [===========================>..] - ETA: 2s
2560/2592 [============================>.] - ETA: 1s
2592/2592 [==============================] - 81s 31ms/step
loss: 0.6872100991967284
acc: 0.5486111111111112
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4284779c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f4284779c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f414449d690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f414449d690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40886bf590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40886bf590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45e44d3310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45e44d3310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47c4090950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47c4090950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41443d11d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41443d11d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45e44d3450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45e44d3450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41443bd950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41443bd950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47c462e250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47c462e250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47c4476a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47c4476a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41443dc610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41443dc610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47c42f3810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47c42f3810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47c46b57d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47c46b57d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47c446ee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f47c446ee50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47c40e8e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f47c40e8e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47c4460590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47c4460590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47c446e050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f47c446e050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47c4460a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47c4460a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41442b2750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41442b2750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41440c3bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41440c3bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4144259050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4144259050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f414433e850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f414433e850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f414412b650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f414412b650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41247014d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41247014d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41245da810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41245da810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4124706590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4124706590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41440f9310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41440f9310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4124586ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4124586ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41243f2d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41243f2d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f412435e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f412435e3d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41242ef390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41242ef390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41243f20d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41243f20d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41245c2d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41245c2d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4124169fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4124169fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f410475b290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f410475b290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4124194b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4124194b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41242e2c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41242e2c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41240b7350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41240b7350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41047e3c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41047e3c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4104433fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4104433fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4104313190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4104313190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41242a84d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41242a84d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f410446ca50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f410446ca50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4104753a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4104753a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4104116750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4104116750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c46be890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c46be890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f410451a450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f410451a450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41040c0f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41040c0f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4104116b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4104116b10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f40e45f6110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f40e45f6110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40e4706450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40e4706450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40e45e7810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40e45e7810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40e45dd7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40e45dd7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f40e45a6090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f40e45a6090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f40e4295990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f40e4295990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40e41b48d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40e41b48d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40e448d490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40e448d490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40e431a850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40e431a850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f40e403dd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f40e403dd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f40c8723e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f40c8723e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40c8610450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40c8610450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40e403d810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40e403d810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40c8616e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40c8616e50>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 1:10:06 - loss: 0.8369 - acc: 0.3750
 128/9333 [..............................] - ETA: 41:25 - loss: 0.8337 - acc: 0.4141  
 192/9333 [..............................] - ETA: 31:30 - loss: 0.8110 - acc: 0.4427
 256/9333 [..............................] - ETA: 26:34 - loss: 0.8015 - acc: 0.4492
 320/9333 [>.............................] - ETA: 23:55 - loss: 0.7840 - acc: 0.4594
 384/9333 [>.............................] - ETA: 22:03 - loss: 0.7771 - acc: 0.4583
 448/9333 [>.............................] - ETA: 20:26 - loss: 0.7730 - acc: 0.4710
 512/9333 [>.............................] - ETA: 19:16 - loss: 0.7707 - acc: 0.4727
 576/9333 [>.............................] - ETA: 18:28 - loss: 0.7654 - acc: 0.4774
 640/9333 [=>............................] - ETA: 17:39 - loss: 0.7625 - acc: 0.4813
 704/9333 [=>............................] - ETA: 16:58 - loss: 0.7599 - acc: 0.4830
 768/9333 [=>............................] - ETA: 16:25 - loss: 0.7611 - acc: 0.4831
 832/9333 [=>............................] - ETA: 16:03 - loss: 0.7588 - acc: 0.4820
 896/9333 [=>............................] - ETA: 15:38 - loss: 0.7559 - acc: 0.4844
 960/9333 [==>...........................] - ETA: 15:15 - loss: 0.7577 - acc: 0.4865
1024/9333 [==>...........................] - ETA: 14:54 - loss: 0.7593 - acc: 0.4844
1088/9333 [==>...........................] - ETA: 14:37 - loss: 0.7569 - acc: 0.4871
1152/9333 [==>...........................] - ETA: 14:19 - loss: 0.7553 - acc: 0.4861
1216/9333 [==>...........................] - ETA: 14:02 - loss: 0.7521 - acc: 0.4893
1280/9333 [===>..........................] - ETA: 13:45 - loss: 0.7497 - acc: 0.4898
1344/9333 [===>..........................] - ETA: 13:35 - loss: 0.7470 - acc: 0.4933
1408/9333 [===>..........................] - ETA: 13:23 - loss: 0.7464 - acc: 0.4943
1472/9333 [===>..........................] - ETA: 13:08 - loss: 0.7438 - acc: 0.4959
1536/9333 [===>..........................] - ETA: 12:55 - loss: 0.7441 - acc: 0.4922
1600/9333 [====>.........................] - ETA: 12:42 - loss: 0.7440 - acc: 0.4900
1664/9333 [====>.........................] - ETA: 12:33 - loss: 0.7414 - acc: 0.4916
1728/9333 [====>.........................] - ETA: 12:21 - loss: 0.7403 - acc: 0.4931
1792/9333 [====>.........................] - ETA: 12:11 - loss: 0.7395 - acc: 0.4933
1856/9333 [====>.........................] - ETA: 12:01 - loss: 0.7387 - acc: 0.4952
1920/9333 [=====>........................] - ETA: 11:51 - loss: 0.7387 - acc: 0.4958
1984/9333 [=====>........................] - ETA: 11:39 - loss: 0.7377 - acc: 0.4950
2048/9333 [=====>........................] - ETA: 11:32 - loss: 0.7362 - acc: 0.4971
2112/9333 [=====>........................] - ETA: 11:23 - loss: 0.7349 - acc: 0.4981
2176/9333 [=====>........................] - ETA: 11:14 - loss: 0.7344 - acc: 0.4968
2240/9333 [======>.......................] - ETA: 11:05 - loss: 0.7341 - acc: 0.4982
2304/9333 [======>.......................] - ETA: 10:58 - loss: 0.7328 - acc: 0.4965
2368/9333 [======>.......................] - ETA: 10:49 - loss: 0.7322 - acc: 0.4945
2432/9333 [======>.......................] - ETA: 10:41 - loss: 0.7313 - acc: 0.4959
2496/9333 [=======>......................] - ETA: 10:32 - loss: 0.7301 - acc: 0.4988
2560/9333 [=======>......................] - ETA: 10:26 - loss: 0.7310 - acc: 0.4969
2624/9333 [=======>......................] - ETA: 10:18 - loss: 0.7301 - acc: 0.4981
2688/9333 [=======>......................] - ETA: 10:10 - loss: 0.7312 - acc: 0.4944
2752/9333 [=======>......................] - ETA: 10:02 - loss: 0.7310 - acc: 0.4924
2816/9333 [========>.....................] - ETA: 9:55 - loss: 0.7307 - acc: 0.4922 
2880/9333 [========>.....................] - ETA: 9:48 - loss: 0.7295 - acc: 0.4944
2944/9333 [========>.....................] - ETA: 9:41 - loss: 0.7296 - acc: 0.4942
3008/9333 [========>.....................] - ETA: 9:33 - loss: 0.7293 - acc: 0.4947
3072/9333 [========>.....................] - ETA: 9:25 - loss: 0.7286 - acc: 0.4951
3136/9333 [=========>....................] - ETA: 9:20 - loss: 0.7276 - acc: 0.4952
3200/9333 [=========>....................] - ETA: 9:13 - loss: 0.7271 - acc: 0.4941
3264/9333 [=========>....................] - ETA: 9:06 - loss: 0.7260 - acc: 0.4957
3328/9333 [=========>....................] - ETA: 9:00 - loss: 0.7250 - acc: 0.4973
3392/9333 [=========>....................] - ETA: 8:53 - loss: 0.7245 - acc: 0.4968
3456/9333 [==========>...................] - ETA: 8:47 - loss: 0.7251 - acc: 0.4948
3520/9333 [==========>...................] - ETA: 8:40 - loss: 0.7241 - acc: 0.4957
3584/9333 [==========>...................] - ETA: 8:33 - loss: 0.7243 - acc: 0.4955
3648/9333 [==========>...................] - ETA: 8:27 - loss: 0.7248 - acc: 0.4942
3712/9333 [==========>...................] - ETA: 8:21 - loss: 0.7240 - acc: 0.4957
3776/9333 [===========>..................] - ETA: 8:14 - loss: 0.7248 - acc: 0.4950
3840/9333 [===========>..................] - ETA: 8:07 - loss: 0.7250 - acc: 0.4943
3904/9333 [===========>..................] - ETA: 8:00 - loss: 0.7253 - acc: 0.4939
3968/9333 [===========>..................] - ETA: 7:53 - loss: 0.7251 - acc: 0.4934
4032/9333 [===========>..................] - ETA: 7:46 - loss: 0.7245 - acc: 0.4940
4096/9333 [============>.................] - ETA: 7:39 - loss: 0.7239 - acc: 0.4946
4160/9333 [============>.................] - ETA: 7:32 - loss: 0.7237 - acc: 0.4942
4224/9333 [============>.................] - ETA: 7:25 - loss: 0.7234 - acc: 0.4960
4288/9333 [============>.................] - ETA: 7:18 - loss: 0.7232 - acc: 0.4951
4352/9333 [============>.................] - ETA: 7:11 - loss: 0.7232 - acc: 0.4954
4416/9333 [=============>................] - ETA: 7:04 - loss: 0.7227 - acc: 0.4964
4480/9333 [=============>................] - ETA: 6:58 - loss: 0.7228 - acc: 0.4955
4544/9333 [=============>................] - ETA: 6:52 - loss: 0.7226 - acc: 0.4960
4608/9333 [=============>................] - ETA: 6:46 - loss: 0.7217 - acc: 0.4970
4672/9333 [==============>...............] - ETA: 6:39 - loss: 0.7217 - acc: 0.4970
4736/9333 [==============>...............] - ETA: 6:33 - loss: 0.7215 - acc: 0.4970
4800/9333 [==============>...............] - ETA: 6:27 - loss: 0.7209 - acc: 0.4985
4864/9333 [==============>...............] - ETA: 6:21 - loss: 0.7208 - acc: 0.4981
4928/9333 [==============>...............] - ETA: 6:15 - loss: 0.7205 - acc: 0.4982
4992/9333 [===============>..............] - ETA: 6:09 - loss: 0.7198 - acc: 0.4980
5056/9333 [===============>..............] - ETA: 6:03 - loss: 0.7198 - acc: 0.4980
5120/9333 [===============>..............] - ETA: 5:57 - loss: 0.7196 - acc: 0.4984
5184/9333 [===============>..............] - ETA: 5:51 - loss: 0.7194 - acc: 0.4990
5248/9333 [===============>..............] - ETA: 5:45 - loss: 0.7191 - acc: 0.5004
5312/9333 [================>.............] - ETA: 5:39 - loss: 0.7183 - acc: 0.5013
5376/9333 [================>.............] - ETA: 5:33 - loss: 0.7180 - acc: 0.5009
5440/9333 [================>.............] - ETA: 5:28 - loss: 0.7182 - acc: 0.5004
5504/9333 [================>.............] - ETA: 5:22 - loss: 0.7183 - acc: 0.4996
5568/9333 [================>.............] - ETA: 5:16 - loss: 0.7183 - acc: 0.4996
5632/9333 [=================>............] - ETA: 5:10 - loss: 0.7181 - acc: 0.4998
5696/9333 [=================>............] - ETA: 5:04 - loss: 0.7180 - acc: 0.4996
5760/9333 [=================>............] - ETA: 4:59 - loss: 0.7181 - acc: 0.4990
5824/9333 [=================>............] - ETA: 4:53 - loss: 0.7181 - acc: 0.4983
5888/9333 [=================>............] - ETA: 4:47 - loss: 0.7180 - acc: 0.4983
5952/9333 [==================>...........] - ETA: 4:41 - loss: 0.7181 - acc: 0.4987
6016/9333 [==================>...........] - ETA: 4:36 - loss: 0.7179 - acc: 0.4992
6080/9333 [==================>...........] - ETA: 4:30 - loss: 0.7177 - acc: 0.4993
6144/9333 [==================>...........] - ETA: 4:24 - loss: 0.7180 - acc: 0.4977
6208/9333 [==================>...........] - ETA: 4:19 - loss: 0.7173 - acc: 0.4990
6272/9333 [===================>..........] - ETA: 4:13 - loss: 0.7168 - acc: 0.5000
6336/9333 [===================>..........] - ETA: 4:08 - loss: 0.7168 - acc: 0.5002
6400/9333 [===================>..........] - ETA: 4:02 - loss: 0.7162 - acc: 0.5014
6464/9333 [===================>..........] - ETA: 3:56 - loss: 0.7162 - acc: 0.5011
6528/9333 [===================>..........] - ETA: 3:51 - loss: 0.7156 - acc: 0.5020
6592/9333 [====================>.........] - ETA: 3:45 - loss: 0.7156 - acc: 0.5018
6656/9333 [====================>.........] - ETA: 3:40 - loss: 0.7157 - acc: 0.5014
6720/9333 [====================>.........] - ETA: 3:35 - loss: 0.7159 - acc: 0.5006
6784/9333 [====================>.........] - ETA: 3:29 - loss: 0.7159 - acc: 0.5006
6848/9333 [=====================>........] - ETA: 3:24 - loss: 0.7158 - acc: 0.5009
6912/9333 [=====================>........] - ETA: 3:18 - loss: 0.7160 - acc: 0.5001
6976/9333 [=====================>........] - ETA: 3:13 - loss: 0.7162 - acc: 0.5004
7040/9333 [=====================>........] - ETA: 3:07 - loss: 0.7163 - acc: 0.5000
7104/9333 [=====================>........] - ETA: 3:02 - loss: 0.7162 - acc: 0.5004
7168/9333 [======================>.......] - ETA: 2:57 - loss: 0.7161 - acc: 0.5007
7232/9333 [======================>.......] - ETA: 2:51 - loss: 0.7162 - acc: 0.5006
7296/9333 [======================>.......] - ETA: 2:46 - loss: 0.7161 - acc: 0.5007
7360/9333 [======================>.......] - ETA: 2:41 - loss: 0.7161 - acc: 0.5001
7424/9333 [======================>.......] - ETA: 2:35 - loss: 0.7158 - acc: 0.5003
7488/9333 [=======================>......] - ETA: 2:30 - loss: 0.7159 - acc: 0.5005
7552/9333 [=======================>......] - ETA: 2:25 - loss: 0.7160 - acc: 0.4997
7616/9333 [=======================>......] - ETA: 2:19 - loss: 0.7157 - acc: 0.5001
7680/9333 [=======================>......] - ETA: 2:14 - loss: 0.7155 - acc: 0.4999
7744/9333 [=======================>......] - ETA: 2:09 - loss: 0.7157 - acc: 0.4988
7808/9333 [========================>.....] - ETA: 2:03 - loss: 0.7153 - acc: 0.4996
7872/9333 [========================>.....] - ETA: 1:58 - loss: 0.7153 - acc: 0.4994
7936/9333 [========================>.....] - ETA: 1:53 - loss: 0.7153 - acc: 0.4991
8000/9333 [========================>.....] - ETA: 1:47 - loss: 0.7151 - acc: 0.4989
8064/9333 [========================>.....] - ETA: 1:42 - loss: 0.7151 - acc: 0.4986
8128/9333 [=========================>....] - ETA: 1:37 - loss: 0.7150 - acc: 0.4991
8192/9333 [=========================>....] - ETA: 1:32 - loss: 0.7149 - acc: 0.4995
8256/9333 [=========================>....] - ETA: 1:27 - loss: 0.7148 - acc: 0.4990
8320/9333 [=========================>....] - ETA: 1:21 - loss: 0.7145 - acc: 0.4994
8384/9333 [=========================>....] - ETA: 1:16 - loss: 0.7143 - acc: 0.4999
8448/9333 [==========================>...] - ETA: 1:11 - loss: 0.7143 - acc: 0.5004
8512/9333 [==========================>...] - ETA: 1:06 - loss: 0.7142 - acc: 0.5002
8576/9333 [==========================>...] - ETA: 1:01 - loss: 0.7142 - acc: 0.5005
8640/9333 [==========================>...] - ETA: 55s - loss: 0.7140 - acc: 0.5003 
8704/9333 [==========================>...] - ETA: 50s - loss: 0.7140 - acc: 0.5006
8768/9333 [===========================>..] - ETA: 45s - loss: 0.7140 - acc: 0.5003
8832/9333 [===========================>..] - ETA: 40s - loss: 0.7137 - acc: 0.5007
8896/9333 [===========================>..] - ETA: 35s - loss: 0.7137 - acc: 0.5008
8960/9333 [===========================>..] - ETA: 29s - loss: 0.7134 - acc: 0.5010
9024/9333 [============================>.] - ETA: 24s - loss: 0.7133 - acc: 0.5014
9088/9333 [============================>.] - ETA: 19s - loss: 0.7132 - acc: 0.5014
9152/9333 [============================>.] - ETA: 14s - loss: 0.7131 - acc: 0.5013
9216/9333 [============================>.] - ETA: 9s - loss: 0.7128 - acc: 0.5016 
9280/9333 [============================>.] - ETA: 4s - loss: 0.7127 - acc: 0.5019
9333/9333 [==============================] - 776s 83ms/step - loss: 0.7127 - acc: 0.5019 - val_loss: 0.6924 - val_acc: 0.5217

Epoch 00001: val_acc improved from -inf to 0.52170, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window06/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 13:24 - loss: 0.6896 - acc: 0.5156
 128/9333 [..............................] - ETA: 12:24 - loss: 0.6842 - acc: 0.5234
 192/9333 [..............................] - ETA: 11:35 - loss: 0.6931 - acc: 0.5312
 256/9333 [..............................] - ETA: 11:07 - loss: 0.6955 - acc: 0.5234
 320/9333 [>.............................] - ETA: 11:14 - loss: 0.6919 - acc: 0.5281
 384/9333 [>.............................] - ETA: 11:13 - loss: 0.6909 - acc: 0.5312
 448/9333 [>.............................] - ETA: 11:07 - loss: 0.6933 - acc: 0.5268
 512/9333 [>.............................] - ETA: 11:00 - loss: 0.6967 - acc: 0.5137
 576/9333 [>.............................] - ETA: 10:52 - loss: 0.6973 - acc: 0.5087
 640/9333 [=>............................] - ETA: 10:53 - loss: 0.6966 - acc: 0.5078
 704/9333 [=>............................] - ETA: 10:45 - loss: 0.6962 - acc: 0.5071
 768/9333 [=>............................] - ETA: 10:38 - loss: 0.6957 - acc: 0.5104
 832/9333 [=>............................] - ETA: 10:34 - loss: 0.6965 - acc: 0.5108
 896/9333 [=>............................] - ETA: 10:31 - loss: 0.6960 - acc: 0.5145
 960/9333 [==>...........................] - ETA: 10:25 - loss: 0.6961 - acc: 0.5156
1024/9333 [==>...........................] - ETA: 10:22 - loss: 0.6945 - acc: 0.5234
1088/9333 [==>...........................] - ETA: 10:14 - loss: 0.6937 - acc: 0.5257
1152/9333 [==>...........................] - ETA: 10:10 - loss: 0.6956 - acc: 0.5217
1216/9333 [==>...........................] - ETA: 10:02 - loss: 0.6961 - acc: 0.5197
1280/9333 [===>..........................] - ETA: 9:58 - loss: 0.6970 - acc: 0.5188 
1344/9333 [===>..........................] - ETA: 9:53 - loss: 0.6957 - acc: 0.5231
1408/9333 [===>..........................] - ETA: 9:45 - loss: 0.6960 - acc: 0.5213
1472/9333 [===>..........................] - ETA: 9:42 - loss: 0.6967 - acc: 0.5177
1536/9333 [===>..........................] - ETA: 9:36 - loss: 0.6950 - acc: 0.5228
1600/9333 [====>.........................] - ETA: 9:33 - loss: 0.6940 - acc: 0.5250
1664/9333 [====>.........................] - ETA: 9:26 - loss: 0.6944 - acc: 0.5222
1728/9333 [====>.........................] - ETA: 9:21 - loss: 0.6948 - acc: 0.5203
1792/9333 [====>.........................] - ETA: 9:15 - loss: 0.6951 - acc: 0.5195
1856/9333 [====>.........................] - ETA: 9:10 - loss: 0.6949 - acc: 0.5210
1920/9333 [=====>........................] - ETA: 9:05 - loss: 0.6952 - acc: 0.5208
1984/9333 [=====>........................] - ETA: 8:59 - loss: 0.6958 - acc: 0.5192
2048/9333 [=====>........................] - ETA: 8:55 - loss: 0.6967 - acc: 0.5176
2112/9333 [=====>........................] - ETA: 8:49 - loss: 0.6971 - acc: 0.5170
2176/9333 [=====>........................] - ETA: 8:45 - loss: 0.6966 - acc: 0.5175
2240/9333 [======>.......................] - ETA: 8:39 - loss: 0.6974 - acc: 0.5165
2304/9333 [======>.......................] - ETA: 8:35 - loss: 0.6969 - acc: 0.5165
2368/9333 [======>.......................] - ETA: 8:30 - loss: 0.6966 - acc: 0.5165
2432/9333 [======>.......................] - ETA: 8:26 - loss: 0.6967 - acc: 0.5160
2496/9333 [=======>......................] - ETA: 8:22 - loss: 0.6961 - acc: 0.5192
2560/9333 [=======>......................] - ETA: 8:18 - loss: 0.6954 - acc: 0.5215
2624/9333 [=======>......................] - ETA: 8:13 - loss: 0.6961 - acc: 0.5198
2688/9333 [=======>......................] - ETA: 8:09 - loss: 0.6956 - acc: 0.5216
2752/9333 [=======>......................] - ETA: 8:05 - loss: 0.6964 - acc: 0.5189
2816/9333 [========>.....................] - ETA: 8:01 - loss: 0.6959 - acc: 0.5206
2880/9333 [========>.....................] - ETA: 7:56 - loss: 0.6957 - acc: 0.5212
2944/9333 [========>.....................] - ETA: 7:52 - loss: 0.6952 - acc: 0.5231
3008/9333 [========>.....................] - ETA: 7:48 - loss: 0.6951 - acc: 0.5233
3072/9333 [========>.....................] - ETA: 7:44 - loss: 0.6951 - acc: 0.5244
3136/9333 [=========>....................] - ETA: 7:39 - loss: 0.6946 - acc: 0.5261
3200/9333 [=========>....................] - ETA: 7:35 - loss: 0.6943 - acc: 0.5266
3264/9333 [=========>....................] - ETA: 7:30 - loss: 0.6941 - acc: 0.5263
3328/9333 [=========>....................] - ETA: 7:26 - loss: 0.6937 - acc: 0.5273
3392/9333 [=========>....................] - ETA: 7:22 - loss: 0.6939 - acc: 0.5262
3456/9333 [==========>...................] - ETA: 7:18 - loss: 0.6936 - acc: 0.5275
3520/9333 [==========>...................] - ETA: 7:14 - loss: 0.6932 - acc: 0.5290
3584/9333 [==========>...................] - ETA: 7:10 - loss: 0.6937 - acc: 0.5282
3648/9333 [==========>...................] - ETA: 7:05 - loss: 0.6944 - acc: 0.5266
3712/9333 [==========>...................] - ETA: 7:01 - loss: 0.6949 - acc: 0.5256
3776/9333 [===========>..................] - ETA: 6:57 - loss: 0.6952 - acc: 0.5241
3840/9333 [===========>..................] - ETA: 6:53 - loss: 0.6948 - acc: 0.5253
3904/9333 [===========>..................] - ETA: 6:49 - loss: 0.6948 - acc: 0.5251
3968/9333 [===========>..................] - ETA: 6:44 - loss: 0.6953 - acc: 0.5229
4032/9333 [===========>..................] - ETA: 6:41 - loss: 0.6949 - acc: 0.5243
4096/9333 [============>.................] - ETA: 6:37 - loss: 0.6950 - acc: 0.5237
4160/9333 [============>.................] - ETA: 6:32 - loss: 0.6949 - acc: 0.5231
4224/9333 [============>.................] - ETA: 6:27 - loss: 0.6954 - acc: 0.5220
4288/9333 [============>.................] - ETA: 6:24 - loss: 0.6950 - acc: 0.5233
4352/9333 [============>.................] - ETA: 6:20 - loss: 0.6951 - acc: 0.5223
4416/9333 [=============>................] - ETA: 6:15 - loss: 0.6950 - acc: 0.5226
4480/9333 [=============>................] - ETA: 6:10 - loss: 0.6948 - acc: 0.5237
4544/9333 [=============>................] - ETA: 6:06 - loss: 0.6947 - acc: 0.5238
4608/9333 [=============>................] - ETA: 6:02 - loss: 0.6949 - acc: 0.5234
4672/9333 [==============>...............] - ETA: 5:57 - loss: 0.6954 - acc: 0.5223
4736/9333 [==============>...............] - ETA: 5:52 - loss: 0.6952 - acc: 0.5224
4800/9333 [==============>...............] - ETA: 5:48 - loss: 0.6952 - acc: 0.5221
4864/9333 [==============>...............] - ETA: 5:43 - loss: 0.6951 - acc: 0.5216
4928/9333 [==============>...............] - ETA: 5:39 - loss: 0.6952 - acc: 0.5213
4992/9333 [===============>..............] - ETA: 5:34 - loss: 0.6952 - acc: 0.5212
5056/9333 [===============>..............] - ETA: 5:30 - loss: 0.6951 - acc: 0.5218
5120/9333 [===============>..............] - ETA: 5:26 - loss: 0.6950 - acc: 0.5219
5184/9333 [===============>..............] - ETA: 5:21 - loss: 0.6950 - acc: 0.5216
5248/9333 [===============>..............] - ETA: 5:17 - loss: 0.6953 - acc: 0.5206
5312/9333 [================>.............] - ETA: 5:13 - loss: 0.6955 - acc: 0.5205
5376/9333 [================>.............] - ETA: 5:08 - loss: 0.6956 - acc: 0.5214
5440/9333 [================>.............] - ETA: 5:03 - loss: 0.6953 - acc: 0.5222
5504/9333 [================>.............] - ETA: 4:59 - loss: 0.6953 - acc: 0.5227
5568/9333 [================>.............] - ETA: 4:54 - loss: 0.6954 - acc: 0.5219
5632/9333 [=================>............] - ETA: 4:49 - loss: 0.6957 - acc: 0.5210
5696/9333 [=================>............] - ETA: 4:44 - loss: 0.6954 - acc: 0.5212
5760/9333 [=================>............] - ETA: 4:40 - loss: 0.6956 - acc: 0.5205
5824/9333 [=================>............] - ETA: 4:35 - loss: 0.6958 - acc: 0.5196
5888/9333 [=================>............] - ETA: 4:31 - loss: 0.6958 - acc: 0.5199
5952/9333 [==================>...........] - ETA: 4:26 - loss: 0.6957 - acc: 0.5205
6016/9333 [==================>...........] - ETA: 4:22 - loss: 0.6954 - acc: 0.5211
6080/9333 [==================>...........] - ETA: 4:17 - loss: 0.6956 - acc: 0.5209
6144/9333 [==================>...........] - ETA: 4:13 - loss: 0.6954 - acc: 0.5220
6208/9333 [==================>...........] - ETA: 4:08 - loss: 0.6954 - acc: 0.5217
6272/9333 [===================>..........] - ETA: 4:03 - loss: 0.6954 - acc: 0.5214
6336/9333 [===================>..........] - ETA: 3:58 - loss: 0.6956 - acc: 0.5211
6400/9333 [===================>..........] - ETA: 3:53 - loss: 0.6957 - acc: 0.5205
6464/9333 [===================>..........] - ETA: 3:49 - loss: 0.6958 - acc: 0.5200
6528/9333 [===================>..........] - ETA: 3:44 - loss: 0.6957 - acc: 0.5207
6592/9333 [====================>.........] - ETA: 3:39 - loss: 0.6962 - acc: 0.5196
6656/9333 [====================>.........] - ETA: 3:34 - loss: 0.6961 - acc: 0.5195
6720/9333 [====================>.........] - ETA: 3:29 - loss: 0.6959 - acc: 0.5207
6784/9333 [====================>.........] - ETA: 3:24 - loss: 0.6958 - acc: 0.5212
6848/9333 [=====================>........] - ETA: 3:19 - loss: 0.6957 - acc: 0.5212
6912/9333 [=====================>........] - ETA: 3:14 - loss: 0.6957 - acc: 0.5211
6976/9333 [=====================>........] - ETA: 3:09 - loss: 0.6958 - acc: 0.5209
7040/9333 [=====================>........] - ETA: 3:04 - loss: 0.6956 - acc: 0.5223
7104/9333 [=====================>........] - ETA: 2:59 - loss: 0.6955 - acc: 0.5228
7168/9333 [======================>.......] - ETA: 2:54 - loss: 0.6955 - acc: 0.5222
7232/9333 [======================>.......] - ETA: 2:49 - loss: 0.6956 - acc: 0.5221
7296/9333 [======================>.......] - ETA: 2:44 - loss: 0.6956 - acc: 0.5225
7360/9333 [======================>.......] - ETA: 2:39 - loss: 0.6957 - acc: 0.5220
7424/9333 [======================>.......] - ETA: 2:34 - loss: 0.6957 - acc: 0.5217
7488/9333 [=======================>......] - ETA: 2:29 - loss: 0.6956 - acc: 0.5223
7552/9333 [=======================>......] - ETA: 2:24 - loss: 0.6958 - acc: 0.5212
7616/9333 [=======================>......] - ETA: 2:19 - loss: 0.6959 - acc: 0.5207
7680/9333 [=======================>......] - ETA: 2:14 - loss: 0.6959 - acc: 0.5204
7744/9333 [=======================>......] - ETA: 2:09 - loss: 0.6958 - acc: 0.5203
7808/9333 [========================>.....] - ETA: 2:04 - loss: 0.6957 - acc: 0.5206
7872/9333 [========================>.....] - ETA: 1:59 - loss: 0.6954 - acc: 0.5218
7936/9333 [========================>.....] - ETA: 1:54 - loss: 0.6956 - acc: 0.5218
8000/9333 [========================>.....] - ETA: 1:49 - loss: 0.6956 - acc: 0.5215
8064/9333 [========================>.....] - ETA: 1:43 - loss: 0.6955 - acc: 0.5215
8128/9333 [=========================>....] - ETA: 1:38 - loss: 0.6957 - acc: 0.5210
8192/9333 [=========================>....] - ETA: 1:33 - loss: 0.6960 - acc: 0.5206
8256/9333 [=========================>....] - ETA: 1:28 - loss: 0.6957 - acc: 0.5213
8320/9333 [=========================>....] - ETA: 1:23 - loss: 0.6956 - acc: 0.5213
8384/9333 [=========================>....] - ETA: 1:18 - loss: 0.6956 - acc: 0.5215
8448/9333 [==========================>...] - ETA: 1:13 - loss: 0.6955 - acc: 0.5220
8512/9333 [==========================>...] - ETA: 1:07 - loss: 0.6954 - acc: 0.5223
8576/9333 [==========================>...] - ETA: 1:02 - loss: 0.6953 - acc: 0.5222
8640/9333 [==========================>...] - ETA: 57s - loss: 0.6952 - acc: 0.5223 
8704/9333 [==========================>...] - ETA: 52s - loss: 0.6952 - acc: 0.5219
8768/9333 [===========================>..] - ETA: 46s - loss: 0.6954 - acc: 0.5214
8832/9333 [===========================>..] - ETA: 41s - loss: 0.6955 - acc: 0.5211
8896/9333 [===========================>..] - ETA: 36s - loss: 0.6956 - acc: 0.5210
8960/9333 [===========================>..] - ETA: 31s - loss: 0.6953 - acc: 0.5220
9024/9333 [============================>.] - ETA: 25s - loss: 0.6954 - acc: 0.5214
9088/9333 [============================>.] - ETA: 20s - loss: 0.6953 - acc: 0.5218
9152/9333 [============================>.] - ETA: 15s - loss: 0.6953 - acc: 0.5221
9216/9333 [============================>.] - ETA: 9s - loss: 0.6952 - acc: 0.5221 
9280/9333 [============================>.] - ETA: 4s - loss: 0.6953 - acc: 0.5218
9333/9333 [==============================] - 813s 87ms/step - loss: 0.6952 - acc: 0.5219 - val_loss: 0.6895 - val_acc: 0.5381

Epoch 00002: val_acc improved from 0.52170 to 0.53809, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window06/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 3/10

  64/9333 [..............................] - ETA: 14:17 - loss: 0.7007 - acc: 0.4844
 128/9333 [..............................] - ETA: 13:58 - loss: 0.7041 - acc: 0.5000
 192/9333 [..............................] - ETA: 13:56 - loss: 0.6983 - acc: 0.5104
 256/9333 [..............................] - ETA: 14:14 - loss: 0.6995 - acc: 0.5000
 320/9333 [>.............................] - ETA: 14:09 - loss: 0.6965 - acc: 0.5094
 384/9333 [>.............................] - ETA: 14:05 - loss: 0.6940 - acc: 0.5130
 448/9333 [>.............................] - ETA: 14:02 - loss: 0.6939 - acc: 0.5067
 512/9333 [>.............................] - ETA: 13:52 - loss: 0.6957 - acc: 0.5059
 576/9333 [>.............................] - ETA: 13:39 - loss: 0.6948 - acc: 0.5069
 640/9333 [=>............................] - ETA: 13:41 - loss: 0.6939 - acc: 0.5156
 704/9333 [=>............................] - ETA: 13:39 - loss: 0.6947 - acc: 0.5185
 768/9333 [=>............................] - ETA: 13:33 - loss: 0.6948 - acc: 0.5156
 832/9333 [=>............................] - ETA: 13:26 - loss: 0.6925 - acc: 0.5276
 896/9333 [=>............................] - ETA: 13:16 - loss: 0.6921 - acc: 0.5290
 960/9333 [==>...........................] - ETA: 13:08 - loss: 0.6921 - acc: 0.5292
1024/9333 [==>...........................] - ETA: 13:01 - loss: 0.6919 - acc: 0.5293
1088/9333 [==>...........................] - ETA: 12:59 - loss: 0.6910 - acc: 0.5322
1152/9333 [==>...........................] - ETA: 12:59 - loss: 0.6914 - acc: 0.5295
1216/9333 [==>...........................] - ETA: 12:51 - loss: 0.6916 - acc: 0.5312
1280/9333 [===>..........................] - ETA: 12:48 - loss: 0.6921 - acc: 0.5297
1344/9333 [===>..........................] - ETA: 12:41 - loss: 0.6927 - acc: 0.5260
1408/9333 [===>..........................] - ETA: 12:33 - loss: 0.6921 - acc: 0.5234
1472/9333 [===>..........................] - ETA: 12:28 - loss: 0.6917 - acc: 0.5272
1536/9333 [===>..........................] - ETA: 12:22 - loss: 0.6923 - acc: 0.5254
1600/9333 [====>.........................] - ETA: 12:15 - loss: 0.6927 - acc: 0.5244
1664/9333 [====>.........................] - ETA: 12:09 - loss: 0.6926 - acc: 0.5240
1728/9333 [====>.........................] - ETA: 12:04 - loss: 0.6922 - acc: 0.5260
1792/9333 [====>.........................] - ETA: 11:57 - loss: 0.6926 - acc: 0.5246
1856/9333 [====>.........................] - ETA: 11:49 - loss: 0.6919 - acc: 0.5264
1920/9333 [=====>........................] - ETA: 11:42 - loss: 0.6920 - acc: 0.5245
1984/9333 [=====>........................] - ETA: 11:37 - loss: 0.6921 - acc: 0.5242
2048/9333 [=====>........................] - ETA: 11:31 - loss: 0.6917 - acc: 0.5244
2112/9333 [=====>........................] - ETA: 11:25 - loss: 0.6929 - acc: 0.5204
2176/9333 [=====>........................] - ETA: 11:19 - loss: 0.6928 - acc: 0.5198
2240/9333 [======>.......................] - ETA: 11:13 - loss: 0.6935 - acc: 0.5174
2304/9333 [======>.......................] - ETA: 11:07 - loss: 0.6939 - acc: 0.5165
2368/9333 [======>.......................] - ETA: 11:00 - loss: 0.6934 - acc: 0.5173
2432/9333 [======>.......................] - ETA: 10:53 - loss: 0.6934 - acc: 0.5160
2496/9333 [=======>......................] - ETA: 10:50 - loss: 0.6932 - acc: 0.5160
2560/9333 [=======>......................] - ETA: 10:44 - loss: 0.6941 - acc: 0.5156
2624/9333 [=======>......................] - ETA: 10:36 - loss: 0.6938 - acc: 0.5175
2688/9333 [=======>......................] - ETA: 10:31 - loss: 0.6948 - acc: 0.5134
2752/9333 [=======>......................] - ETA: 10:25 - loss: 0.6947 - acc: 0.5138
2816/9333 [========>.....................] - ETA: 10:18 - loss: 0.6944 - acc: 0.5135
2880/9333 [========>.....................] - ETA: 10:12 - loss: 0.6941 - acc: 0.5149
2944/9333 [========>.....................] - ETA: 10:06 - loss: 0.6943 - acc: 0.5143
3008/9333 [========>.....................] - ETA: 10:00 - loss: 0.6935 - acc: 0.5173
3072/9333 [========>.....................] - ETA: 9:53 - loss: 0.6933 - acc: 0.5173 
3136/9333 [=========>....................] - ETA: 9:46 - loss: 0.6929 - acc: 0.5182
3200/9333 [=========>....................] - ETA: 9:40 - loss: 0.6935 - acc: 0.5169
3264/9333 [=========>....................] - ETA: 9:33 - loss: 0.6932 - acc: 0.5162
3328/9333 [=========>....................] - ETA: 9:26 - loss: 0.6931 - acc: 0.5168
3392/9333 [=========>....................] - ETA: 9:20 - loss: 0.6936 - acc: 0.5153
3456/9333 [==========>...................] - ETA: 9:13 - loss: 0.6941 - acc: 0.5130
3520/9333 [==========>...................] - ETA: 9:06 - loss: 0.6944 - acc: 0.5128
3584/9333 [==========>...................] - ETA: 9:00 - loss: 0.6946 - acc: 0.5114
3648/9333 [==========>...................] - ETA: 8:53 - loss: 0.6954 - acc: 0.5093
3712/9333 [==========>...................] - ETA: 8:46 - loss: 0.6955 - acc: 0.5097
3776/9333 [===========>..................] - ETA: 8:40 - loss: 0.6954 - acc: 0.5101
3840/9333 [===========>..................] - ETA: 8:33 - loss: 0.6956 - acc: 0.5089
3904/9333 [===========>..................] - ETA: 8:26 - loss: 0.6953 - acc: 0.5102
3968/9333 [===========>..................] - ETA: 8:19 - loss: 0.6947 - acc: 0.5123
4032/9333 [===========>..................] - ETA: 8:13 - loss: 0.6946 - acc: 0.5136
4096/9333 [============>.................] - ETA: 8:07 - loss: 0.6945 - acc: 0.5142
4160/9333 [============>.................] - ETA: 8:00 - loss: 0.6945 - acc: 0.5135
4224/9333 [============>.................] - ETA: 7:53 - loss: 0.6942 - acc: 0.5137
4288/9333 [============>.................] - ETA: 7:47 - loss: 0.6945 - acc: 0.5131
4352/9333 [============>.................] - ETA: 7:40 - loss: 0.6943 - acc: 0.5145
4416/9333 [=============>................] - ETA: 7:34 - loss: 0.6940 - acc: 0.5152
4480/9333 [=============>................] - ETA: 7:28 - loss: 0.6942 - acc: 0.5154
4544/9333 [=============>................] - ETA: 7:22 - loss: 0.6938 - acc: 0.5174
4608/9333 [=============>................] - ETA: 7:15 - loss: 0.6939 - acc: 0.5178
4672/9333 [==============>...............] - ETA: 7:09 - loss: 0.6939 - acc: 0.5169
4736/9333 [==============>...............] - ETA: 7:03 - loss: 0.6939 - acc: 0.5173
4800/9333 [==============>...............] - ETA: 6:57 - loss: 0.6941 - acc: 0.5169
4864/9333 [==============>...............] - ETA: 6:51 - loss: 0.6940 - acc: 0.5164
4928/9333 [==============>...............] - ETA: 6:44 - loss: 0.6941 - acc: 0.5160
4992/9333 [===============>..............] - ETA: 6:38 - loss: 0.6941 - acc: 0.5162
5056/9333 [===============>..............] - ETA: 6:32 - loss: 0.6943 - acc: 0.5162
5120/9333 [===============>..............] - ETA: 6:26 - loss: 0.6943 - acc: 0.5160
5184/9333 [===============>..............] - ETA: 6:20 - loss: 0.6944 - acc: 0.5156
5248/9333 [===============>..............] - ETA: 6:14 - loss: 0.6943 - acc: 0.5158
5312/9333 [================>.............] - ETA: 6:08 - loss: 0.6940 - acc: 0.5168
5376/9333 [================>.............] - ETA: 6:02 - loss: 0.6940 - acc: 0.5162
5440/9333 [================>.............] - ETA: 5:56 - loss: 0.6942 - acc: 0.5153
5504/9333 [================>.............] - ETA: 5:50 - loss: 0.6942 - acc: 0.5147
5568/9333 [================>.............] - ETA: 5:44 - loss: 0.6944 - acc: 0.5149
5632/9333 [=================>............] - ETA: 5:38 - loss: 0.6945 - acc: 0.5147
5696/9333 [=================>............] - ETA: 5:32 - loss: 0.6946 - acc: 0.5151
5760/9333 [=================>............] - ETA: 5:26 - loss: 0.6946 - acc: 0.5153
5824/9333 [=================>............] - ETA: 5:20 - loss: 0.6946 - acc: 0.5151
5888/9333 [=================>............] - ETA: 5:14 - loss: 0.6944 - acc: 0.5161
5952/9333 [==================>...........] - ETA: 5:08 - loss: 0.6945 - acc: 0.5151
6016/9333 [==================>...........] - ETA: 5:02 - loss: 0.6944 - acc: 0.5163
6080/9333 [==================>...........] - ETA: 4:56 - loss: 0.6942 - acc: 0.5164
6144/9333 [==================>...........] - ETA: 4:50 - loss: 0.6945 - acc: 0.5161
6208/9333 [==================>...........] - ETA: 4:44 - loss: 0.6943 - acc: 0.5159
6272/9333 [===================>..........] - ETA: 4:38 - loss: 0.6947 - acc: 0.5153
6336/9333 [===================>..........] - ETA: 4:32 - loss: 0.6945 - acc: 0.5163
6400/9333 [===================>..........] - ETA: 4:26 - loss: 0.6941 - acc: 0.5175
6464/9333 [===================>..........] - ETA: 4:20 - loss: 0.6940 - acc: 0.5178
6528/9333 [===================>..........] - ETA: 4:14 - loss: 0.6939 - acc: 0.5176
6592/9333 [====================>.........] - ETA: 4:08 - loss: 0.6938 - acc: 0.5181
6656/9333 [====================>.........] - ETA: 4:02 - loss: 0.6939 - acc: 0.5186
6720/9333 [====================>.........] - ETA: 3:56 - loss: 0.6939 - acc: 0.5195
6784/9333 [====================>.........] - ETA: 3:50 - loss: 0.6939 - acc: 0.5195
6848/9333 [=====================>........] - ETA: 3:44 - loss: 0.6940 - acc: 0.5190
6912/9333 [=====================>........] - ETA: 3:38 - loss: 0.6940 - acc: 0.5188
6976/9333 [=====================>........] - ETA: 3:32 - loss: 0.6939 - acc: 0.5196
7040/9333 [=====================>........] - ETA: 3:26 - loss: 0.6937 - acc: 0.5207
7104/9333 [=====================>........] - ETA: 3:20 - loss: 0.6936 - acc: 0.5213
7168/9333 [======================>.......] - ETA: 3:14 - loss: 0.6935 - acc: 0.5215
7232/9333 [======================>.......] - ETA: 3:08 - loss: 0.6935 - acc: 0.5214
7296/9333 [======================>.......] - ETA: 3:02 - loss: 0.6935 - acc: 0.5215
7360/9333 [======================>.......] - ETA: 2:56 - loss: 0.6936 - acc: 0.5212
7424/9333 [======================>.......] - ETA: 2:50 - loss: 0.6935 - acc: 0.5213
7488/9333 [=======================>......] - ETA: 2:45 - loss: 0.6935 - acc: 0.5212
7552/9333 [=======================>......] - ETA: 2:39 - loss: 0.6935 - acc: 0.5216
7616/9333 [=======================>......] - ETA: 2:33 - loss: 0.6935 - acc: 0.5215
7680/9333 [=======================>......] - ETA: 2:27 - loss: 0.6933 - acc: 0.5220
7744/9333 [=======================>......] - ETA: 2:21 - loss: 0.6933 - acc: 0.5216
7808/9333 [========================>.....] - ETA: 2:16 - loss: 0.6934 - acc: 0.5214
7872/9333 [========================>.....] - ETA: 2:10 - loss: 0.6933 - acc: 0.5218
7936/9333 [========================>.....] - ETA: 2:04 - loss: 0.6934 - acc: 0.5223
8000/9333 [========================>.....] - ETA: 1:58 - loss: 0.6934 - acc: 0.5221
8064/9333 [========================>.....] - ETA: 1:53 - loss: 0.6935 - acc: 0.5221
8128/9333 [=========================>....] - ETA: 1:47 - loss: 0.6932 - acc: 0.5230
8192/9333 [=========================>....] - ETA: 1:41 - loss: 0.6932 - acc: 0.5231
8256/9333 [=========================>....] - ETA: 1:35 - loss: 0.6931 - acc: 0.5234
8320/9333 [=========================>....] - ETA: 1:30 - loss: 0.6931 - acc: 0.5231
8384/9333 [=========================>....] - ETA: 1:24 - loss: 0.6934 - acc: 0.5223
8448/9333 [==========================>...] - ETA: 1:18 - loss: 0.6935 - acc: 0.5219
8512/9333 [==========================>...] - ETA: 1:12 - loss: 0.6936 - acc: 0.5215
8576/9333 [==========================>...] - ETA: 1:07 - loss: 0.6936 - acc: 0.5213
8640/9333 [==========================>...] - ETA: 1:01 - loss: 0.6936 - acc: 0.5211
8704/9333 [==========================>...] - ETA: 55s - loss: 0.6935 - acc: 0.5214 
8768/9333 [===========================>..] - ETA: 50s - loss: 0.6933 - acc: 0.5216
8832/9333 [===========================>..] - ETA: 44s - loss: 0.6932 - acc: 0.5219
8896/9333 [===========================>..] - ETA: 38s - loss: 0.6933 - acc: 0.5212
8960/9333 [===========================>..] - ETA: 33s - loss: 0.6932 - acc: 0.5214
9024/9333 [============================>.] - ETA: 27s - loss: 0.6931 - acc: 0.5223
9088/9333 [============================>.] - ETA: 21s - loss: 0.6931 - acc: 0.5222
9152/9333 [============================>.] - ETA: 16s - loss: 0.6930 - acc: 0.5224
9216/9333 [============================>.] - ETA: 10s - loss: 0.6929 - acc: 0.5230
9280/9333 [============================>.] - ETA: 4s - loss: 0.6931 - acc: 0.5226 
9333/9333 [==============================] - 853s 91ms/step - loss: 0.6931 - acc: 0.5229 - val_loss: 0.6915 - val_acc: 0.5313

Epoch 00003: val_acc did not improve from 0.53809
Epoch 4/10

  64/9333 [..............................] - ETA: 14:15 - loss: 0.6759 - acc: 0.6406
 128/9333 [..............................] - ETA: 13:00 - loss: 0.6808 - acc: 0.6094
 192/9333 [..............................] - ETA: 12:30 - loss: 0.6928 - acc: 0.5208
 256/9333 [..............................] - ETA: 12:22 - loss: 0.6906 - acc: 0.5117
 320/9333 [>.............................] - ETA: 12:21 - loss: 0.6955 - acc: 0.4906
 384/9333 [>.............................] - ETA: 12:20 - loss: 0.6948 - acc: 0.4922
 448/9333 [>.............................] - ETA: 12:07 - loss: 0.6979 - acc: 0.4933
 512/9333 [>.............................] - ETA: 11:55 - loss: 0.6995 - acc: 0.4961
 576/9333 [>.............................] - ETA: 11:46 - loss: 0.6983 - acc: 0.4965
 640/9333 [=>............................] - ETA: 11:38 - loss: 0.6986 - acc: 0.4969
 704/9333 [=>............................] - ETA: 11:32 - loss: 0.6981 - acc: 0.5085
 768/9333 [=>............................] - ETA: 11:21 - loss: 0.6976 - acc: 0.5091
 832/9333 [=>............................] - ETA: 11:15 - loss: 0.6978 - acc: 0.5060
 896/9333 [=>............................] - ETA: 11:16 - loss: 0.6979 - acc: 0.5000
 960/9333 [==>...........................] - ETA: 11:07 - loss: 0.6961 - acc: 0.5073
1024/9333 [==>...........................] - ETA: 11:04 - loss: 0.6963 - acc: 0.5078
1088/9333 [==>...........................] - ETA: 10:58 - loss: 0.6970 - acc: 0.5037
1152/9333 [==>...........................] - ETA: 10:52 - loss: 0.6968 - acc: 0.5052
1216/9333 [==>...........................] - ETA: 10:50 - loss: 0.6979 - acc: 0.5041
1280/9333 [===>..........................] - ETA: 10:41 - loss: 0.6968 - acc: 0.5078
1344/9333 [===>..........................] - ETA: 10:35 - loss: 0.6976 - acc: 0.5030
1408/9333 [===>..........................] - ETA: 10:32 - loss: 0.6976 - acc: 0.5050
1472/9333 [===>..........................] - ETA: 10:25 - loss: 0.6974 - acc: 0.5061
1536/9333 [===>..........................] - ETA: 10:21 - loss: 0.6967 - acc: 0.5104
1600/9333 [====>.........................] - ETA: 10:14 - loss: 0.6963 - acc: 0.5106
1664/9333 [====>.........................] - ETA: 10:09 - loss: 0.6970 - acc: 0.5096
1728/9333 [====>.........................] - ETA: 10:05 - loss: 0.6976 - acc: 0.5064
1792/9333 [====>.........................] - ETA: 9:59 - loss: 0.6976 - acc: 0.5061 
1856/9333 [====>.........................] - ETA: 9:55 - loss: 0.6975 - acc: 0.5081
1920/9333 [=====>........................] - ETA: 9:49 - loss: 0.6970 - acc: 0.5089
1984/9333 [=====>........................] - ETA: 9:46 - loss: 0.6963 - acc: 0.5131
2048/9333 [=====>........................] - ETA: 9:43 - loss: 0.6956 - acc: 0.5146
2112/9333 [=====>........................] - ETA: 9:37 - loss: 0.6949 - acc: 0.5161
2176/9333 [=====>........................] - ETA: 9:31 - loss: 0.6946 - acc: 0.5165
2240/9333 [======>.......................] - ETA: 9:28 - loss: 0.6939 - acc: 0.5192
2304/9333 [======>.......................] - ETA: 9:22 - loss: 0.6943 - acc: 0.5191
2368/9333 [======>.......................] - ETA: 9:17 - loss: 0.6953 - acc: 0.5152
2432/9333 [======>.......................] - ETA: 9:11 - loss: 0.6949 - acc: 0.5189
2496/9333 [=======>......................] - ETA: 9:06 - loss: 0.6949 - acc: 0.5176
2560/9333 [=======>......................] - ETA: 9:01 - loss: 0.6954 - acc: 0.5152
2624/9333 [=======>......................] - ETA: 8:56 - loss: 0.6955 - acc: 0.5141
2688/9333 [=======>......................] - ETA: 8:51 - loss: 0.6956 - acc: 0.5141
2752/9333 [=======>......................] - ETA: 8:46 - loss: 0.6951 - acc: 0.5156
2816/9333 [========>.....................] - ETA: 8:40 - loss: 0.6947 - acc: 0.5160
2880/9333 [========>.....................] - ETA: 8:35 - loss: 0.6945 - acc: 0.5146
2944/9333 [========>.....................] - ETA: 8:29 - loss: 0.6944 - acc: 0.5149
3008/9333 [========>.....................] - ETA: 8:23 - loss: 0.6945 - acc: 0.5136
3072/9333 [========>.....................] - ETA: 8:18 - loss: 0.6945 - acc: 0.5143
3136/9333 [=========>....................] - ETA: 8:12 - loss: 0.6946 - acc: 0.5150
3200/9333 [=========>....................] - ETA: 8:08 - loss: 0.6947 - acc: 0.5144
3264/9333 [=========>....................] - ETA: 8:03 - loss: 0.6941 - acc: 0.5175
3328/9333 [=========>....................] - ETA: 7:58 - loss: 0.6936 - acc: 0.5186
3392/9333 [=========>....................] - ETA: 7:53 - loss: 0.6935 - acc: 0.5209
3456/9333 [==========>...................] - ETA: 7:47 - loss: 0.6938 - acc: 0.5208
3520/9333 [==========>...................] - ETA: 7:43 - loss: 0.6937 - acc: 0.5216
3584/9333 [==========>...................] - ETA: 7:38 - loss: 0.6938 - acc: 0.5206
3648/9333 [==========>...................] - ETA: 7:33 - loss: 0.6935 - acc: 0.5206
3712/9333 [==========>...................] - ETA: 7:28 - loss: 0.6937 - acc: 0.5199
3776/9333 [===========>..................] - ETA: 7:23 - loss: 0.6939 - acc: 0.5193
3840/9333 [===========>..................] - ETA: 7:19 - loss: 0.6937 - acc: 0.5195
3904/9333 [===========>..................] - ETA: 7:14 - loss: 0.6940 - acc: 0.5187
3968/9333 [===========>..................] - ETA: 7:09 - loss: 0.6939 - acc: 0.5194
4032/9333 [===========>..................] - ETA: 7:05 - loss: 0.6940 - acc: 0.5198
4096/9333 [============>.................] - ETA: 7:00 - loss: 0.6937 - acc: 0.5215
4160/9333 [============>.................] - ETA: 6:55 - loss: 0.6934 - acc: 0.5226
4224/9333 [============>.................] - ETA: 6:50 - loss: 0.6930 - acc: 0.5246
4288/9333 [============>.................] - ETA: 6:46 - loss: 0.6928 - acc: 0.5257
4352/9333 [============>.................] - ETA: 6:41 - loss: 0.6925 - acc: 0.5269
4416/9333 [=============>................] - ETA: 6:36 - loss: 0.6926 - acc: 0.5258
4480/9333 [=============>................] - ETA: 6:31 - loss: 0.6923 - acc: 0.5268
4544/9333 [=============>................] - ETA: 6:27 - loss: 0.6921 - acc: 0.5273
4608/9333 [=============>................] - ETA: 6:22 - loss: 0.6923 - acc: 0.5265
4672/9333 [==============>...............] - ETA: 6:17 - loss: 0.6920 - acc: 0.5278
4736/9333 [==============>...............] - ETA: 6:12 - loss: 0.6916 - acc: 0.5287
4800/9333 [==============>...............] - ETA: 6:08 - loss: 0.6919 - acc: 0.5288
4864/9333 [==============>...............] - ETA: 6:02 - loss: 0.6924 - acc: 0.5278
4928/9333 [==============>...............] - ETA: 5:57 - loss: 0.6924 - acc: 0.5274
4992/9333 [===============>..............] - ETA: 5:53 - loss: 0.6921 - acc: 0.5288
5056/9333 [===============>..............] - ETA: 5:48 - loss: 0.6922 - acc: 0.5283
5120/9333 [===============>..............] - ETA: 5:43 - loss: 0.6923 - acc: 0.5283
5184/9333 [===============>..............] - ETA: 5:38 - loss: 0.6923 - acc: 0.5287
5248/9333 [===============>..............] - ETA: 5:33 - loss: 0.6924 - acc: 0.5282
5312/9333 [================>.............] - ETA: 5:28 - loss: 0.6926 - acc: 0.5286
5376/9333 [================>.............] - ETA: 5:23 - loss: 0.6923 - acc: 0.5298
5440/9333 [================>.............] - ETA: 5:18 - loss: 0.6922 - acc: 0.5290
5504/9333 [================>.............] - ETA: 5:13 - loss: 0.6922 - acc: 0.5294
5568/9333 [================>.............] - ETA: 5:08 - loss: 0.6919 - acc: 0.5307
5632/9333 [=================>............] - ETA: 5:03 - loss: 0.6918 - acc: 0.5305
5696/9333 [=================>............] - ETA: 4:58 - loss: 0.6920 - acc: 0.5298
5760/9333 [=================>............] - ETA: 4:53 - loss: 0.6920 - acc: 0.5300
5824/9333 [=================>............] - ETA: 4:48 - loss: 0.6918 - acc: 0.5290
5888/9333 [=================>............] - ETA: 4:43 - loss: 0.6914 - acc: 0.5306
5952/9333 [==================>...........] - ETA: 4:38 - loss: 0.6912 - acc: 0.5307
6016/9333 [==================>...........] - ETA: 4:33 - loss: 0.6915 - acc: 0.5306
6080/9333 [==================>...........] - ETA: 4:28 - loss: 0.6916 - acc: 0.5301
6144/9333 [==================>...........] - ETA: 4:23 - loss: 0.6920 - acc: 0.5293
6208/9333 [==================>...........] - ETA: 4:18 - loss: 0.6918 - acc: 0.5295
6272/9333 [===================>..........] - ETA: 4:13 - loss: 0.6914 - acc: 0.5311
6336/9333 [===================>..........] - ETA: 4:08 - loss: 0.6913 - acc: 0.5317
6400/9333 [===================>..........] - ETA: 4:03 - loss: 0.6913 - acc: 0.5319
6464/9333 [===================>..........] - ETA: 3:58 - loss: 0.6909 - acc: 0.5328
6528/9333 [===================>..........] - ETA: 3:53 - loss: 0.6911 - acc: 0.5325
6592/9333 [====================>.........] - ETA: 3:48 - loss: 0.6908 - acc: 0.5332
6656/9333 [====================>.........] - ETA: 3:42 - loss: 0.6909 - acc: 0.5334
6720/9333 [====================>.........] - ETA: 3:38 - loss: 0.6912 - acc: 0.5327
6784/9333 [====================>.........] - ETA: 3:32 - loss: 0.6913 - acc: 0.5323
6848/9333 [=====================>........] - ETA: 3:27 - loss: 0.6914 - acc: 0.5320
6912/9333 [=====================>........] - ETA: 3:22 - loss: 0.6913 - acc: 0.5321
6976/9333 [=====================>........] - ETA: 3:17 - loss: 0.6913 - acc: 0.5324
7040/9333 [=====================>........] - ETA: 3:12 - loss: 0.6913 - acc: 0.5318
7104/9333 [=====================>........] - ETA: 3:07 - loss: 0.6914 - acc: 0.5318
7168/9333 [======================>.......] - ETA: 3:01 - loss: 0.6913 - acc: 0.5319
7232/9333 [======================>.......] - ETA: 2:56 - loss: 0.6915 - acc: 0.5317
7296/9333 [======================>.......] - ETA: 2:51 - loss: 0.6914 - acc: 0.5321
7360/9333 [======================>.......] - ETA: 2:46 - loss: 0.6914 - acc: 0.5323
7424/9333 [======================>.......] - ETA: 2:41 - loss: 0.6913 - acc: 0.5325
7488/9333 [=======================>......] - ETA: 2:35 - loss: 0.6915 - acc: 0.5323
7552/9333 [=======================>......] - ETA: 2:30 - loss: 0.6912 - acc: 0.5328
7616/9333 [=======================>......] - ETA: 2:25 - loss: 0.6914 - acc: 0.5331
7680/9333 [=======================>......] - ETA: 2:20 - loss: 0.6914 - acc: 0.5329
7744/9333 [=======================>......] - ETA: 2:14 - loss: 0.6915 - acc: 0.5323
7808/9333 [========================>.....] - ETA: 2:09 - loss: 0.6914 - acc: 0.5327
7872/9333 [========================>.....] - ETA: 2:04 - loss: 0.6913 - acc: 0.5324
7936/9333 [========================>.....] - ETA: 1:58 - loss: 0.6912 - acc: 0.5325
8000/9333 [========================>.....] - ETA: 1:53 - loss: 0.6913 - acc: 0.5323
8064/9333 [========================>.....] - ETA: 1:48 - loss: 0.6912 - acc: 0.5326
8128/9333 [=========================>....] - ETA: 1:42 - loss: 0.6914 - acc: 0.5314
8192/9333 [=========================>....] - ETA: 1:37 - loss: 0.6914 - acc: 0.5314
8256/9333 [=========================>....] - ETA: 1:32 - loss: 0.6915 - acc: 0.5309
8320/9333 [=========================>....] - ETA: 1:26 - loss: 0.6917 - acc: 0.5304
8384/9333 [=========================>....] - ETA: 1:21 - loss: 0.6917 - acc: 0.5302
8448/9333 [==========================>...] - ETA: 1:16 - loss: 0.6918 - acc: 0.5298
8512/9333 [==========================>...] - ETA: 1:10 - loss: 0.6919 - acc: 0.5295
8576/9333 [==========================>...] - ETA: 1:05 - loss: 0.6919 - acc: 0.5297
8640/9333 [==========================>...] - ETA: 59s - loss: 0.6919 - acc: 0.5301 
8704/9333 [==========================>...] - ETA: 54s - loss: 0.6920 - acc: 0.5296
8768/9333 [===========================>..] - ETA: 48s - loss: 0.6920 - acc: 0.5293
8832/9333 [===========================>..] - ETA: 43s - loss: 0.6921 - acc: 0.5289
8896/9333 [===========================>..] - ETA: 37s - loss: 0.6922 - acc: 0.5286
8960/9333 [===========================>..] - ETA: 32s - loss: 0.6925 - acc: 0.5272
9024/9333 [============================>.] - ETA: 26s - loss: 0.6927 - acc: 0.5268
9088/9333 [============================>.] - ETA: 21s - loss: 0.6926 - acc: 0.5267
9152/9333 [============================>.] - ETA: 15s - loss: 0.6926 - acc: 0.5262
9216/9333 [============================>.] - ETA: 10s - loss: 0.6925 - acc: 0.5263
9280/9333 [============================>.] - ETA: 4s - loss: 0.6926 - acc: 0.5254 
9333/9333 [==============================] - 845s 91ms/step - loss: 0.6925 - acc: 0.5257 - val_loss: 0.6896 - val_acc: 0.5256

Epoch 00004: val_acc did not improve from 0.53809
Epoch 5/10

  64/9333 [..............................] - ETA: 14:24 - loss: 0.6706 - acc: 0.5312
 128/9333 [..............................] - ETA: 14:53 - loss: 0.6677 - acc: 0.5859
 192/9333 [..............................] - ETA: 14:46 - loss: 0.6755 - acc: 0.5521
 256/9333 [..............................] - ETA: 15:06 - loss: 0.6838 - acc: 0.5352
 320/9333 [>.............................] - ETA: 15:03 - loss: 0.6866 - acc: 0.5344
 384/9333 [>.............................] - ETA: 14:46 - loss: 0.6871 - acc: 0.5443
 448/9333 [>.............................] - ETA: 14:34 - loss: 0.6880 - acc: 0.5379
 512/9333 [>.............................] - ETA: 14:26 - loss: 0.6887 - acc: 0.5293
 576/9333 [>.............................] - ETA: 14:23 - loss: 0.6893 - acc: 0.5226
 640/9333 [=>............................] - ETA: 14:18 - loss: 0.6895 - acc: 0.5203
 704/9333 [=>............................] - ETA: 14:08 - loss: 0.6910 - acc: 0.5142
 768/9333 [=>............................] - ETA: 14:09 - loss: 0.6902 - acc: 0.5195
 832/9333 [=>............................] - ETA: 14:02 - loss: 0.6920 - acc: 0.5192
 896/9333 [=>............................] - ETA: 13:50 - loss: 0.6921 - acc: 0.5179
 960/9333 [==>...........................] - ETA: 13:43 - loss: 0.6923 - acc: 0.5188
1024/9333 [==>...........................] - ETA: 13:37 - loss: 0.6916 - acc: 0.5195
1088/9333 [==>...........................] - ETA: 13:34 - loss: 0.6928 - acc: 0.5193
1152/9333 [==>...........................] - ETA: 13:29 - loss: 0.6936 - acc: 0.5174
1216/9333 [==>...........................] - ETA: 13:22 - loss: 0.6936 - acc: 0.5148
1280/9333 [===>..........................] - ETA: 13:13 - loss: 0.6945 - acc: 0.5133
1344/9333 [===>..........................] - ETA: 13:06 - loss: 0.6950 - acc: 0.5082
1408/9333 [===>..........................] - ETA: 13:00 - loss: 0.6950 - acc: 0.5092
1472/9333 [===>..........................] - ETA: 12:55 - loss: 0.6948 - acc: 0.5088
1536/9333 [===>..........................] - ETA: 12:47 - loss: 0.6941 - acc: 0.5111
1600/9333 [====>.........................] - ETA: 12:40 - loss: 0.6936 - acc: 0.5125
1664/9333 [====>.........................] - ETA: 12:34 - loss: 0.6941 - acc: 0.5108
1728/9333 [====>.........................] - ETA: 12:26 - loss: 0.6944 - acc: 0.5133
1792/9333 [====>.........................] - ETA: 12:18 - loss: 0.6944 - acc: 0.5128
1856/9333 [====>.........................] - ETA: 12:14 - loss: 0.6943 - acc: 0.5145
1920/9333 [=====>........................] - ETA: 12:07 - loss: 0.6932 - acc: 0.5172
1984/9333 [=====>........................] - ETA: 11:59 - loss: 0.6933 - acc: 0.5166
2048/9333 [=====>........................] - ETA: 11:53 - loss: 0.6934 - acc: 0.5161
2112/9333 [=====>........................] - ETA: 11:47 - loss: 0.6929 - acc: 0.5170
2176/9333 [=====>........................] - ETA: 11:40 - loss: 0.6926 - acc: 0.5198
2240/9333 [======>.......................] - ETA: 11:34 - loss: 0.6927 - acc: 0.5179
2304/9333 [======>.......................] - ETA: 11:27 - loss: 0.6935 - acc: 0.5152
2368/9333 [======>.......................] - ETA: 11:21 - loss: 0.6936 - acc: 0.5135
2432/9333 [======>.......................] - ETA: 11:15 - loss: 0.6936 - acc: 0.5144
2496/9333 [=======>......................] - ETA: 11:08 - loss: 0.6934 - acc: 0.5124
2560/9333 [=======>......................] - ETA: 11:02 - loss: 0.6930 - acc: 0.5145
2624/9333 [=======>......................] - ETA: 10:55 - loss: 0.6929 - acc: 0.5137
2688/9333 [=======>......................] - ETA: 10:48 - loss: 0.6924 - acc: 0.5149
2752/9333 [=======>......................] - ETA: 10:42 - loss: 0.6925 - acc: 0.5145
2816/9333 [========>.....................] - ETA: 10:34 - loss: 0.6919 - acc: 0.5167
2880/9333 [========>.....................] - ETA: 10:28 - loss: 0.6921 - acc: 0.5156
2944/9333 [========>.....................] - ETA: 10:22 - loss: 0.6918 - acc: 0.5173
3008/9333 [========>.....................] - ETA: 10:15 - loss: 0.6923 - acc: 0.5163
3072/9333 [========>.....................] - ETA: 10:09 - loss: 0.6931 - acc: 0.5150
3136/9333 [=========>....................] - ETA: 10:03 - loss: 0.6930 - acc: 0.5153
3200/9333 [=========>....................] - ETA: 9:56 - loss: 0.6933 - acc: 0.5141 
3264/9333 [=========>....................] - ETA: 9:49 - loss: 0.6931 - acc: 0.5141
3328/9333 [=========>....................] - ETA: 9:44 - loss: 0.6924 - acc: 0.5162
3392/9333 [=========>....................] - ETA: 9:38 - loss: 0.6924 - acc: 0.5171
3456/9333 [==========>...................] - ETA: 9:31 - loss: 0.6926 - acc: 0.5177
3520/9333 [==========>...................] - ETA: 9:24 - loss: 0.6927 - acc: 0.5182
3584/9333 [==========>...................] - ETA: 9:17 - loss: 0.6924 - acc: 0.5187
3648/9333 [==========>...................] - ETA: 9:11 - loss: 0.6925 - acc: 0.5175
3712/9333 [==========>...................] - ETA: 9:04 - loss: 0.6926 - acc: 0.5186
3776/9333 [===========>..................] - ETA: 8:58 - loss: 0.6932 - acc: 0.5162
3840/9333 [===========>..................] - ETA: 8:52 - loss: 0.6931 - acc: 0.5167
3904/9333 [===========>..................] - ETA: 8:44 - loss: 0.6935 - acc: 0.5149
3968/9333 [===========>..................] - ETA: 8:38 - loss: 0.6932 - acc: 0.5159
4032/9333 [===========>..................] - ETA: 8:32 - loss: 0.6927 - acc: 0.5186
4096/9333 [============>.................] - ETA: 8:25 - loss: 0.6924 - acc: 0.5188
4160/9333 [============>.................] - ETA: 8:19 - loss: 0.6926 - acc: 0.5192
4224/9333 [============>.................] - ETA: 8:12 - loss: 0.6925 - acc: 0.5196
4288/9333 [============>.................] - ETA: 8:06 - loss: 0.6927 - acc: 0.5191
4352/9333 [============>.................] - ETA: 8:00 - loss: 0.6926 - acc: 0.5207
4416/9333 [=============>................] - ETA: 7:53 - loss: 0.6926 - acc: 0.5204
4480/9333 [=============>................] - ETA: 7:47 - loss: 0.6923 - acc: 0.5219
4544/9333 [=============>................] - ETA: 7:41 - loss: 0.6926 - acc: 0.5211
4608/9333 [=============>................] - ETA: 7:35 - loss: 0.6926 - acc: 0.5208
4672/9333 [==============>...............] - ETA: 7:28 - loss: 0.6923 - acc: 0.5227
4736/9333 [==============>...............] - ETA: 7:22 - loss: 0.6925 - acc: 0.5232
4800/9333 [==============>...............] - ETA: 7:16 - loss: 0.6922 - acc: 0.5242
4864/9333 [==============>...............] - ETA: 7:09 - loss: 0.6919 - acc: 0.5255
4928/9333 [==============>...............] - ETA: 7:03 - loss: 0.6920 - acc: 0.5250
4992/9333 [===============>..............] - ETA: 6:56 - loss: 0.6921 - acc: 0.5248
5056/9333 [===============>..............] - ETA: 6:50 - loss: 0.6918 - acc: 0.5255
5120/9333 [===============>..............] - ETA: 6:44 - loss: 0.6918 - acc: 0.5254
5184/9333 [===============>..............] - ETA: 6:37 - loss: 0.6917 - acc: 0.5255
5248/9333 [===============>..............] - ETA: 6:32 - loss: 0.6922 - acc: 0.5240
5312/9333 [================>.............] - ETA: 6:26 - loss: 0.6924 - acc: 0.5232
5376/9333 [================>.............] - ETA: 6:19 - loss: 0.6924 - acc: 0.5229
5440/9333 [================>.............] - ETA: 6:13 - loss: 0.6925 - acc: 0.5222
5504/9333 [================>.............] - ETA: 6:07 - loss: 0.6924 - acc: 0.5234
5568/9333 [================>.............] - ETA: 6:00 - loss: 0.6920 - acc: 0.5246
5632/9333 [=================>............] - ETA: 5:54 - loss: 0.6917 - acc: 0.5261
5696/9333 [=================>............] - ETA: 5:47 - loss: 0.6920 - acc: 0.5262
5760/9333 [=================>............] - ETA: 5:41 - loss: 0.6918 - acc: 0.5267
5824/9333 [=================>............] - ETA: 5:35 - loss: 0.6916 - acc: 0.5282
5888/9333 [=================>............] - ETA: 5:28 - loss: 0.6915 - acc: 0.5292
5952/9333 [==================>...........] - ETA: 5:22 - loss: 0.6915 - acc: 0.5292
6016/9333 [==================>...........] - ETA: 5:15 - loss: 0.6916 - acc: 0.5291
6080/9333 [==================>...........] - ETA: 5:09 - loss: 0.6916 - acc: 0.5288
6144/9333 [==================>...........] - ETA: 5:03 - loss: 0.6916 - acc: 0.5288
6208/9333 [==================>...........] - ETA: 4:57 - loss: 0.6916 - acc: 0.5284
6272/9333 [===================>..........] - ETA: 4:50 - loss: 0.6915 - acc: 0.5277
6336/9333 [===================>..........] - ETA: 4:44 - loss: 0.6914 - acc: 0.5279
6400/9333 [===================>..........] - ETA: 4:38 - loss: 0.6918 - acc: 0.5264
6464/9333 [===================>..........] - ETA: 4:31 - loss: 0.6920 - acc: 0.5257
6528/9333 [===================>..........] - ETA: 4:25 - loss: 0.6920 - acc: 0.5256
6592/9333 [====================>.........] - ETA: 4:19 - loss: 0.6919 - acc: 0.5252
6656/9333 [====================>.........] - ETA: 4:13 - loss: 0.6921 - acc: 0.5249
6720/9333 [====================>.........] - ETA: 4:07 - loss: 0.6921 - acc: 0.5246
6784/9333 [====================>.........] - ETA: 4:01 - loss: 0.6923 - acc: 0.5248
6848/9333 [=====================>........] - ETA: 3:54 - loss: 0.6924 - acc: 0.5238
6912/9333 [=====================>........] - ETA: 3:48 - loss: 0.6925 - acc: 0.5240
6976/9333 [=====================>........] - ETA: 3:42 - loss: 0.6925 - acc: 0.5238
7040/9333 [=====================>........] - ETA: 3:36 - loss: 0.6928 - acc: 0.5233
7104/9333 [=====================>........] - ETA: 3:30 - loss: 0.6927 - acc: 0.5231
7168/9333 [======================>.......] - ETA: 3:24 - loss: 0.6928 - acc: 0.5229
7232/9333 [======================>.......] - ETA: 3:18 - loss: 0.6929 - acc: 0.5224
7296/9333 [======================>.......] - ETA: 3:11 - loss: 0.6929 - acc: 0.5223
7360/9333 [======================>.......] - ETA: 3:05 - loss: 0.6929 - acc: 0.5220
7424/9333 [======================>.......] - ETA: 2:59 - loss: 0.6928 - acc: 0.5228
7488/9333 [=======================>......] - ETA: 2:53 - loss: 0.6929 - acc: 0.5223
7552/9333 [=======================>......] - ETA: 2:47 - loss: 0.6929 - acc: 0.5220
7616/9333 [=======================>......] - ETA: 2:41 - loss: 0.6928 - acc: 0.5222
7680/9333 [=======================>......] - ETA: 2:35 - loss: 0.6927 - acc: 0.5223
7744/9333 [=======================>......] - ETA: 2:29 - loss: 0.6926 - acc: 0.5229
7808/9333 [========================>.....] - ETA: 2:22 - loss: 0.6928 - acc: 0.5222
7872/9333 [========================>.....] - ETA: 2:16 - loss: 0.6928 - acc: 0.5218
7936/9333 [========================>.....] - ETA: 2:10 - loss: 0.6928 - acc: 0.5219
8000/9333 [========================>.....] - ETA: 2:04 - loss: 0.6930 - acc: 0.5214
8064/9333 [========================>.....] - ETA: 1:58 - loss: 0.6930 - acc: 0.5208
8128/9333 [=========================>....] - ETA: 1:52 - loss: 0.6930 - acc: 0.5209
8192/9333 [=========================>....] - ETA: 1:46 - loss: 0.6930 - acc: 0.5210
8256/9333 [=========================>....] - ETA: 1:40 - loss: 0.6930 - acc: 0.5210
8320/9333 [=========================>....] - ETA: 1:34 - loss: 0.6929 - acc: 0.5215
8384/9333 [=========================>....] - ETA: 1:28 - loss: 0.6928 - acc: 0.5215
8448/9333 [==========================>...] - ETA: 1:22 - loss: 0.6928 - acc: 0.5213
8512/9333 [==========================>...] - ETA: 1:16 - loss: 0.6927 - acc: 0.5211
8576/9333 [==========================>...] - ETA: 1:10 - loss: 0.6926 - acc: 0.5222
8640/9333 [==========================>...] - ETA: 1:04 - loss: 0.6926 - acc: 0.5226
8704/9333 [==========================>...] - ETA: 58s - loss: 0.6926 - acc: 0.5224 
8768/9333 [===========================>..] - ETA: 52s - loss: 0.6926 - acc: 0.5227
8832/9333 [===========================>..] - ETA: 46s - loss: 0.6926 - acc: 0.5231
8896/9333 [===========================>..] - ETA: 40s - loss: 0.6926 - acc: 0.5230
8960/9333 [===========================>..] - ETA: 34s - loss: 0.6927 - acc: 0.5227
9024/9333 [============================>.] - ETA: 28s - loss: 0.6927 - acc: 0.5228
9088/9333 [============================>.] - ETA: 22s - loss: 0.6927 - acc: 0.5229
9152/9333 [============================>.] - ETA: 16s - loss: 0.6926 - acc: 0.5235
9216/9333 [============================>.] - ETA: 10s - loss: 0.6926 - acc: 0.5237
9280/9333 [============================>.] - ETA: 4s - loss: 0.6924 - acc: 0.5242 
9333/9333 [==============================] - 896s 96ms/step - loss: 0.6923 - acc: 0.5243 - val_loss: 0.6884 - val_acc: 0.5313

Epoch 00005: val_acc did not improve from 0.53809
Epoch 6/10

  64/9333 [..............................] - ETA: 13:49 - loss: 0.6756 - acc: 0.6562
 128/9333 [..............................] - ETA: 13:41 - loss: 0.6753 - acc: 0.6016
 192/9333 [..............................] - ETA: 13:27 - loss: 0.6721 - acc: 0.5938
 256/9333 [..............................] - ETA: 13:33 - loss: 0.6730 - acc: 0.5977
 320/9333 [>.............................] - ETA: 13:31 - loss: 0.6787 - acc: 0.5813
 384/9333 [>.............................] - ETA: 13:17 - loss: 0.6814 - acc: 0.5729
 448/9333 [>.............................] - ETA: 13:17 - loss: 0.6830 - acc: 0.5625
 512/9333 [>.............................] - ETA: 13:07 - loss: 0.6852 - acc: 0.5508
 576/9333 [>.............................] - ETA: 13:00 - loss: 0.6856 - acc: 0.5451
 640/9333 [=>............................] - ETA: 13:00 - loss: 0.6826 - acc: 0.5531
 704/9333 [=>............................] - ETA: 13:02 - loss: 0.6833 - acc: 0.5469
 768/9333 [=>............................] - ETA: 12:52 - loss: 0.6849 - acc: 0.5495
 832/9333 [=>............................] - ETA: 12:42 - loss: 0.6872 - acc: 0.5433
 896/9333 [=>............................] - ETA: 12:36 - loss: 0.6885 - acc: 0.5413
 960/9333 [==>...........................] - ETA: 12:28 - loss: 0.6883 - acc: 0.5396
1024/9333 [==>...........................] - ETA: 12:19 - loss: 0.6885 - acc: 0.5410
1088/9333 [==>...........................] - ETA: 12:12 - loss: 0.6875 - acc: 0.5441
1152/9333 [==>...........................] - ETA: 12:04 - loss: 0.6881 - acc: 0.5425
1216/9333 [==>...........................] - ETA: 11:58 - loss: 0.6892 - acc: 0.5419
1280/9333 [===>..........................] - ETA: 11:50 - loss: 0.6887 - acc: 0.5445
1344/9333 [===>..........................] - ETA: 11:48 - loss: 0.6863 - acc: 0.5528
1408/9333 [===>..........................] - ETA: 11:43 - loss: 0.6875 - acc: 0.5476
1472/9333 [===>..........................] - ETA: 11:35 - loss: 0.6877 - acc: 0.5469
1536/9333 [===>..........................] - ETA: 11:27 - loss: 0.6876 - acc: 0.5482
1600/9333 [====>.........................] - ETA: 11:24 - loss: 0.6886 - acc: 0.5456
1664/9333 [====>.........................] - ETA: 11:19 - loss: 0.6875 - acc: 0.5499
1728/9333 [====>.........................] - ETA: 11:13 - loss: 0.6865 - acc: 0.5521
1792/9333 [====>.........................] - ETA: 11:06 - loss: 0.6858 - acc: 0.5541
1856/9333 [====>.........................] - ETA: 11:01 - loss: 0.6850 - acc: 0.5593
1920/9333 [=====>........................] - ETA: 10:55 - loss: 0.6852 - acc: 0.5583
1984/9333 [=====>........................] - ETA: 10:48 - loss: 0.6853 - acc: 0.5580
2048/9333 [=====>........................] - ETA: 10:43 - loss: 0.6849 - acc: 0.5586
2112/9333 [=====>........................] - ETA: 10:38 - loss: 0.6842 - acc: 0.5620
2176/9333 [=====>........................] - ETA: 10:33 - loss: 0.6839 - acc: 0.5630
2240/9333 [======>.......................] - ETA: 10:28 - loss: 0.6843 - acc: 0.5616
2304/9333 [======>.......................] - ETA: 10:24 - loss: 0.6842 - acc: 0.5608
2368/9333 [======>.......................] - ETA: 10:18 - loss: 0.6845 - acc: 0.5587
2432/9333 [======>.......................] - ETA: 10:13 - loss: 0.6844 - acc: 0.5588
2496/9333 [=======>......................] - ETA: 10:08 - loss: 0.6853 - acc: 0.5565
2560/9333 [=======>......................] - ETA: 10:02 - loss: 0.6860 - acc: 0.5543
2624/9333 [=======>......................] - ETA: 9:56 - loss: 0.6860 - acc: 0.5541 
2688/9333 [=======>......................] - ETA: 9:50 - loss: 0.6863 - acc: 0.5532
2752/9333 [=======>......................] - ETA: 9:44 - loss: 0.6850 - acc: 0.5563
2816/9333 [========>.....................] - ETA: 9:38 - loss: 0.6845 - acc: 0.5579
2880/9333 [========>.....................] - ETA: 9:33 - loss: 0.6846 - acc: 0.5576
2944/9333 [========>.....................] - ETA: 9:27 - loss: 0.6848 - acc: 0.5571
3008/9333 [========>.....................] - ETA: 9:20 - loss: 0.6859 - acc: 0.5542
3072/9333 [========>.....................] - ETA: 9:15 - loss: 0.6860 - acc: 0.5544
3136/9333 [=========>....................] - ETA: 9:09 - loss: 0.6862 - acc: 0.5545
3200/9333 [=========>....................] - ETA: 9:03 - loss: 0.6858 - acc: 0.5572
3264/9333 [=========>....................] - ETA: 8:58 - loss: 0.6859 - acc: 0.5558
3328/9333 [=========>....................] - ETA: 8:53 - loss: 0.6862 - acc: 0.5550
3392/9333 [=========>....................] - ETA: 8:48 - loss: 0.6863 - acc: 0.5540
3456/9333 [==========>...................] - ETA: 8:41 - loss: 0.6861 - acc: 0.5541
3520/9333 [==========>...................] - ETA: 8:36 - loss: 0.6862 - acc: 0.5543
3584/9333 [==========>...................] - ETA: 8:30 - loss: 0.6860 - acc: 0.5544
3648/9333 [==========>...................] - ETA: 8:24 - loss: 0.6859 - acc: 0.5543
3712/9333 [==========>...................] - ETA: 8:19 - loss: 0.6862 - acc: 0.5531
3776/9333 [===========>..................] - ETA: 8:13 - loss: 0.6868 - acc: 0.5503
3840/9333 [===========>..................] - ETA: 8:08 - loss: 0.6870 - acc: 0.5495
3904/9333 [===========>..................] - ETA: 8:02 - loss: 0.6876 - acc: 0.5464
3968/9333 [===========>..................] - ETA: 7:58 - loss: 0.6875 - acc: 0.5459
4032/9333 [===========>..................] - ETA: 7:52 - loss: 0.6876 - acc: 0.5449
4096/9333 [============>.................] - ETA: 7:47 - loss: 0.6875 - acc: 0.5454
4160/9333 [============>.................] - ETA: 7:42 - loss: 0.6873 - acc: 0.5464
4224/9333 [============>.................] - ETA: 7:37 - loss: 0.6871 - acc: 0.5466
4288/9333 [============>.................] - ETA: 7:31 - loss: 0.6872 - acc: 0.5459
4352/9333 [============>.................] - ETA: 7:26 - loss: 0.6874 - acc: 0.5446
4416/9333 [=============>................] - ETA: 7:20 - loss: 0.6874 - acc: 0.5444
4480/9333 [=============>................] - ETA: 7:15 - loss: 0.6874 - acc: 0.5435
4544/9333 [=============>................] - ETA: 7:09 - loss: 0.6878 - acc: 0.5425
4608/9333 [=============>................] - ETA: 7:03 - loss: 0.6879 - acc: 0.5417
4672/9333 [==============>...............] - ETA: 6:58 - loss: 0.6881 - acc: 0.5402
4736/9333 [==============>...............] - ETA: 6:52 - loss: 0.6881 - acc: 0.5408
4800/9333 [==============>...............] - ETA: 6:46 - loss: 0.6882 - acc: 0.5396
4864/9333 [==============>...............] - ETA: 6:41 - loss: 0.6884 - acc: 0.5387
4928/9333 [==============>...............] - ETA: 6:35 - loss: 0.6882 - acc: 0.5394
4992/9333 [===============>..............] - ETA: 6:30 - loss: 0.6885 - acc: 0.5393
5056/9333 [===============>..............] - ETA: 6:24 - loss: 0.6885 - acc: 0.5388
5120/9333 [===============>..............] - ETA: 6:18 - loss: 0.6886 - acc: 0.5383
5184/9333 [===============>..............] - ETA: 6:13 - loss: 0.6884 - acc: 0.5390
5248/9333 [===============>..............] - ETA: 6:07 - loss: 0.6886 - acc: 0.5379
5312/9333 [================>.............] - ETA: 6:01 - loss: 0.6888 - acc: 0.5367
5376/9333 [================>.............] - ETA: 5:56 - loss: 0.6887 - acc: 0.5379
5440/9333 [================>.............] - ETA: 5:50 - loss: 0.6887 - acc: 0.5386
5504/9333 [================>.............] - ETA: 5:44 - loss: 0.6888 - acc: 0.5382
5568/9333 [================>.............] - ETA: 5:38 - loss: 0.6890 - acc: 0.5368
5632/9333 [=================>............] - ETA: 5:33 - loss: 0.6889 - acc: 0.5378
5696/9333 [=================>............] - ETA: 5:27 - loss: 0.6892 - acc: 0.5369
5760/9333 [=================>............] - ETA: 5:22 - loss: 0.6892 - acc: 0.5373
5824/9333 [=================>............] - ETA: 5:16 - loss: 0.6892 - acc: 0.5373
5888/9333 [=================>............] - ETA: 5:10 - loss: 0.6892 - acc: 0.5370
5952/9333 [==================>...........] - ETA: 5:04 - loss: 0.6894 - acc: 0.5365
6016/9333 [==================>...........] - ETA: 4:59 - loss: 0.6894 - acc: 0.5356
6080/9333 [==================>...........] - ETA: 4:53 - loss: 0.6896 - acc: 0.5345
6144/9333 [==================>...........] - ETA: 4:48 - loss: 0.6896 - acc: 0.5340
6208/9333 [==================>...........] - ETA: 4:42 - loss: 0.6898 - acc: 0.5330
6272/9333 [===================>..........] - ETA: 4:37 - loss: 0.6898 - acc: 0.5332
6336/9333 [===================>..........] - ETA: 4:31 - loss: 0.6897 - acc: 0.5346
6400/9333 [===================>..........] - ETA: 4:25 - loss: 0.6897 - acc: 0.5350
6464/9333 [===================>..........] - ETA: 4:20 - loss: 0.6895 - acc: 0.5362
6528/9333 [===================>..........] - ETA: 4:14 - loss: 0.6896 - acc: 0.5354
6592/9333 [====================>.........] - ETA: 4:08 - loss: 0.6895 - acc: 0.5360
6656/9333 [====================>.........] - ETA: 4:02 - loss: 0.6895 - acc: 0.5365
6720/9333 [====================>.........] - ETA: 3:57 - loss: 0.6896 - acc: 0.5362
6784/9333 [====================>.........] - ETA: 3:51 - loss: 0.6895 - acc: 0.5370
6848/9333 [=====================>........] - ETA: 3:45 - loss: 0.6896 - acc: 0.5365
6912/9333 [=====================>........] - ETA: 3:40 - loss: 0.6896 - acc: 0.5365
6976/9333 [=====================>........] - ETA: 3:34 - loss: 0.6894 - acc: 0.5366
7040/9333 [=====================>........] - ETA: 3:28 - loss: 0.6893 - acc: 0.5375
7104/9333 [=====================>........] - ETA: 3:22 - loss: 0.6894 - acc: 0.5374
7168/9333 [======================>.......] - ETA: 3:17 - loss: 0.6893 - acc: 0.5377
7232/9333 [======================>.......] - ETA: 3:11 - loss: 0.6896 - acc: 0.5369
7296/9333 [======================>.......] - ETA: 3:05 - loss: 0.6895 - acc: 0.5378
7360/9333 [======================>.......] - ETA: 2:59 - loss: 0.6896 - acc: 0.5374
7424/9333 [======================>.......] - ETA: 2:53 - loss: 0.6897 - acc: 0.5366
7488/9333 [=======================>......] - ETA: 2:48 - loss: 0.6896 - acc: 0.5373
7552/9333 [=======================>......] - ETA: 2:42 - loss: 0.6899 - acc: 0.5363
7616/9333 [=======================>......] - ETA: 2:36 - loss: 0.6896 - acc: 0.5368
7680/9333 [=======================>......] - ETA: 2:30 - loss: 0.6897 - acc: 0.5371
7744/9333 [=======================>......] - ETA: 2:24 - loss: 0.6894 - acc: 0.5380
7808/9333 [========================>.....] - ETA: 2:18 - loss: 0.6894 - acc: 0.5380
7872/9333 [========================>.....] - ETA: 2:13 - loss: 0.6894 - acc: 0.5380
7936/9333 [========================>.....] - ETA: 2:07 - loss: 0.6895 - acc: 0.5376
8000/9333 [========================>.....] - ETA: 2:01 - loss: 0.6893 - acc: 0.5380
8064/9333 [========================>.....] - ETA: 1:55 - loss: 0.6894 - acc: 0.5376
8128/9333 [=========================>....] - ETA: 1:49 - loss: 0.6894 - acc: 0.5380
8192/9333 [=========================>....] - ETA: 1:44 - loss: 0.6894 - acc: 0.5385
8256/9333 [=========================>....] - ETA: 1:38 - loss: 0.6894 - acc: 0.5383
8320/9333 [=========================>....] - ETA: 1:32 - loss: 0.6896 - acc: 0.5376
8384/9333 [=========================>....] - ETA: 1:26 - loss: 0.6895 - acc: 0.5380
8448/9333 [==========================>...] - ETA: 1:20 - loss: 0.6895 - acc: 0.5376
8512/9333 [==========================>...] - ETA: 1:14 - loss: 0.6897 - acc: 0.5374
8576/9333 [==========================>...] - ETA: 1:09 - loss: 0.6899 - acc: 0.5365
8640/9333 [==========================>...] - ETA: 1:03 - loss: 0.6901 - acc: 0.5360
8704/9333 [==========================>...] - ETA: 57s - loss: 0.6901 - acc: 0.5360 
8768/9333 [===========================>..] - ETA: 51s - loss: 0.6899 - acc: 0.5366
8832/9333 [===========================>..] - ETA: 45s - loss: 0.6900 - acc: 0.5362
8896/9333 [===========================>..] - ETA: 39s - loss: 0.6899 - acc: 0.5362
8960/9333 [===========================>..] - ETA: 34s - loss: 0.6900 - acc: 0.5356
9024/9333 [============================>.] - ETA: 28s - loss: 0.6899 - acc: 0.5359
9088/9333 [============================>.] - ETA: 22s - loss: 0.6899 - acc: 0.5355
9152/9333 [============================>.] - ETA: 16s - loss: 0.6899 - acc: 0.5351
9216/9333 [============================>.] - ETA: 10s - loss: 0.6900 - acc: 0.5353
9280/9333 [============================>.] - ETA: 4s - loss: 0.6901 - acc: 0.5345 
9333/9333 [==============================] - 883s 95ms/step - loss: 0.6901 - acc: 0.5349 - val_loss: 0.6943 - val_acc: 0.5159

Epoch 00006: val_acc did not improve from 0.53809
Epoch 7/10

  64/9333 [..............................] - ETA: 13:58 - loss: 0.6894 - acc: 0.5156
 128/9333 [..............................] - ETA: 13:44 - loss: 0.6879 - acc: 0.5234
 192/9333 [..............................] - ETA: 13:29 - loss: 0.6896 - acc: 0.5469
 256/9333 [..............................] - ETA: 13:33 - loss: 0.6888 - acc: 0.5430
 320/9333 [>.............................] - ETA: 13:13 - loss: 0.6885 - acc: 0.5469
 384/9333 [>.............................] - ETA: 13:11 - loss: 0.6892 - acc: 0.5443
 448/9333 [>.............................] - ETA: 13:10 - loss: 0.6887 - acc: 0.5424
 512/9333 [>.............................] - ETA: 12:59 - loss: 0.6871 - acc: 0.5527
 576/9333 [>.............................] - ETA: 12:45 - loss: 0.6878 - acc: 0.5556
 640/9333 [=>............................] - ETA: 12:54 - loss: 0.6875 - acc: 0.5531
 704/9333 [=>............................] - ETA: 12:48 - loss: 0.6882 - acc: 0.5540
 768/9333 [=>............................] - ETA: 12:41 - loss: 0.6883 - acc: 0.5521
 832/9333 [=>............................] - ETA: 12:36 - loss: 0.6889 - acc: 0.5457
 896/9333 [=>............................] - ETA: 12:31 - loss: 0.6885 - acc: 0.5469
 960/9333 [==>...........................] - ETA: 12:26 - loss: 0.6885 - acc: 0.5521
1024/9333 [==>...........................] - ETA: 12:18 - loss: 0.6889 - acc: 0.5479
1088/9333 [==>...........................] - ETA: 12:15 - loss: 0.6889 - acc: 0.5450
1152/9333 [==>...........................] - ETA: 12:08 - loss: 0.6884 - acc: 0.5477
1216/9333 [==>...........................] - ETA: 12:04 - loss: 0.6891 - acc: 0.5452
1280/9333 [===>..........................] - ETA: 11:59 - loss: 0.6897 - acc: 0.5437
1344/9333 [===>..........................] - ETA: 11:52 - loss: 0.6891 - acc: 0.5469
1408/9333 [===>..........................] - ETA: 11:47 - loss: 0.6898 - acc: 0.5433
1472/9333 [===>..........................] - ETA: 11:40 - loss: 0.6895 - acc: 0.5442
1536/9333 [===>..........................] - ETA: 11:30 - loss: 0.6900 - acc: 0.5417
1600/9333 [====>.........................] - ETA: 11:27 - loss: 0.6894 - acc: 0.5444
1664/9333 [====>.........................] - ETA: 11:22 - loss: 0.6891 - acc: 0.5457
1728/9333 [====>.........................] - ETA: 11:15 - loss: 0.6891 - acc: 0.5434
1792/9333 [====>.........................] - ETA: 11:09 - loss: 0.6896 - acc: 0.5424
1856/9333 [====>.........................] - ETA: 11:04 - loss: 0.6897 - acc: 0.5409
1920/9333 [=====>........................] - ETA: 10:56 - loss: 0.6896 - acc: 0.5417
1984/9333 [=====>........................] - ETA: 10:50 - loss: 0.6895 - acc: 0.5408
2048/9333 [=====>........................] - ETA: 10:45 - loss: 0.6893 - acc: 0.5415
2112/9333 [=====>........................] - ETA: 10:39 - loss: 0.6891 - acc: 0.5412
2176/9333 [=====>........................] - ETA: 10:30 - loss: 0.6895 - acc: 0.5400
2240/9333 [======>.......................] - ETA: 10:23 - loss: 0.6896 - acc: 0.5402
2304/9333 [======>.......................] - ETA: 10:17 - loss: 0.6891 - acc: 0.5412
2368/9333 [======>.......................] - ETA: 10:11 - loss: 0.6888 - acc: 0.5439
2432/9333 [======>.......................] - ETA: 10:04 - loss: 0.6885 - acc: 0.5461
2496/9333 [=======>......................] - ETA: 9:58 - loss: 0.6881 - acc: 0.5493 
2560/9333 [=======>......................] - ETA: 9:53 - loss: 0.6875 - acc: 0.5516
2624/9333 [=======>......................] - ETA: 9:47 - loss: 0.6875 - acc: 0.5511
2688/9333 [=======>......................] - ETA: 9:40 - loss: 0.6868 - acc: 0.5532
2752/9333 [=======>......................] - ETA: 9:36 - loss: 0.6871 - acc: 0.5509
2816/9333 [========>.....................] - ETA: 9:31 - loss: 0.6872 - acc: 0.5501
2880/9333 [========>.....................] - ETA: 9:25 - loss: 0.6875 - acc: 0.5486
2944/9333 [========>.....................] - ETA: 9:20 - loss: 0.6874 - acc: 0.5493
3008/9333 [========>.....................] - ETA: 9:13 - loss: 0.6874 - acc: 0.5499
3072/9333 [========>.....................] - ETA: 9:07 - loss: 0.6874 - acc: 0.5508
3136/9333 [=========>....................] - ETA: 9:01 - loss: 0.6877 - acc: 0.5507
3200/9333 [=========>....................] - ETA: 8:55 - loss: 0.6880 - acc: 0.5497
3264/9333 [=========>....................] - ETA: 8:49 - loss: 0.6883 - acc: 0.5490
3328/9333 [=========>....................] - ETA: 8:43 - loss: 0.6882 - acc: 0.5499
3392/9333 [=========>....................] - ETA: 8:37 - loss: 0.6882 - acc: 0.5501
3456/9333 [==========>...................] - ETA: 8:32 - loss: 0.6885 - acc: 0.5489
3520/9333 [==========>...................] - ETA: 8:27 - loss: 0.6882 - acc: 0.5491
3584/9333 [==========>...................] - ETA: 8:21 - loss: 0.6886 - acc: 0.5483
3648/9333 [==========>...................] - ETA: 8:15 - loss: 0.6882 - acc: 0.5491
3712/9333 [==========>...................] - ETA: 8:10 - loss: 0.6881 - acc: 0.5501
3776/9333 [===========>..................] - ETA: 8:05 - loss: 0.6885 - acc: 0.5487
3840/9333 [===========>..................] - ETA: 7:59 - loss: 0.6886 - acc: 0.5474
3904/9333 [===========>..................] - ETA: 7:54 - loss: 0.6886 - acc: 0.5476
3968/9333 [===========>..................] - ETA: 7:48 - loss: 0.6886 - acc: 0.5474
4032/9333 [===========>..................] - ETA: 7:42 - loss: 0.6886 - acc: 0.5484
4096/9333 [============>.................] - ETA: 7:36 - loss: 0.6884 - acc: 0.5483
4160/9333 [============>.................] - ETA: 7:31 - loss: 0.6884 - acc: 0.5478
4224/9333 [============>.................] - ETA: 7:25 - loss: 0.6883 - acc: 0.5481
4288/9333 [============>.................] - ETA: 7:19 - loss: 0.6885 - acc: 0.5476
4352/9333 [============>.................] - ETA: 7:13 - loss: 0.6884 - acc: 0.5466
4416/9333 [=============>................] - ETA: 7:08 - loss: 0.6886 - acc: 0.5466
4480/9333 [=============>................] - ETA: 7:02 - loss: 0.6887 - acc: 0.5462
4544/9333 [=============>................] - ETA: 6:56 - loss: 0.6884 - acc: 0.5469
4608/9333 [=============>................] - ETA: 6:50 - loss: 0.6884 - acc: 0.5473
4672/9333 [==============>...............] - ETA: 6:45 - loss: 0.6886 - acc: 0.5473
4736/9333 [==============>...............] - ETA: 6:39 - loss: 0.6888 - acc: 0.5467
4800/9333 [==============>...............] - ETA: 6:33 - loss: 0.6888 - acc: 0.5465
4864/9333 [==============>...............] - ETA: 6:27 - loss: 0.6888 - acc: 0.5465
4928/9333 [==============>...............] - ETA: 6:22 - loss: 0.6889 - acc: 0.5457
4992/9333 [===============>..............] - ETA: 6:16 - loss: 0.6891 - acc: 0.5445
5056/9333 [===============>..............] - ETA: 6:10 - loss: 0.6888 - acc: 0.5455
5120/9333 [===============>..............] - ETA: 6:04 - loss: 0.6887 - acc: 0.5463
5184/9333 [===============>..............] - ETA: 5:58 - loss: 0.6885 - acc: 0.5469
5248/9333 [===============>..............] - ETA: 5:53 - loss: 0.6884 - acc: 0.5469
5312/9333 [================>.............] - ETA: 5:47 - loss: 0.6881 - acc: 0.5484
5376/9333 [================>.............] - ETA: 5:41 - loss: 0.6882 - acc: 0.5474
5440/9333 [================>.............] - ETA: 5:35 - loss: 0.6881 - acc: 0.5474
5504/9333 [================>.............] - ETA: 5:29 - loss: 0.6883 - acc: 0.5461
5568/9333 [================>.............] - ETA: 5:24 - loss: 0.6882 - acc: 0.5465
5632/9333 [=================>............] - ETA: 5:18 - loss: 0.6882 - acc: 0.5465
5696/9333 [=================>............] - ETA: 5:12 - loss: 0.6881 - acc: 0.5460
5760/9333 [=================>............] - ETA: 5:06 - loss: 0.6883 - acc: 0.5457
5824/9333 [=================>............] - ETA: 5:00 - loss: 0.6886 - acc: 0.5453
5888/9333 [=================>............] - ETA: 4:55 - loss: 0.6889 - acc: 0.5445
5952/9333 [==================>...........] - ETA: 4:49 - loss: 0.6884 - acc: 0.5462
6016/9333 [==================>...........] - ETA: 4:44 - loss: 0.6885 - acc: 0.5452
6080/9333 [==================>...........] - ETA: 4:38 - loss: 0.6886 - acc: 0.5449
6144/9333 [==================>...........] - ETA: 4:32 - loss: 0.6885 - acc: 0.5449
6208/9333 [==================>...........] - ETA: 4:26 - loss: 0.6885 - acc: 0.5453
6272/9333 [===================>..........] - ETA: 4:21 - loss: 0.6884 - acc: 0.5456
6336/9333 [===================>..........] - ETA: 4:15 - loss: 0.6885 - acc: 0.5462
6400/9333 [===================>..........] - ETA: 4:09 - loss: 0.6888 - acc: 0.5453
6464/9333 [===================>..........] - ETA: 4:04 - loss: 0.6887 - acc: 0.5461
6528/9333 [===================>..........] - ETA: 3:58 - loss: 0.6887 - acc: 0.5456
6592/9333 [====================>.........] - ETA: 3:53 - loss: 0.6888 - acc: 0.5455
6656/9333 [====================>.........] - ETA: 3:47 - loss: 0.6889 - acc: 0.5457
6720/9333 [====================>.........] - ETA: 3:42 - loss: 0.6891 - acc: 0.5446
6784/9333 [====================>.........] - ETA: 3:36 - loss: 0.6892 - acc: 0.5436
6848/9333 [=====================>........] - ETA: 3:31 - loss: 0.6891 - acc: 0.5442
6912/9333 [=====================>........] - ETA: 3:25 - loss: 0.6890 - acc: 0.5451
6976/9333 [=====================>........] - ETA: 3:20 - loss: 0.6893 - acc: 0.5446
7040/9333 [=====================>........] - ETA: 3:14 - loss: 0.6893 - acc: 0.5446
7104/9333 [=====================>........] - ETA: 3:08 - loss: 0.6894 - acc: 0.5441
7168/9333 [======================>.......] - ETA: 3:03 - loss: 0.6895 - acc: 0.5435
7232/9333 [======================>.......] - ETA: 2:58 - loss: 0.6895 - acc: 0.5437
7296/9333 [======================>.......] - ETA: 2:52 - loss: 0.6894 - acc: 0.5437
7360/9333 [======================>.......] - ETA: 2:47 - loss: 0.6894 - acc: 0.5436
7424/9333 [======================>.......] - ETA: 2:41 - loss: 0.6892 - acc: 0.5443
7488/9333 [=======================>......] - ETA: 2:36 - loss: 0.6892 - acc: 0.5446
7552/9333 [=======================>......] - ETA: 2:30 - loss: 0.6893 - acc: 0.5442
7616/9333 [=======================>......] - ETA: 2:25 - loss: 0.6892 - acc: 0.5446
7680/9333 [=======================>......] - ETA: 2:19 - loss: 0.6892 - acc: 0.5453
7744/9333 [=======================>......] - ETA: 2:14 - loss: 0.6892 - acc: 0.5451
7808/9333 [========================>.....] - ETA: 2:08 - loss: 0.6893 - acc: 0.5450
7872/9333 [========================>.....] - ETA: 2:02 - loss: 0.6894 - acc: 0.5447
7936/9333 [========================>.....] - ETA: 1:57 - loss: 0.6892 - acc: 0.5456
8000/9333 [========================>.....] - ETA: 1:51 - loss: 0.6892 - acc: 0.5454
8064/9333 [========================>.....] - ETA: 1:46 - loss: 0.6892 - acc: 0.5453
8128/9333 [=========================>....] - ETA: 1:40 - loss: 0.6893 - acc: 0.5448
8192/9333 [=========================>....] - ETA: 1:35 - loss: 0.6894 - acc: 0.5446
8256/9333 [=========================>....] - ETA: 1:29 - loss: 0.6895 - acc: 0.5438
8320/9333 [=========================>....] - ETA: 1:24 - loss: 0.6894 - acc: 0.5437
8384/9333 [=========================>....] - ETA: 1:18 - loss: 0.6895 - acc: 0.5435
8448/9333 [==========================>...] - ETA: 1:13 - loss: 0.6895 - acc: 0.5436
8512/9333 [==========================>...] - ETA: 1:08 - loss: 0.6895 - acc: 0.5436
8576/9333 [==========================>...] - ETA: 1:02 - loss: 0.6895 - acc: 0.5438
8640/9333 [==========================>...] - ETA: 57s - loss: 0.6895 - acc: 0.5442 
8704/9333 [==========================>...] - ETA: 51s - loss: 0.6895 - acc: 0.5446
8768/9333 [===========================>..] - ETA: 46s - loss: 0.6895 - acc: 0.5440
8832/9333 [===========================>..] - ETA: 41s - loss: 0.6895 - acc: 0.5439
8896/9333 [===========================>..] - ETA: 36s - loss: 0.6894 - acc: 0.5447
8960/9333 [===========================>..] - ETA: 30s - loss: 0.6894 - acc: 0.5444
9024/9333 [============================>.] - ETA: 25s - loss: 0.6894 - acc: 0.5443
9088/9333 [============================>.] - ETA: 20s - loss: 0.6894 - acc: 0.5446
9152/9333 [============================>.] - ETA: 14s - loss: 0.6892 - acc: 0.5450
9216/9333 [============================>.] - ETA: 9s - loss: 0.6892 - acc: 0.5450 
9280/9333 [============================>.] - ETA: 4s - loss: 0.6892 - acc: 0.5448
9333/9333 [==============================] - 800s 86ms/step - loss: 0.6892 - acc: 0.5446 - val_loss: 0.6888 - val_acc: 0.5381

Epoch 00007: val_acc did not improve from 0.53809
Epoch 8/10

  64/9333 [..............................] - ETA: 12:46 - loss: 0.6901 - acc: 0.5938
 128/9333 [..............................] - ETA: 13:11 - loss: 0.6840 - acc: 0.6094
 192/9333 [..............................] - ETA: 12:54 - loss: 0.6882 - acc: 0.5990
 256/9333 [..............................] - ETA: 12:56 - loss: 0.6862 - acc: 0.6055
 320/9333 [>.............................] - ETA: 12:59 - loss: 0.6849 - acc: 0.5969
 384/9333 [>.............................] - ETA: 12:49 - loss: 0.6803 - acc: 0.5990
 448/9333 [>.............................] - ETA: 12:42 - loss: 0.6841 - acc: 0.5848
 512/9333 [>.............................] - ETA: 12:48 - loss: 0.6845 - acc: 0.5762
 576/9333 [>.............................] - ETA: 12:38 - loss: 0.6855 - acc: 0.5799
 640/9333 [=>............................] - ETA: 12:28 - loss: 0.6890 - acc: 0.5703
 704/9333 [=>............................] - ETA: 12:16 - loss: 0.6901 - acc: 0.5668
 768/9333 [=>............................] - ETA: 12:08 - loss: 0.6879 - acc: 0.5677
 832/9333 [=>............................] - ETA: 12:06 - loss: 0.6875 - acc: 0.5673
 896/9333 [=>............................] - ETA: 11:55 - loss: 0.6865 - acc: 0.5658
 960/9333 [==>...........................] - ETA: 11:51 - loss: 0.6862 - acc: 0.5677
1024/9333 [==>...........................] - ETA: 11:46 - loss: 0.6855 - acc: 0.5664
1088/9333 [==>...........................] - ETA: 11:46 - loss: 0.6840 - acc: 0.5735
1152/9333 [==>...........................] - ETA: 11:38 - loss: 0.6851 - acc: 0.5686
1216/9333 [==>...........................] - ETA: 11:30 - loss: 0.6850 - acc: 0.5674
1280/9333 [===>..........................] - ETA: 11:27 - loss: 0.6852 - acc: 0.5656
1344/9333 [===>..........................] - ETA: 11:22 - loss: 0.6846 - acc: 0.5655
1408/9333 [===>..........................] - ETA: 11:18 - loss: 0.6850 - acc: 0.5646
1472/9333 [===>..........................] - ETA: 11:13 - loss: 0.6857 - acc: 0.5618
1536/9333 [===>..........................] - ETA: 11:09 - loss: 0.6845 - acc: 0.5651
1600/9333 [====>.........................] - ETA: 11:04 - loss: 0.6850 - acc: 0.5637
1664/9333 [====>.........................] - ETA: 10:59 - loss: 0.6844 - acc: 0.5673
1728/9333 [====>.........................] - ETA: 10:56 - loss: 0.6833 - acc: 0.5689
1792/9333 [====>.........................] - ETA: 10:52 - loss: 0.6831 - acc: 0.5681
1856/9333 [====>.........................] - ETA: 10:45 - loss: 0.6827 - acc: 0.5690
1920/9333 [=====>........................] - ETA: 10:40 - loss: 0.6839 - acc: 0.5667
1984/9333 [=====>........................] - ETA: 10:34 - loss: 0.6846 - acc: 0.5640
2048/9333 [=====>........................] - ETA: 10:29 - loss: 0.6842 - acc: 0.5649
2112/9333 [=====>........................] - ETA: 10:21 - loss: 0.6841 - acc: 0.5620
2176/9333 [=====>........................] - ETA: 10:17 - loss: 0.6842 - acc: 0.5634
2240/9333 [======>.......................] - ETA: 10:12 - loss: 0.6846 - acc: 0.5621
2304/9333 [======>.......................] - ETA: 10:06 - loss: 0.6846 - acc: 0.5625
2368/9333 [======>.......................] - ETA: 10:01 - loss: 0.6848 - acc: 0.5612
2432/9333 [======>.......................] - ETA: 9:55 - loss: 0.6843 - acc: 0.5609 
2496/9333 [=======>......................] - ETA: 9:50 - loss: 0.6849 - acc: 0.5601
2560/9333 [=======>......................] - ETA: 9:45 - loss: 0.6851 - acc: 0.5582
2624/9333 [=======>......................] - ETA: 9:39 - loss: 0.6854 - acc: 0.5587
2688/9333 [=======>......................] - ETA: 9:34 - loss: 0.6852 - acc: 0.5595
2752/9333 [=======>......................] - ETA: 9:28 - loss: 0.6848 - acc: 0.5603
2816/9333 [========>.....................] - ETA: 9:22 - loss: 0.6850 - acc: 0.5604
2880/9333 [========>.....................] - ETA: 9:17 - loss: 0.6853 - acc: 0.5580
2944/9333 [========>.....................] - ETA: 9:12 - loss: 0.6852 - acc: 0.5574
3008/9333 [========>.....................] - ETA: 9:07 - loss: 0.6861 - acc: 0.5552
3072/9333 [========>.....................] - ETA: 9:01 - loss: 0.6862 - acc: 0.5550
3136/9333 [=========>....................] - ETA: 8:56 - loss: 0.6858 - acc: 0.5574
3200/9333 [=========>....................] - ETA: 8:51 - loss: 0.6860 - acc: 0.5559
3264/9333 [=========>....................] - ETA: 8:46 - loss: 0.6858 - acc: 0.5558
3328/9333 [=========>....................] - ETA: 8:40 - loss: 0.6864 - acc: 0.5544
3392/9333 [=========>....................] - ETA: 8:35 - loss: 0.6866 - acc: 0.5534
3456/9333 [==========>...................] - ETA: 8:30 - loss: 0.6865 - acc: 0.5550
3520/9333 [==========>...................] - ETA: 8:24 - loss: 0.6864 - acc: 0.5548
3584/9333 [==========>...................] - ETA: 8:19 - loss: 0.6867 - acc: 0.5541
3648/9333 [==========>...................] - ETA: 8:14 - loss: 0.6867 - acc: 0.5535
3712/9333 [==========>...................] - ETA: 8:08 - loss: 0.6866 - acc: 0.5533
3776/9333 [===========>..................] - ETA: 8:02 - loss: 0.6866 - acc: 0.5532
3840/9333 [===========>..................] - ETA: 7:57 - loss: 0.6863 - acc: 0.5547
3904/9333 [===========>..................] - ETA: 7:50 - loss: 0.6860 - acc: 0.5561
3968/9333 [===========>..................] - ETA: 7:45 - loss: 0.6858 - acc: 0.5562
4032/9333 [===========>..................] - ETA: 7:40 - loss: 0.6858 - acc: 0.5563
4096/9333 [============>.................] - ETA: 7:34 - loss: 0.6855 - acc: 0.5574
4160/9333 [============>.................] - ETA: 7:28 - loss: 0.6854 - acc: 0.5579
4224/9333 [============>.................] - ETA: 7:22 - loss: 0.6855 - acc: 0.5568
4288/9333 [============>.................] - ETA: 7:16 - loss: 0.6861 - acc: 0.5548
4352/9333 [============>.................] - ETA: 7:12 - loss: 0.6864 - acc: 0.5526
4416/9333 [=============>................] - ETA: 7:06 - loss: 0.6861 - acc: 0.5537
4480/9333 [=============>................] - ETA: 7:00 - loss: 0.6863 - acc: 0.5529
4544/9333 [=============>................] - ETA: 6:54 - loss: 0.6863 - acc: 0.5530
4608/9333 [=============>................] - ETA: 6:49 - loss: 0.6863 - acc: 0.5530
4672/9333 [==============>...............] - ETA: 6:43 - loss: 0.6863 - acc: 0.5533
4736/9333 [==============>...............] - ETA: 6:38 - loss: 0.6861 - acc: 0.5536
4800/9333 [==============>...............] - ETA: 6:32 - loss: 0.6863 - acc: 0.5531
4864/9333 [==============>...............] - ETA: 6:27 - loss: 0.6862 - acc: 0.5535
4928/9333 [==============>...............] - ETA: 6:21 - loss: 0.6859 - acc: 0.5542
4992/9333 [===============>..............] - ETA: 6:16 - loss: 0.6862 - acc: 0.5527
5056/9333 [===============>..............] - ETA: 6:10 - loss: 0.6862 - acc: 0.5536
5120/9333 [===============>..............] - ETA: 6:05 - loss: 0.6864 - acc: 0.5539
5184/9333 [===============>..............] - ETA: 6:00 - loss: 0.6863 - acc: 0.5542
5248/9333 [===============>..............] - ETA: 5:54 - loss: 0.6864 - acc: 0.5539
5312/9333 [================>.............] - ETA: 5:49 - loss: 0.6860 - acc: 0.5544
5376/9333 [================>.............] - ETA: 5:43 - loss: 0.6864 - acc: 0.5532
5440/9333 [================>.............] - ETA: 5:37 - loss: 0.6865 - acc: 0.5528
5504/9333 [================>.............] - ETA: 5:32 - loss: 0.6867 - acc: 0.5518
5568/9333 [================>.............] - ETA: 5:26 - loss: 0.6865 - acc: 0.5528
5632/9333 [=================>............] - ETA: 5:21 - loss: 0.6862 - acc: 0.5533
5696/9333 [=================>............] - ETA: 5:15 - loss: 0.6862 - acc: 0.5535
5760/9333 [=================>............] - ETA: 5:10 - loss: 0.6861 - acc: 0.5531
5824/9333 [=================>............] - ETA: 5:05 - loss: 0.6861 - acc: 0.5531
5888/9333 [=================>............] - ETA: 4:59 - loss: 0.6864 - acc: 0.5525
5952/9333 [==================>...........] - ETA: 4:54 - loss: 0.6864 - acc: 0.5529
6016/9333 [==================>...........] - ETA: 4:48 - loss: 0.6866 - acc: 0.5524
6080/9333 [==================>...........] - ETA: 4:42 - loss: 0.6868 - acc: 0.5521
6144/9333 [==================>...........] - ETA: 4:37 - loss: 0.6867 - acc: 0.5527
6208/9333 [==================>...........] - ETA: 4:31 - loss: 0.6864 - acc: 0.5540
6272/9333 [===================>..........] - ETA: 4:26 - loss: 0.6863 - acc: 0.5537
6336/9333 [===================>..........] - ETA: 4:20 - loss: 0.6865 - acc: 0.5532
6400/9333 [===================>..........] - ETA: 4:14 - loss: 0.6862 - acc: 0.5539
6464/9333 [===================>..........] - ETA: 4:09 - loss: 0.6862 - acc: 0.5540
6528/9333 [===================>..........] - ETA: 4:03 - loss: 0.6861 - acc: 0.5545
6592/9333 [====================>.........] - ETA: 3:58 - loss: 0.6862 - acc: 0.5542
6656/9333 [====================>.........] - ETA: 3:52 - loss: 0.6859 - acc: 0.5545
6720/9333 [====================>.........] - ETA: 3:47 - loss: 0.6859 - acc: 0.5545
6784/9333 [====================>.........] - ETA: 3:42 - loss: 0.6859 - acc: 0.5538
6848/9333 [=====================>........] - ETA: 3:36 - loss: 0.6860 - acc: 0.5537
6912/9333 [=====================>........] - ETA: 3:31 - loss: 0.6858 - acc: 0.5544
6976/9333 [=====================>........] - ETA: 3:25 - loss: 0.6858 - acc: 0.5545
7040/9333 [=====================>........] - ETA: 3:20 - loss: 0.6856 - acc: 0.5548
7104/9333 [=====================>........] - ETA: 3:14 - loss: 0.6857 - acc: 0.5545
7168/9333 [======================>.......] - ETA: 3:08 - loss: 0.6853 - acc: 0.5554
7232/9333 [======================>.......] - ETA: 3:03 - loss: 0.6856 - acc: 0.5546
7296/9333 [======================>.......] - ETA: 2:58 - loss: 0.6857 - acc: 0.5546
7360/9333 [======================>.......] - ETA: 2:52 - loss: 0.6857 - acc: 0.5550
7424/9333 [======================>.......] - ETA: 2:47 - loss: 0.6858 - acc: 0.5551
7488/9333 [=======================>......] - ETA: 2:41 - loss: 0.6859 - acc: 0.5550
7552/9333 [=======================>......] - ETA: 2:35 - loss: 0.6859 - acc: 0.5552
7616/9333 [=======================>......] - ETA: 2:30 - loss: 0.6863 - acc: 0.5538
7680/9333 [=======================>......] - ETA: 2:24 - loss: 0.6867 - acc: 0.5529
7744/9333 [=======================>......] - ETA: 2:18 - loss: 0.6869 - acc: 0.5529
7808/9333 [========================>.....] - ETA: 2:13 - loss: 0.6871 - acc: 0.5528
7872/9333 [========================>.....] - ETA: 2:07 - loss: 0.6872 - acc: 0.5526
7936/9333 [========================>.....] - ETA: 2:02 - loss: 0.6870 - acc: 0.5532
8000/9333 [========================>.....] - ETA: 1:56 - loss: 0.6871 - acc: 0.5531
8064/9333 [========================>.....] - ETA: 1:51 - loss: 0.6869 - acc: 0.5541
8128/9333 [=========================>....] - ETA: 1:45 - loss: 0.6867 - acc: 0.5546
8192/9333 [=========================>....] - ETA: 1:39 - loss: 0.6865 - acc: 0.5549
8256/9333 [=========================>....] - ETA: 1:34 - loss: 0.6864 - acc: 0.5552
8320/9333 [=========================>....] - ETA: 1:28 - loss: 0.6865 - acc: 0.5547
8384/9333 [=========================>....] - ETA: 1:23 - loss: 0.6864 - acc: 0.5553
8448/9333 [==========================>...] - ETA: 1:17 - loss: 0.6865 - acc: 0.5548
8512/9333 [==========================>...] - ETA: 1:11 - loss: 0.6863 - acc: 0.5545
8576/9333 [==========================>...] - ETA: 1:06 - loss: 0.6863 - acc: 0.5543
8640/9333 [==========================>...] - ETA: 1:00 - loss: 0.6865 - acc: 0.5537
8704/9333 [==========================>...] - ETA: 55s - loss: 0.6867 - acc: 0.5526 
8768/9333 [===========================>..] - ETA: 49s - loss: 0.6866 - acc: 0.5528
8832/9333 [===========================>..] - ETA: 43s - loss: 0.6868 - acc: 0.5523
8896/9333 [===========================>..] - ETA: 38s - loss: 0.6870 - acc: 0.5516
8960/9333 [===========================>..] - ETA: 32s - loss: 0.6872 - acc: 0.5507
9024/9333 [============================>.] - ETA: 27s - loss: 0.6872 - acc: 0.5505
9088/9333 [============================>.] - ETA: 21s - loss: 0.6873 - acc: 0.5509
9152/9333 [============================>.] - ETA: 15s - loss: 0.6873 - acc: 0.5515
9216/9333 [============================>.] - ETA: 10s - loss: 0.6874 - acc: 0.5511
9280/9333 [============================>.] - ETA: 4s - loss: 0.6872 - acc: 0.5518 
9333/9333 [==============================] - 850s 91ms/step - loss: 0.6874 - acc: 0.5513 - val_loss: 0.6884 - val_acc: 0.5207

Epoch 00008: val_acc did not improve from 0.53809
Epoch 9/10

  64/9333 [..............................] - ETA: 13:46 - loss: 0.6903 - acc: 0.5469
 128/9333 [..............................] - ETA: 13:58 - loss: 0.6941 - acc: 0.5156
 192/9333 [..............................] - ETA: 13:52 - loss: 0.6894 - acc: 0.5469
 256/9333 [..............................] - ETA: 13:58 - loss: 0.6905 - acc: 0.5234
 320/9333 [>.............................] - ETA: 14:05 - loss: 0.6905 - acc: 0.5219
 384/9333 [>.............................] - ETA: 13:54 - loss: 0.6912 - acc: 0.5182
 448/9333 [>.............................] - ETA: 13:36 - loss: 0.6923 - acc: 0.5179
 512/9333 [>.............................] - ETA: 13:21 - loss: 0.6929 - acc: 0.5215
 576/9333 [>.............................] - ETA: 13:22 - loss: 0.6933 - acc: 0.5174
 640/9333 [=>............................] - ETA: 13:16 - loss: 0.6923 - acc: 0.5156
 704/9333 [=>............................] - ETA: 13:07 - loss: 0.6901 - acc: 0.5213
 768/9333 [=>............................] - ETA: 12:55 - loss: 0.6889 - acc: 0.5247
 832/9333 [=>............................] - ETA: 12:46 - loss: 0.6896 - acc: 0.5216
 896/9333 [=>............................] - ETA: 12:30 - loss: 0.6899 - acc: 0.5234
 960/9333 [==>...........................] - ETA: 12:20 - loss: 0.6902 - acc: 0.5219
1024/9333 [==>...........................] - ETA: 12:10 - loss: 0.6898 - acc: 0.5244
1088/9333 [==>...........................] - ETA: 12:00 - loss: 0.6891 - acc: 0.5322
1152/9333 [==>...........................] - ETA: 11:51 - loss: 0.6888 - acc: 0.5339
1216/9333 [==>...........................] - ETA: 11:43 - loss: 0.6877 - acc: 0.5403
1280/9333 [===>..........................] - ETA: 11:34 - loss: 0.6877 - acc: 0.5414
1344/9333 [===>..........................] - ETA: 11:25 - loss: 0.6879 - acc: 0.5402
1408/9333 [===>..........................] - ETA: 11:17 - loss: 0.6887 - acc: 0.5369
1472/9333 [===>..........................] - ETA: 11:11 - loss: 0.6888 - acc: 0.5353
1536/9333 [===>..........................] - ETA: 11:02 - loss: 0.6900 - acc: 0.5319
1600/9333 [====>.........................] - ETA: 10:54 - loss: 0.6894 - acc: 0.5319
1664/9333 [====>.........................] - ETA: 10:49 - loss: 0.6898 - acc: 0.5288
1728/9333 [====>.........................] - ETA: 10:42 - loss: 0.6902 - acc: 0.5266
1792/9333 [====>.........................] - ETA: 10:34 - loss: 0.6892 - acc: 0.5301
1856/9333 [====>.........................] - ETA: 10:27 - loss: 0.6893 - acc: 0.5307
1920/9333 [=====>........................] - ETA: 10:23 - loss: 0.6892 - acc: 0.5328
1984/9333 [=====>........................] - ETA: 10:16 - loss: 0.6885 - acc: 0.5353
2048/9333 [=====>........................] - ETA: 10:10 - loss: 0.6887 - acc: 0.5356
2112/9333 [=====>........................] - ETA: 10:04 - loss: 0.6887 - acc: 0.5369
2176/9333 [=====>........................] - ETA: 9:59 - loss: 0.6888 - acc: 0.5377 
2240/9333 [======>.......................] - ETA: 9:53 - loss: 0.6886 - acc: 0.5375
2304/9333 [======>.......................] - ETA: 9:46 - loss: 0.6884 - acc: 0.5369
2368/9333 [======>.......................] - ETA: 9:39 - loss: 0.6878 - acc: 0.5380
2432/9333 [======>.......................] - ETA: 9:34 - loss: 0.6880 - acc: 0.5391
2496/9333 [=======>......................] - ETA: 9:28 - loss: 0.6884 - acc: 0.5369
2560/9333 [=======>......................] - ETA: 9:23 - loss: 0.6884 - acc: 0.5363
2624/9333 [=======>......................] - ETA: 9:17 - loss: 0.6882 - acc: 0.5373
2688/9333 [=======>......................] - ETA: 9:12 - loss: 0.6879 - acc: 0.5387
2752/9333 [=======>......................] - ETA: 9:06 - loss: 0.6877 - acc: 0.5396
2816/9333 [========>.....................] - ETA: 8:59 - loss: 0.6874 - acc: 0.5408
2880/9333 [========>.....................] - ETA: 8:54 - loss: 0.6870 - acc: 0.5434
2944/9333 [========>.....................] - ETA: 8:48 - loss: 0.6869 - acc: 0.5442
3008/9333 [========>.....................] - ETA: 8:43 - loss: 0.6864 - acc: 0.5455
3072/9333 [========>.....................] - ETA: 8:37 - loss: 0.6861 - acc: 0.5475
3136/9333 [=========>....................] - ETA: 8:32 - loss: 0.6859 - acc: 0.5485
3200/9333 [=========>....................] - ETA: 8:27 - loss: 0.6857 - acc: 0.5491
3264/9333 [=========>....................] - ETA: 8:21 - loss: 0.6856 - acc: 0.5487
3328/9333 [=========>....................] - ETA: 8:15 - loss: 0.6855 - acc: 0.5496
3392/9333 [=========>....................] - ETA: 8:09 - loss: 0.6859 - acc: 0.5481
3456/9333 [==========>...................] - ETA: 8:03 - loss: 0.6862 - acc: 0.5472
3520/9333 [==========>...................] - ETA: 7:56 - loss: 0.6861 - acc: 0.5480
3584/9333 [==========>...................] - ETA: 7:51 - loss: 0.6860 - acc: 0.5494
3648/9333 [==========>...................] - ETA: 7:45 - loss: 0.6856 - acc: 0.5499
3712/9333 [==========>...................] - ETA: 7:40 - loss: 0.6857 - acc: 0.5501
3776/9333 [===========>..................] - ETA: 7:34 - loss: 0.6853 - acc: 0.5508
3840/9333 [===========>..................] - ETA: 7:28 - loss: 0.6855 - acc: 0.5500
3904/9333 [===========>..................] - ETA: 7:23 - loss: 0.6857 - acc: 0.5492
3968/9333 [===========>..................] - ETA: 7:17 - loss: 0.6855 - acc: 0.5496
4032/9333 [===========>..................] - ETA: 7:10 - loss: 0.6851 - acc: 0.5503
4096/9333 [============>.................] - ETA: 7:05 - loss: 0.6847 - acc: 0.5515
4160/9333 [============>.................] - ETA: 6:59 - loss: 0.6841 - acc: 0.5529
4224/9333 [============>.................] - ETA: 6:53 - loss: 0.6839 - acc: 0.5528
4288/9333 [============>.................] - ETA: 6:47 - loss: 0.6842 - acc: 0.5522
4352/9333 [============>.................] - ETA: 6:42 - loss: 0.6844 - acc: 0.5524
4416/9333 [=============>................] - ETA: 6:36 - loss: 0.6844 - acc: 0.5514
4480/9333 [=============>................] - ETA: 6:31 - loss: 0.6847 - acc: 0.5500
4544/9333 [=============>................] - ETA: 6:25 - loss: 0.6845 - acc: 0.5506
4608/9333 [=============>................] - ETA: 6:20 - loss: 0.6844 - acc: 0.5501
4672/9333 [==============>...............] - ETA: 6:14 - loss: 0.6842 - acc: 0.5507
4736/9333 [==============>...............] - ETA: 6:09 - loss: 0.6837 - acc: 0.5526
4800/9333 [==============>...............] - ETA: 6:03 - loss: 0.6842 - acc: 0.5517
4864/9333 [==============>...............] - ETA: 5:58 - loss: 0.6844 - acc: 0.5504
4928/9333 [==============>...............] - ETA: 5:52 - loss: 0.6849 - acc: 0.5483
4992/9333 [===============>..............] - ETA: 5:47 - loss: 0.6844 - acc: 0.5495
5056/9333 [===============>..............] - ETA: 5:42 - loss: 0.6847 - acc: 0.5485
5120/9333 [===============>..............] - ETA: 5:36 - loss: 0.6847 - acc: 0.5496
5184/9333 [===============>..............] - ETA: 5:31 - loss: 0.6848 - acc: 0.5492
5248/9333 [===============>..............] - ETA: 5:26 - loss: 0.6849 - acc: 0.5492
5312/9333 [================>.............] - ETA: 5:20 - loss: 0.6853 - acc: 0.5480
5376/9333 [================>.............] - ETA: 5:15 - loss: 0.6854 - acc: 0.5472
5440/9333 [================>.............] - ETA: 5:09 - loss: 0.6855 - acc: 0.5469
5504/9333 [================>.............] - ETA: 5:04 - loss: 0.6856 - acc: 0.5469
5568/9333 [================>.............] - ETA: 4:58 - loss: 0.6851 - acc: 0.5487
5632/9333 [=================>............] - ETA: 4:53 - loss: 0.6851 - acc: 0.5490
5696/9333 [=================>............] - ETA: 4:48 - loss: 0.6849 - acc: 0.5497
5760/9333 [=================>............] - ETA: 4:43 - loss: 0.6848 - acc: 0.5500
5824/9333 [=================>............] - ETA: 4:38 - loss: 0.6851 - acc: 0.5488
5888/9333 [=================>............] - ETA: 4:33 - loss: 0.6855 - acc: 0.5479
5952/9333 [==================>...........] - ETA: 4:27 - loss: 0.6854 - acc: 0.5477
6016/9333 [==================>...........] - ETA: 4:22 - loss: 0.6853 - acc: 0.5482
6080/9333 [==================>...........] - ETA: 4:17 - loss: 0.6855 - acc: 0.5477
6144/9333 [==================>...........] - ETA: 4:12 - loss: 0.6858 - acc: 0.5467
6208/9333 [==================>...........] - ETA: 4:07 - loss: 0.6859 - acc: 0.5461
6272/9333 [===================>..........] - ETA: 4:02 - loss: 0.6858 - acc: 0.5464
6336/9333 [===================>..........] - ETA: 3:56 - loss: 0.6859 - acc: 0.5470
6400/9333 [===================>..........] - ETA: 3:51 - loss: 0.6860 - acc: 0.5466
6464/9333 [===================>..........] - ETA: 3:46 - loss: 0.6860 - acc: 0.5459
6528/9333 [===================>..........] - ETA: 3:41 - loss: 0.6859 - acc: 0.5466
6592/9333 [====================>.........] - ETA: 3:36 - loss: 0.6859 - acc: 0.5470
6656/9333 [====================>.........] - ETA: 3:31 - loss: 0.6858 - acc: 0.5478
6720/9333 [====================>.........] - ETA: 3:26 - loss: 0.6860 - acc: 0.5472
6784/9333 [====================>.........] - ETA: 3:21 - loss: 0.6860 - acc: 0.5479
6848/9333 [=====================>........] - ETA: 3:16 - loss: 0.6859 - acc: 0.5483
6912/9333 [=====================>........] - ETA: 3:11 - loss: 0.6859 - acc: 0.5480
6976/9333 [=====================>........] - ETA: 3:05 - loss: 0.6858 - acc: 0.5480
7040/9333 [=====================>........] - ETA: 3:00 - loss: 0.6859 - acc: 0.5479
7104/9333 [=====================>........] - ETA: 2:55 - loss: 0.6856 - acc: 0.5487
7168/9333 [======================>.......] - ETA: 2:50 - loss: 0.6857 - acc: 0.5484
7232/9333 [======================>.......] - ETA: 2:45 - loss: 0.6857 - acc: 0.5483
7296/9333 [======================>.......] - ETA: 2:40 - loss: 0.6858 - acc: 0.5482
7360/9333 [======================>.......] - ETA: 2:35 - loss: 0.6859 - acc: 0.5474
7424/9333 [======================>.......] - ETA: 2:30 - loss: 0.6859 - acc: 0.5475
7488/9333 [=======================>......] - ETA: 2:25 - loss: 0.6859 - acc: 0.5477
7552/9333 [=======================>......] - ETA: 2:20 - loss: 0.6860 - acc: 0.5477
7616/9333 [=======================>......] - ETA: 2:15 - loss: 0.6864 - acc: 0.5467
7680/9333 [=======================>......] - ETA: 2:10 - loss: 0.6865 - acc: 0.5471
7744/9333 [=======================>......] - ETA: 2:05 - loss: 0.6863 - acc: 0.5479
7808/9333 [========================>.....] - ETA: 2:00 - loss: 0.6865 - acc: 0.5467
7872/9333 [========================>.....] - ETA: 1:55 - loss: 0.6865 - acc: 0.5465
7936/9333 [========================>.....] - ETA: 1:50 - loss: 0.6865 - acc: 0.5466
8000/9333 [========================>.....] - ETA: 1:45 - loss: 0.6864 - acc: 0.5473
8064/9333 [========================>.....] - ETA: 1:40 - loss: 0.6865 - acc: 0.5469
8128/9333 [=========================>....] - ETA: 1:35 - loss: 0.6866 - acc: 0.5466
8192/9333 [=========================>....] - ETA: 1:30 - loss: 0.6867 - acc: 0.5464
8256/9333 [=========================>....] - ETA: 1:25 - loss: 0.6865 - acc: 0.5475
8320/9333 [=========================>....] - ETA: 1:20 - loss: 0.6865 - acc: 0.5476
8384/9333 [=========================>....] - ETA: 1:14 - loss: 0.6865 - acc: 0.5472
8448/9333 [==========================>...] - ETA: 1:09 - loss: 0.6864 - acc: 0.5478
8512/9333 [==========================>...] - ETA: 1:04 - loss: 0.6865 - acc: 0.5475
8576/9333 [==========================>...] - ETA: 59s - loss: 0.6866 - acc: 0.5473 
8640/9333 [==========================>...] - ETA: 54s - loss: 0.6867 - acc: 0.5471
8704/9333 [==========================>...] - ETA: 49s - loss: 0.6865 - acc: 0.5476
8768/9333 [===========================>..] - ETA: 44s - loss: 0.6864 - acc: 0.5481
8832/9333 [===========================>..] - ETA: 39s - loss: 0.6863 - acc: 0.5483
8896/9333 [===========================>..] - ETA: 34s - loss: 0.6862 - acc: 0.5490
8960/9333 [===========================>..] - ETA: 29s - loss: 0.6862 - acc: 0.5492
9024/9333 [============================>.] - ETA: 24s - loss: 0.6864 - acc: 0.5485
9088/9333 [============================>.] - ETA: 19s - loss: 0.6863 - acc: 0.5484
9152/9333 [============================>.] - ETA: 14s - loss: 0.6864 - acc: 0.5482
9216/9333 [============================>.] - ETA: 9s - loss: 0.6863 - acc: 0.5485 
9280/9333 [============================>.] - ETA: 4s - loss: 0.6863 - acc: 0.5485
9333/9333 [==============================] - 766s 82ms/step - loss: 0.6862 - acc: 0.5488 - val_loss: 0.6890 - val_acc: 0.5371

Epoch 00009: val_acc did not improve from 0.53809
Epoch 10/10

  64/9333 [..............................] - ETA: 11:59 - loss: 0.6851 - acc: 0.5156
 128/9333 [..............................] - ETA: 11:37 - loss: 0.6844 - acc: 0.5391
 192/9333 [..............................] - ETA: 11:50 - loss: 0.6935 - acc: 0.5208
 256/9333 [..............................] - ETA: 11:42 - loss: 0.6969 - acc: 0.5156
 320/9333 [>.............................] - ETA: 11:50 - loss: 0.7021 - acc: 0.5031
 384/9333 [>.............................] - ETA: 11:39 - loss: 0.6991 - acc: 0.5026
 448/9333 [>.............................] - ETA: 11:35 - loss: 0.6901 - acc: 0.5335
 512/9333 [>.............................] - ETA: 11:38 - loss: 0.6869 - acc: 0.5410
 576/9333 [>.............................] - ETA: 11:36 - loss: 0.6861 - acc: 0.5521
 640/9333 [=>............................] - ETA: 11:34 - loss: 0.6868 - acc: 0.5547
 704/9333 [=>............................] - ETA: 11:26 - loss: 0.6867 - acc: 0.5540
 768/9333 [=>............................] - ETA: 11:23 - loss: 0.6872 - acc: 0.5534
 832/9333 [=>............................] - ETA: 11:24 - loss: 0.6865 - acc: 0.5565
 896/9333 [=>............................] - ETA: 11:22 - loss: 0.6877 - acc: 0.5547
 960/9333 [==>...........................] - ETA: 11:11 - loss: 0.6895 - acc: 0.5510
1024/9333 [==>...........................] - ETA: 11:12 - loss: 0.6902 - acc: 0.5518
1088/9333 [==>...........................] - ETA: 11:05 - loss: 0.6900 - acc: 0.5487
1152/9333 [==>...........................] - ETA: 10:58 - loss: 0.6908 - acc: 0.5460
1216/9333 [==>...........................] - ETA: 10:50 - loss: 0.6892 - acc: 0.5502
1280/9333 [===>..........................] - ETA: 10:44 - loss: 0.6903 - acc: 0.5453
1344/9333 [===>..........................] - ETA: 10:41 - loss: 0.6905 - acc: 0.5432
1408/9333 [===>..........................] - ETA: 10:33 - loss: 0.6906 - acc: 0.5462
1472/9333 [===>..........................] - ETA: 10:28 - loss: 0.6897 - acc: 0.5496
1536/9333 [===>..........................] - ETA: 10:19 - loss: 0.6896 - acc: 0.5495
1600/9333 [====>.........................] - ETA: 10:19 - loss: 0.6894 - acc: 0.5506
1664/9333 [====>.........................] - ETA: 10:15 - loss: 0.6907 - acc: 0.5427
1728/9333 [====>.........................] - ETA: 10:10 - loss: 0.6902 - acc: 0.5434
1792/9333 [====>.........................] - ETA: 10:04 - loss: 0.6898 - acc: 0.5463
1856/9333 [====>.........................] - ETA: 10:01 - loss: 0.6896 - acc: 0.5485
1920/9333 [=====>........................] - ETA: 9:56 - loss: 0.6896 - acc: 0.5479 
1984/9333 [=====>........................] - ETA: 9:50 - loss: 0.6892 - acc: 0.5489
2048/9333 [=====>........................] - ETA: 9:43 - loss: 0.6887 - acc: 0.5503
2112/9333 [=====>........................] - ETA: 9:40 - loss: 0.6887 - acc: 0.5497
2176/9333 [=====>........................] - ETA: 9:34 - loss: 0.6887 - acc: 0.5501
2240/9333 [======>.......................] - ETA: 9:28 - loss: 0.6884 - acc: 0.5500
2304/9333 [======>.......................] - ETA: 9:22 - loss: 0.6879 - acc: 0.5521
2368/9333 [======>.......................] - ETA: 9:18 - loss: 0.6877 - acc: 0.5528
2432/9333 [======>.......................] - ETA: 9:12 - loss: 0.6871 - acc: 0.5547
2496/9333 [=======>......................] - ETA: 9:06 - loss: 0.6871 - acc: 0.5541
2560/9333 [=======>......................] - ETA: 8:59 - loss: 0.6870 - acc: 0.5543
2624/9333 [=======>......................] - ETA: 8:54 - loss: 0.6864 - acc: 0.5556
2688/9333 [=======>......................] - ETA: 8:48 - loss: 0.6864 - acc: 0.5558
2752/9333 [=======>......................] - ETA: 8:41 - loss: 0.6871 - acc: 0.5545
2816/9333 [========>.....................] - ETA: 8:34 - loss: 0.6869 - acc: 0.5543
2880/9333 [========>.....................] - ETA: 8:30 - loss: 0.6866 - acc: 0.5535
2944/9333 [========>.....................] - ETA: 8:24 - loss: 0.6864 - acc: 0.5543
3008/9333 [========>.....................] - ETA: 8:18 - loss: 0.6862 - acc: 0.5552
3072/9333 [========>.....................] - ETA: 8:11 - loss: 0.6861 - acc: 0.5547
3136/9333 [=========>....................] - ETA: 8:05 - loss: 0.6863 - acc: 0.5539
3200/9333 [=========>....................] - ETA: 8:00 - loss: 0.6873 - acc: 0.5516
3264/9333 [=========>....................] - ETA: 7:54 - loss: 0.6874 - acc: 0.5509
3328/9333 [=========>....................] - ETA: 7:48 - loss: 0.6879 - acc: 0.5502
3392/9333 [=========>....................] - ETA: 7:42 - loss: 0.6883 - acc: 0.5489
3456/9333 [==========>...................] - ETA: 7:37 - loss: 0.6882 - acc: 0.5492
3520/9333 [==========>...................] - ETA: 7:31 - loss: 0.6893 - acc: 0.5472
3584/9333 [==========>...................] - ETA: 7:25 - loss: 0.6889 - acc: 0.5488
3648/9333 [==========>...................] - ETA: 7:19 - loss: 0.6891 - acc: 0.5480
3712/9333 [==========>...................] - ETA: 7:13 - loss: 0.6880 - acc: 0.5509
3776/9333 [===========>..................] - ETA: 7:08 - loss: 0.6881 - acc: 0.5503
3840/9333 [===========>..................] - ETA: 7:02 - loss: 0.6879 - acc: 0.5503
3904/9333 [===========>..................] - ETA: 6:56 - loss: 0.6881 - acc: 0.5499
3968/9333 [===========>..................] - ETA: 6:50 - loss: 0.6880 - acc: 0.5509
4032/9333 [===========>..................] - ETA: 6:45 - loss: 0.6880 - acc: 0.5513
4096/9333 [============>.................] - ETA: 6:39 - loss: 0.6879 - acc: 0.5513
4160/9333 [============>.................] - ETA: 6:34 - loss: 0.6882 - acc: 0.5500
4224/9333 [============>.................] - ETA: 6:27 - loss: 0.6884 - acc: 0.5488
4288/9333 [============>.................] - ETA: 6:22 - loss: 0.6886 - acc: 0.5476
4352/9333 [============>.................] - ETA: 6:16 - loss: 0.6888 - acc: 0.5471
4416/9333 [=============>................] - ETA: 6:11 - loss: 0.6885 - acc: 0.5478
4480/9333 [=============>................] - ETA: 6:06 - loss: 0.6884 - acc: 0.5478
4544/9333 [=============>................] - ETA: 6:00 - loss: 0.6886 - acc: 0.5478
4608/9333 [=============>................] - ETA: 5:54 - loss: 0.6884 - acc: 0.5475
4672/9333 [==============>...............] - ETA: 5:49 - loss: 0.6885 - acc: 0.5473
4736/9333 [==============>...............] - ETA: 5:43 - loss: 0.6883 - acc: 0.5481
4800/9333 [==============>...............] - ETA: 5:38 - loss: 0.6886 - acc: 0.5479
4864/9333 [==============>...............] - ETA: 5:32 - loss: 0.6889 - acc: 0.5473
4928/9333 [==============>...............] - ETA: 5:27 - loss: 0.6891 - acc: 0.5469
4992/9333 [===============>..............] - ETA: 5:21 - loss: 0.6891 - acc: 0.5463
5056/9333 [===============>..............] - ETA: 5:16 - loss: 0.6888 - acc: 0.5465
5120/9333 [===============>..............] - ETA: 5:11 - loss: 0.6889 - acc: 0.5463
5184/9333 [===============>..............] - ETA: 5:05 - loss: 0.6890 - acc: 0.5457
5248/9333 [===============>..............] - ETA: 5:00 - loss: 0.6889 - acc: 0.5457
5312/9333 [================>.............] - ETA: 4:55 - loss: 0.6889 - acc: 0.5459
5376/9333 [================>.............] - ETA: 4:50 - loss: 0.6891 - acc: 0.5450
5440/9333 [================>.............] - ETA: 4:45 - loss: 0.6891 - acc: 0.5436
5504/9333 [================>.............] - ETA: 4:39 - loss: 0.6893 - acc: 0.5436
5568/9333 [================>.............] - ETA: 4:34 - loss: 0.6891 - acc: 0.5444
5632/9333 [=================>............] - ETA: 4:29 - loss: 0.6891 - acc: 0.5451
5696/9333 [=================>............] - ETA: 4:24 - loss: 0.6891 - acc: 0.5451
5760/9333 [=================>............] - ETA: 4:19 - loss: 0.6891 - acc: 0.5455
5824/9333 [=================>............] - ETA: 4:14 - loss: 0.6890 - acc: 0.5462
5888/9333 [=================>............] - ETA: 4:08 - loss: 0.6892 - acc: 0.5448
5952/9333 [==================>...........] - ETA: 4:03 - loss: 0.6892 - acc: 0.5449
6016/9333 [==================>...........] - ETA: 3:58 - loss: 0.6891 - acc: 0.5454
6080/9333 [==================>...........] - ETA: 3:53 - loss: 0.6890 - acc: 0.5457
6144/9333 [==================>...........] - ETA: 3:49 - loss: 0.6890 - acc: 0.5465
6208/9333 [==================>...........] - ETA: 3:44 - loss: 0.6888 - acc: 0.5474
6272/9333 [===================>..........] - ETA: 3:39 - loss: 0.6887 - acc: 0.5480
6336/9333 [===================>..........] - ETA: 3:34 - loss: 0.6887 - acc: 0.5481
6400/9333 [===================>..........] - ETA: 3:29 - loss: 0.6887 - acc: 0.5480
6464/9333 [===================>..........] - ETA: 3:24 - loss: 0.6886 - acc: 0.5486
6528/9333 [===================>..........] - ETA: 3:19 - loss: 0.6887 - acc: 0.5484
6592/9333 [====================>.........] - ETA: 3:14 - loss: 0.6886 - acc: 0.5485
6656/9333 [====================>.........] - ETA: 3:09 - loss: 0.6886 - acc: 0.5488
6720/9333 [====================>.........] - ETA: 3:05 - loss: 0.6888 - acc: 0.5478
6784/9333 [====================>.........] - ETA: 3:00 - loss: 0.6888 - acc: 0.5476
6848/9333 [=====================>........] - ETA: 2:55 - loss: 0.6886 - acc: 0.5482
6912/9333 [=====================>........] - ETA: 2:50 - loss: 0.6885 - acc: 0.5482
6976/9333 [=====================>........] - ETA: 2:45 - loss: 0.6886 - acc: 0.5482
7040/9333 [=====================>........] - ETA: 2:41 - loss: 0.6885 - acc: 0.5480
7104/9333 [=====================>........] - ETA: 2:36 - loss: 0.6884 - acc: 0.5480
7168/9333 [======================>.......] - ETA: 2:31 - loss: 0.6883 - acc: 0.5483
7232/9333 [======================>.......] - ETA: 2:27 - loss: 0.6881 - acc: 0.5488
7296/9333 [======================>.......] - ETA: 2:22 - loss: 0.6882 - acc: 0.5484
7360/9333 [======================>.......] - ETA: 2:17 - loss: 0.6883 - acc: 0.5477
7424/9333 [======================>.......] - ETA: 2:13 - loss: 0.6884 - acc: 0.5478
7488/9333 [=======================>......] - ETA: 2:08 - loss: 0.6883 - acc: 0.5482
7552/9333 [=======================>......] - ETA: 2:04 - loss: 0.6884 - acc: 0.5475
7616/9333 [=======================>......] - ETA: 1:59 - loss: 0.6883 - acc: 0.5479
7680/9333 [=======================>......] - ETA: 1:54 - loss: 0.6884 - acc: 0.5471
7744/9333 [=======================>......] - ETA: 1:49 - loss: 0.6883 - acc: 0.5476
7808/9333 [========================>.....] - ETA: 1:45 - loss: 0.6883 - acc: 0.5479
7872/9333 [========================>.....] - ETA: 1:40 - loss: 0.6882 - acc: 0.5483
7936/9333 [========================>.....] - ETA: 1:35 - loss: 0.6881 - acc: 0.5481
8000/9333 [========================>.....] - ETA: 1:31 - loss: 0.6880 - acc: 0.5487
8064/9333 [========================>.....] - ETA: 1:26 - loss: 0.6880 - acc: 0.5489
8128/9333 [=========================>....] - ETA: 1:22 - loss: 0.6881 - acc: 0.5486
8192/9333 [=========================>....] - ETA: 1:17 - loss: 0.6882 - acc: 0.5486
8256/9333 [=========================>....] - ETA: 1:13 - loss: 0.6881 - acc: 0.5487
8320/9333 [=========================>....] - ETA: 1:08 - loss: 0.6881 - acc: 0.5486
8384/9333 [=========================>....] - ETA: 1:04 - loss: 0.6882 - acc: 0.5482
8448/9333 [==========================>...] - ETA: 59s - loss: 0.6885 - acc: 0.5471 
8512/9333 [==========================>...] - ETA: 55s - loss: 0.6884 - acc: 0.5475
8576/9333 [==========================>...] - ETA: 51s - loss: 0.6882 - acc: 0.5476
8640/9333 [==========================>...] - ETA: 46s - loss: 0.6883 - acc: 0.5473
8704/9333 [==========================>...] - ETA: 42s - loss: 0.6882 - acc: 0.5474
8768/9333 [===========================>..] - ETA: 37s - loss: 0.6883 - acc: 0.5472
8832/9333 [===========================>..] - ETA: 33s - loss: 0.6882 - acc: 0.5472
8896/9333 [===========================>..] - ETA: 29s - loss: 0.6880 - acc: 0.5477
8960/9333 [===========================>..] - ETA: 24s - loss: 0.6882 - acc: 0.5469
9024/9333 [============================>.] - ETA: 20s - loss: 0.6881 - acc: 0.5471
9088/9333 [============================>.] - ETA: 16s - loss: 0.6880 - acc: 0.5473
9152/9333 [============================>.] - ETA: 12s - loss: 0.6881 - acc: 0.5470
9216/9333 [============================>.] - ETA: 7s - loss: 0.6882 - acc: 0.5469 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6882 - acc: 0.5468
9333/9333 [==============================] - 637s 68ms/step - loss: 0.6882 - acc: 0.5473 - val_loss: 0.6902 - val_acc: 0.5381

Epoch 00010: val_acc did not improve from 0.53809
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f45e46d6450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f45e46d6450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f45e4660f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f45e4660f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48c413c310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f48c413c310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45c4730cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45c4730cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45c46f83d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45c46f83d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c450b090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c450b090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45c4730910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45c4730910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40c877ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40c877ee90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fa460b450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fa460b450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45c44b0050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45c44b0050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fa4510350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fa4510350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fa460bed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fa460bed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c44aa210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c44aa210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45c427edd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45c427edd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45c4156390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45c4156390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c4222710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c4222710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45c4266f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45c4266f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45a47c5710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45a47c5710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45a467ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45a467ee90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45a45f5a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45a45f5a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45a45f2d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45a45f2d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45a467ebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45a467ebd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45a45a4250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45a45a4250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45a4389510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45a4389510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45a4255ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45a4255ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45a43a9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45a43a9050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45a4389750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45a4389750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45a43b84d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45a43b84d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45a4043fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45a4043fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45847724d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45847724d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4584604b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4584604b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45a4043650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45a4043650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4584700fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4584700fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45a46d3c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45a46d3c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4584421950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4584421950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f458478f810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f458478f810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f458462f1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f458462f1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f458431e150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f458431e150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f458421f2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f458421f2d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45840c3650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45840c3650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44bc4f8210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44bc4f8210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f458421f0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f458421f0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44bc40a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44bc40a550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44bc41a410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44bc41a410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44bc385710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44bc385710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f458421c290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f458421c290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44bc41a850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44bc41a850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44842e7090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44842e7090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44bc32ae50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44bc32ae50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f446473f850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f446473f850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4464653f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4464653f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44842d40d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f44842d40d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4464778e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4464778e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44645067d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f44645067d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4464470150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4464470150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4464322610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4464322610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4464506fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4464506fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44644cedd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44644cedd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f446422e410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f446422e410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44641f3390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f44641f3390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4464457e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4464457e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f446422ea90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f446422ea90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44447e1a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44447e1a90>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 6:53
 128/2592 [>.............................] - ETA: 3:54
 192/2592 [=>............................] - ETA: 2:51
 256/2592 [=>............................] - ETA: 2:19
 320/2592 [==>...........................] - ETA: 2:01
 384/2592 [===>..........................] - ETA: 1:46
 448/2592 [====>.........................] - ETA: 1:35
 512/2592 [====>.........................] - ETA: 1:27
 576/2592 [=====>........................] - ETA: 1:20
 640/2592 [======>.......................] - ETA: 1:16
 704/2592 [=======>......................] - ETA: 1:11
 768/2592 [=======>......................] - ETA: 1:06
 832/2592 [========>.....................] - ETA: 1:02
 896/2592 [=========>....................] - ETA: 59s 
 960/2592 [==========>...................] - ETA: 55s
1024/2592 [==========>...................] - ETA: 52s
1088/2592 [===========>..................] - ETA: 49s
1152/2592 [============>.................] - ETA: 46s
1216/2592 [=============>................] - ETA: 43s
1280/2592 [=============>................] - ETA: 41s
1344/2592 [==============>...............] - ETA: 39s
1408/2592 [===============>..............] - ETA: 36s
1472/2592 [================>.............] - ETA: 34s
1536/2592 [================>.............] - ETA: 32s
1600/2592 [=================>............] - ETA: 30s
1664/2592 [==================>...........] - ETA: 27s
1728/2592 [===================>..........] - ETA: 25s
1792/2592 [===================>..........] - ETA: 23s
1856/2592 [====================>.........] - ETA: 21s
1920/2592 [=====================>........] - ETA: 19s
1984/2592 [=====================>........] - ETA: 17s
2048/2592 [======================>.......] - ETA: 15s
2112/2592 [=======================>......] - ETA: 14s
2176/2592 [========================>.....] - ETA: 12s
2240/2592 [========================>.....] - ETA: 10s
2304/2592 [=========================>....] - ETA: 8s 
2368/2592 [==========================>...] - ETA: 6s
2432/2592 [===========================>..] - ETA: 4s
2496/2592 [===========================>..] - ETA: 2s
2560/2592 [============================>.] - ETA: 0s
2592/2592 [==============================] - 73s 28ms/step
loss: 0.6899032548621848
acc: 0.5285493827160493
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3f4469e990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3f4469e990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3f446a0cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3f446a0cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f442c59dd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f442c59dd90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f442c42c810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f442c42c810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f442c581350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f442c581350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c474c690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c474c690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f442c42c590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f442c42c590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c47d7090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45c47d7090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45e4614cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45e4614cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45e431cd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45e431cd90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45e43a9510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45e43a9510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45e4641150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f45e4641150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45e45d52d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45e45d52d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45e4370350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45e4370350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45e4081490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f45e4081490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ea4358210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ea4358210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4464104950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4464104950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45e4344dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45e4344dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f442c118190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f442c118190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f443d9cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f443d9cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45e408a7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45e408a7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f4443ded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f4443ded0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ea4179c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ea4179c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f443585d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f443585d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f4410c090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f4410c090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f246d5850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f246d5850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f443e95d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f443e95d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f440630d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f440630d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45e408a850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f45e408a850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f244da350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f244da350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f245caf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f245caf10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f24602d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f24602d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f44081950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f44081950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f242835d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f242835d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f242d48d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f242d48d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44641e2910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44641e2910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f24283250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f24283250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f241aa350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f241aa350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f04770b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f04770b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f04658ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f04658ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f044f9650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f044f9650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f4410c990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f4410c990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f046e6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f046e6a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f044a7110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f044a7110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f04375f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3f04375f90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45e45711d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f45e45711d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f044a7dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f044a7dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f0455e790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f0455e790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f04492110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f04492110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ee47d8390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ee47d8390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ee46f2090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ee46f2090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f04212410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f04212410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f04319550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f04319550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ee45fdcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ee45fdcd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ee44a9310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ee44a9310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ee4785350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ee4785350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3ee45fd0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3ee45fd0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ee439ab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ee439ab10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ee42cb4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ee42cb4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ee4191d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ee4191d10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ee420b750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ee420b750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3ee42a4150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3ee42a4150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ee4295ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ee4295ed0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 1:30:34 - loss: 0.6210 - acc: 0.7344
 128/9333 [..............................] - ETA: 51:00 - loss: 0.6948 - acc: 0.6562  
 192/9333 [..............................] - ETA: 37:38 - loss: 0.7160 - acc: 0.5833
 256/9333 [..............................] - ETA: 30:51 - loss: 0.7403 - acc: 0.5625
 320/9333 [>.............................] - ETA: 26:44 - loss: 0.7488 - acc: 0.5563
 384/9333 [>.............................] - ETA: 24:03 - loss: 0.7589 - acc: 0.5443
 448/9333 [>.............................] - ETA: 21:48 - loss: 0.7540 - acc: 0.5469
 512/9333 [>.............................] - ETA: 20:08 - loss: 0.7467 - acc: 0.5625
 576/9333 [>.............................] - ETA: 18:47 - loss: 0.7449 - acc: 0.5590
 640/9333 [=>............................] - ETA: 17:40 - loss: 0.7539 - acc: 0.5469
 704/9333 [=>............................] - ETA: 16:43 - loss: 0.7542 - acc: 0.5455
 768/9333 [=>............................] - ETA: 15:59 - loss: 0.7543 - acc: 0.5391
 832/9333 [=>............................] - ETA: 15:21 - loss: 0.7526 - acc: 0.5373
 896/9333 [=>............................] - ETA: 14:50 - loss: 0.7536 - acc: 0.5312
 960/9333 [==>...........................] - ETA: 14:20 - loss: 0.7504 - acc: 0.5312
1024/9333 [==>...........................] - ETA: 13:53 - loss: 0.7548 - acc: 0.5283
1088/9333 [==>...........................] - ETA: 13:32 - loss: 0.7529 - acc: 0.5303
1152/9333 [==>...........................] - ETA: 13:10 - loss: 0.7516 - acc: 0.5304
1216/9333 [==>...........................] - ETA: 12:50 - loss: 0.7543 - acc: 0.5263
1280/9333 [===>..........................] - ETA: 12:31 - loss: 0.7519 - acc: 0.5266
1344/9333 [===>..........................] - ETA: 12:10 - loss: 0.7483 - acc: 0.5305
1408/9333 [===>..........................] - ETA: 11:53 - loss: 0.7466 - acc: 0.5298
1472/9333 [===>..........................] - ETA: 11:37 - loss: 0.7457 - acc: 0.5312
1536/9333 [===>..........................] - ETA: 11:21 - loss: 0.7472 - acc: 0.5273
1600/9333 [====>.........................] - ETA: 11:07 - loss: 0.7449 - acc: 0.5269
1664/9333 [====>.........................] - ETA: 10:53 - loss: 0.7463 - acc: 0.5252
1728/9333 [====>.........................] - ETA: 10:42 - loss: 0.7476 - acc: 0.5231
1792/9333 [====>.........................] - ETA: 10:31 - loss: 0.7458 - acc: 0.5234
1856/9333 [====>.........................] - ETA: 10:19 - loss: 0.7457 - acc: 0.5221
1920/9333 [=====>........................] - ETA: 10:09 - loss: 0.7463 - acc: 0.5208
1984/9333 [=====>........................] - ETA: 9:59 - loss: 0.7463 - acc: 0.5192 
2048/9333 [=====>........................] - ETA: 9:50 - loss: 0.7445 - acc: 0.5190
2112/9333 [=====>........................] - ETA: 9:41 - loss: 0.7440 - acc: 0.5180
2176/9333 [=====>........................] - ETA: 9:31 - loss: 0.7424 - acc: 0.5184
2240/9333 [======>.......................] - ETA: 9:22 - loss: 0.7411 - acc: 0.5183
2304/9333 [======>.......................] - ETA: 9:13 - loss: 0.7405 - acc: 0.5187
2368/9333 [======>.......................] - ETA: 9:06 - loss: 0.7411 - acc: 0.5173
2432/9333 [======>.......................] - ETA: 8:57 - loss: 0.7423 - acc: 0.5152
2496/9333 [=======>......................] - ETA: 8:50 - loss: 0.7408 - acc: 0.5156
2560/9333 [=======>......................] - ETA: 8:42 - loss: 0.7413 - acc: 0.5133
2624/9333 [=======>......................] - ETA: 8:34 - loss: 0.7402 - acc: 0.5149
2688/9333 [=======>......................] - ETA: 8:27 - loss: 0.7396 - acc: 0.5149
2752/9333 [=======>......................] - ETA: 8:19 - loss: 0.7392 - acc: 0.5131
2816/9333 [========>.....................] - ETA: 8:12 - loss: 0.7381 - acc: 0.5146
2880/9333 [========>.....................] - ETA: 8:06 - loss: 0.7385 - acc: 0.5125
2944/9333 [========>.....................] - ETA: 7:58 - loss: 0.7385 - acc: 0.5109
3008/9333 [========>.....................] - ETA: 7:52 - loss: 0.7385 - acc: 0.5106
3072/9333 [========>.....................] - ETA: 7:45 - loss: 0.7379 - acc: 0.5114
3136/9333 [=========>....................] - ETA: 7:39 - loss: 0.7363 - acc: 0.5137
3200/9333 [=========>....................] - ETA: 7:33 - loss: 0.7357 - acc: 0.5141
3264/9333 [=========>....................] - ETA: 7:26 - loss: 0.7358 - acc: 0.5129
3328/9333 [=========>....................] - ETA: 7:20 - loss: 0.7349 - acc: 0.5135
3392/9333 [=========>....................] - ETA: 7:14 - loss: 0.7344 - acc: 0.5153
3456/9333 [==========>...................] - ETA: 7:08 - loss: 0.7352 - acc: 0.5130
3520/9333 [==========>...................] - ETA: 7:02 - loss: 0.7354 - acc: 0.5119
3584/9333 [==========>...................] - ETA: 6:56 - loss: 0.7348 - acc: 0.5128
3648/9333 [==========>...................] - ETA: 6:50 - loss: 0.7339 - acc: 0.5145
3712/9333 [==========>...................] - ETA: 6:45 - loss: 0.7338 - acc: 0.5143
3776/9333 [===========>..................] - ETA: 6:39 - loss: 0.7333 - acc: 0.5148
3840/9333 [===========>..................] - ETA: 6:33 - loss: 0.7334 - acc: 0.5146
3904/9333 [===========>..................] - ETA: 6:28 - loss: 0.7330 - acc: 0.5149
3968/9333 [===========>..................] - ETA: 6:23 - loss: 0.7324 - acc: 0.5156
4032/9333 [===========>..................] - ETA: 6:17 - loss: 0.7323 - acc: 0.5149
4096/9333 [============>.................] - ETA: 6:12 - loss: 0.7321 - acc: 0.5154
4160/9333 [============>.................] - ETA: 6:07 - loss: 0.7317 - acc: 0.5154
4224/9333 [============>.................] - ETA: 6:01 - loss: 0.7319 - acc: 0.5140
4288/9333 [============>.................] - ETA: 5:56 - loss: 0.7315 - acc: 0.5138
4352/9333 [============>.................] - ETA: 5:50 - loss: 0.7307 - acc: 0.5154
4416/9333 [=============>................] - ETA: 5:45 - loss: 0.7303 - acc: 0.5143
4480/9333 [=============>................] - ETA: 5:40 - loss: 0.7309 - acc: 0.5134
4544/9333 [=============>................] - ETA: 5:35 - loss: 0.7299 - acc: 0.5141
4608/9333 [=============>................] - ETA: 5:30 - loss: 0.7297 - acc: 0.5126
4672/9333 [==============>...............] - ETA: 5:26 - loss: 0.7287 - acc: 0.5139
4736/9333 [==============>...............] - ETA: 5:21 - loss: 0.7286 - acc: 0.5137
4800/9333 [==============>...............] - ETA: 5:16 - loss: 0.7284 - acc: 0.5129
4864/9333 [==============>...............] - ETA: 5:11 - loss: 0.7278 - acc: 0.5136
4928/9333 [==============>...............] - ETA: 5:06 - loss: 0.7277 - acc: 0.5132
4992/9333 [===============>..............] - ETA: 5:01 - loss: 0.7271 - acc: 0.5144
5056/9333 [===============>..............] - ETA: 4:56 - loss: 0.7267 - acc: 0.5144
5120/9333 [===============>..............] - ETA: 4:51 - loss: 0.7272 - acc: 0.5127
5184/9333 [===============>..............] - ETA: 4:46 - loss: 0.7266 - acc: 0.5141
5248/9333 [===============>..............] - ETA: 4:41 - loss: 0.7262 - acc: 0.5152
5312/9333 [================>.............] - ETA: 4:36 - loss: 0.7263 - acc: 0.5134
5376/9333 [================>.............] - ETA: 4:32 - loss: 0.7263 - acc: 0.5138
5440/9333 [================>.............] - ETA: 4:27 - loss: 0.7262 - acc: 0.5132
5504/9333 [================>.............] - ETA: 4:23 - loss: 0.7260 - acc: 0.5138
5568/9333 [================>.............] - ETA: 4:18 - loss: 0.7260 - acc: 0.5135
5632/9333 [=================>............] - ETA: 4:13 - loss: 0.7257 - acc: 0.5138
5696/9333 [=================>............] - ETA: 4:09 - loss: 0.7255 - acc: 0.5137
5760/9333 [=================>............] - ETA: 4:04 - loss: 0.7254 - acc: 0.5132
5824/9333 [=================>............] - ETA: 4:00 - loss: 0.7248 - acc: 0.5146
5888/9333 [=================>............] - ETA: 3:55 - loss: 0.7248 - acc: 0.5144
5952/9333 [==================>...........] - ETA: 3:50 - loss: 0.7246 - acc: 0.5134
6016/9333 [==================>...........] - ETA: 3:46 - loss: 0.7246 - acc: 0.5128
6080/9333 [==================>...........] - ETA: 3:41 - loss: 0.7244 - acc: 0.5127
6144/9333 [==================>...........] - ETA: 3:36 - loss: 0.7241 - acc: 0.5132
6208/9333 [==================>...........] - ETA: 3:32 - loss: 0.7244 - acc: 0.5113
6272/9333 [===================>..........] - ETA: 3:27 - loss: 0.7244 - acc: 0.5113
6336/9333 [===================>..........] - ETA: 3:23 - loss: 0.7244 - acc: 0.5112
6400/9333 [===================>..........] - ETA: 3:19 - loss: 0.7250 - acc: 0.5097
6464/9333 [===================>..........] - ETA: 3:15 - loss: 0.7244 - acc: 0.5107
6528/9333 [===================>..........] - ETA: 3:11 - loss: 0.7241 - acc: 0.5109
6592/9333 [====================>.........] - ETA: 3:06 - loss: 0.7240 - acc: 0.5109
6656/9333 [====================>.........] - ETA: 3:02 - loss: 0.7238 - acc: 0.5108
6720/9333 [====================>.........] - ETA: 2:58 - loss: 0.7235 - acc: 0.5106
6784/9333 [====================>.........] - ETA: 2:54 - loss: 0.7237 - acc: 0.5096
6848/9333 [=====================>........] - ETA: 2:50 - loss: 0.7233 - acc: 0.5107
6912/9333 [=====================>........] - ETA: 2:46 - loss: 0.7229 - acc: 0.5114
6976/9333 [=====================>........] - ETA: 2:41 - loss: 0.7228 - acc: 0.5116
7040/9333 [=====================>........] - ETA: 2:37 - loss: 0.7227 - acc: 0.5112
7104/9333 [=====================>........] - ETA: 2:33 - loss: 0.7225 - acc: 0.5117
7168/9333 [======================>.......] - ETA: 2:28 - loss: 0.7224 - acc: 0.5120
7232/9333 [======================>.......] - ETA: 2:24 - loss: 0.7224 - acc: 0.5116
7296/9333 [======================>.......] - ETA: 2:20 - loss: 0.7220 - acc: 0.5122
7360/9333 [======================>.......] - ETA: 2:15 - loss: 0.7221 - acc: 0.5118
7424/9333 [======================>.......] - ETA: 2:11 - loss: 0.7223 - acc: 0.5113
7488/9333 [=======================>......] - ETA: 2:07 - loss: 0.7217 - acc: 0.5120
7552/9333 [=======================>......] - ETA: 2:02 - loss: 0.7214 - acc: 0.5123
7616/9333 [=======================>......] - ETA: 1:58 - loss: 0.7214 - acc: 0.5121
7680/9333 [=======================>......] - ETA: 1:54 - loss: 0.7213 - acc: 0.5117
7744/9333 [=======================>......] - ETA: 1:49 - loss: 0.7209 - acc: 0.5120
7808/9333 [========================>.....] - ETA: 1:45 - loss: 0.7208 - acc: 0.5117
7872/9333 [========================>.....] - ETA: 1:40 - loss: 0.7206 - acc: 0.5114
7936/9333 [========================>.....] - ETA: 1:36 - loss: 0.7203 - acc: 0.5113
8000/9333 [========================>.....] - ETA: 1:32 - loss: 0.7204 - acc: 0.5105
8064/9333 [========================>.....] - ETA: 1:27 - loss: 0.7204 - acc: 0.5102
8128/9333 [=========================>....] - ETA: 1:23 - loss: 0.7203 - acc: 0.5101
8192/9333 [=========================>....] - ETA: 1:19 - loss: 0.7200 - acc: 0.5101
8256/9333 [=========================>....] - ETA: 1:14 - loss: 0.7202 - acc: 0.5096
8320/9333 [=========================>....] - ETA: 1:10 - loss: 0.7202 - acc: 0.5095
8384/9333 [=========================>....] - ETA: 1:05 - loss: 0.7200 - acc: 0.5098
8448/9333 [==========================>...] - ETA: 1:01 - loss: 0.7196 - acc: 0.5103
8512/9333 [==========================>...] - ETA: 57s - loss: 0.7195 - acc: 0.5106 
8576/9333 [==========================>...] - ETA: 52s - loss: 0.7195 - acc: 0.5105
8640/9333 [==========================>...] - ETA: 48s - loss: 0.7192 - acc: 0.5113
8704/9333 [==========================>...] - ETA: 43s - loss: 0.7193 - acc: 0.5111
8768/9333 [===========================>..] - ETA: 39s - loss: 0.7190 - acc: 0.5112
8832/9333 [===========================>..] - ETA: 34s - loss: 0.7188 - acc: 0.5112
8896/9333 [===========================>..] - ETA: 30s - loss: 0.7187 - acc: 0.5110
8960/9333 [===========================>..] - ETA: 25s - loss: 0.7186 - acc: 0.5108
9024/9333 [============================>.] - ETA: 21s - loss: 0.7189 - acc: 0.5100
9088/9333 [============================>.] - ETA: 17s - loss: 0.7185 - acc: 0.5105
9152/9333 [============================>.] - ETA: 12s - loss: 0.7182 - acc: 0.5110
9216/9333 [============================>.] - ETA: 8s - loss: 0.7181 - acc: 0.5111 
9280/9333 [============================>.] - ETA: 3s - loss: 0.7180 - acc: 0.5112
9333/9333 [==============================] - 685s 73ms/step - loss: 0.7180 - acc: 0.5113 - val_loss: 0.6875 - val_acc: 0.5661

Epoch 00001: val_acc improved from -inf to 0.56606, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window07/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 10:34 - loss: 0.6864 - acc: 0.5625
 128/9333 [..............................] - ETA: 10:51 - loss: 0.6819 - acc: 0.5625
 192/9333 [..............................] - ETA: 10:42 - loss: 0.6910 - acc: 0.5677
 256/9333 [..............................] - ETA: 10:44 - loss: 0.6875 - acc: 0.5625
 320/9333 [>.............................] - ETA: 10:36 - loss: 0.6854 - acc: 0.5656
 384/9333 [>.............................] - ETA: 10:37 - loss: 0.6863 - acc: 0.5547
 448/9333 [>.............................] - ETA: 10:31 - loss: 0.6901 - acc: 0.5536
 512/9333 [>.............................] - ETA: 10:22 - loss: 0.6875 - acc: 0.5488
 576/9333 [>.............................] - ETA: 10:22 - loss: 0.6910 - acc: 0.5451
 640/9333 [=>............................] - ETA: 10:14 - loss: 0.6959 - acc: 0.5297
 704/9333 [=>............................] - ETA: 10:12 - loss: 0.6981 - acc: 0.5256
 768/9333 [=>............................] - ETA: 10:04 - loss: 0.6962 - acc: 0.5312
 832/9333 [=>............................] - ETA: 10:04 - loss: 0.6972 - acc: 0.5325
 896/9333 [=>............................] - ETA: 10:00 - loss: 0.6963 - acc: 0.5324
 960/9333 [==>...........................] - ETA: 9:58 - loss: 0.6986 - acc: 0.5219 
1024/9333 [==>...........................] - ETA: 9:55 - loss: 0.6995 - acc: 0.5205
1088/9333 [==>...........................] - ETA: 9:51 - loss: 0.6986 - acc: 0.5202
1152/9333 [==>...........................] - ETA: 9:44 - loss: 0.6989 - acc: 0.5217
1216/9333 [==>...........................] - ETA: 9:40 - loss: 0.6985 - acc: 0.5189
1280/9333 [===>..........................] - ETA: 9:34 - loss: 0.6990 - acc: 0.5164
1344/9333 [===>..........................] - ETA: 9:30 - loss: 0.6989 - acc: 0.5186
1408/9333 [===>..........................] - ETA: 9:26 - loss: 0.6995 - acc: 0.5149
1472/9333 [===>..........................] - ETA: 9:22 - loss: 0.7007 - acc: 0.5136
1536/9333 [===>..........................] - ETA: 9:17 - loss: 0.7021 - acc: 0.5104
1600/9333 [====>.........................] - ETA: 9:12 - loss: 0.7010 - acc: 0.5112
1664/9333 [====>.........................] - ETA: 9:07 - loss: 0.7003 - acc: 0.5144
1728/9333 [====>.........................] - ETA: 9:02 - loss: 0.6998 - acc: 0.5139
1792/9333 [====>.........................] - ETA: 8:58 - loss: 0.6994 - acc: 0.5156
1856/9333 [====>.........................] - ETA: 8:53 - loss: 0.6991 - acc: 0.5172
1920/9333 [=====>........................] - ETA: 8:49 - loss: 0.6986 - acc: 0.5161
1984/9333 [=====>........................] - ETA: 8:44 - loss: 0.6988 - acc: 0.5156
2048/9333 [=====>........................] - ETA: 8:39 - loss: 0.6991 - acc: 0.5117
2112/9333 [=====>........................] - ETA: 8:36 - loss: 0.6992 - acc: 0.5104
2176/9333 [=====>........................] - ETA: 8:31 - loss: 0.6993 - acc: 0.5097
2240/9333 [======>.......................] - ETA: 8:26 - loss: 0.6990 - acc: 0.5103
2304/9333 [======>.......................] - ETA: 8:22 - loss: 0.6984 - acc: 0.5130
2368/9333 [======>.......................] - ETA: 8:17 - loss: 0.6983 - acc: 0.5139
2432/9333 [======>.......................] - ETA: 8:12 - loss: 0.6985 - acc: 0.5115
2496/9333 [=======>......................] - ETA: 8:07 - loss: 0.6980 - acc: 0.5116
2560/9333 [=======>......................] - ETA: 8:02 - loss: 0.6984 - acc: 0.5094
2624/9333 [=======>......................] - ETA: 7:58 - loss: 0.6977 - acc: 0.5107
2688/9333 [=======>......................] - ETA: 7:53 - loss: 0.6983 - acc: 0.5082
2752/9333 [=======>......................] - ETA: 7:49 - loss: 0.6987 - acc: 0.5065
2816/9333 [========>.....................] - ETA: 7:44 - loss: 0.6988 - acc: 0.5064
2880/9333 [========>.....................] - ETA: 7:40 - loss: 0.6992 - acc: 0.5038
2944/9333 [========>.....................] - ETA: 7:35 - loss: 0.6988 - acc: 0.5048
3008/9333 [========>.....................] - ETA: 7:30 - loss: 0.6986 - acc: 0.5060
3072/9333 [========>.....................] - ETA: 7:27 - loss: 0.6988 - acc: 0.5055
3136/9333 [=========>....................] - ETA: 7:22 - loss: 0.6982 - acc: 0.5067
3200/9333 [=========>....................] - ETA: 7:17 - loss: 0.6978 - acc: 0.5078
3264/9333 [=========>....................] - ETA: 7:13 - loss: 0.6978 - acc: 0.5080
3328/9333 [=========>....................] - ETA: 7:08 - loss: 0.6982 - acc: 0.5072
3392/9333 [=========>....................] - ETA: 7:04 - loss: 0.6988 - acc: 0.5053
3456/9333 [==========>...................] - ETA: 6:59 - loss: 0.6984 - acc: 0.5067
3520/9333 [==========>...................] - ETA: 6:55 - loss: 0.6983 - acc: 0.5074
3584/9333 [==========>...................] - ETA: 6:50 - loss: 0.6984 - acc: 0.5073
3648/9333 [==========>...................] - ETA: 6:46 - loss: 0.6984 - acc: 0.5074
3712/9333 [==========>...................] - ETA: 6:41 - loss: 0.6983 - acc: 0.5062
3776/9333 [===========>..................] - ETA: 6:37 - loss: 0.6982 - acc: 0.5072
3840/9333 [===========>..................] - ETA: 6:32 - loss: 0.6976 - acc: 0.5089
3904/9333 [===========>..................] - ETA: 6:28 - loss: 0.6975 - acc: 0.5090
3968/9333 [===========>..................] - ETA: 6:23 - loss: 0.6971 - acc: 0.5103
4032/9333 [===========>..................] - ETA: 6:19 - loss: 0.6970 - acc: 0.5112
4096/9333 [============>.................] - ETA: 6:14 - loss: 0.6971 - acc: 0.5112
4160/9333 [============>.................] - ETA: 6:09 - loss: 0.6972 - acc: 0.5125
4224/9333 [============>.................] - ETA: 6:05 - loss: 0.6974 - acc: 0.5125
4288/9333 [============>.................] - ETA: 6:00 - loss: 0.6972 - acc: 0.5121
4352/9333 [============>.................] - ETA: 5:56 - loss: 0.6969 - acc: 0.5131
4416/9333 [=============>................] - ETA: 5:51 - loss: 0.6964 - acc: 0.5138
4480/9333 [=============>................] - ETA: 5:47 - loss: 0.6965 - acc: 0.5132
4544/9333 [=============>................] - ETA: 5:42 - loss: 0.6965 - acc: 0.5130
4608/9333 [=============>................] - ETA: 5:37 - loss: 0.6960 - acc: 0.5145
4672/9333 [==============>...............] - ETA: 5:33 - loss: 0.6964 - acc: 0.5133
4736/9333 [==============>...............] - ETA: 5:28 - loss: 0.6961 - acc: 0.5150
4800/9333 [==============>...............] - ETA: 5:24 - loss: 0.6965 - acc: 0.5144
4864/9333 [==============>...............] - ETA: 5:19 - loss: 0.6969 - acc: 0.5132
4928/9333 [==============>...............] - ETA: 5:14 - loss: 0.6967 - acc: 0.5130
4992/9333 [===============>..............] - ETA: 5:09 - loss: 0.6966 - acc: 0.5136
5056/9333 [===============>..............] - ETA: 5:06 - loss: 0.6968 - acc: 0.5131
5120/9333 [===============>..............] - ETA: 5:01 - loss: 0.6968 - acc: 0.5133
5184/9333 [===============>..............] - ETA: 4:56 - loss: 0.6968 - acc: 0.5139
5248/9333 [===============>..............] - ETA: 4:52 - loss: 0.6971 - acc: 0.5126
5312/9333 [================>.............] - ETA: 4:47 - loss: 0.6970 - acc: 0.5132
5376/9333 [================>.............] - ETA: 4:42 - loss: 0.6969 - acc: 0.5134
5440/9333 [================>.............] - ETA: 4:38 - loss: 0.6969 - acc: 0.5132
5504/9333 [================>.............] - ETA: 4:33 - loss: 0.6967 - acc: 0.5134
5568/9333 [================>.............] - ETA: 4:28 - loss: 0.6968 - acc: 0.5138
5632/9333 [=================>............] - ETA: 4:24 - loss: 0.6966 - acc: 0.5142
5696/9333 [=================>............] - ETA: 4:19 - loss: 0.6966 - acc: 0.5140
5760/9333 [=================>............] - ETA: 4:15 - loss: 0.6967 - acc: 0.5132
5824/9333 [=================>............] - ETA: 4:10 - loss: 0.6965 - acc: 0.5136
5888/9333 [=================>............] - ETA: 4:05 - loss: 0.6966 - acc: 0.5134
5952/9333 [==================>...........] - ETA: 4:01 - loss: 0.6964 - acc: 0.5144
6016/9333 [==================>...........] - ETA: 3:56 - loss: 0.6961 - acc: 0.5155
6080/9333 [==================>...........] - ETA: 3:52 - loss: 0.6960 - acc: 0.5163
6144/9333 [==================>...........] - ETA: 3:47 - loss: 0.6959 - acc: 0.5163
6208/9333 [==================>...........] - ETA: 3:43 - loss: 0.6959 - acc: 0.5163
6272/9333 [===================>..........] - ETA: 3:38 - loss: 0.6958 - acc: 0.5169
6336/9333 [===================>..........] - ETA: 3:33 - loss: 0.6959 - acc: 0.5174
6400/9333 [===================>..........] - ETA: 3:29 - loss: 0.6954 - acc: 0.5191
6464/9333 [===================>..........] - ETA: 3:24 - loss: 0.6956 - acc: 0.5184
6528/9333 [===================>..........] - ETA: 3:20 - loss: 0.6956 - acc: 0.5187
6592/9333 [====================>.........] - ETA: 3:15 - loss: 0.6958 - acc: 0.5187
6656/9333 [====================>.........] - ETA: 3:10 - loss: 0.6960 - acc: 0.5185
6720/9333 [====================>.........] - ETA: 3:06 - loss: 0.6959 - acc: 0.5188
6784/9333 [====================>.........] - ETA: 3:01 - loss: 0.6957 - acc: 0.5192
6848/9333 [=====================>........] - ETA: 2:57 - loss: 0.6960 - acc: 0.5188
6912/9333 [=====================>........] - ETA: 2:52 - loss: 0.6961 - acc: 0.5181
6976/9333 [=====================>........] - ETA: 2:48 - loss: 0.6964 - acc: 0.5173
7040/9333 [=====================>........] - ETA: 2:43 - loss: 0.6963 - acc: 0.5178
7104/9333 [=====================>........] - ETA: 2:38 - loss: 0.6959 - acc: 0.5191
7168/9333 [======================>.......] - ETA: 2:34 - loss: 0.6958 - acc: 0.5190
7232/9333 [======================>.......] - ETA: 2:29 - loss: 0.6958 - acc: 0.5191
7296/9333 [======================>.......] - ETA: 2:25 - loss: 0.6956 - acc: 0.5195
7360/9333 [======================>.......] - ETA: 2:20 - loss: 0.6958 - acc: 0.5186
7424/9333 [======================>.......] - ETA: 2:15 - loss: 0.6959 - acc: 0.5183
7488/9333 [=======================>......] - ETA: 2:11 - loss: 0.6960 - acc: 0.5182
7552/9333 [=======================>......] - ETA: 2:06 - loss: 0.6962 - acc: 0.5180
7616/9333 [=======================>......] - ETA: 2:02 - loss: 0.6963 - acc: 0.5179
7680/9333 [=======================>......] - ETA: 1:57 - loss: 0.6963 - acc: 0.5178
7744/9333 [=======================>......] - ETA: 1:53 - loss: 0.6962 - acc: 0.5176
7808/9333 [========================>.....] - ETA: 1:48 - loss: 0.6963 - acc: 0.5173
7872/9333 [========================>.....] - ETA: 1:44 - loss: 0.6964 - acc: 0.5165
7936/9333 [========================>.....] - ETA: 1:39 - loss: 0.6964 - acc: 0.5169
8000/9333 [========================>.....] - ETA: 1:34 - loss: 0.6962 - acc: 0.5178
8064/9333 [========================>.....] - ETA: 1:30 - loss: 0.6962 - acc: 0.5172
8128/9333 [=========================>....] - ETA: 1:25 - loss: 0.6962 - acc: 0.5170
8192/9333 [=========================>....] - ETA: 1:21 - loss: 0.6963 - acc: 0.5168
8256/9333 [=========================>....] - ETA: 1:16 - loss: 0.6961 - acc: 0.5171
8320/9333 [=========================>....] - ETA: 1:12 - loss: 0.6961 - acc: 0.5174
8384/9333 [=========================>....] - ETA: 1:07 - loss: 0.6958 - acc: 0.5178
8448/9333 [==========================>...] - ETA: 1:02 - loss: 0.6959 - acc: 0.5178
8512/9333 [==========================>...] - ETA: 58s - loss: 0.6959 - acc: 0.5180 
8576/9333 [==========================>...] - ETA: 53s - loss: 0.6958 - acc: 0.5182
8640/9333 [==========================>...] - ETA: 49s - loss: 0.6959 - acc: 0.5178
8704/9333 [==========================>...] - ETA: 44s - loss: 0.6959 - acc: 0.5176
8768/9333 [===========================>..] - ETA: 40s - loss: 0.6958 - acc: 0.5177
8832/9333 [===========================>..] - ETA: 35s - loss: 0.6958 - acc: 0.5181
8896/9333 [===========================>..] - ETA: 31s - loss: 0.6957 - acc: 0.5183
8960/9333 [===========================>..] - ETA: 26s - loss: 0.6958 - acc: 0.5182
9024/9333 [============================>.] - ETA: 21s - loss: 0.6959 - acc: 0.5180
9088/9333 [============================>.] - ETA: 17s - loss: 0.6958 - acc: 0.5184
9152/9333 [============================>.] - ETA: 12s - loss: 0.6959 - acc: 0.5182
9216/9333 [============================>.] - ETA: 8s - loss: 0.6958 - acc: 0.5184 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6960 - acc: 0.5182
9333/9333 [==============================] - 689s 74ms/step - loss: 0.6960 - acc: 0.5181 - val_loss: 0.6874 - val_acc: 0.5487

Epoch 00002: val_acc did not improve from 0.56606
Epoch 3/10

  64/9333 [..............................] - ETA: 11:57 - loss: 0.6920 - acc: 0.5312
 128/9333 [..............................] - ETA: 10:55 - loss: 0.6968 - acc: 0.5078
 192/9333 [..............................] - ETA: 11:04 - loss: 0.6995 - acc: 0.5208
 256/9333 [..............................] - ETA: 10:58 - loss: 0.6973 - acc: 0.5156
 320/9333 [>.............................] - ETA: 10:49 - loss: 0.6998 - acc: 0.5000
 384/9333 [>.............................] - ETA: 10:44 - loss: 0.7026 - acc: 0.4896
 448/9333 [>.............................] - ETA: 10:42 - loss: 0.7012 - acc: 0.5022
 512/9333 [>.............................] - ETA: 10:40 - loss: 0.6990 - acc: 0.5195
 576/9333 [>.............................] - ETA: 10:38 - loss: 0.6976 - acc: 0.5226
 640/9333 [=>............................] - ETA: 10:32 - loss: 0.6988 - acc: 0.5172
 704/9333 [=>............................] - ETA: 10:28 - loss: 0.6961 - acc: 0.5213
 768/9333 [=>............................] - ETA: 10:23 - loss: 0.6954 - acc: 0.5195
 832/9333 [=>............................] - ETA: 10:18 - loss: 0.6945 - acc: 0.5168
 896/9333 [=>............................] - ETA: 10:12 - loss: 0.6946 - acc: 0.5134
 960/9333 [==>...........................] - ETA: 10:10 - loss: 0.6946 - acc: 0.5125
1024/9333 [==>...........................] - ETA: 10:04 - loss: 0.6941 - acc: 0.5156
1088/9333 [==>...........................] - ETA: 10:00 - loss: 0.6933 - acc: 0.5184
1152/9333 [==>...........................] - ETA: 9:57 - loss: 0.6924 - acc: 0.5208 
1216/9333 [==>...........................] - ETA: 9:49 - loss: 0.6931 - acc: 0.5214
1280/9333 [===>..........................] - ETA: 9:45 - loss: 0.6934 - acc: 0.5195
1344/9333 [===>..........................] - ETA: 9:38 - loss: 0.6921 - acc: 0.5238
1408/9333 [===>..........................] - ETA: 9:33 - loss: 0.6921 - acc: 0.5270
1472/9333 [===>..........................] - ETA: 9:24 - loss: 0.6933 - acc: 0.5265
1536/9333 [===>..........................] - ETA: 9:20 - loss: 0.6925 - acc: 0.5299
1600/9333 [====>.........................] - ETA: 9:13 - loss: 0.6918 - acc: 0.5337
1664/9333 [====>.........................] - ETA: 9:09 - loss: 0.6912 - acc: 0.5355
1728/9333 [====>.........................] - ETA: 9:02 - loss: 0.6909 - acc: 0.5353
1792/9333 [====>.........................] - ETA: 8:56 - loss: 0.6905 - acc: 0.5385
1856/9333 [====>.........................] - ETA: 8:51 - loss: 0.6912 - acc: 0.5372
1920/9333 [=====>........................] - ETA: 8:45 - loss: 0.6903 - acc: 0.5401
1984/9333 [=====>........................] - ETA: 8:40 - loss: 0.6909 - acc: 0.5408
2048/9333 [=====>........................] - ETA: 8:36 - loss: 0.6916 - acc: 0.5376
2112/9333 [=====>........................] - ETA: 8:30 - loss: 0.6923 - acc: 0.5374
2176/9333 [=====>........................] - ETA: 8:26 - loss: 0.6929 - acc: 0.5372
2240/9333 [======>.......................] - ETA: 8:21 - loss: 0.6931 - acc: 0.5353
2304/9333 [======>.......................] - ETA: 8:16 - loss: 0.6928 - acc: 0.5352
2368/9333 [======>.......................] - ETA: 8:13 - loss: 0.6928 - acc: 0.5355
2432/9333 [======>.......................] - ETA: 8:07 - loss: 0.6934 - acc: 0.5354
2496/9333 [=======>......................] - ETA: 8:02 - loss: 0.6938 - acc: 0.5329
2560/9333 [=======>......................] - ETA: 7:57 - loss: 0.6939 - acc: 0.5312
2624/9333 [=======>......................] - ETA: 7:52 - loss: 0.6936 - acc: 0.5309
2688/9333 [=======>......................] - ETA: 7:47 - loss: 0.6938 - acc: 0.5298
2752/9333 [=======>......................] - ETA: 7:43 - loss: 0.6943 - acc: 0.5283
2816/9333 [========>.....................] - ETA: 7:38 - loss: 0.6945 - acc: 0.5270
2880/9333 [========>.....................] - ETA: 7:33 - loss: 0.6945 - acc: 0.5260
2944/9333 [========>.....................] - ETA: 7:27 - loss: 0.6946 - acc: 0.5272
3008/9333 [========>.....................] - ETA: 7:23 - loss: 0.6945 - acc: 0.5279
3072/9333 [========>.....................] - ETA: 7:17 - loss: 0.6947 - acc: 0.5277
3136/9333 [=========>....................] - ETA: 7:13 - loss: 0.6945 - acc: 0.5284
3200/9333 [=========>....................] - ETA: 7:07 - loss: 0.6942 - acc: 0.5312
3264/9333 [=========>....................] - ETA: 7:03 - loss: 0.6943 - acc: 0.5300
3328/9333 [=========>....................] - ETA: 6:58 - loss: 0.6940 - acc: 0.5306
3392/9333 [=========>....................] - ETA: 6:54 - loss: 0.6941 - acc: 0.5304
3456/9333 [==========>...................] - ETA: 6:49 - loss: 0.6941 - acc: 0.5310
3520/9333 [==========>...................] - ETA: 6:44 - loss: 0.6938 - acc: 0.5315
3584/9333 [==========>...................] - ETA: 6:40 - loss: 0.6937 - acc: 0.5307
3648/9333 [==========>...................] - ETA: 6:35 - loss: 0.6933 - acc: 0.5332
3712/9333 [==========>...................] - ETA: 6:31 - loss: 0.6932 - acc: 0.5334
3776/9333 [===========>..................] - ETA: 6:27 - loss: 0.6933 - acc: 0.5326
3840/9333 [===========>..................] - ETA: 6:22 - loss: 0.6937 - acc: 0.5323
3904/9333 [===========>..................] - ETA: 6:18 - loss: 0.6937 - acc: 0.5302
3968/9333 [===========>..................] - ETA: 6:14 - loss: 0.6937 - acc: 0.5297
4032/9333 [===========>..................] - ETA: 6:09 - loss: 0.6938 - acc: 0.5300
4096/9333 [============>.................] - ETA: 6:04 - loss: 0.6934 - acc: 0.5312
4160/9333 [============>.................] - ETA: 6:00 - loss: 0.6938 - acc: 0.5305
4224/9333 [============>.................] - ETA: 5:56 - loss: 0.6939 - acc: 0.5296
4288/9333 [============>.................] - ETA: 5:51 - loss: 0.6940 - acc: 0.5294
4352/9333 [============>.................] - ETA: 5:47 - loss: 0.6942 - acc: 0.5294
4416/9333 [=============>................] - ETA: 5:43 - loss: 0.6941 - acc: 0.5290
4480/9333 [=============>................] - ETA: 5:39 - loss: 0.6938 - acc: 0.5295
4544/9333 [=============>................] - ETA: 5:34 - loss: 0.6938 - acc: 0.5293
4608/9333 [=============>................] - ETA: 5:30 - loss: 0.6937 - acc: 0.5299
4672/9333 [==============>...............] - ETA: 5:26 - loss: 0.6937 - acc: 0.5285
4736/9333 [==============>...............] - ETA: 5:21 - loss: 0.6937 - acc: 0.5283
4800/9333 [==============>...............] - ETA: 5:17 - loss: 0.6937 - acc: 0.5277
4864/9333 [==============>...............] - ETA: 5:13 - loss: 0.6938 - acc: 0.5280
4928/9333 [==============>...............] - ETA: 5:08 - loss: 0.6935 - acc: 0.5286
4992/9333 [===============>..............] - ETA: 5:04 - loss: 0.6936 - acc: 0.5280
5056/9333 [===============>..............] - ETA: 5:00 - loss: 0.6936 - acc: 0.5281
5120/9333 [===============>..............] - ETA: 4:55 - loss: 0.6936 - acc: 0.5273
5184/9333 [===============>..............] - ETA: 4:51 - loss: 0.6934 - acc: 0.5284
5248/9333 [===============>..............] - ETA: 4:46 - loss: 0.6932 - acc: 0.5284
5312/9333 [================>.............] - ETA: 4:42 - loss: 0.6934 - acc: 0.5277
5376/9333 [================>.............] - ETA: 4:38 - loss: 0.6932 - acc: 0.5283
5440/9333 [================>.............] - ETA: 4:33 - loss: 0.6932 - acc: 0.5279
5504/9333 [================>.............] - ETA: 4:29 - loss: 0.6931 - acc: 0.5287
5568/9333 [================>.............] - ETA: 4:24 - loss: 0.6927 - acc: 0.5302
5632/9333 [=================>............] - ETA: 4:20 - loss: 0.6930 - acc: 0.5289
5696/9333 [=================>............] - ETA: 4:15 - loss: 0.6932 - acc: 0.5284
5760/9333 [=================>............] - ETA: 4:11 - loss: 0.6933 - acc: 0.5283
5824/9333 [=================>............] - ETA: 4:06 - loss: 0.6927 - acc: 0.5297
5888/9333 [=================>............] - ETA: 4:02 - loss: 0.6930 - acc: 0.5297
5952/9333 [==================>...........] - ETA: 3:57 - loss: 0.6932 - acc: 0.5302
6016/9333 [==================>...........] - ETA: 3:53 - loss: 0.6934 - acc: 0.5294
6080/9333 [==================>...........] - ETA: 3:48 - loss: 0.6935 - acc: 0.5289
6144/9333 [==================>...........] - ETA: 3:44 - loss: 0.6932 - acc: 0.5303
6208/9333 [==================>...........] - ETA: 3:39 - loss: 0.6932 - acc: 0.5296
6272/9333 [===================>..........] - ETA: 3:35 - loss: 0.6932 - acc: 0.5292
6336/9333 [===================>..........] - ETA: 3:30 - loss: 0.6929 - acc: 0.5298
6400/9333 [===================>..........] - ETA: 3:26 - loss: 0.6929 - acc: 0.5297
6464/9333 [===================>..........] - ETA: 3:21 - loss: 0.6930 - acc: 0.5295
6528/9333 [===================>..........] - ETA: 3:17 - loss: 0.6930 - acc: 0.5291
6592/9333 [====================>.........] - ETA: 3:12 - loss: 0.6927 - acc: 0.5303
6656/9333 [====================>.........] - ETA: 3:08 - loss: 0.6924 - acc: 0.5309
6720/9333 [====================>.........] - ETA: 3:03 - loss: 0.6921 - acc: 0.5314
6784/9333 [====================>.........] - ETA: 2:58 - loss: 0.6918 - acc: 0.5320
6848/9333 [=====================>........] - ETA: 2:53 - loss: 0.6920 - acc: 0.5310
6912/9333 [=====================>........] - ETA: 2:49 - loss: 0.6922 - acc: 0.5304
6976/9333 [=====================>........] - ETA: 2:44 - loss: 0.6919 - acc: 0.5308
7040/9333 [=====================>........] - ETA: 2:39 - loss: 0.6920 - acc: 0.5310
7104/9333 [=====================>........] - ETA: 2:35 - loss: 0.6921 - acc: 0.5314
7168/9333 [======================>.......] - ETA: 2:30 - loss: 0.6923 - acc: 0.5308
7232/9333 [======================>.......] - ETA: 2:26 - loss: 0.6921 - acc: 0.5312
7296/9333 [======================>.......] - ETA: 2:21 - loss: 0.6920 - acc: 0.5321
7360/9333 [======================>.......] - ETA: 2:16 - loss: 0.6919 - acc: 0.5317
7424/9333 [======================>.......] - ETA: 2:12 - loss: 0.6917 - acc: 0.5318
7488/9333 [=======================>......] - ETA: 2:07 - loss: 0.6915 - acc: 0.5326
7552/9333 [=======================>......] - ETA: 2:02 - loss: 0.6916 - acc: 0.5326
7616/9333 [=======================>......] - ETA: 1:58 - loss: 0.6915 - acc: 0.5330
7680/9333 [=======================>......] - ETA: 1:53 - loss: 0.6915 - acc: 0.5332
7744/9333 [=======================>......] - ETA: 1:49 - loss: 0.6915 - acc: 0.5333
7808/9333 [========================>.....] - ETA: 1:44 - loss: 0.6914 - acc: 0.5337
7872/9333 [========================>.....] - ETA: 1:40 - loss: 0.6914 - acc: 0.5342
7936/9333 [========================>.....] - ETA: 1:35 - loss: 0.6914 - acc: 0.5341
8000/9333 [========================>.....] - ETA: 1:31 - loss: 0.6916 - acc: 0.5340
8064/9333 [========================>.....] - ETA: 1:27 - loss: 0.6915 - acc: 0.5337
8128/9333 [=========================>....] - ETA: 1:22 - loss: 0.6914 - acc: 0.5338
8192/9333 [=========================>....] - ETA: 1:18 - loss: 0.6913 - acc: 0.5339
8256/9333 [=========================>....] - ETA: 1:13 - loss: 0.6914 - acc: 0.5334
8320/9333 [=========================>....] - ETA: 1:09 - loss: 0.6913 - acc: 0.5340
8384/9333 [=========================>....] - ETA: 1:04 - loss: 0.6913 - acc: 0.5340
8448/9333 [==========================>...] - ETA: 1:00 - loss: 0.6914 - acc: 0.5336
8512/9333 [==========================>...] - ETA: 56s - loss: 0.6914 - acc: 0.5334 
8576/9333 [==========================>...] - ETA: 51s - loss: 0.6913 - acc: 0.5336
8640/9333 [==========================>...] - ETA: 47s - loss: 0.6912 - acc: 0.5334
8704/9333 [==========================>...] - ETA: 42s - loss: 0.6913 - acc: 0.5333
8768/9333 [===========================>..] - ETA: 38s - loss: 0.6914 - acc: 0.5331
8832/9333 [===========================>..] - ETA: 34s - loss: 0.6912 - acc: 0.5334
8896/9333 [===========================>..] - ETA: 29s - loss: 0.6912 - acc: 0.5330
8960/9333 [===========================>..] - ETA: 25s - loss: 0.6912 - acc: 0.5331
9024/9333 [============================>.] - ETA: 21s - loss: 0.6912 - acc: 0.5330
9088/9333 [============================>.] - ETA: 16s - loss: 0.6913 - acc: 0.5324
9152/9333 [============================>.] - ETA: 12s - loss: 0.6914 - acc: 0.5321
9216/9333 [============================>.] - ETA: 7s - loss: 0.6915 - acc: 0.5320 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6915 - acc: 0.5322
9333/9333 [==============================] - 656s 70ms/step - loss: 0.6917 - acc: 0.5319 - val_loss: 0.6876 - val_acc: 0.5333

Epoch 00003: val_acc did not improve from 0.56606
Epoch 4/10

  64/9333 [..............................] - ETA: 9:28 - loss: 0.7056 - acc: 0.4375
 128/9333 [..............................] - ETA: 9:13 - loss: 0.6928 - acc: 0.5000
 192/9333 [..............................] - ETA: 9:08 - loss: 0.6842 - acc: 0.5260
 256/9333 [..............................] - ETA: 8:59 - loss: 0.6886 - acc: 0.5195
 320/9333 [>.............................] - ETA: 9:10 - loss: 0.6915 - acc: 0.5188
 384/9333 [>.............................] - ETA: 9:01 - loss: 0.6912 - acc: 0.5078
 448/9333 [>.............................] - ETA: 9:03 - loss: 0.6883 - acc: 0.5179
 512/9333 [>.............................] - ETA: 8:57 - loss: 0.6894 - acc: 0.5215
 576/9333 [>.............................] - ETA: 8:56 - loss: 0.6963 - acc: 0.5104
 640/9333 [=>............................] - ETA: 8:50 - loss: 0.6956 - acc: 0.5156
 704/9333 [=>............................] - ETA: 8:52 - loss: 0.6972 - acc: 0.5085
 768/9333 [=>............................] - ETA: 8:46 - loss: 0.6971 - acc: 0.5117
 832/9333 [=>............................] - ETA: 8:47 - loss: 0.6987 - acc: 0.5048
 896/9333 [=>............................] - ETA: 8:42 - loss: 0.6987 - acc: 0.5045
 960/9333 [==>...........................] - ETA: 8:40 - loss: 0.6968 - acc: 0.5094
1024/9333 [==>...........................] - ETA: 8:34 - loss: 0.6948 - acc: 0.5166
1088/9333 [==>...........................] - ETA: 8:32 - loss: 0.6919 - acc: 0.5285
1152/9333 [==>...........................] - ETA: 8:26 - loss: 0.6920 - acc: 0.5226
1216/9333 [==>...........................] - ETA: 8:22 - loss: 0.6891 - acc: 0.5321
1280/9333 [===>..........................] - ETA: 8:17 - loss: 0.6885 - acc: 0.5305
1344/9333 [===>..........................] - ETA: 8:14 - loss: 0.6883 - acc: 0.5312
1408/9333 [===>..........................] - ETA: 8:09 - loss: 0.6888 - acc: 0.5256
1472/9333 [===>..........................] - ETA: 8:05 - loss: 0.6892 - acc: 0.5238
1536/9333 [===>..........................] - ETA: 8:02 - loss: 0.6897 - acc: 0.5228
1600/9333 [====>.........................] - ETA: 7:58 - loss: 0.6897 - acc: 0.5238
1664/9333 [====>.........................] - ETA: 7:54 - loss: 0.6902 - acc: 0.5228
1728/9333 [====>.........................] - ETA: 7:52 - loss: 0.6910 - acc: 0.5208
1792/9333 [====>.........................] - ETA: 7:47 - loss: 0.6903 - acc: 0.5234
1856/9333 [====>.........................] - ETA: 7:44 - loss: 0.6914 - acc: 0.5232
1920/9333 [=====>........................] - ETA: 7:38 - loss: 0.6906 - acc: 0.5245
1984/9333 [=====>........................] - ETA: 7:34 - loss: 0.6906 - acc: 0.5257
2048/9333 [=====>........................] - ETA: 7:30 - loss: 0.6906 - acc: 0.5269
2112/9333 [=====>........................] - ETA: 7:26 - loss: 0.6906 - acc: 0.5251
2176/9333 [=====>........................] - ETA: 7:23 - loss: 0.6911 - acc: 0.5216
2240/9333 [======>.......................] - ETA: 7:18 - loss: 0.6911 - acc: 0.5219
2304/9333 [======>.......................] - ETA: 7:14 - loss: 0.6908 - acc: 0.5230
2368/9333 [======>.......................] - ETA: 7:09 - loss: 0.6905 - acc: 0.5228
2432/9333 [======>.......................] - ETA: 7:06 - loss: 0.6911 - acc: 0.5226
2496/9333 [=======>......................] - ETA: 7:01 - loss: 0.6914 - acc: 0.5208
2560/9333 [=======>......................] - ETA: 6:58 - loss: 0.6920 - acc: 0.5172
2624/9333 [=======>......................] - ETA: 6:53 - loss: 0.6923 - acc: 0.5156
2688/9333 [=======>......................] - ETA: 6:50 - loss: 0.6921 - acc: 0.5171
2752/9333 [=======>......................] - ETA: 6:46 - loss: 0.6916 - acc: 0.5200
2816/9333 [========>.....................] - ETA: 6:42 - loss: 0.6916 - acc: 0.5199
2880/9333 [========>.....................] - ETA: 6:37 - loss: 0.6917 - acc: 0.5191
2944/9333 [========>.....................] - ETA: 6:34 - loss: 0.6920 - acc: 0.5190
3008/9333 [========>.....................] - ETA: 6:29 - loss: 0.6917 - acc: 0.5203
3072/9333 [========>.....................] - ETA: 6:26 - loss: 0.6924 - acc: 0.5186
3136/9333 [=========>....................] - ETA: 6:21 - loss: 0.6929 - acc: 0.5172
3200/9333 [=========>....................] - ETA: 6:17 - loss: 0.6927 - acc: 0.5181
3264/9333 [=========>....................] - ETA: 6:13 - loss: 0.6925 - acc: 0.5193
3328/9333 [=========>....................] - ETA: 6:10 - loss: 0.6925 - acc: 0.5189
3392/9333 [=========>....................] - ETA: 6:06 - loss: 0.6927 - acc: 0.5177
3456/9333 [==========>...................] - ETA: 6:01 - loss: 0.6922 - acc: 0.5179
3520/9333 [==========>...................] - ETA: 5:57 - loss: 0.6923 - acc: 0.5170
3584/9333 [==========>...................] - ETA: 5:53 - loss: 0.6920 - acc: 0.5184
3648/9333 [==========>...................] - ETA: 5:50 - loss: 0.6919 - acc: 0.5189
3712/9333 [==========>...................] - ETA: 5:46 - loss: 0.6920 - acc: 0.5189
3776/9333 [===========>..................] - ETA: 5:42 - loss: 0.6919 - acc: 0.5191
3840/9333 [===========>..................] - ETA: 5:38 - loss: 0.6922 - acc: 0.5198
3904/9333 [===========>..................] - ETA: 5:34 - loss: 0.6930 - acc: 0.5174
3968/9333 [===========>..................] - ETA: 5:29 - loss: 0.6930 - acc: 0.5174
4032/9333 [===========>..................] - ETA: 5:25 - loss: 0.6930 - acc: 0.5186
4096/9333 [============>.................] - ETA: 5:21 - loss: 0.6930 - acc: 0.5181
4160/9333 [============>.................] - ETA: 5:17 - loss: 0.6927 - acc: 0.5197
4224/9333 [============>.................] - ETA: 5:13 - loss: 0.6929 - acc: 0.5196
4288/9333 [============>.................] - ETA: 5:09 - loss: 0.6930 - acc: 0.5198
4352/9333 [============>.................] - ETA: 5:05 - loss: 0.6930 - acc: 0.5195
4416/9333 [=============>................] - ETA: 5:01 - loss: 0.6929 - acc: 0.5204
4480/9333 [=============>................] - ETA: 4:57 - loss: 0.6927 - acc: 0.5205
4544/9333 [=============>................] - ETA: 4:53 - loss: 0.6928 - acc: 0.5205
4608/9333 [=============>................] - ETA: 4:50 - loss: 0.6928 - acc: 0.5202
4672/9333 [==============>...............] - ETA: 4:45 - loss: 0.6925 - acc: 0.5212
4736/9333 [==============>...............] - ETA: 4:42 - loss: 0.6921 - acc: 0.5236
4800/9333 [==============>...............] - ETA: 4:38 - loss: 0.6922 - acc: 0.5240
4864/9333 [==============>...............] - ETA: 4:34 - loss: 0.6922 - acc: 0.5241
4928/9333 [==============>...............] - ETA: 4:30 - loss: 0.6923 - acc: 0.5241
4992/9333 [===============>..............] - ETA: 4:26 - loss: 0.6922 - acc: 0.5242
5056/9333 [===============>..............] - ETA: 4:22 - loss: 0.6921 - acc: 0.5243
5120/9333 [===============>..............] - ETA: 4:19 - loss: 0.6919 - acc: 0.5252
5184/9333 [===============>..............] - ETA: 4:14 - loss: 0.6916 - acc: 0.5264
5248/9333 [===============>..............] - ETA: 4:11 - loss: 0.6917 - acc: 0.5267
5312/9333 [================>.............] - ETA: 4:06 - loss: 0.6916 - acc: 0.5271
5376/9333 [================>.............] - ETA: 4:03 - loss: 0.6919 - acc: 0.5264
5440/9333 [================>.............] - ETA: 3:59 - loss: 0.6917 - acc: 0.5267
5504/9333 [================>.............] - ETA: 3:55 - loss: 0.6916 - acc: 0.5256
5568/9333 [================>.............] - ETA: 3:51 - loss: 0.6915 - acc: 0.5262
5632/9333 [=================>............] - ETA: 3:47 - loss: 0.6919 - acc: 0.5247
5696/9333 [=================>............] - ETA: 3:43 - loss: 0.6918 - acc: 0.5249
5760/9333 [=================>............] - ETA: 3:39 - loss: 0.6918 - acc: 0.5252
5824/9333 [=================>............] - ETA: 3:35 - loss: 0.6920 - acc: 0.5252
5888/9333 [=================>............] - ETA: 3:31 - loss: 0.6920 - acc: 0.5253
5952/9333 [==================>...........] - ETA: 3:27 - loss: 0.6921 - acc: 0.5252
6016/9333 [==================>...........] - ETA: 3:23 - loss: 0.6922 - acc: 0.5241
6080/9333 [==================>...........] - ETA: 3:20 - loss: 0.6926 - acc: 0.5232
6144/9333 [==================>...........] - ETA: 3:16 - loss: 0.6926 - acc: 0.5236
6208/9333 [==================>...........] - ETA: 3:12 - loss: 0.6925 - acc: 0.5242
6272/9333 [===================>..........] - ETA: 3:08 - loss: 0.6927 - acc: 0.5238
6336/9333 [===================>..........] - ETA: 3:04 - loss: 0.6927 - acc: 0.5238
6400/9333 [===================>..........] - ETA: 3:00 - loss: 0.6925 - acc: 0.5245
6464/9333 [===================>..........] - ETA: 2:56 - loss: 0.6925 - acc: 0.5244
6528/9333 [===================>..........] - ETA: 2:52 - loss: 0.6928 - acc: 0.5234
6592/9333 [====================>.........] - ETA: 2:48 - loss: 0.6927 - acc: 0.5237
6656/9333 [====================>.........] - ETA: 2:44 - loss: 0.6925 - acc: 0.5249
6720/9333 [====================>.........] - ETA: 2:41 - loss: 0.6924 - acc: 0.5262
6784/9333 [====================>.........] - ETA: 2:37 - loss: 0.6925 - acc: 0.5270
6848/9333 [=====================>........] - ETA: 2:33 - loss: 0.6925 - acc: 0.5272
6912/9333 [=====================>........] - ETA: 2:29 - loss: 0.6925 - acc: 0.5276
6976/9333 [=====================>........] - ETA: 2:25 - loss: 0.6925 - acc: 0.5278
7040/9333 [=====================>........] - ETA: 2:21 - loss: 0.6926 - acc: 0.5273
7104/9333 [=====================>........] - ETA: 2:17 - loss: 0.6926 - acc: 0.5269
7168/9333 [======================>.......] - ETA: 2:13 - loss: 0.6925 - acc: 0.5269
7232/9333 [======================>.......] - ETA: 2:09 - loss: 0.6923 - acc: 0.5286
7296/9333 [======================>.......] - ETA: 2:05 - loss: 0.6923 - acc: 0.5289
7360/9333 [======================>.......] - ETA: 2:01 - loss: 0.6922 - acc: 0.5302
7424/9333 [======================>.......] - ETA: 1:57 - loss: 0.6923 - acc: 0.5295
7488/9333 [=======================>......] - ETA: 1:53 - loss: 0.6924 - acc: 0.5283
7552/9333 [=======================>......] - ETA: 1:49 - loss: 0.6925 - acc: 0.5275
7616/9333 [=======================>......] - ETA: 1:45 - loss: 0.6924 - acc: 0.5282
7680/9333 [=======================>......] - ETA: 1:41 - loss: 0.6925 - acc: 0.5272
7744/9333 [=======================>......] - ETA: 1:37 - loss: 0.6926 - acc: 0.5272
7808/9333 [========================>.....] - ETA: 1:33 - loss: 0.6926 - acc: 0.5272
7872/9333 [========================>.....] - ETA: 1:29 - loss: 0.6925 - acc: 0.5276
7936/9333 [========================>.....] - ETA: 1:25 - loss: 0.6923 - acc: 0.5289
8000/9333 [========================>.....] - ETA: 1:21 - loss: 0.6921 - acc: 0.5290
8064/9333 [========================>.....] - ETA: 1:17 - loss: 0.6920 - acc: 0.5291
8128/9333 [=========================>....] - ETA: 1:13 - loss: 0.6920 - acc: 0.5293
8192/9333 [=========================>....] - ETA: 1:09 - loss: 0.6919 - acc: 0.5298
8256/9333 [=========================>....] - ETA: 1:06 - loss: 0.6918 - acc: 0.5304
8320/9333 [=========================>....] - ETA: 1:02 - loss: 0.6919 - acc: 0.5300
8384/9333 [=========================>....] - ETA: 58s - loss: 0.6920 - acc: 0.5297 
8448/9333 [==========================>...] - ETA: 54s - loss: 0.6919 - acc: 0.5298
8512/9333 [==========================>...] - ETA: 50s - loss: 0.6919 - acc: 0.5298
8576/9333 [==========================>...] - ETA: 46s - loss: 0.6919 - acc: 0.5297
8640/9333 [==========================>...] - ETA: 42s - loss: 0.6918 - acc: 0.5301
8704/9333 [==========================>...] - ETA: 38s - loss: 0.6920 - acc: 0.5291
8768/9333 [===========================>..] - ETA: 34s - loss: 0.6920 - acc: 0.5291
8832/9333 [===========================>..] - ETA: 30s - loss: 0.6921 - acc: 0.5285
8896/9333 [===========================>..] - ETA: 26s - loss: 0.6923 - acc: 0.5281
8960/9333 [===========================>..] - ETA: 22s - loss: 0.6921 - acc: 0.5292
9024/9333 [============================>.] - ETA: 18s - loss: 0.6919 - acc: 0.5295
9088/9333 [============================>.] - ETA: 14s - loss: 0.6919 - acc: 0.5294
9152/9333 [============================>.] - ETA: 11s - loss: 0.6918 - acc: 0.5293
9216/9333 [============================>.] - ETA: 7s - loss: 0.6915 - acc: 0.5306 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6917 - acc: 0.5300
9333/9333 [==============================] - 593s 64ms/step - loss: 0.6916 - acc: 0.5303 - val_loss: 0.6886 - val_acc: 0.5458

Epoch 00004: val_acc did not improve from 0.56606
Epoch 5/10

  64/9333 [..............................] - ETA: 9:05 - loss: 0.6594 - acc: 0.6250
 128/9333 [..............................] - ETA: 9:39 - loss: 0.6722 - acc: 0.6328
 192/9333 [..............................] - ETA: 9:31 - loss: 0.6821 - acc: 0.5938
 256/9333 [..............................] - ETA: 9:22 - loss: 0.6844 - acc: 0.5664
 320/9333 [>.............................] - ETA: 9:34 - loss: 0.6867 - acc: 0.5594
 384/9333 [>.............................] - ETA: 9:29 - loss: 0.6859 - acc: 0.5625
 448/9333 [>.............................] - ETA: 9:24 - loss: 0.6805 - acc: 0.5759
 512/9333 [>.............................] - ETA: 9:14 - loss: 0.6855 - acc: 0.5645
 576/9333 [>.............................] - ETA: 9:11 - loss: 0.6840 - acc: 0.5625
 640/9333 [=>............................] - ETA: 9:04 - loss: 0.6853 - acc: 0.5578
 704/9333 [=>............................] - ETA: 8:58 - loss: 0.6877 - acc: 0.5511
 768/9333 [=>............................] - ETA: 8:54 - loss: 0.6900 - acc: 0.5469
 832/9333 [=>............................] - ETA: 8:51 - loss: 0.6910 - acc: 0.5433
 896/9333 [=>............................] - ETA: 8:43 - loss: 0.6914 - acc: 0.5402
 960/9333 [==>...........................] - ETA: 8:39 - loss: 0.6924 - acc: 0.5365
1024/9333 [==>...........................] - ETA: 8:34 - loss: 0.6914 - acc: 0.5371
1088/9333 [==>...........................] - ETA: 8:29 - loss: 0.6896 - acc: 0.5395
1152/9333 [==>...........................] - ETA: 8:25 - loss: 0.6882 - acc: 0.5425
1216/9333 [==>...........................] - ETA: 8:21 - loss: 0.6864 - acc: 0.5493
1280/9333 [===>..........................] - ETA: 8:17 - loss: 0.6866 - acc: 0.5500
1344/9333 [===>..........................] - ETA: 8:12 - loss: 0.6858 - acc: 0.5521
1408/9333 [===>..........................] - ETA: 8:09 - loss: 0.6865 - acc: 0.5476
1472/9333 [===>..........................] - ETA: 8:03 - loss: 0.6863 - acc: 0.5496
1536/9333 [===>..........................] - ETA: 8:01 - loss: 0.6852 - acc: 0.5501
1600/9333 [====>.........................] - ETA: 7:56 - loss: 0.6862 - acc: 0.5444
1664/9333 [====>.........................] - ETA: 7:54 - loss: 0.6881 - acc: 0.5415
1728/9333 [====>.........................] - ETA: 7:49 - loss: 0.6879 - acc: 0.5417
1792/9333 [====>.........................] - ETA: 7:45 - loss: 0.6887 - acc: 0.5424
1856/9333 [====>.........................] - ETA: 7:40 - loss: 0.6892 - acc: 0.5415
1920/9333 [=====>........................] - ETA: 7:37 - loss: 0.6895 - acc: 0.5406
1984/9333 [=====>........................] - ETA: 7:31 - loss: 0.6890 - acc: 0.5408
2048/9333 [=====>........................] - ETA: 7:28 - loss: 0.6896 - acc: 0.5381
2112/9333 [=====>........................] - ETA: 7:24 - loss: 0.6899 - acc: 0.5360
2176/9333 [=====>........................] - ETA: 7:22 - loss: 0.6906 - acc: 0.5340
2240/9333 [======>.......................] - ETA: 7:18 - loss: 0.6900 - acc: 0.5371
2304/9333 [======>.......................] - ETA: 7:14 - loss: 0.6901 - acc: 0.5365
2368/9333 [======>.......................] - ETA: 7:10 - loss: 0.6893 - acc: 0.5376
2432/9333 [======>.......................] - ETA: 7:05 - loss: 0.6888 - acc: 0.5382
2496/9333 [=======>......................] - ETA: 7:02 - loss: 0.6891 - acc: 0.5357
2560/9333 [=======>......................] - ETA: 6:58 - loss: 0.6902 - acc: 0.5332
2624/9333 [=======>......................] - ETA: 6:54 - loss: 0.6908 - acc: 0.5324
2688/9333 [=======>......................] - ETA: 6:49 - loss: 0.6901 - acc: 0.5346
2752/9333 [=======>......................] - ETA: 6:46 - loss: 0.6900 - acc: 0.5345
2816/9333 [========>.....................] - ETA: 6:42 - loss: 0.6901 - acc: 0.5341
2880/9333 [========>.....................] - ETA: 6:39 - loss: 0.6911 - acc: 0.5316
2944/9333 [========>.....................] - ETA: 6:35 - loss: 0.6909 - acc: 0.5336
3008/9333 [========>.....................] - ETA: 6:31 - loss: 0.6911 - acc: 0.5319
3072/9333 [========>.....................] - ETA: 6:28 - loss: 0.6912 - acc: 0.5326
3136/9333 [=========>....................] - ETA: 6:24 - loss: 0.6909 - acc: 0.5325
3200/9333 [=========>....................] - ETA: 6:20 - loss: 0.6908 - acc: 0.5319
3264/9333 [=========>....................] - ETA: 6:16 - loss: 0.6910 - acc: 0.5306
3328/9333 [=========>....................] - ETA: 6:12 - loss: 0.6908 - acc: 0.5316
3392/9333 [=========>....................] - ETA: 6:08 - loss: 0.6908 - acc: 0.5318
3456/9333 [==========>...................] - ETA: 6:03 - loss: 0.6907 - acc: 0.5307
3520/9333 [==========>...................] - ETA: 5:59 - loss: 0.6907 - acc: 0.5307
3584/9333 [==========>...................] - ETA: 5:55 - loss: 0.6906 - acc: 0.5304
3648/9333 [==========>...................] - ETA: 5:52 - loss: 0.6901 - acc: 0.5326
3712/9333 [==========>...................] - ETA: 5:47 - loss: 0.6903 - acc: 0.5331
3776/9333 [===========>..................] - ETA: 5:44 - loss: 0.6898 - acc: 0.5347
3840/9333 [===========>..................] - ETA: 5:41 - loss: 0.6899 - acc: 0.5346
3904/9333 [===========>..................] - ETA: 5:38 - loss: 0.6898 - acc: 0.5359
3968/9333 [===========>..................] - ETA: 5:33 - loss: 0.6898 - acc: 0.5358
4032/9333 [===========>..................] - ETA: 5:30 - loss: 0.6898 - acc: 0.5372
4096/9333 [============>.................] - ETA: 5:25 - loss: 0.6895 - acc: 0.5366
4160/9333 [============>.................] - ETA: 5:22 - loss: 0.6897 - acc: 0.5358
4224/9333 [============>.................] - ETA: 5:18 - loss: 0.6899 - acc: 0.5348
4288/9333 [============>.................] - ETA: 5:14 - loss: 0.6900 - acc: 0.5329
4352/9333 [============>.................] - ETA: 5:10 - loss: 0.6897 - acc: 0.5331
4416/9333 [=============>................] - ETA: 5:06 - loss: 0.6896 - acc: 0.5340
4480/9333 [=============>................] - ETA: 5:02 - loss: 0.6897 - acc: 0.5342
4544/9333 [=============>................] - ETA: 4:59 - loss: 0.6895 - acc: 0.5359
4608/9333 [=============>................] - ETA: 4:55 - loss: 0.6899 - acc: 0.5354
4672/9333 [==============>...............] - ETA: 4:51 - loss: 0.6898 - acc: 0.5357
4736/9333 [==============>...............] - ETA: 4:47 - loss: 0.6898 - acc: 0.5357
4800/9333 [==============>...............] - ETA: 4:43 - loss: 0.6902 - acc: 0.5352
4864/9333 [==============>...............] - ETA: 4:39 - loss: 0.6901 - acc: 0.5358
4928/9333 [==============>...............] - ETA: 4:35 - loss: 0.6901 - acc: 0.5357
4992/9333 [===============>..............] - ETA: 4:31 - loss: 0.6901 - acc: 0.5351
5056/9333 [===============>..............] - ETA: 4:27 - loss: 0.6903 - acc: 0.5348
5120/9333 [===============>..............] - ETA: 4:22 - loss: 0.6899 - acc: 0.5355
5184/9333 [===============>..............] - ETA: 4:19 - loss: 0.6899 - acc: 0.5357
5248/9333 [===============>..............] - ETA: 4:14 - loss: 0.6899 - acc: 0.5360
5312/9333 [================>.............] - ETA: 4:11 - loss: 0.6900 - acc: 0.5361
5376/9333 [================>.............] - ETA: 4:06 - loss: 0.6901 - acc: 0.5359
5440/9333 [================>.............] - ETA: 4:02 - loss: 0.6900 - acc: 0.5369
5504/9333 [================>.............] - ETA: 3:58 - loss: 0.6901 - acc: 0.5367
5568/9333 [================>.............] - ETA: 3:54 - loss: 0.6901 - acc: 0.5363
5632/9333 [=================>............] - ETA: 3:50 - loss: 0.6904 - acc: 0.5344
5696/9333 [=================>............] - ETA: 3:46 - loss: 0.6902 - acc: 0.5348
5760/9333 [=================>............] - ETA: 3:42 - loss: 0.6903 - acc: 0.5345
5824/9333 [=================>............] - ETA: 3:38 - loss: 0.6905 - acc: 0.5338
5888/9333 [=================>............] - ETA: 3:34 - loss: 0.6906 - acc: 0.5328
5952/9333 [==================>...........] - ETA: 3:30 - loss: 0.6907 - acc: 0.5333
6016/9333 [==================>...........] - ETA: 3:26 - loss: 0.6909 - acc: 0.5329
6080/9333 [==================>...........] - ETA: 3:22 - loss: 0.6911 - acc: 0.5322
6144/9333 [==================>...........] - ETA: 3:18 - loss: 0.6910 - acc: 0.5322
6208/9333 [==================>...........] - ETA: 3:13 - loss: 0.6909 - acc: 0.5325
6272/9333 [===================>..........] - ETA: 3:09 - loss: 0.6907 - acc: 0.5330
6336/9333 [===================>..........] - ETA: 3:05 - loss: 0.6905 - acc: 0.5336
6400/9333 [===================>..........] - ETA: 3:01 - loss: 0.6904 - acc: 0.5339
6464/9333 [===================>..........] - ETA: 2:57 - loss: 0.6905 - acc: 0.5339
6528/9333 [===================>..........] - ETA: 2:52 - loss: 0.6906 - acc: 0.5335
6592/9333 [====================>.........] - ETA: 2:48 - loss: 0.6907 - acc: 0.5323
6656/9333 [====================>.........] - ETA: 2:44 - loss: 0.6908 - acc: 0.5320
6720/9333 [====================>.........] - ETA: 2:40 - loss: 0.6906 - acc: 0.5333
6784/9333 [====================>.........] - ETA: 2:36 - loss: 0.6907 - acc: 0.5332
6848/9333 [=====================>........] - ETA: 2:32 - loss: 0.6907 - acc: 0.5334
6912/9333 [=====================>........] - ETA: 2:28 - loss: 0.6906 - acc: 0.5341
6976/9333 [=====================>........] - ETA: 2:24 - loss: 0.6907 - acc: 0.5337
7040/9333 [=====================>........] - ETA: 2:20 - loss: 0.6906 - acc: 0.5342
7104/9333 [=====================>........] - ETA: 2:16 - loss: 0.6906 - acc: 0.5342
7168/9333 [======================>.......] - ETA: 2:12 - loss: 0.6906 - acc: 0.5339
7232/9333 [======================>.......] - ETA: 2:08 - loss: 0.6907 - acc: 0.5337
7296/9333 [======================>.......] - ETA: 2:04 - loss: 0.6909 - acc: 0.5332
7360/9333 [======================>.......] - ETA: 2:00 - loss: 0.6906 - acc: 0.5342
7424/9333 [======================>.......] - ETA: 1:56 - loss: 0.6905 - acc: 0.5343
7488/9333 [=======================>......] - ETA: 1:52 - loss: 0.6904 - acc: 0.5351
7552/9333 [=======================>......] - ETA: 1:48 - loss: 0.6903 - acc: 0.5351
7616/9333 [=======================>......] - ETA: 1:44 - loss: 0.6901 - acc: 0.5357
7680/9333 [=======================>......] - ETA: 1:40 - loss: 0.6900 - acc: 0.5355
7744/9333 [=======================>......] - ETA: 1:36 - loss: 0.6900 - acc: 0.5360
7808/9333 [========================>.....] - ETA: 1:32 - loss: 0.6899 - acc: 0.5362
7872/9333 [========================>.....] - ETA: 1:29 - loss: 0.6900 - acc: 0.5356
7936/9333 [========================>.....] - ETA: 1:25 - loss: 0.6898 - acc: 0.5359
8000/9333 [========================>.....] - ETA: 1:21 - loss: 0.6900 - acc: 0.5359
8064/9333 [========================>.....] - ETA: 1:17 - loss: 0.6900 - acc: 0.5360
8128/9333 [=========================>....] - ETA: 1:13 - loss: 0.6903 - acc: 0.5354
8192/9333 [=========================>....] - ETA: 1:09 - loss: 0.6904 - acc: 0.5353
8256/9333 [=========================>....] - ETA: 1:05 - loss: 0.6904 - acc: 0.5355
8320/9333 [=========================>....] - ETA: 1:01 - loss: 0.6904 - acc: 0.5352
8384/9333 [=========================>....] - ETA: 57s - loss: 0.6906 - acc: 0.5341 
8448/9333 [==========================>...] - ETA: 53s - loss: 0.6907 - acc: 0.5335
8512/9333 [==========================>...] - ETA: 49s - loss: 0.6910 - acc: 0.5325
8576/9333 [==========================>...] - ETA: 46s - loss: 0.6909 - acc: 0.5329
8640/9333 [==========================>...] - ETA: 42s - loss: 0.6910 - acc: 0.5324
8704/9333 [==========================>...] - ETA: 38s - loss: 0.6910 - acc: 0.5323
8768/9333 [===========================>..] - ETA: 34s - loss: 0.6909 - acc: 0.5331
8832/9333 [===========================>..] - ETA: 30s - loss: 0.6909 - acc: 0.5328
8896/9333 [===========================>..] - ETA: 26s - loss: 0.6907 - acc: 0.5334
8960/9333 [===========================>..] - ETA: 22s - loss: 0.6907 - acc: 0.5337
9024/9333 [============================>.] - ETA: 18s - loss: 0.6905 - acc: 0.5351
9088/9333 [============================>.] - ETA: 14s - loss: 0.6906 - acc: 0.5348
9152/9333 [============================>.] - ETA: 11s - loss: 0.6906 - acc: 0.5345
9216/9333 [============================>.] - ETA: 7s - loss: 0.6904 - acc: 0.5348 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6905 - acc: 0.5346
9333/9333 [==============================] - 591s 63ms/step - loss: 0.6904 - acc: 0.5351 - val_loss: 0.6861 - val_acc: 0.5448

Epoch 00005: val_acc did not improve from 0.56606
Epoch 6/10

  64/9333 [..............................] - ETA: 9:23 - loss: 0.6648 - acc: 0.6719
 128/9333 [..............................] - ETA: 9:35 - loss: 0.6972 - acc: 0.5391
 192/9333 [..............................] - ETA: 9:22 - loss: 0.7027 - acc: 0.5312
 256/9333 [..............................] - ETA: 9:17 - loss: 0.6948 - acc: 0.5352
 320/9333 [>.............................] - ETA: 9:08 - loss: 0.6899 - acc: 0.5500
 384/9333 [>.............................] - ETA: 9:10 - loss: 0.6865 - acc: 0.5495
 448/9333 [>.............................] - ETA: 9:05 - loss: 0.6850 - acc: 0.5536
 512/9333 [>.............................] - ETA: 9:05 - loss: 0.6855 - acc: 0.5527
 576/9333 [>.............................] - ETA: 9:01 - loss: 0.6863 - acc: 0.5573
 640/9333 [=>............................] - ETA: 8:58 - loss: 0.6854 - acc: 0.5594
 704/9333 [=>............................] - ETA: 8:52 - loss: 0.6861 - acc: 0.5526
 768/9333 [=>............................] - ETA: 8:46 - loss: 0.6864 - acc: 0.5508
 832/9333 [=>............................] - ETA: 8:49 - loss: 0.6867 - acc: 0.5505
 896/9333 [=>............................] - ETA: 8:43 - loss: 0.6848 - acc: 0.5580
 960/9333 [==>...........................] - ETA: 8:42 - loss: 0.6847 - acc: 0.5563
1024/9333 [==>...........................] - ETA: 8:37 - loss: 0.6865 - acc: 0.5488
1088/9333 [==>...........................] - ETA: 8:34 - loss: 0.6875 - acc: 0.5469
1152/9333 [==>...........................] - ETA: 8:31 - loss: 0.6878 - acc: 0.5451
1216/9333 [==>...........................] - ETA: 8:26 - loss: 0.6879 - acc: 0.5428
1280/9333 [===>..........................] - ETA: 8:22 - loss: 0.6878 - acc: 0.5437
1344/9333 [===>..........................] - ETA: 8:19 - loss: 0.6883 - acc: 0.5417
1408/9333 [===>..........................] - ETA: 8:15 - loss: 0.6896 - acc: 0.5398
1472/9333 [===>..........................] - ETA: 8:11 - loss: 0.6894 - acc: 0.5408
1536/9333 [===>..........................] - ETA: 8:07 - loss: 0.6896 - acc: 0.5391
1600/9333 [====>.........................] - ETA: 8:04 - loss: 0.6888 - acc: 0.5425
1664/9333 [====>.........................] - ETA: 7:59 - loss: 0.6884 - acc: 0.5427
1728/9333 [====>.........................] - ETA: 7:56 - loss: 0.6876 - acc: 0.5469
1792/9333 [====>.........................] - ETA: 7:50 - loss: 0.6874 - acc: 0.5480
1856/9333 [====>.........................] - ETA: 7:46 - loss: 0.6871 - acc: 0.5474
1920/9333 [=====>........................] - ETA: 7:40 - loss: 0.6879 - acc: 0.5464
1984/9333 [=====>........................] - ETA: 7:35 - loss: 0.6876 - acc: 0.5474
2048/9333 [=====>........................] - ETA: 7:32 - loss: 0.6875 - acc: 0.5483
2112/9333 [=====>........................] - ETA: 7:28 - loss: 0.6874 - acc: 0.5464
2176/9333 [=====>........................] - ETA: 7:24 - loss: 0.6871 - acc: 0.5469
2240/9333 [======>.......................] - ETA: 7:19 - loss: 0.6871 - acc: 0.5464
2304/9333 [======>.......................] - ETA: 7:15 - loss: 0.6870 - acc: 0.5451
2368/9333 [======>.......................] - ETA: 7:11 - loss: 0.6876 - acc: 0.5443
2432/9333 [======>.......................] - ETA: 7:07 - loss: 0.6875 - acc: 0.5432
2496/9333 [=======>......................] - ETA: 7:01 - loss: 0.6878 - acc: 0.5425
2560/9333 [=======>......................] - ETA: 6:57 - loss: 0.6883 - acc: 0.5410
2624/9333 [=======>......................] - ETA: 6:53 - loss: 0.6884 - acc: 0.5408
2688/9333 [=======>......................] - ETA: 6:49 - loss: 0.6881 - acc: 0.5413
2752/9333 [=======>......................] - ETA: 6:44 - loss: 0.6872 - acc: 0.5447
2816/9333 [========>.....................] - ETA: 6:41 - loss: 0.6871 - acc: 0.5451
2880/9333 [========>.....................] - ETA: 6:38 - loss: 0.6867 - acc: 0.5458
2944/9333 [========>.....................] - ETA: 6:33 - loss: 0.6873 - acc: 0.5438
3008/9333 [========>.....................] - ETA: 6:29 - loss: 0.6873 - acc: 0.5449
3072/9333 [========>.....................] - ETA: 6:24 - loss: 0.6869 - acc: 0.5456
3136/9333 [=========>....................] - ETA: 6:20 - loss: 0.6870 - acc: 0.5453
3200/9333 [=========>....................] - ETA: 6:15 - loss: 0.6872 - acc: 0.5456
3264/9333 [=========>....................] - ETA: 6:12 - loss: 0.6873 - acc: 0.5453
3328/9333 [=========>....................] - ETA: 6:08 - loss: 0.6870 - acc: 0.5457
3392/9333 [=========>....................] - ETA: 6:03 - loss: 0.6865 - acc: 0.5481
3456/9333 [==========>...................] - ETA: 6:00 - loss: 0.6864 - acc: 0.5480
3520/9333 [==========>...................] - ETA: 5:56 - loss: 0.6862 - acc: 0.5489
3584/9333 [==========>...................] - ETA: 5:52 - loss: 0.6868 - acc: 0.5474
3648/9333 [==========>...................] - ETA: 5:49 - loss: 0.6871 - acc: 0.5477
3712/9333 [==========>...................] - ETA: 5:44 - loss: 0.6883 - acc: 0.5450
3776/9333 [===========>..................] - ETA: 5:40 - loss: 0.6886 - acc: 0.5448
3840/9333 [===========>..................] - ETA: 5:37 - loss: 0.6890 - acc: 0.5443
3904/9333 [===========>..................] - ETA: 5:32 - loss: 0.6887 - acc: 0.5471
3968/9333 [===========>..................] - ETA: 5:29 - loss: 0.6890 - acc: 0.5459
4032/9333 [===========>..................] - ETA: 5:25 - loss: 0.6889 - acc: 0.5454
4096/9333 [============>.................] - ETA: 5:21 - loss: 0.6887 - acc: 0.5457
4160/9333 [============>.................] - ETA: 5:17 - loss: 0.6887 - acc: 0.5452
4224/9333 [============>.................] - ETA: 5:13 - loss: 0.6894 - acc: 0.5421
4288/9333 [============>.................] - ETA: 5:09 - loss: 0.6894 - acc: 0.5415
4352/9333 [============>.................] - ETA: 5:05 - loss: 0.6895 - acc: 0.5416
4416/9333 [=============>................] - ETA: 5:01 - loss: 0.6896 - acc: 0.5410
4480/9333 [=============>................] - ETA: 4:57 - loss: 0.6896 - acc: 0.5406
4544/9333 [=============>................] - ETA: 4:53 - loss: 0.6896 - acc: 0.5403
4608/9333 [=============>................] - ETA: 4:49 - loss: 0.6894 - acc: 0.5401
4672/9333 [==============>...............] - ETA: 4:45 - loss: 0.6895 - acc: 0.5394
4736/9333 [==============>...............] - ETA: 4:41 - loss: 0.6890 - acc: 0.5401
4800/9333 [==============>...............] - ETA: 4:37 - loss: 0.6889 - acc: 0.5404
4864/9333 [==============>...............] - ETA: 4:34 - loss: 0.6888 - acc: 0.5407
4928/9333 [==============>...............] - ETA: 4:30 - loss: 0.6888 - acc: 0.5412
4992/9333 [===============>..............] - ETA: 4:25 - loss: 0.6887 - acc: 0.5413
5056/9333 [===============>..............] - ETA: 4:22 - loss: 0.6887 - acc: 0.5415
5120/9333 [===============>..............] - ETA: 4:18 - loss: 0.6889 - acc: 0.5402
5184/9333 [===============>..............] - ETA: 4:14 - loss: 0.6889 - acc: 0.5403
5248/9333 [===============>..............] - ETA: 4:10 - loss: 0.6889 - acc: 0.5402
5312/9333 [================>.............] - ETA: 4:06 - loss: 0.6890 - acc: 0.5399
5376/9333 [================>.............] - ETA: 4:02 - loss: 0.6894 - acc: 0.5391
5440/9333 [================>.............] - ETA: 3:58 - loss: 0.6895 - acc: 0.5388
5504/9333 [================>.............] - ETA: 3:54 - loss: 0.6892 - acc: 0.5394
5568/9333 [================>.............] - ETA: 3:50 - loss: 0.6889 - acc: 0.5411
5632/9333 [=================>............] - ETA: 3:46 - loss: 0.6889 - acc: 0.5414
5696/9333 [=================>............] - ETA: 3:42 - loss: 0.6893 - acc: 0.5404
5760/9333 [=================>............] - ETA: 3:39 - loss: 0.6893 - acc: 0.5406
5824/9333 [=================>............] - ETA: 3:34 - loss: 0.6892 - acc: 0.5412
5888/9333 [=================>............] - ETA: 3:31 - loss: 0.6895 - acc: 0.5404
5952/9333 [==================>...........] - ETA: 3:27 - loss: 0.6896 - acc: 0.5407
6016/9333 [==================>...........] - ETA: 3:23 - loss: 0.6895 - acc: 0.5412
6080/9333 [==================>...........] - ETA: 3:19 - loss: 0.6895 - acc: 0.5416
6144/9333 [==================>...........] - ETA: 3:15 - loss: 0.6893 - acc: 0.5420
6208/9333 [==================>...........] - ETA: 3:11 - loss: 0.6894 - acc: 0.5411
6272/9333 [===================>..........] - ETA: 3:07 - loss: 0.6892 - acc: 0.5421
6336/9333 [===================>..........] - ETA: 3:03 - loss: 0.6890 - acc: 0.5421
6400/9333 [===================>..........] - ETA: 2:59 - loss: 0.6889 - acc: 0.5422
6464/9333 [===================>..........] - ETA: 2:55 - loss: 0.6888 - acc: 0.5422
6528/9333 [===================>..........] - ETA: 2:51 - loss: 0.6889 - acc: 0.5421
6592/9333 [====================>.........] - ETA: 2:47 - loss: 0.6889 - acc: 0.5426
6656/9333 [====================>.........] - ETA: 2:43 - loss: 0.6890 - acc: 0.5422
6720/9333 [====================>.........] - ETA: 2:40 - loss: 0.6890 - acc: 0.5420
6784/9333 [====================>.........] - ETA: 2:36 - loss: 0.6891 - acc: 0.5416
6848/9333 [=====================>........] - ETA: 2:32 - loss: 0.6890 - acc: 0.5421
6912/9333 [=====================>........] - ETA: 2:28 - loss: 0.6888 - acc: 0.5430
6976/9333 [=====================>........] - ETA: 2:24 - loss: 0.6889 - acc: 0.5424
7040/9333 [=====================>........] - ETA: 2:20 - loss: 0.6889 - acc: 0.5422
7104/9333 [=====================>........] - ETA: 2:16 - loss: 0.6890 - acc: 0.5419
7168/9333 [======================>.......] - ETA: 2:12 - loss: 0.6886 - acc: 0.5430
7232/9333 [======================>.......] - ETA: 2:08 - loss: 0.6889 - acc: 0.5425
7296/9333 [======================>.......] - ETA: 2:04 - loss: 0.6894 - acc: 0.5414
7360/9333 [======================>.......] - ETA: 2:00 - loss: 0.6893 - acc: 0.5414
7424/9333 [======================>.......] - ETA: 1:56 - loss: 0.6893 - acc: 0.5414
7488/9333 [=======================>......] - ETA: 1:53 - loss: 0.6894 - acc: 0.5407
7552/9333 [=======================>......] - ETA: 1:49 - loss: 0.6894 - acc: 0.5413
7616/9333 [=======================>......] - ETA: 1:45 - loss: 0.6893 - acc: 0.5415
7680/9333 [=======================>......] - ETA: 1:41 - loss: 0.6896 - acc: 0.5406
7744/9333 [=======================>......] - ETA: 1:37 - loss: 0.6899 - acc: 0.5398
7808/9333 [========================>.....] - ETA: 1:33 - loss: 0.6898 - acc: 0.5406
7872/9333 [========================>.....] - ETA: 1:29 - loss: 0.6897 - acc: 0.5407
7936/9333 [========================>.....] - ETA: 1:25 - loss: 0.6894 - acc: 0.5421
8000/9333 [========================>.....] - ETA: 1:21 - loss: 0.6892 - acc: 0.5430
8064/9333 [========================>.....] - ETA: 1:17 - loss: 0.6893 - acc: 0.5432
8128/9333 [=========================>....] - ETA: 1:13 - loss: 0.6893 - acc: 0.5429
8192/9333 [=========================>....] - ETA: 1:09 - loss: 0.6892 - acc: 0.5433
8256/9333 [=========================>....] - ETA: 1:05 - loss: 0.6889 - acc: 0.5442
8320/9333 [=========================>....] - ETA: 1:02 - loss: 0.6888 - acc: 0.5437
8384/9333 [=========================>....] - ETA: 58s - loss: 0.6886 - acc: 0.5445 
8448/9333 [==========================>...] - ETA: 54s - loss: 0.6886 - acc: 0.5442
8512/9333 [==========================>...] - ETA: 50s - loss: 0.6887 - acc: 0.5438
8576/9333 [==========================>...] - ETA: 46s - loss: 0.6886 - acc: 0.5444
8640/9333 [==========================>...] - ETA: 42s - loss: 0.6886 - acc: 0.5443
8704/9333 [==========================>...] - ETA: 38s - loss: 0.6886 - acc: 0.5445
8768/9333 [===========================>..] - ETA: 34s - loss: 0.6885 - acc: 0.5445
8832/9333 [===========================>..] - ETA: 30s - loss: 0.6884 - acc: 0.5445
8896/9333 [===========================>..] - ETA: 26s - loss: 0.6880 - acc: 0.5454
8960/9333 [===========================>..] - ETA: 22s - loss: 0.6877 - acc: 0.5459
9024/9333 [============================>.] - ETA: 18s - loss: 0.6877 - acc: 0.5459
9088/9333 [============================>.] - ETA: 14s - loss: 0.6880 - acc: 0.5453
9152/9333 [============================>.] - ETA: 11s - loss: 0.6881 - acc: 0.5451
9216/9333 [============================>.] - ETA: 7s - loss: 0.6883 - acc: 0.5447 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6881 - acc: 0.5448
9333/9333 [==============================] - 594s 64ms/step - loss: 0.6880 - acc: 0.5446 - val_loss: 0.6890 - val_acc: 0.5400

Epoch 00006: val_acc did not improve from 0.56606
Epoch 7/10

  64/9333 [..............................] - ETA: 8:43 - loss: 0.7547 - acc: 0.3906
 128/9333 [..............................] - ETA: 9:12 - loss: 0.7122 - acc: 0.4766
 192/9333 [..............................] - ETA: 8:59 - loss: 0.7018 - acc: 0.4844
 256/9333 [..............................] - ETA: 9:04 - loss: 0.7026 - acc: 0.4883
 320/9333 [>.............................] - ETA: 8:51 - loss: 0.7062 - acc: 0.4750
 384/9333 [>.............................] - ETA: 8:55 - loss: 0.7065 - acc: 0.4870
 448/9333 [>.............................] - ETA: 8:49 - loss: 0.7066 - acc: 0.4955
 512/9333 [>.............................] - ETA: 8:45 - loss: 0.7008 - acc: 0.5137
 576/9333 [>.............................] - ETA: 8:44 - loss: 0.6979 - acc: 0.5191
 640/9333 [=>............................] - ETA: 8:39 - loss: 0.7001 - acc: 0.5219
 704/9333 [=>............................] - ETA: 8:36 - loss: 0.6995 - acc: 0.5170
 768/9333 [=>............................] - ETA: 8:33 - loss: 0.6978 - acc: 0.5221
 832/9333 [=>............................] - ETA: 8:30 - loss: 0.6971 - acc: 0.5216
 896/9333 [=>............................] - ETA: 8:25 - loss: 0.6951 - acc: 0.5257
 960/9333 [==>...........................] - ETA: 8:25 - loss: 0.6935 - acc: 0.5281
1024/9333 [==>...........................] - ETA: 8:18 - loss: 0.6933 - acc: 0.5332
1088/9333 [==>...........................] - ETA: 8:19 - loss: 0.6946 - acc: 0.5285
1152/9333 [==>...........................] - ETA: 8:14 - loss: 0.6959 - acc: 0.5200
1216/9333 [==>...........................] - ETA: 8:13 - loss: 0.6947 - acc: 0.5214
1280/9333 [===>..........................] - ETA: 8:09 - loss: 0.6948 - acc: 0.5219
1344/9333 [===>..........................] - ETA: 8:06 - loss: 0.6955 - acc: 0.5193
1408/9333 [===>..........................] - ETA: 8:04 - loss: 0.6961 - acc: 0.5170
1472/9333 [===>..........................] - ETA: 8:02 - loss: 0.6958 - acc: 0.5183
1536/9333 [===>..........................] - ETA: 7:56 - loss: 0.6943 - acc: 0.5241
1600/9333 [====>.........................] - ETA: 7:51 - loss: 0.6933 - acc: 0.5262
1664/9333 [====>.........................] - ETA: 7:48 - loss: 0.6927 - acc: 0.5276
1728/9333 [====>.........................] - ETA: 7:43 - loss: 0.6938 - acc: 0.5260
1792/9333 [====>.........................] - ETA: 7:40 - loss: 0.6936 - acc: 0.5234
1856/9333 [====>.........................] - ETA: 7:35 - loss: 0.6941 - acc: 0.5205
1920/9333 [=====>........................] - ETA: 7:32 - loss: 0.6942 - acc: 0.5214
1984/9333 [=====>........................] - ETA: 7:28 - loss: 0.6944 - acc: 0.5232
2048/9333 [=====>........................] - ETA: 7:24 - loss: 0.6941 - acc: 0.5239
2112/9333 [=====>........................] - ETA: 7:19 - loss: 0.6939 - acc: 0.5260
2176/9333 [=====>........................] - ETA: 7:16 - loss: 0.6937 - acc: 0.5262
2240/9333 [======>.......................] - ETA: 7:11 - loss: 0.6929 - acc: 0.5272
2304/9333 [======>.......................] - ETA: 7:07 - loss: 0.6930 - acc: 0.5260
2368/9333 [======>.......................] - ETA: 7:02 - loss: 0.6930 - acc: 0.5270
2432/9333 [======>.......................] - ETA: 6:58 - loss: 0.6929 - acc: 0.5271
2496/9333 [=======>......................] - ETA: 6:55 - loss: 0.6926 - acc: 0.5284
2560/9333 [=======>......................] - ETA: 6:50 - loss: 0.6927 - acc: 0.5289
2624/9333 [=======>......................] - ETA: 6:47 - loss: 0.6934 - acc: 0.5301
2688/9333 [=======>......................] - ETA: 6:42 - loss: 0.6927 - acc: 0.5316
2752/9333 [=======>......................] - ETA: 6:38 - loss: 0.6916 - acc: 0.5352
2816/9333 [========>.....................] - ETA: 6:34 - loss: 0.6908 - acc: 0.5369
2880/9333 [========>.....................] - ETA: 6:31 - loss: 0.6904 - acc: 0.5385
2944/9333 [========>.....................] - ETA: 6:26 - loss: 0.6908 - acc: 0.5370
3008/9333 [========>.....................] - ETA: 6:23 - loss: 0.6912 - acc: 0.5349
3072/9333 [========>.....................] - ETA: 6:19 - loss: 0.6917 - acc: 0.5335
3136/9333 [=========>....................] - ETA: 6:15 - loss: 0.6907 - acc: 0.5354
3200/9333 [=========>....................] - ETA: 6:11 - loss: 0.6908 - acc: 0.5359
3264/9333 [=========>....................] - ETA: 6:06 - loss: 0.6911 - acc: 0.5349
3328/9333 [=========>....................] - ETA: 6:02 - loss: 0.6904 - acc: 0.5358
3392/9333 [=========>....................] - ETA: 5:58 - loss: 0.6910 - acc: 0.5336
3456/9333 [==========>...................] - ETA: 5:54 - loss: 0.6907 - acc: 0.5344
3520/9333 [==========>...................] - ETA: 5:50 - loss: 0.6902 - acc: 0.5352
3584/9333 [==========>...................] - ETA: 5:46 - loss: 0.6904 - acc: 0.5343
3648/9333 [==========>...................] - ETA: 5:42 - loss: 0.6900 - acc: 0.5345
3712/9333 [==========>...................] - ETA: 5:38 - loss: 0.6900 - acc: 0.5348
3776/9333 [===========>..................] - ETA: 5:34 - loss: 0.6898 - acc: 0.5358
3840/9333 [===========>..................] - ETA: 5:30 - loss: 0.6897 - acc: 0.5357
3904/9333 [===========>..................] - ETA: 5:27 - loss: 0.6899 - acc: 0.5353
3968/9333 [===========>..................] - ETA: 5:22 - loss: 0.6898 - acc: 0.5358
4032/9333 [===========>..................] - ETA: 5:18 - loss: 0.6897 - acc: 0.5360
4096/9333 [============>.................] - ETA: 5:15 - loss: 0.6898 - acc: 0.5356
4160/9333 [============>.................] - ETA: 5:11 - loss: 0.6900 - acc: 0.5353
4224/9333 [============>.................] - ETA: 5:07 - loss: 0.6903 - acc: 0.5348
4288/9333 [============>.................] - ETA: 5:04 - loss: 0.6903 - acc: 0.5347
4352/9333 [============>.................] - ETA: 5:00 - loss: 0.6903 - acc: 0.5347
4416/9333 [=============>................] - ETA: 4:56 - loss: 0.6901 - acc: 0.5351
4480/9333 [=============>................] - ETA: 4:52 - loss: 0.6902 - acc: 0.5357
4544/9333 [=============>................] - ETA: 4:48 - loss: 0.6901 - acc: 0.5361
4608/9333 [=============>................] - ETA: 4:44 - loss: 0.6900 - acc: 0.5367
4672/9333 [==============>...............] - ETA: 4:40 - loss: 0.6896 - acc: 0.5381
4736/9333 [==============>...............] - ETA: 4:36 - loss: 0.6895 - acc: 0.5389
4800/9333 [==============>...............] - ETA: 4:32 - loss: 0.6894 - acc: 0.5387
4864/9333 [==============>...............] - ETA: 4:28 - loss: 0.6889 - acc: 0.5401
4928/9333 [==============>...............] - ETA: 4:24 - loss: 0.6886 - acc: 0.5406
4992/9333 [===============>..............] - ETA: 4:21 - loss: 0.6880 - acc: 0.5415
5056/9333 [===============>..............] - ETA: 4:17 - loss: 0.6880 - acc: 0.5411
5120/9333 [===============>..............] - ETA: 4:13 - loss: 0.6878 - acc: 0.5414
5184/9333 [===============>..............] - ETA: 4:09 - loss: 0.6874 - acc: 0.5428
5248/9333 [===============>..............] - ETA: 4:06 - loss: 0.6876 - acc: 0.5431
5312/9333 [================>.............] - ETA: 4:02 - loss: 0.6874 - acc: 0.5439
5376/9333 [================>.............] - ETA: 3:58 - loss: 0.6873 - acc: 0.5441
5440/9333 [================>.............] - ETA: 3:54 - loss: 0.6871 - acc: 0.5449
5504/9333 [================>.............] - ETA: 3:50 - loss: 0.6870 - acc: 0.5451
5568/9333 [================>.............] - ETA: 3:46 - loss: 0.6867 - acc: 0.5453
5632/9333 [=================>............] - ETA: 3:42 - loss: 0.6871 - acc: 0.5449
5696/9333 [=================>............] - ETA: 3:39 - loss: 0.6877 - acc: 0.5441
5760/9333 [=================>............] - ETA: 3:35 - loss: 0.6875 - acc: 0.5446
5824/9333 [=================>............] - ETA: 3:31 - loss: 0.6880 - acc: 0.5434
5888/9333 [=================>............] - ETA: 3:27 - loss: 0.6881 - acc: 0.5438
5952/9333 [==================>...........] - ETA: 3:23 - loss: 0.6879 - acc: 0.5439
6016/9333 [==================>...........] - ETA: 3:19 - loss: 0.6877 - acc: 0.5440
6080/9333 [==================>...........] - ETA: 3:15 - loss: 0.6875 - acc: 0.5442
6144/9333 [==================>...........] - ETA: 3:11 - loss: 0.6875 - acc: 0.5446
6208/9333 [==================>...........] - ETA: 3:08 - loss: 0.6873 - acc: 0.5453
6272/9333 [===================>..........] - ETA: 3:04 - loss: 0.6870 - acc: 0.5459
6336/9333 [===================>..........] - ETA: 3:00 - loss: 0.6869 - acc: 0.5464
6400/9333 [===================>..........] - ETA: 2:56 - loss: 0.6870 - acc: 0.5459
6464/9333 [===================>..........] - ETA: 2:52 - loss: 0.6874 - acc: 0.5450
6528/9333 [===================>..........] - ETA: 2:48 - loss: 0.6873 - acc: 0.5450
6592/9333 [====================>.........] - ETA: 2:44 - loss: 0.6874 - acc: 0.5446
6656/9333 [====================>.........] - ETA: 2:41 - loss: 0.6873 - acc: 0.5449
6720/9333 [====================>.........] - ETA: 2:37 - loss: 0.6874 - acc: 0.5445
6784/9333 [====================>.........] - ETA: 2:33 - loss: 0.6875 - acc: 0.5444
6848/9333 [=====================>........] - ETA: 2:29 - loss: 0.6874 - acc: 0.5447
6912/9333 [=====================>........] - ETA: 2:25 - loss: 0.6870 - acc: 0.5460
6976/9333 [=====================>........] - ETA: 2:21 - loss: 0.6869 - acc: 0.5467
7040/9333 [=====================>........] - ETA: 2:18 - loss: 0.6869 - acc: 0.5466
7104/9333 [=====================>........] - ETA: 2:14 - loss: 0.6870 - acc: 0.5465
7168/9333 [======================>.......] - ETA: 2:10 - loss: 0.6869 - acc: 0.5466
7232/9333 [======================>.......] - ETA: 2:06 - loss: 0.6869 - acc: 0.5470
7296/9333 [======================>.......] - ETA: 2:02 - loss: 0.6868 - acc: 0.5477
7360/9333 [======================>.......] - ETA: 1:58 - loss: 0.6869 - acc: 0.5473
7424/9333 [======================>.......] - ETA: 1:55 - loss: 0.6870 - acc: 0.5465
7488/9333 [=======================>......] - ETA: 1:51 - loss: 0.6870 - acc: 0.5463
7552/9333 [=======================>......] - ETA: 1:47 - loss: 0.6871 - acc: 0.5467
7616/9333 [=======================>......] - ETA: 1:43 - loss: 0.6872 - acc: 0.5462
7680/9333 [=======================>......] - ETA: 1:39 - loss: 0.6874 - acc: 0.5460
7744/9333 [=======================>......] - ETA: 1:35 - loss: 0.6873 - acc: 0.5460
7808/9333 [========================>.....] - ETA: 1:32 - loss: 0.6871 - acc: 0.5469
7872/9333 [========================>.....] - ETA: 1:28 - loss: 0.6873 - acc: 0.5466
7936/9333 [========================>.....] - ETA: 1:24 - loss: 0.6873 - acc: 0.5464
8000/9333 [========================>.....] - ETA: 1:20 - loss: 0.6876 - acc: 0.5456
8064/9333 [========================>.....] - ETA: 1:16 - loss: 0.6876 - acc: 0.5456
8128/9333 [=========================>....] - ETA: 1:12 - loss: 0.6874 - acc: 0.5465
8192/9333 [=========================>....] - ETA: 1:08 - loss: 0.6874 - acc: 0.5461
8256/9333 [=========================>....] - ETA: 1:05 - loss: 0.6874 - acc: 0.5459
8320/9333 [=========================>....] - ETA: 1:01 - loss: 0.6874 - acc: 0.5466
8384/9333 [=========================>....] - ETA: 57s - loss: 0.6872 - acc: 0.5474 
8448/9333 [==========================>...] - ETA: 53s - loss: 0.6874 - acc: 0.5465
8512/9333 [==========================>...] - ETA: 49s - loss: 0.6872 - acc: 0.5462
8576/9333 [==========================>...] - ETA: 45s - loss: 0.6872 - acc: 0.5459
8640/9333 [==========================>...] - ETA: 41s - loss: 0.6875 - acc: 0.5449
8704/9333 [==========================>...] - ETA: 38s - loss: 0.6873 - acc: 0.5456
8768/9333 [===========================>..] - ETA: 34s - loss: 0.6872 - acc: 0.5454
8832/9333 [===========================>..] - ETA: 30s - loss: 0.6871 - acc: 0.5456
8896/9333 [===========================>..] - ETA: 26s - loss: 0.6870 - acc: 0.5460
8960/9333 [===========================>..] - ETA: 22s - loss: 0.6872 - acc: 0.5458
9024/9333 [============================>.] - ETA: 18s - loss: 0.6870 - acc: 0.5463
9088/9333 [============================>.] - ETA: 14s - loss: 0.6871 - acc: 0.5457
9152/9333 [============================>.] - ETA: 10s - loss: 0.6873 - acc: 0.5452
9216/9333 [============================>.] - ETA: 7s - loss: 0.6873 - acc: 0.5448 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6874 - acc: 0.5447
9333/9333 [==============================] - 587s 63ms/step - loss: 0.6874 - acc: 0.5445 - val_loss: 0.6846 - val_acc: 0.5371

Epoch 00007: val_acc did not improve from 0.56606
Epoch 8/10

  64/9333 [..............................] - ETA: 9:42 - loss: 0.6880 - acc: 0.5625
 128/9333 [..............................] - ETA: 9:35 - loss: 0.6881 - acc: 0.5859
 192/9333 [..............................] - ETA: 9:10 - loss: 0.6901 - acc: 0.5729
 256/9333 [..............................] - ETA: 9:20 - loss: 0.6852 - acc: 0.6016
 320/9333 [>.............................] - ETA: 9:13 - loss: 0.6769 - acc: 0.6062
 384/9333 [>.............................] - ETA: 9:15 - loss: 0.6784 - acc: 0.5990
 448/9333 [>.............................] - ETA: 9:05 - loss: 0.6854 - acc: 0.5826
 512/9333 [>.............................] - ETA: 9:02 - loss: 0.6892 - acc: 0.5781
 576/9333 [>.............................] - ETA: 8:54 - loss: 0.6884 - acc: 0.5660
 640/9333 [=>............................] - ETA: 8:49 - loss: 0.6870 - acc: 0.5703
 704/9333 [=>............................] - ETA: 8:44 - loss: 0.6873 - acc: 0.5696
 768/9333 [=>............................] - ETA: 8:43 - loss: 0.6871 - acc: 0.5690
 832/9333 [=>............................] - ETA: 8:36 - loss: 0.6883 - acc: 0.5589
 896/9333 [=>............................] - ETA: 8:35 - loss: 0.6866 - acc: 0.5636
 960/9333 [==>...........................] - ETA: 8:31 - loss: 0.6847 - acc: 0.5667
1024/9333 [==>...........................] - ETA: 8:25 - loss: 0.6841 - acc: 0.5645
1088/9333 [==>...........................] - ETA: 8:21 - loss: 0.6853 - acc: 0.5588
1152/9333 [==>...........................] - ETA: 8:14 - loss: 0.6853 - acc: 0.5582
1216/9333 [==>...........................] - ETA: 8:10 - loss: 0.6843 - acc: 0.5600
1280/9333 [===>..........................] - ETA: 8:04 - loss: 0.6834 - acc: 0.5648
1344/9333 [===>..........................] - ETA: 8:00 - loss: 0.6836 - acc: 0.5670
1408/9333 [===>..........................] - ETA: 7:56 - loss: 0.6839 - acc: 0.5668
1472/9333 [===>..........................] - ETA: 7:52 - loss: 0.6837 - acc: 0.5645
1536/9333 [===>..........................] - ETA: 7:50 - loss: 0.6844 - acc: 0.5625
1600/9333 [====>.........................] - ETA: 7:45 - loss: 0.6831 - acc: 0.5663
1664/9333 [====>.........................] - ETA: 7:42 - loss: 0.6839 - acc: 0.5655
1728/9333 [====>.........................] - ETA: 7:38 - loss: 0.6846 - acc: 0.5654
1792/9333 [====>.........................] - ETA: 7:34 - loss: 0.6848 - acc: 0.5647
1856/9333 [====>.........................] - ETA: 7:30 - loss: 0.6847 - acc: 0.5647
1920/9333 [=====>........................] - ETA: 7:26 - loss: 0.6850 - acc: 0.5615
1984/9333 [=====>........................] - ETA: 7:22 - loss: 0.6855 - acc: 0.5610
2048/9333 [=====>........................] - ETA: 7:18 - loss: 0.6864 - acc: 0.5596
2112/9333 [=====>........................] - ETA: 7:13 - loss: 0.6868 - acc: 0.5568
2176/9333 [=====>........................] - ETA: 7:09 - loss: 0.6863 - acc: 0.5584
2240/9333 [======>.......................] - ETA: 7:07 - loss: 0.6867 - acc: 0.5585
2304/9333 [======>.......................] - ETA: 7:03 - loss: 0.6874 - acc: 0.5564
2368/9333 [======>.......................] - ETA: 6:59 - loss: 0.6872 - acc: 0.5562
2432/9333 [======>.......................] - ETA: 6:55 - loss: 0.6871 - acc: 0.5563
2496/9333 [=======>......................] - ETA: 6:51 - loss: 0.6874 - acc: 0.5565
2560/9333 [=======>......................] - ETA: 6:47 - loss: 0.6876 - acc: 0.5559
2624/9333 [=======>......................] - ETA: 6:44 - loss: 0.6874 - acc: 0.5572
2688/9333 [=======>......................] - ETA: 6:40 - loss: 0.6875 - acc: 0.5558
2752/9333 [=======>......................] - ETA: 6:36 - loss: 0.6871 - acc: 0.5567
2816/9333 [========>.....................] - ETA: 6:32 - loss: 0.6872 - acc: 0.5554
2880/9333 [========>.....................] - ETA: 6:29 - loss: 0.6873 - acc: 0.5559
2944/9333 [========>.....................] - ETA: 6:25 - loss: 0.6877 - acc: 0.5533
3008/9333 [========>.....................] - ETA: 6:21 - loss: 0.6883 - acc: 0.5505
3072/9333 [========>.....................] - ETA: 6:17 - loss: 0.6877 - acc: 0.5521
3136/9333 [=========>....................] - ETA: 6:13 - loss: 0.6873 - acc: 0.5513
3200/9333 [=========>....................] - ETA: 6:10 - loss: 0.6869 - acc: 0.5534
3264/9333 [=========>....................] - ETA: 6:06 - loss: 0.6864 - acc: 0.5545
3328/9333 [=========>....................] - ETA: 6:02 - loss: 0.6866 - acc: 0.5535
3392/9333 [=========>....................] - ETA: 5:58 - loss: 0.6866 - acc: 0.5522
3456/9333 [==========>...................] - ETA: 5:54 - loss: 0.6865 - acc: 0.5527
3520/9333 [==========>...................] - ETA: 5:50 - loss: 0.6865 - acc: 0.5531
3584/9333 [==========>...................] - ETA: 5:46 - loss: 0.6862 - acc: 0.5541
3648/9333 [==========>...................] - ETA: 5:42 - loss: 0.6862 - acc: 0.5537
3712/9333 [==========>...................] - ETA: 5:38 - loss: 0.6861 - acc: 0.5536
3776/9333 [===========>..................] - ETA: 5:35 - loss: 0.6865 - acc: 0.5535
3840/9333 [===========>..................] - ETA: 5:31 - loss: 0.6868 - acc: 0.5529
3904/9333 [===========>..................] - ETA: 5:27 - loss: 0.6869 - acc: 0.5535
3968/9333 [===========>..................] - ETA: 5:23 - loss: 0.6866 - acc: 0.5539
4032/9333 [===========>..................] - ETA: 5:19 - loss: 0.6869 - acc: 0.5523
4096/9333 [============>.................] - ETA: 5:15 - loss: 0.6866 - acc: 0.5527
4160/9333 [============>.................] - ETA: 5:11 - loss: 0.6866 - acc: 0.5534
4224/9333 [============>.................] - ETA: 5:07 - loss: 0.6865 - acc: 0.5528
4288/9333 [============>.................] - ETA: 5:03 - loss: 0.6864 - acc: 0.5532
4352/9333 [============>.................] - ETA: 5:00 - loss: 0.6865 - acc: 0.5522
4416/9333 [=============>................] - ETA: 4:56 - loss: 0.6864 - acc: 0.5525
4480/9333 [=============>................] - ETA: 4:52 - loss: 0.6861 - acc: 0.5538
4544/9333 [=============>................] - ETA: 4:48 - loss: 0.6857 - acc: 0.5539
4608/9333 [=============>................] - ETA: 4:44 - loss: 0.6856 - acc: 0.5540
4672/9333 [==============>...............] - ETA: 4:40 - loss: 0.6859 - acc: 0.5533
4736/9333 [==============>...............] - ETA: 4:37 - loss: 0.6864 - acc: 0.5524
4800/9333 [==============>...............] - ETA: 4:32 - loss: 0.6864 - acc: 0.5523
4864/9333 [==============>...............] - ETA: 4:29 - loss: 0.6862 - acc: 0.5528
4928/9333 [==============>...............] - ETA: 4:24 - loss: 0.6862 - acc: 0.5526
4992/9333 [===============>..............] - ETA: 4:21 - loss: 0.6864 - acc: 0.5515
5056/9333 [===============>..............] - ETA: 4:17 - loss: 0.6863 - acc: 0.5508
5120/9333 [===============>..............] - ETA: 4:13 - loss: 0.6863 - acc: 0.5510
5184/9333 [===============>..............] - ETA: 4:09 - loss: 0.6867 - acc: 0.5502
5248/9333 [===============>..............] - ETA: 4:05 - loss: 0.6867 - acc: 0.5495
5312/9333 [================>.............] - ETA: 4:01 - loss: 0.6867 - acc: 0.5497
5376/9333 [================>.............] - ETA: 3:57 - loss: 0.6864 - acc: 0.5506
5440/9333 [================>.............] - ETA: 3:54 - loss: 0.6864 - acc: 0.5506
5504/9333 [================>.............] - ETA: 3:50 - loss: 0.6864 - acc: 0.5503
5568/9333 [================>.............] - ETA: 3:46 - loss: 0.6865 - acc: 0.5503
5632/9333 [=================>............] - ETA: 3:42 - loss: 0.6869 - acc: 0.5499
5696/9333 [=================>............] - ETA: 3:38 - loss: 0.6869 - acc: 0.5502
5760/9333 [=================>............] - ETA: 3:34 - loss: 0.6869 - acc: 0.5503
5824/9333 [=================>............] - ETA: 3:30 - loss: 0.6869 - acc: 0.5505
5888/9333 [=================>............] - ETA: 3:27 - loss: 0.6873 - acc: 0.5499
5952/9333 [==================>...........] - ETA: 3:23 - loss: 0.6874 - acc: 0.5492
6016/9333 [==================>...........] - ETA: 3:19 - loss: 0.6871 - acc: 0.5505
6080/9333 [==================>...........] - ETA: 3:15 - loss: 0.6872 - acc: 0.5507
6144/9333 [==================>...........] - ETA: 3:11 - loss: 0.6872 - acc: 0.5505
6208/9333 [==================>...........] - ETA: 3:07 - loss: 0.6871 - acc: 0.5507
6272/9333 [===================>..........] - ETA: 3:04 - loss: 0.6871 - acc: 0.5513
6336/9333 [===================>..........] - ETA: 3:00 - loss: 0.6872 - acc: 0.5507
6400/9333 [===================>..........] - ETA: 2:56 - loss: 0.6871 - acc: 0.5511
6464/9333 [===================>..........] - ETA: 2:52 - loss: 0.6871 - acc: 0.5503
6528/9333 [===================>..........] - ETA: 2:48 - loss: 0.6872 - acc: 0.5498
6592/9333 [====================>.........] - ETA: 2:45 - loss: 0.6872 - acc: 0.5501
6656/9333 [====================>.........] - ETA: 2:41 - loss: 0.6870 - acc: 0.5511
6720/9333 [====================>.........] - ETA: 2:37 - loss: 0.6871 - acc: 0.5507
6784/9333 [====================>.........] - ETA: 2:33 - loss: 0.6871 - acc: 0.5503
6848/9333 [=====================>........] - ETA: 2:29 - loss: 0.6870 - acc: 0.5505
6912/9333 [=====================>........] - ETA: 2:26 - loss: 0.6870 - acc: 0.5508
6976/9333 [=====================>........] - ETA: 2:22 - loss: 0.6870 - acc: 0.5507
7040/9333 [=====================>........] - ETA: 2:18 - loss: 0.6870 - acc: 0.5509
7104/9333 [=====================>........] - ETA: 2:14 - loss: 0.6869 - acc: 0.5512
7168/9333 [======================>.......] - ETA: 2:10 - loss: 0.6873 - acc: 0.5501
7232/9333 [======================>.......] - ETA: 2:07 - loss: 0.6872 - acc: 0.5512
7296/9333 [======================>.......] - ETA: 2:03 - loss: 0.6873 - acc: 0.5510
7360/9333 [======================>.......] - ETA: 1:59 - loss: 0.6872 - acc: 0.5511
7424/9333 [======================>.......] - ETA: 1:55 - loss: 0.6872 - acc: 0.5513
7488/9333 [=======================>......] - ETA: 1:51 - loss: 0.6871 - acc: 0.5522
7552/9333 [=======================>......] - ETA: 1:47 - loss: 0.6870 - acc: 0.5531
7616/9333 [=======================>......] - ETA: 1:44 - loss: 0.6870 - acc: 0.5530
7680/9333 [=======================>......] - ETA: 1:40 - loss: 0.6869 - acc: 0.5533
7744/9333 [=======================>......] - ETA: 1:36 - loss: 0.6869 - acc: 0.5535
7808/9333 [========================>.....] - ETA: 1:32 - loss: 0.6867 - acc: 0.5535
7872/9333 [========================>.....] - ETA: 1:28 - loss: 0.6866 - acc: 0.5539
7936/9333 [========================>.....] - ETA: 1:24 - loss: 0.6866 - acc: 0.5537
8000/9333 [========================>.....] - ETA: 1:21 - loss: 0.6866 - acc: 0.5534
8064/9333 [========================>.....] - ETA: 1:17 - loss: 0.6864 - acc: 0.5539
8128/9333 [=========================>....] - ETA: 1:13 - loss: 0.6864 - acc: 0.5541
8192/9333 [=========================>....] - ETA: 1:09 - loss: 0.6865 - acc: 0.5540
8256/9333 [=========================>....] - ETA: 1:05 - loss: 0.6866 - acc: 0.5534
8320/9333 [=========================>....] - ETA: 1:01 - loss: 0.6866 - acc: 0.5532
8384/9333 [=========================>....] - ETA: 57s - loss: 0.6865 - acc: 0.5534 
8448/9333 [==========================>...] - ETA: 54s - loss: 0.6864 - acc: 0.5530
8512/9333 [==========================>...] - ETA: 50s - loss: 0.6864 - acc: 0.5530
8576/9333 [==========================>...] - ETA: 46s - loss: 0.6865 - acc: 0.5525
8640/9333 [==========================>...] - ETA: 42s - loss: 0.6864 - acc: 0.5525
8704/9333 [==========================>...] - ETA: 38s - loss: 0.6866 - acc: 0.5514
8768/9333 [===========================>..] - ETA: 34s - loss: 0.6865 - acc: 0.5514
8832/9333 [===========================>..] - ETA: 30s - loss: 0.6864 - acc: 0.5516
8896/9333 [===========================>..] - ETA: 26s - loss: 0.6863 - acc: 0.5518
8960/9333 [===========================>..] - ETA: 22s - loss: 0.6863 - acc: 0.5518
9024/9333 [============================>.] - ETA: 18s - loss: 0.6865 - acc: 0.5514
9088/9333 [============================>.] - ETA: 14s - loss: 0.6863 - acc: 0.5519
9152/9333 [============================>.] - ETA: 11s - loss: 0.6864 - acc: 0.5517
9216/9333 [============================>.] - ETA: 7s - loss: 0.6867 - acc: 0.5510 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6867 - acc: 0.5509
9333/9333 [==============================] - 590s 63ms/step - loss: 0.6865 - acc: 0.5513 - val_loss: 0.6890 - val_acc: 0.5506

Epoch 00008: val_acc did not improve from 0.56606
Epoch 9/10

  64/9333 [..............................] - ETA: 9:16 - loss: 0.6773 - acc: 0.5938
 128/9333 [..............................] - ETA: 9:08 - loss: 0.6967 - acc: 0.5312
 192/9333 [..............................] - ETA: 9:20 - loss: 0.7053 - acc: 0.4948
 256/9333 [..............................] - ETA: 9:10 - loss: 0.7003 - acc: 0.5000
 320/9333 [>.............................] - ETA: 9:11 - loss: 0.6968 - acc: 0.5188
 384/9333 [>.............................] - ETA: 9:09 - loss: 0.6934 - acc: 0.5339
 448/9333 [>.............................] - ETA: 9:05 - loss: 0.6935 - acc: 0.5223
 512/9333 [>.............................] - ETA: 9:02 - loss: 0.6957 - acc: 0.5273
 576/9333 [>.............................] - ETA: 8:59 - loss: 0.6932 - acc: 0.5330
 640/9333 [=>............................] - ETA: 8:56 - loss: 0.6939 - acc: 0.5328
 704/9333 [=>............................] - ETA: 8:54 - loss: 0.6916 - acc: 0.5384
 768/9333 [=>............................] - ETA: 8:45 - loss: 0.6922 - acc: 0.5352
 832/9333 [=>............................] - ETA: 8:45 - loss: 0.6921 - acc: 0.5349
 896/9333 [=>............................] - ETA: 8:35 - loss: 0.6929 - acc: 0.5324
 960/9333 [==>...........................] - ETA: 8:31 - loss: 0.6918 - acc: 0.5354
1024/9333 [==>...........................] - ETA: 8:24 - loss: 0.6913 - acc: 0.5371
1088/9333 [==>...........................] - ETA: 8:20 - loss: 0.6924 - acc: 0.5358
1152/9333 [==>...........................] - ETA: 8:17 - loss: 0.6925 - acc: 0.5382
1216/9333 [==>...........................] - ETA: 8:11 - loss: 0.6913 - acc: 0.5444
1280/9333 [===>..........................] - ETA: 8:07 - loss: 0.6905 - acc: 0.5461
1344/9333 [===>..........................] - ETA: 8:01 - loss: 0.6894 - acc: 0.5469
1408/9333 [===>..........................] - ETA: 7:56 - loss: 0.6893 - acc: 0.5469
1472/9333 [===>..........................] - ETA: 7:52 - loss: 0.6878 - acc: 0.5503
1536/9333 [===>..........................] - ETA: 7:49 - loss: 0.6875 - acc: 0.5514
1600/9333 [====>.........................] - ETA: 7:44 - loss: 0.6877 - acc: 0.5513
1664/9333 [====>.........................] - ETA: 7:41 - loss: 0.6875 - acc: 0.5511
1728/9333 [====>.........................] - ETA: 7:38 - loss: 0.6868 - acc: 0.5527
1792/9333 [====>.........................] - ETA: 7:34 - loss: 0.6868 - acc: 0.5536
1856/9333 [====>.........................] - ETA: 7:33 - loss: 0.6869 - acc: 0.5550
1920/9333 [=====>........................] - ETA: 7:28 - loss: 0.6867 - acc: 0.5536
1984/9333 [=====>........................] - ETA: 7:26 - loss: 0.6867 - acc: 0.5539
2048/9333 [=====>........................] - ETA: 7:20 - loss: 0.6869 - acc: 0.5527
2112/9333 [=====>........................] - ETA: 7:16 - loss: 0.6865 - acc: 0.5545
2176/9333 [=====>........................] - ETA: 7:12 - loss: 0.6869 - acc: 0.5524
2240/9333 [======>.......................] - ETA: 7:09 - loss: 0.6860 - acc: 0.5563
2304/9333 [======>.......................] - ETA: 7:04 - loss: 0.6860 - acc: 0.5573
2368/9333 [======>.......................] - ETA: 7:01 - loss: 0.6861 - acc: 0.5557
2432/9333 [======>.......................] - ETA: 6:57 - loss: 0.6859 - acc: 0.5563
2496/9333 [=======>......................] - ETA: 6:53 - loss: 0.6863 - acc: 0.5549
2560/9333 [=======>......................] - ETA: 6:50 - loss: 0.6860 - acc: 0.5555
2624/9333 [=======>......................] - ETA: 6:46 - loss: 0.6851 - acc: 0.5575
2688/9333 [=======>......................] - ETA: 6:42 - loss: 0.6857 - acc: 0.5565
2752/9333 [=======>......................] - ETA: 6:38 - loss: 0.6860 - acc: 0.5552
2816/9333 [========>.....................] - ETA: 6:35 - loss: 0.6865 - acc: 0.5550
2880/9333 [========>.....................] - ETA: 6:31 - loss: 0.6864 - acc: 0.5535
2944/9333 [========>.....................] - ETA: 6:27 - loss: 0.6858 - acc: 0.5557
3008/9333 [========>.....................] - ETA: 6:23 - loss: 0.6864 - acc: 0.5542
3072/9333 [========>.....................] - ETA: 6:20 - loss: 0.6864 - acc: 0.5540
3136/9333 [=========>....................] - ETA: 6:16 - loss: 0.6860 - acc: 0.5558
3200/9333 [=========>....................] - ETA: 6:12 - loss: 0.6862 - acc: 0.5534
3264/9333 [=========>....................] - ETA: 6:08 - loss: 0.6868 - acc: 0.5521
3328/9333 [=========>....................] - ETA: 6:04 - loss: 0.6866 - acc: 0.5526
3392/9333 [=========>....................] - ETA: 6:01 - loss: 0.6864 - acc: 0.5545
3456/9333 [==========>...................] - ETA: 5:58 - loss: 0.6865 - acc: 0.5547
3520/9333 [==========>...................] - ETA: 5:54 - loss: 0.6870 - acc: 0.5534
3584/9333 [==========>...................] - ETA: 5:51 - loss: 0.6872 - acc: 0.5522
3648/9333 [==========>...................] - ETA: 5:47 - loss: 0.6872 - acc: 0.5535
3712/9333 [==========>...................] - ETA: 5:43 - loss: 0.6870 - acc: 0.5533
3776/9333 [===========>..................] - ETA: 5:40 - loss: 0.6867 - acc: 0.5553
3840/9333 [===========>..................] - ETA: 5:35 - loss: 0.6863 - acc: 0.5565
3904/9333 [===========>..................] - ETA: 5:32 - loss: 0.6866 - acc: 0.5540
3968/9333 [===========>..................] - ETA: 5:28 - loss: 0.6866 - acc: 0.5549
4032/9333 [===========>..................] - ETA: 5:24 - loss: 0.6864 - acc: 0.5563
4096/9333 [============>.................] - ETA: 5:20 - loss: 0.6862 - acc: 0.5562
4160/9333 [============>.................] - ETA: 5:16 - loss: 0.6859 - acc: 0.5565
4224/9333 [============>.................] - ETA: 5:12 - loss: 0.6863 - acc: 0.5547
4288/9333 [============>.................] - ETA: 5:08 - loss: 0.6863 - acc: 0.5539
4352/9333 [============>.................] - ETA: 5:04 - loss: 0.6859 - acc: 0.5549
4416/9333 [=============>................] - ETA: 5:00 - loss: 0.6859 - acc: 0.5541
4480/9333 [=============>................] - ETA: 4:56 - loss: 0.6858 - acc: 0.5540
4544/9333 [=============>................] - ETA: 4:52 - loss: 0.6857 - acc: 0.5544
4608/9333 [=============>................] - ETA: 4:49 - loss: 0.6858 - acc: 0.5538
4672/9333 [==============>...............] - ETA: 4:45 - loss: 0.6856 - acc: 0.5550
4736/9333 [==============>...............] - ETA: 4:41 - loss: 0.6851 - acc: 0.5576
4800/9333 [==============>...............] - ETA: 4:37 - loss: 0.6853 - acc: 0.5571
4864/9333 [==============>...............] - ETA: 4:33 - loss: 0.6853 - acc: 0.5576
4928/9333 [==============>...............] - ETA: 4:29 - loss: 0.6854 - acc: 0.5582
4992/9333 [===============>..............] - ETA: 4:26 - loss: 0.6856 - acc: 0.5581
5056/9333 [===============>..............] - ETA: 4:22 - loss: 0.6859 - acc: 0.5581
5120/9333 [===============>..............] - ETA: 4:18 - loss: 0.6856 - acc: 0.5588
5184/9333 [===============>..............] - ETA: 4:14 - loss: 0.6856 - acc: 0.5594
5248/9333 [===============>..............] - ETA: 4:10 - loss: 0.6855 - acc: 0.5596
5312/9333 [================>.............] - ETA: 4:06 - loss: 0.6853 - acc: 0.5595
5376/9333 [================>.............] - ETA: 4:02 - loss: 0.6855 - acc: 0.5593
5440/9333 [================>.............] - ETA: 3:58 - loss: 0.6858 - acc: 0.5590
5504/9333 [================>.............] - ETA: 3:54 - loss: 0.6860 - acc: 0.5581
5568/9333 [================>.............] - ETA: 3:51 - loss: 0.6859 - acc: 0.5589
5632/9333 [=================>............] - ETA: 3:47 - loss: 0.6858 - acc: 0.5602
5696/9333 [=================>............] - ETA: 3:43 - loss: 0.6856 - acc: 0.5604
5760/9333 [=================>............] - ETA: 3:39 - loss: 0.6858 - acc: 0.5595
5824/9333 [=================>............] - ETA: 3:35 - loss: 0.6859 - acc: 0.5592
5888/9333 [=================>............] - ETA: 3:31 - loss: 0.6858 - acc: 0.5600
5952/9333 [==================>...........] - ETA: 3:27 - loss: 0.6858 - acc: 0.5600
6016/9333 [==================>...........] - ETA: 3:23 - loss: 0.6856 - acc: 0.5608
6080/9333 [==================>...........] - ETA: 3:20 - loss: 0.6858 - acc: 0.5604
6144/9333 [==================>...........] - ETA: 3:15 - loss: 0.6857 - acc: 0.5609
6208/9333 [==================>...........] - ETA: 3:12 - loss: 0.6858 - acc: 0.5609
6272/9333 [===================>..........] - ETA: 3:08 - loss: 0.6857 - acc: 0.5612
6336/9333 [===================>..........] - ETA: 3:04 - loss: 0.6856 - acc: 0.5620
6400/9333 [===================>..........] - ETA: 3:00 - loss: 0.6854 - acc: 0.5628
6464/9333 [===================>..........] - ETA: 2:56 - loss: 0.6856 - acc: 0.5623
6528/9333 [===================>..........] - ETA: 2:52 - loss: 0.6855 - acc: 0.5623
6592/9333 [====================>.........] - ETA: 2:48 - loss: 0.6854 - acc: 0.5631
6656/9333 [====================>.........] - ETA: 2:44 - loss: 0.6852 - acc: 0.5634
6720/9333 [====================>.........] - ETA: 2:40 - loss: 0.6853 - acc: 0.5632
6784/9333 [====================>.........] - ETA: 2:37 - loss: 0.6853 - acc: 0.5626
6848/9333 [=====================>........] - ETA: 2:33 - loss: 0.6850 - acc: 0.5637
6912/9333 [=====================>........] - ETA: 2:29 - loss: 0.6848 - acc: 0.5634
6976/9333 [=====================>........] - ETA: 2:25 - loss: 0.6849 - acc: 0.5629
7040/9333 [=====================>........] - ETA: 2:21 - loss: 0.6852 - acc: 0.5625
7104/9333 [=====================>........] - ETA: 2:17 - loss: 0.6854 - acc: 0.5617
7168/9333 [======================>.......] - ETA: 2:13 - loss: 0.6856 - acc: 0.5603
7232/9333 [======================>.......] - ETA: 2:09 - loss: 0.6857 - acc: 0.5603
7296/9333 [======================>.......] - ETA: 2:05 - loss: 0.6853 - acc: 0.5615
7360/9333 [======================>.......] - ETA: 2:01 - loss: 0.6854 - acc: 0.5617
7424/9333 [======================>.......] - ETA: 1:57 - loss: 0.6853 - acc: 0.5616
7488/9333 [=======================>......] - ETA: 1:53 - loss: 0.6853 - acc: 0.5610
7552/9333 [=======================>......] - ETA: 1:49 - loss: 0.6852 - acc: 0.5610
7616/9333 [=======================>......] - ETA: 1:45 - loss: 0.6853 - acc: 0.5613
7680/9333 [=======================>......] - ETA: 1:41 - loss: 0.6853 - acc: 0.5616
7744/9333 [=======================>......] - ETA: 1:37 - loss: 0.6850 - acc: 0.5620
7808/9333 [========================>.....] - ETA: 1:33 - loss: 0.6850 - acc: 0.5624
7872/9333 [========================>.....] - ETA: 1:29 - loss: 0.6852 - acc: 0.5616
7936/9333 [========================>.....] - ETA: 1:25 - loss: 0.6851 - acc: 0.5619
8000/9333 [========================>.....] - ETA: 1:21 - loss: 0.6853 - acc: 0.5617
8064/9333 [========================>.....] - ETA: 1:17 - loss: 0.6855 - acc: 0.5614
8128/9333 [=========================>....] - ETA: 1:14 - loss: 0.6855 - acc: 0.5614
8192/9333 [=========================>....] - ETA: 1:10 - loss: 0.6856 - acc: 0.5610
8256/9333 [=========================>....] - ETA: 1:06 - loss: 0.6857 - acc: 0.5612
8320/9333 [=========================>....] - ETA: 1:02 - loss: 0.6859 - acc: 0.5603
8384/9333 [=========================>....] - ETA: 58s - loss: 0.6858 - acc: 0.5606 
8448/9333 [==========================>...] - ETA: 54s - loss: 0.6860 - acc: 0.5605
8512/9333 [==========================>...] - ETA: 50s - loss: 0.6858 - acc: 0.5607
8576/9333 [==========================>...] - ETA: 46s - loss: 0.6858 - acc: 0.5610
8640/9333 [==========================>...] - ETA: 42s - loss: 0.6858 - acc: 0.5608
8704/9333 [==========================>...] - ETA: 38s - loss: 0.6859 - acc: 0.5604
8768/9333 [===========================>..] - ETA: 34s - loss: 0.6859 - acc: 0.5603
8832/9333 [===========================>..] - ETA: 30s - loss: 0.6861 - acc: 0.5597
8896/9333 [===========================>..] - ETA: 26s - loss: 0.6859 - acc: 0.5597
8960/9333 [===========================>..] - ETA: 22s - loss: 0.6859 - acc: 0.5599
9024/9333 [============================>.] - ETA: 18s - loss: 0.6860 - acc: 0.5595
9088/9333 [============================>.] - ETA: 14s - loss: 0.6859 - acc: 0.5597
9152/9333 [============================>.] - ETA: 11s - loss: 0.6861 - acc: 0.5594
9216/9333 [============================>.] - ETA: 7s - loss: 0.6861 - acc: 0.5590 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6860 - acc: 0.5592
9333/9333 [==============================] - 592s 63ms/step - loss: 0.6861 - acc: 0.5587 - val_loss: 0.6868 - val_acc: 0.5516

Epoch 00009: val_acc did not improve from 0.56606
Epoch 10/10

  64/9333 [..............................] - ETA: 9:59 - loss: 0.6590 - acc: 0.6562
 128/9333 [..............................] - ETA: 9:00 - loss: 0.6628 - acc: 0.6484
 192/9333 [..............................] - ETA: 9:16 - loss: 0.6743 - acc: 0.6198
 256/9333 [..............................] - ETA: 8:58 - loss: 0.6704 - acc: 0.6250
 320/9333 [>.............................] - ETA: 9:00 - loss: 0.6759 - acc: 0.6094
 384/9333 [>.............................] - ETA: 8:59 - loss: 0.6797 - acc: 0.5990
 448/9333 [>.............................] - ETA: 8:51 - loss: 0.6823 - acc: 0.5804
 512/9333 [>.............................] - ETA: 8:53 - loss: 0.6823 - acc: 0.5723
 576/9333 [>.............................] - ETA: 8:42 - loss: 0.6819 - acc: 0.5694
 640/9333 [=>............................] - ETA: 8:39 - loss: 0.6810 - acc: 0.5766
 704/9333 [=>............................] - ETA: 8:31 - loss: 0.6828 - acc: 0.5668
 768/9333 [=>............................] - ETA: 8:28 - loss: 0.6830 - acc: 0.5690
 832/9333 [=>............................] - ETA: 8:26 - loss: 0.6860 - acc: 0.5601
 896/9333 [=>............................] - ETA: 8:19 - loss: 0.6849 - acc: 0.5636
 960/9333 [==>...........................] - ETA: 8:16 - loss: 0.6840 - acc: 0.5646
1024/9333 [==>...........................] - ETA: 8:11 - loss: 0.6841 - acc: 0.5615
1088/9333 [==>...........................] - ETA: 8:08 - loss: 0.6836 - acc: 0.5625
1152/9333 [==>...........................] - ETA: 8:02 - loss: 0.6823 - acc: 0.5668
1216/9333 [==>...........................] - ETA: 8:01 - loss: 0.6829 - acc: 0.5658
1280/9333 [===>..........................] - ETA: 7:55 - loss: 0.6850 - acc: 0.5602
1344/9333 [===>..........................] - ETA: 7:53 - loss: 0.6849 - acc: 0.5588
1408/9333 [===>..........................] - ETA: 7:48 - loss: 0.6851 - acc: 0.5604
1472/9333 [===>..........................] - ETA: 7:44 - loss: 0.6851 - acc: 0.5611
1536/9333 [===>..........................] - ETA: 7:40 - loss: 0.6854 - acc: 0.5625
1600/9333 [====>.........................] - ETA: 7:38 - loss: 0.6863 - acc: 0.5594
1664/9333 [====>.........................] - ETA: 7:33 - loss: 0.6871 - acc: 0.5571
1728/9333 [====>.........................] - ETA: 7:27 - loss: 0.6862 - acc: 0.5584
1792/9333 [====>.........................] - ETA: 7:24 - loss: 0.6867 - acc: 0.5552
1856/9333 [====>.........................] - ETA: 7:19 - loss: 0.6879 - acc: 0.5501
1920/9333 [=====>........................] - ETA: 7:15 - loss: 0.6880 - acc: 0.5469
1984/9333 [=====>........................] - ETA: 7:12 - loss: 0.6883 - acc: 0.5439
2048/9333 [=====>........................] - ETA: 7:08 - loss: 0.6871 - acc: 0.5493
2112/9333 [=====>........................] - ETA: 7:05 - loss: 0.6875 - acc: 0.5459
2176/9333 [=====>........................] - ETA: 7:01 - loss: 0.6874 - acc: 0.5455
2240/9333 [======>.......................] - ETA: 6:58 - loss: 0.6873 - acc: 0.5442
2304/9333 [======>.......................] - ETA: 6:54 - loss: 0.6867 - acc: 0.5451
2368/9333 [======>.......................] - ETA: 6:53 - loss: 0.6872 - acc: 0.5435
2432/9333 [======>.......................] - ETA: 6:48 - loss: 0.6874 - acc: 0.5424
2496/9333 [=======>......................] - ETA: 6:45 - loss: 0.6882 - acc: 0.5381
2560/9333 [=======>......................] - ETA: 6:40 - loss: 0.6885 - acc: 0.5355
2624/9333 [=======>......................] - ETA: 6:37 - loss: 0.6889 - acc: 0.5339
2688/9333 [=======>......................] - ETA: 6:33 - loss: 0.6885 - acc: 0.5361
2752/9333 [=======>......................] - ETA: 6:29 - loss: 0.6886 - acc: 0.5363
2816/9333 [========>.....................] - ETA: 6:24 - loss: 0.6887 - acc: 0.5352
2880/9333 [========>.....................] - ETA: 6:20 - loss: 0.6885 - acc: 0.5358
2944/9333 [========>.....................] - ETA: 6:17 - loss: 0.6881 - acc: 0.5377
3008/9333 [========>.....................] - ETA: 6:12 - loss: 0.6879 - acc: 0.5399
3072/9333 [========>.....................] - ETA: 6:09 - loss: 0.6884 - acc: 0.5394
3136/9333 [=========>....................] - ETA: 6:05 - loss: 0.6879 - acc: 0.5421
3200/9333 [=========>....................] - ETA: 6:01 - loss: 0.6879 - acc: 0.5434
3264/9333 [=========>....................] - ETA: 5:57 - loss: 0.6874 - acc: 0.5450
3328/9333 [=========>....................] - ETA: 5:53 - loss: 0.6867 - acc: 0.5469
3392/9333 [=========>....................] - ETA: 5:50 - loss: 0.6866 - acc: 0.5466
3456/9333 [==========>...................] - ETA: 5:46 - loss: 0.6865 - acc: 0.5477
3520/9333 [==========>...................] - ETA: 5:43 - loss: 0.6864 - acc: 0.5474
3584/9333 [==========>...................] - ETA: 5:38 - loss: 0.6862 - acc: 0.5474
3648/9333 [==========>...................] - ETA: 5:34 - loss: 0.6862 - acc: 0.5463
3712/9333 [==========>...................] - ETA: 5:30 - loss: 0.6867 - acc: 0.5455
3776/9333 [===========>..................] - ETA: 5:27 - loss: 0.6865 - acc: 0.5469
3840/9333 [===========>..................] - ETA: 5:23 - loss: 0.6867 - acc: 0.5461
3904/9333 [===========>..................] - ETA: 5:19 - loss: 0.6865 - acc: 0.5471
3968/9333 [===========>..................] - ETA: 5:15 - loss: 0.6863 - acc: 0.5474
4032/9333 [===========>..................] - ETA: 5:11 - loss: 0.6865 - acc: 0.5456
4096/9333 [============>.................] - ETA: 5:08 - loss: 0.6864 - acc: 0.5459
4160/9333 [============>.................] - ETA: 5:04 - loss: 0.6865 - acc: 0.5452
4224/9333 [============>.................] - ETA: 5:00 - loss: 0.6868 - acc: 0.5447
4288/9333 [============>.................] - ETA: 4:56 - loss: 0.6870 - acc: 0.5445
4352/9333 [============>.................] - ETA: 4:53 - loss: 0.6869 - acc: 0.5455
4416/9333 [=============>................] - ETA: 4:49 - loss: 0.6867 - acc: 0.5460
4480/9333 [=============>................] - ETA: 4:45 - loss: 0.6866 - acc: 0.5467
4544/9333 [=============>................] - ETA: 4:41 - loss: 0.6863 - acc: 0.5478
4608/9333 [=============>................] - ETA: 4:37 - loss: 0.6867 - acc: 0.5477
4672/9333 [==============>...............] - ETA: 4:33 - loss: 0.6862 - acc: 0.5490
4736/9333 [==============>...............] - ETA: 4:29 - loss: 0.6861 - acc: 0.5492
4800/9333 [==============>...............] - ETA: 4:26 - loss: 0.6858 - acc: 0.5496
4864/9333 [==============>...............] - ETA: 4:22 - loss: 0.6858 - acc: 0.5489
4928/9333 [==============>...............] - ETA: 4:18 - loss: 0.6856 - acc: 0.5495
4992/9333 [===============>..............] - ETA: 4:15 - loss: 0.6851 - acc: 0.5499
5056/9333 [===============>..............] - ETA: 4:11 - loss: 0.6851 - acc: 0.5494
5120/9333 [===============>..............] - ETA: 4:07 - loss: 0.6854 - acc: 0.5492
5184/9333 [===============>..............] - ETA: 4:03 - loss: 0.6852 - acc: 0.5494
5248/9333 [===============>..............] - ETA: 3:59 - loss: 0.6854 - acc: 0.5494
5312/9333 [================>.............] - ETA: 3:55 - loss: 0.6853 - acc: 0.5505
5376/9333 [================>.............] - ETA: 3:52 - loss: 0.6850 - acc: 0.5515
5440/9333 [================>.............] - ETA: 3:48 - loss: 0.6850 - acc: 0.5513
5504/9333 [================>.............] - ETA: 3:44 - loss: 0.6851 - acc: 0.5514
5568/9333 [================>.............] - ETA: 3:40 - loss: 0.6850 - acc: 0.5523
5632/9333 [=================>............] - ETA: 3:37 - loss: 0.6849 - acc: 0.5520
5696/9333 [=================>............] - ETA: 3:33 - loss: 0.6848 - acc: 0.5525
5760/9333 [=================>............] - ETA: 3:29 - loss: 0.6845 - acc: 0.5530
5824/9333 [=================>............] - ETA: 3:25 - loss: 0.6845 - acc: 0.5536
5888/9333 [=================>............] - ETA: 3:22 - loss: 0.6842 - acc: 0.5547
5952/9333 [==================>...........] - ETA: 3:18 - loss: 0.6843 - acc: 0.5548
6016/9333 [==================>...........] - ETA: 3:14 - loss: 0.6841 - acc: 0.5555
6080/9333 [==================>...........] - ETA: 3:10 - loss: 0.6838 - acc: 0.5559
6144/9333 [==================>...........] - ETA: 3:06 - loss: 0.6837 - acc: 0.5568
6208/9333 [==================>...........] - ETA: 3:03 - loss: 0.6835 - acc: 0.5575
6272/9333 [===================>..........] - ETA: 2:59 - loss: 0.6832 - acc: 0.5579
6336/9333 [===================>..........] - ETA: 2:56 - loss: 0.6835 - acc: 0.5571
6400/9333 [===================>..........] - ETA: 2:52 - loss: 0.6834 - acc: 0.5572
6464/9333 [===================>..........] - ETA: 2:48 - loss: 0.6836 - acc: 0.5569
6528/9333 [===================>..........] - ETA: 2:45 - loss: 0.6834 - acc: 0.5574
6592/9333 [====================>.........] - ETA: 2:41 - loss: 0.6841 - acc: 0.5566
6656/9333 [====================>.........] - ETA: 2:37 - loss: 0.6840 - acc: 0.5560
6720/9333 [====================>.........] - ETA: 2:33 - loss: 0.6839 - acc: 0.5560
6784/9333 [====================>.........] - ETA: 2:30 - loss: 0.6834 - acc: 0.5569
6848/9333 [=====================>........] - ETA: 2:26 - loss: 0.6838 - acc: 0.5565
6912/9333 [=====================>........] - ETA: 2:22 - loss: 0.6839 - acc: 0.5561
6976/9333 [=====================>........] - ETA: 2:19 - loss: 0.6844 - acc: 0.5559
7040/9333 [=====================>........] - ETA: 2:15 - loss: 0.6843 - acc: 0.5560
7104/9333 [=====================>........] - ETA: 2:11 - loss: 0.6843 - acc: 0.5563
7168/9333 [======================>.......] - ETA: 2:07 - loss: 0.6841 - acc: 0.5572
7232/9333 [======================>.......] - ETA: 2:03 - loss: 0.6842 - acc: 0.5568
7296/9333 [======================>.......] - ETA: 2:00 - loss: 0.6844 - acc: 0.5558
7360/9333 [======================>.......] - ETA: 1:56 - loss: 0.6846 - acc: 0.5553
7424/9333 [======================>.......] - ETA: 1:52 - loss: 0.6845 - acc: 0.5563
7488/9333 [=======================>......] - ETA: 1:48 - loss: 0.6844 - acc: 0.5566
7552/9333 [=======================>......] - ETA: 1:44 - loss: 0.6846 - acc: 0.5561
7616/9333 [=======================>......] - ETA: 1:41 - loss: 0.6850 - acc: 0.5559
7680/9333 [=======================>......] - ETA: 1:37 - loss: 0.6853 - acc: 0.5544
7744/9333 [=======================>......] - ETA: 1:33 - loss: 0.6853 - acc: 0.5545
7808/9333 [========================>.....] - ETA: 1:29 - loss: 0.6853 - acc: 0.5546
7872/9333 [========================>.....] - ETA: 1:25 - loss: 0.6853 - acc: 0.5548
7936/9333 [========================>.....] - ETA: 1:22 - loss: 0.6854 - acc: 0.5548
8000/9333 [========================>.....] - ETA: 1:18 - loss: 0.6853 - acc: 0.5545
8064/9333 [========================>.....] - ETA: 1:14 - loss: 0.6854 - acc: 0.5542
8128/9333 [=========================>....] - ETA: 1:10 - loss: 0.6857 - acc: 0.5535
8192/9333 [=========================>....] - ETA: 1:07 - loss: 0.6856 - acc: 0.5540
8256/9333 [=========================>....] - ETA: 1:03 - loss: 0.6855 - acc: 0.5544
8320/9333 [=========================>....] - ETA: 59s - loss: 0.6855 - acc: 0.5546 
8384/9333 [=========================>....] - ETA: 55s - loss: 0.6854 - acc: 0.5552
8448/9333 [==========================>...] - ETA: 51s - loss: 0.6854 - acc: 0.5555
8512/9333 [==========================>...] - ETA: 48s - loss: 0.6854 - acc: 0.5557
8576/9333 [==========================>...] - ETA: 44s - loss: 0.6852 - acc: 0.5561
8640/9333 [==========================>...] - ETA: 40s - loss: 0.6853 - acc: 0.5559
8704/9333 [==========================>...] - ETA: 36s - loss: 0.6855 - acc: 0.5555
8768/9333 [===========================>..] - ETA: 33s - loss: 0.6853 - acc: 0.5555
8832/9333 [===========================>..] - ETA: 29s - loss: 0.6852 - acc: 0.5559
8896/9333 [===========================>..] - ETA: 25s - loss: 0.6853 - acc: 0.5556
8960/9333 [===========================>..] - ETA: 21s - loss: 0.6851 - acc: 0.5560
9024/9333 [============================>.] - ETA: 18s - loss: 0.6850 - acc: 0.5564
9088/9333 [============================>.] - ETA: 14s - loss: 0.6847 - acc: 0.5573
9152/9333 [============================>.] - ETA: 10s - loss: 0.6847 - acc: 0.5578
9216/9333 [============================>.] - ETA: 6s - loss: 0.6849 - acc: 0.5574 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6849 - acc: 0.5577
9333/9333 [==============================] - 567s 61ms/step - loss: 0.6849 - acc: 0.5575 - val_loss: 0.6868 - val_acc: 0.5381

Epoch 00010: val_acc did not improve from 0.56606
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f443c083150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f443c083150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f45e4660990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f45e4660990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47c4312610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f47c4312610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f445ff0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3f445ff0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ca4295f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ca4295f90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44086970d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44086970d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f445ff810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f445ff810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4408322310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4408322310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4144492510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4144492510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f440863c790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f440863c790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f4460eb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3f4460eb90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f446ed190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f446ed190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4408502e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4408502e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4408756690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4408756690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4408468310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4408468310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f440849c3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f440849c3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4408736790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4408736790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f440835b990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f440835b990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f440836c250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f440836c250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f440805a5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f440805a5d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44080e6e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f44080e6e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43d078f7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43d078f7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43d0667650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43d0667650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f43d05dd990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f43d05dd990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43d04b1c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43d04b1c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43d07f77d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43d07f77d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43d0543810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43d0543810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43d0360e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43d0360e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f43d05dd6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f43d05dd6d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43d0156710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43d0156710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43d04b1cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43d04b1cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43d058e2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43d058e2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a47c0750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a47c0750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f43d0064c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f43d0064c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43a45e7d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43a45e7d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a4768550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a4768550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43d01022d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43d01022d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a4647110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a4647110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f43a440aad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f43a440aad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43a425d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f43a425d710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a46457d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a46457d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43a424f610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f43a424f610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a425ab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a425ab50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42a4508810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42a4508810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42844002d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42844002d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a425f910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f43a425f910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42a4678090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42a4678090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4284309490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4284309490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4284236f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4284236f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4284122690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4284122690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42647f2690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42647f2690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4284236b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4284236b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4264754bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4264754bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42646e2710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42646e2710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4264585e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4264585e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42841aa110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42841aa110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42647f2a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42647f2a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42644a0b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42644a0b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42643ccbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42643ccbd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4264260fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4264260fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42643dc490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42643dc490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f426439ded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f426439ded0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42643320d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42643320d0>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 7:30
 128/2592 [>.............................] - ETA: 4:02
 192/2592 [=>............................] - ETA: 2:53
 256/2592 [=>............................] - ETA: 2:17
 320/2592 [==>...........................] - ETA: 1:55
 384/2592 [===>..........................] - ETA: 1:40
 448/2592 [====>.........................] - ETA: 1:28
 512/2592 [====>.........................] - ETA: 1:20
 576/2592 [=====>........................] - ETA: 1:13
 640/2592 [======>.......................] - ETA: 1:08
 704/2592 [=======>......................] - ETA: 1:03
 768/2592 [=======>......................] - ETA: 58s 
 832/2592 [========>.....................] - ETA: 55s
 896/2592 [=========>....................] - ETA: 51s
 960/2592 [==========>...................] - ETA: 48s
1024/2592 [==========>...................] - ETA: 45s
1088/2592 [===========>..................] - ETA: 42s
1152/2592 [============>.................] - ETA: 39s
1216/2592 [=============>................] - ETA: 37s
1280/2592 [=============>................] - ETA: 35s
1344/2592 [==============>...............] - ETA: 32s
1408/2592 [===============>..............] - ETA: 30s
1472/2592 [================>.............] - ETA: 28s
1536/2592 [================>.............] - ETA: 26s
1600/2592 [=================>............] - ETA: 25s
1664/2592 [==================>...........] - ETA: 23s
1728/2592 [===================>..........] - ETA: 21s
1792/2592 [===================>..........] - ETA: 19s
1856/2592 [====================>.........] - ETA: 17s
1920/2592 [=====================>........] - ETA: 16s
1984/2592 [=====================>........] - ETA: 14s
2048/2592 [======================>.......] - ETA: 12s
2112/2592 [=======================>......] - ETA: 11s
2176/2592 [========================>.....] - ETA: 9s 
2240/2592 [========================>.....] - ETA: 8s
2304/2592 [=========================>....] - ETA: 6s
2368/2592 [==========================>...] - ETA: 5s
2432/2592 [===========================>..] - ETA: 3s
2496/2592 [===========================>..] - ETA: 2s
2560/2592 [============================>.] - ETA: 0s
2592/2592 [==============================] - 59s 23ms/step
loss: 0.6895080039530624
acc: 0.5362654320987654
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3d64082510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3d64082510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3d64051990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3d64051990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f442c7e7d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f442c7e7d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f423c107990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f423c107990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d447e6ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d447e6ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42346ba7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42346ba7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f423c107e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f423c107e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42342ed190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42342ed190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f423c117790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f423c117790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f442c13bcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f442c13bcd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f442c6001d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f442c6001d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42347022d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42347022d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f442c4aaa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f442c4aaa90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f442c240190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f442c240190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d44796b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d44796b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f442c36c610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f442c36c610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f442c6fa610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f442c6fa610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d447a4a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d447a4a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f442c5aab90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f442c5aab90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d44584310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d44584310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d444a7450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d444a7450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d4462df90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d4462df90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d442c7d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d442c7d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d442c9310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d442c9310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d44199610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d44199610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d444f0610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d444f0610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d442c9c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d442c9c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d44046c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d44046c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d246f9a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d246f9a10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d2462b7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d2462b7d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d2476a510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d2476a510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d2471c710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d2471c710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d24526750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d24526750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d24513390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d24513390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d24626290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d24626290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d24505690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d24505690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d245057d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d245057d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d442a5790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d442a5790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d24162550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d24162550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d24449cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d24449cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d243ec3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d243ec3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d24162c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d24162c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d2444a510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d2444a510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d086a6b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d086a6b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d08443ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d08443ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d0851ed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d0851ed90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d08644a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d08644a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d085c4610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d085c4610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d0823f150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d0823f150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d081b2f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d081b2f90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d08039b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d08039b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d083af8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d083af8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d08160d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3d08160d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d08062950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3d08062950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d08197750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3d08197750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ce4722950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ce4722950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d082234d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d082234d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ce46171d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ce46171d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ce4459650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ce4459650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ce43c0110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ce43c0110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ce4468b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ce4468b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3ce4700c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3ce4700c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ce43239d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ce43239d0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 1:47:22 - loss: 0.7126 - acc: 0.6094
 128/9333 [..............................] - ETA: 59:08 - loss: 0.7511 - acc: 0.5469  
 192/9333 [..............................] - ETA: 42:49 - loss: 0.7577 - acc: 0.5208
 256/9333 [..............................] - ETA: 34:59 - loss: 0.7326 - acc: 0.5352
 320/9333 [>.............................] - ETA: 30:06 - loss: 0.7228 - acc: 0.5500
 384/9333 [>.............................] - ETA: 26:25 - loss: 0.7268 - acc: 0.5365
 448/9333 [>.............................] - ETA: 23:50 - loss: 0.7283 - acc: 0.5424
 512/9333 [>.............................] - ETA: 22:09 - loss: 0.7312 - acc: 0.5449
 576/9333 [>.............................] - ETA: 20:46 - loss: 0.7296 - acc: 0.5486
 640/9333 [=>............................] - ETA: 19:33 - loss: 0.7342 - acc: 0.5328
 704/9333 [=>............................] - ETA: 18:34 - loss: 0.7273 - acc: 0.5412
 768/9333 [=>............................] - ETA: 17:45 - loss: 0.7276 - acc: 0.5365
 832/9333 [=>............................] - ETA: 17:06 - loss: 0.7241 - acc: 0.5385
 896/9333 [=>............................] - ETA: 16:33 - loss: 0.7229 - acc: 0.5368
 960/9333 [==>...........................] - ETA: 16:05 - loss: 0.7190 - acc: 0.5437
1024/9333 [==>...........................] - ETA: 15:40 - loss: 0.7175 - acc: 0.5439
1088/9333 [==>...........................] - ETA: 15:16 - loss: 0.7195 - acc: 0.5423
1152/9333 [==>...........................] - ETA: 14:54 - loss: 0.7153 - acc: 0.5469
1216/9333 [==>...........................] - ETA: 14:35 - loss: 0.7198 - acc: 0.5395
1280/9333 [===>..........................] - ETA: 14:14 - loss: 0.7208 - acc: 0.5375
1344/9333 [===>..........................] - ETA: 13:57 - loss: 0.7216 - acc: 0.5335
1408/9333 [===>..........................] - ETA: 13:36 - loss: 0.7203 - acc: 0.5320
1472/9333 [===>..........................] - ETA: 13:19 - loss: 0.7184 - acc: 0.5346
1536/9333 [===>..........................] - ETA: 13:00 - loss: 0.7195 - acc: 0.5299
1600/9333 [====>.........................] - ETA: 12:43 - loss: 0.7209 - acc: 0.5294
1664/9333 [====>.........................] - ETA: 12:24 - loss: 0.7208 - acc: 0.5276
1728/9333 [====>.........................] - ETA: 12:10 - loss: 0.7203 - acc: 0.5272
1792/9333 [====>.........................] - ETA: 11:53 - loss: 0.7198 - acc: 0.5262
1856/9333 [====>.........................] - ETA: 11:40 - loss: 0.7218 - acc: 0.5226
1920/9333 [=====>........................] - ETA: 11:26 - loss: 0.7210 - acc: 0.5245
1984/9333 [=====>........................] - ETA: 11:13 - loss: 0.7204 - acc: 0.5237
2048/9333 [=====>........................] - ETA: 10:59 - loss: 0.7201 - acc: 0.5220
2112/9333 [=====>........................] - ETA: 10:48 - loss: 0.7201 - acc: 0.5218
2176/9333 [=====>........................] - ETA: 10:38 - loss: 0.7193 - acc: 0.5234
2240/9333 [======>.......................] - ETA: 10:28 - loss: 0.7195 - acc: 0.5241
2304/9333 [======>.......................] - ETA: 10:17 - loss: 0.7204 - acc: 0.5195
2368/9333 [======>.......................] - ETA: 10:06 - loss: 0.7203 - acc: 0.5182
2432/9333 [======>.......................] - ETA: 9:56 - loss: 0.7191 - acc: 0.5193 
2496/9333 [=======>......................] - ETA: 9:49 - loss: 0.7198 - acc: 0.5184
2560/9333 [=======>......................] - ETA: 9:40 - loss: 0.7184 - acc: 0.5215
2624/9333 [=======>......................] - ETA: 9:31 - loss: 0.7189 - acc: 0.5213
2688/9333 [=======>......................] - ETA: 9:21 - loss: 0.7196 - acc: 0.5205
2752/9333 [=======>......................] - ETA: 9:12 - loss: 0.7192 - acc: 0.5200
2816/9333 [========>.....................] - ETA: 9:05 - loss: 0.7192 - acc: 0.5202
2880/9333 [========>.....................] - ETA: 8:57 - loss: 0.7195 - acc: 0.5170
2944/9333 [========>.....................] - ETA: 8:49 - loss: 0.7190 - acc: 0.5190
3008/9333 [========>.....................] - ETA: 8:41 - loss: 0.7186 - acc: 0.5189
3072/9333 [========>.....................] - ETA: 8:33 - loss: 0.7176 - acc: 0.5192
3136/9333 [=========>....................] - ETA: 8:26 - loss: 0.7173 - acc: 0.5195
3200/9333 [=========>....................] - ETA: 8:19 - loss: 0.7169 - acc: 0.5197
3264/9333 [=========>....................] - ETA: 8:12 - loss: 0.7166 - acc: 0.5196
3328/9333 [=========>....................] - ETA: 8:07 - loss: 0.7168 - acc: 0.5192
3392/9333 [=========>....................] - ETA: 8:01 - loss: 0.7171 - acc: 0.5171
3456/9333 [==========>...................] - ETA: 7:55 - loss: 0.7170 - acc: 0.5159
3520/9333 [==========>...................] - ETA: 7:49 - loss: 0.7173 - acc: 0.5136
3584/9333 [==========>...................] - ETA: 7:42 - loss: 0.7173 - acc: 0.5134
3648/9333 [==========>...................] - ETA: 7:37 - loss: 0.7175 - acc: 0.5123
3712/9333 [==========>...................] - ETA: 7:31 - loss: 0.7168 - acc: 0.5135
3776/9333 [===========>..................] - ETA: 7:24 - loss: 0.7163 - acc: 0.5140
3840/9333 [===========>..................] - ETA: 7:20 - loss: 0.7161 - acc: 0.5128
3904/9333 [===========>..................] - ETA: 7:14 - loss: 0.7162 - acc: 0.5123
3968/9333 [===========>..................] - ETA: 7:08 - loss: 0.7162 - acc: 0.5113
4032/9333 [===========>..................] - ETA: 7:01 - loss: 0.7158 - acc: 0.5109
4096/9333 [============>.................] - ETA: 6:57 - loss: 0.7154 - acc: 0.5112
4160/9333 [============>.................] - ETA: 6:52 - loss: 0.7149 - acc: 0.5120
4224/9333 [============>.................] - ETA: 6:46 - loss: 0.7146 - acc: 0.5121
4288/9333 [============>.................] - ETA: 6:39 - loss: 0.7148 - acc: 0.5114
4352/9333 [============>.................] - ETA: 6:33 - loss: 0.7151 - acc: 0.5113
4416/9333 [=============>................] - ETA: 6:29 - loss: 0.7151 - acc: 0.5109
4480/9333 [=============>................] - ETA: 6:23 - loss: 0.7151 - acc: 0.5109
4544/9333 [=============>................] - ETA: 6:18 - loss: 0.7150 - acc: 0.5103
4608/9333 [=============>................] - ETA: 6:12 - loss: 0.7144 - acc: 0.5115
4672/9333 [==============>...............] - ETA: 6:06 - loss: 0.7136 - acc: 0.5128
4736/9333 [==============>...............] - ETA: 6:01 - loss: 0.7134 - acc: 0.5131
4800/9333 [==============>...............] - ETA: 5:55 - loss: 0.7127 - acc: 0.5144
4864/9333 [==============>...............] - ETA: 5:50 - loss: 0.7127 - acc: 0.5134
4928/9333 [==============>...............] - ETA: 5:45 - loss: 0.7122 - acc: 0.5142
4992/9333 [===============>..............] - ETA: 5:40 - loss: 0.7116 - acc: 0.5150
5056/9333 [===============>..............] - ETA: 5:34 - loss: 0.7112 - acc: 0.5160
5120/9333 [===============>..............] - ETA: 5:29 - loss: 0.7115 - acc: 0.5154
5184/9333 [===============>..............] - ETA: 5:23 - loss: 0.7115 - acc: 0.5156
5248/9333 [===============>..............] - ETA: 5:17 - loss: 0.7114 - acc: 0.5160
5312/9333 [================>.............] - ETA: 5:12 - loss: 0.7113 - acc: 0.5164
5376/9333 [================>.............] - ETA: 5:07 - loss: 0.7116 - acc: 0.5162
5440/9333 [================>.............] - ETA: 5:02 - loss: 0.7114 - acc: 0.5160
5504/9333 [================>.............] - ETA: 4:57 - loss: 0.7107 - acc: 0.5171
5568/9333 [================>.............] - ETA: 4:53 - loss: 0.7104 - acc: 0.5178
5632/9333 [=================>............] - ETA: 4:48 - loss: 0.7106 - acc: 0.5172
5696/9333 [=================>............] - ETA: 4:42 - loss: 0.7100 - acc: 0.5183
5760/9333 [=================>............] - ETA: 4:37 - loss: 0.7099 - acc: 0.5181
5824/9333 [=================>............] - ETA: 4:32 - loss: 0.7094 - acc: 0.5185
5888/9333 [=================>............] - ETA: 4:27 - loss: 0.7096 - acc: 0.5177
5952/9333 [==================>...........] - ETA: 4:22 - loss: 0.7095 - acc: 0.5171
6016/9333 [==================>...........] - ETA: 4:17 - loss: 0.7096 - acc: 0.5160
6080/9333 [==================>...........] - ETA: 4:12 - loss: 0.7095 - acc: 0.5163
6144/9333 [==================>...........] - ETA: 4:07 - loss: 0.7094 - acc: 0.5164
6208/9333 [==================>...........] - ETA: 4:03 - loss: 0.7092 - acc: 0.5161
6272/9333 [===================>..........] - ETA: 3:58 - loss: 0.7093 - acc: 0.5161
6336/9333 [===================>..........] - ETA: 3:53 - loss: 0.7090 - acc: 0.5172
6400/9333 [===================>..........] - ETA: 3:48 - loss: 0.7095 - acc: 0.5161
6464/9333 [===================>..........] - ETA: 3:43 - loss: 0.7094 - acc: 0.5159
6528/9333 [===================>..........] - ETA: 3:38 - loss: 0.7090 - acc: 0.5169
6592/9333 [====================>.........] - ETA: 3:33 - loss: 0.7090 - acc: 0.5162
6656/9333 [====================>.........] - ETA: 3:28 - loss: 0.7090 - acc: 0.5161
6720/9333 [====================>.........] - ETA: 3:23 - loss: 0.7092 - acc: 0.5155
6784/9333 [====================>.........] - ETA: 3:18 - loss: 0.7090 - acc: 0.5164
6848/9333 [=====================>........] - ETA: 3:13 - loss: 0.7088 - acc: 0.5168
6912/9333 [=====================>........] - ETA: 3:08 - loss: 0.7085 - acc: 0.5175
6976/9333 [=====================>........] - ETA: 3:02 - loss: 0.7085 - acc: 0.5168
7040/9333 [=====================>........] - ETA: 2:57 - loss: 0.7088 - acc: 0.5156
7104/9333 [=====================>........] - ETA: 2:52 - loss: 0.7084 - acc: 0.5156
7168/9333 [======================>.......] - ETA: 2:47 - loss: 0.7083 - acc: 0.5158
7232/9333 [======================>.......] - ETA: 2:42 - loss: 0.7080 - acc: 0.5165
7296/9333 [======================>.......] - ETA: 2:37 - loss: 0.7080 - acc: 0.5167
7360/9333 [======================>.......] - ETA: 2:32 - loss: 0.7080 - acc: 0.5171
7424/9333 [======================>.......] - ETA: 2:27 - loss: 0.7077 - acc: 0.5175
7488/9333 [=======================>......] - ETA: 2:22 - loss: 0.7074 - acc: 0.5186
7552/9333 [=======================>......] - ETA: 2:17 - loss: 0.7075 - acc: 0.5180
7616/9333 [=======================>......] - ETA: 2:12 - loss: 0.7072 - acc: 0.5184
7680/9333 [=======================>......] - ETA: 2:07 - loss: 0.7071 - acc: 0.5191
7744/9333 [=======================>......] - ETA: 2:02 - loss: 0.7068 - acc: 0.5196
7808/9333 [========================>.....] - ETA: 1:57 - loss: 0.7063 - acc: 0.5204
7872/9333 [========================>.....] - ETA: 1:52 - loss: 0.7058 - acc: 0.5211
7936/9333 [========================>.....] - ETA: 1:47 - loss: 0.7058 - acc: 0.5213
8000/9333 [========================>.....] - ETA: 1:42 - loss: 0.7058 - acc: 0.5215
8064/9333 [========================>.....] - ETA: 1:38 - loss: 0.7060 - acc: 0.5206
8128/9333 [=========================>....] - ETA: 1:33 - loss: 0.7059 - acc: 0.5205
8192/9333 [=========================>....] - ETA: 1:27 - loss: 0.7058 - acc: 0.5203
8256/9333 [=========================>....] - ETA: 1:22 - loss: 0.7061 - acc: 0.5200
8320/9333 [=========================>....] - ETA: 1:17 - loss: 0.7059 - acc: 0.5201
8384/9333 [=========================>....] - ETA: 1:12 - loss: 0.7059 - acc: 0.5200
8448/9333 [==========================>...] - ETA: 1:07 - loss: 0.7057 - acc: 0.5201
8512/9333 [==========================>...] - ETA: 1:02 - loss: 0.7054 - acc: 0.5207
8576/9333 [==========================>...] - ETA: 57s - loss: 0.7055 - acc: 0.5203 
8640/9333 [==========================>...] - ETA: 52s - loss: 0.7054 - acc: 0.5204
8704/9333 [==========================>...] - ETA: 47s - loss: 0.7053 - acc: 0.5206
8768/9333 [===========================>..] - ETA: 43s - loss: 0.7055 - acc: 0.5201
8832/9333 [===========================>..] - ETA: 38s - loss: 0.7054 - acc: 0.5200
8896/9333 [===========================>..] - ETA: 33s - loss: 0.7056 - acc: 0.5193
8960/9333 [===========================>..] - ETA: 28s - loss: 0.7055 - acc: 0.5193
9024/9333 [============================>.] - ETA: 23s - loss: 0.7054 - acc: 0.5197
9088/9333 [============================>.] - ETA: 18s - loss: 0.7050 - acc: 0.5202
9152/9333 [============================>.] - ETA: 13s - loss: 0.7048 - acc: 0.5201
9216/9333 [============================>.] - ETA: 8s - loss: 0.7050 - acc: 0.5195 
9280/9333 [============================>.] - ETA: 4s - loss: 0.7051 - acc: 0.5193
9333/9333 [==============================] - 737s 79ms/step - loss: 0.7050 - acc: 0.5190 - val_loss: 0.6984 - val_acc: 0.5063

Epoch 00001: val_acc improved from -inf to 0.50627, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window08/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 8:27 - loss: 0.7517 - acc: 0.4062
 128/9333 [..............................] - ETA: 9:13 - loss: 0.7213 - acc: 0.4688
 192/9333 [..............................] - ETA: 9:11 - loss: 0.7282 - acc: 0.4740
 256/9333 [..............................] - ETA: 9:26 - loss: 0.7233 - acc: 0.4805
 320/9333 [>.............................] - ETA: 9:27 - loss: 0.7195 - acc: 0.4750
 384/9333 [>.............................] - ETA: 9:37 - loss: 0.7183 - acc: 0.4766
 448/9333 [>.............................] - ETA: 9:39 - loss: 0.7112 - acc: 0.4978
 512/9333 [>.............................] - ETA: 9:32 - loss: 0.7096 - acc: 0.5020
 576/9333 [>.............................] - ETA: 9:32 - loss: 0.7095 - acc: 0.5017
 640/9333 [=>............................] - ETA: 9:31 - loss: 0.7079 - acc: 0.5016
 704/9333 [=>............................] - ETA: 9:24 - loss: 0.7058 - acc: 0.5085
 768/9333 [=>............................] - ETA: 9:24 - loss: 0.7039 - acc: 0.5065
 832/9333 [=>............................] - ETA: 9:13 - loss: 0.7015 - acc: 0.5156
 896/9333 [=>............................] - ETA: 9:20 - loss: 0.6997 - acc: 0.5190
 960/9333 [==>...........................] - ETA: 9:21 - loss: 0.6999 - acc: 0.5135
1024/9333 [==>...........................] - ETA: 9:15 - loss: 0.7008 - acc: 0.5107
1088/9333 [==>...........................] - ETA: 9:14 - loss: 0.7017 - acc: 0.5110
1152/9333 [==>...........................] - ETA: 9:12 - loss: 0.7029 - acc: 0.5069
1216/9333 [==>...........................] - ETA: 9:05 - loss: 0.7006 - acc: 0.5132
1280/9333 [===>..........................] - ETA: 9:02 - loss: 0.6999 - acc: 0.5156
1344/9333 [===>..........................] - ETA: 8:57 - loss: 0.6989 - acc: 0.5171
1408/9333 [===>..........................] - ETA: 8:56 - loss: 0.6988 - acc: 0.5142
1472/9333 [===>..........................] - ETA: 8:53 - loss: 0.6982 - acc: 0.5156
1536/9333 [===>..........................] - ETA: 8:48 - loss: 0.6991 - acc: 0.5163
1600/9333 [====>.........................] - ETA: 8:41 - loss: 0.7009 - acc: 0.5125
1664/9333 [====>.........................] - ETA: 8:35 - loss: 0.6995 - acc: 0.5162
1728/9333 [====>.........................] - ETA: 8:31 - loss: 0.6991 - acc: 0.5127
1792/9333 [====>.........................] - ETA: 8:27 - loss: 0.6993 - acc: 0.5140
1856/9333 [====>.........................] - ETA: 8:26 - loss: 0.6991 - acc: 0.5135
1920/9333 [=====>........................] - ETA: 8:20 - loss: 0.6989 - acc: 0.5120
1984/9333 [=====>........................] - ETA: 8:14 - loss: 0.6994 - acc: 0.5116
2048/9333 [=====>........................] - ETA: 8:08 - loss: 0.6989 - acc: 0.5146
2112/9333 [=====>........................] - ETA: 8:02 - loss: 0.6991 - acc: 0.5128
2176/9333 [=====>........................] - ETA: 7:58 - loss: 0.6991 - acc: 0.5156
2240/9333 [======>.......................] - ETA: 7:54 - loss: 0.6991 - acc: 0.5156
2304/9333 [======>.......................] - ETA: 7:51 - loss: 0.6995 - acc: 0.5143
2368/9333 [======>.......................] - ETA: 7:47 - loss: 0.6993 - acc: 0.5135
2432/9333 [======>.......................] - ETA: 7:44 - loss: 0.6994 - acc: 0.5127
2496/9333 [=======>......................] - ETA: 7:41 - loss: 0.6997 - acc: 0.5124
2560/9333 [=======>......................] - ETA: 7:35 - loss: 0.6992 - acc: 0.5129
2624/9333 [=======>......................] - ETA: 7:30 - loss: 0.6992 - acc: 0.5133
2688/9333 [=======>......................] - ETA: 7:24 - loss: 0.7005 - acc: 0.5108
2752/9333 [=======>......................] - ETA: 7:19 - loss: 0.7002 - acc: 0.5124
2816/9333 [========>.....................] - ETA: 7:14 - loss: 0.6997 - acc: 0.5131
2880/9333 [========>.....................] - ETA: 7:08 - loss: 0.6995 - acc: 0.5142
2944/9333 [========>.....................] - ETA: 7:06 - loss: 0.7009 - acc: 0.5112
3008/9333 [========>.....................] - ETA: 7:02 - loss: 0.7008 - acc: 0.5123
3072/9333 [========>.....................] - ETA: 6:59 - loss: 0.7003 - acc: 0.5143
3136/9333 [=========>....................] - ETA: 6:56 - loss: 0.7003 - acc: 0.5131
3200/9333 [=========>....................] - ETA: 6:53 - loss: 0.7004 - acc: 0.5116
3264/9333 [=========>....................] - ETA: 6:49 - loss: 0.7004 - acc: 0.5116
3328/9333 [=========>....................] - ETA: 6:43 - loss: 0.6999 - acc: 0.5129
3392/9333 [=========>....................] - ETA: 6:38 - loss: 0.6999 - acc: 0.5118
3456/9333 [==========>...................] - ETA: 6:33 - loss: 0.6999 - acc: 0.5113
3520/9333 [==========>...................] - ETA: 6:29 - loss: 0.7002 - acc: 0.5105
3584/9333 [==========>...................] - ETA: 6:23 - loss: 0.7003 - acc: 0.5103
3648/9333 [==========>...................] - ETA: 6:18 - loss: 0.7002 - acc: 0.5107
3712/9333 [==========>...................] - ETA: 6:13 - loss: 0.7001 - acc: 0.5113
3776/9333 [===========>..................] - ETA: 6:09 - loss: 0.7003 - acc: 0.5106
3840/9333 [===========>..................] - ETA: 6:05 - loss: 0.6999 - acc: 0.5112
3904/9333 [===========>..................] - ETA: 6:02 - loss: 0.6996 - acc: 0.5105
3968/9333 [===========>..................] - ETA: 5:58 - loss: 0.6995 - acc: 0.5111
4032/9333 [===========>..................] - ETA: 5:54 - loss: 0.6999 - acc: 0.5109
4096/9333 [============>.................] - ETA: 5:50 - loss: 0.6997 - acc: 0.5107
4160/9333 [============>.................] - ETA: 5:46 - loss: 0.6996 - acc: 0.5111
4224/9333 [============>.................] - ETA: 5:41 - loss: 0.6994 - acc: 0.5121
4288/9333 [============>.................] - ETA: 5:36 - loss: 0.6996 - acc: 0.5110
4352/9333 [============>.................] - ETA: 5:31 - loss: 0.6992 - acc: 0.5115
4416/9333 [=============>................] - ETA: 5:26 - loss: 0.6991 - acc: 0.5113
4480/9333 [=============>................] - ETA: 5:22 - loss: 0.6990 - acc: 0.5112
4544/9333 [=============>................] - ETA: 5:17 - loss: 0.6990 - acc: 0.5119
4608/9333 [=============>................] - ETA: 5:14 - loss: 0.6993 - acc: 0.5104
4672/9333 [==============>...............] - ETA: 5:10 - loss: 0.6994 - acc: 0.5107
4736/9333 [==============>...............] - ETA: 5:06 - loss: 0.6992 - acc: 0.5110
4800/9333 [==============>...............] - ETA: 5:02 - loss: 0.6988 - acc: 0.5119
4864/9333 [==============>...............] - ETA: 4:59 - loss: 0.6985 - acc: 0.5134
4928/9333 [==============>...............] - ETA: 4:55 - loss: 0.6984 - acc: 0.5138
4992/9333 [===============>..............] - ETA: 4:51 - loss: 0.6984 - acc: 0.5132
5056/9333 [===============>..............] - ETA: 4:46 - loss: 0.6988 - acc: 0.5119
5120/9333 [===============>..............] - ETA: 4:42 - loss: 0.6985 - acc: 0.5129
5184/9333 [===============>..............] - ETA: 4:37 - loss: 0.6988 - acc: 0.5125
5248/9333 [===============>..............] - ETA: 4:32 - loss: 0.6989 - acc: 0.5114
5312/9333 [================>.............] - ETA: 4:28 - loss: 0.6987 - acc: 0.5128
5376/9333 [================>.............] - ETA: 4:23 - loss: 0.6987 - acc: 0.5121
5440/9333 [================>.............] - ETA: 4:19 - loss: 0.6986 - acc: 0.5123
5504/9333 [================>.............] - ETA: 4:15 - loss: 0.6983 - acc: 0.5134
5568/9333 [================>.............] - ETA: 4:11 - loss: 0.6984 - acc: 0.5129
5632/9333 [=================>............] - ETA: 4:07 - loss: 0.6985 - acc: 0.5126
5696/9333 [=================>............] - ETA: 4:03 - loss: 0.6983 - acc: 0.5132
5760/9333 [=================>............] - ETA: 3:59 - loss: 0.6984 - acc: 0.5134
5824/9333 [=================>............] - ETA: 3:55 - loss: 0.6984 - acc: 0.5132
5888/9333 [=================>............] - ETA: 3:51 - loss: 0.6982 - acc: 0.5138
5952/9333 [==================>...........] - ETA: 3:47 - loss: 0.6979 - acc: 0.5150
6016/9333 [==================>...........] - ETA: 3:43 - loss: 0.6979 - acc: 0.5141
6080/9333 [==================>...........] - ETA: 3:38 - loss: 0.6980 - acc: 0.5140
6144/9333 [==================>...........] - ETA: 3:34 - loss: 0.6976 - acc: 0.5153
6208/9333 [==================>...........] - ETA: 3:30 - loss: 0.6974 - acc: 0.5151
6272/9333 [===================>..........] - ETA: 3:26 - loss: 0.6975 - acc: 0.5148
6336/9333 [===================>..........] - ETA: 3:22 - loss: 0.6975 - acc: 0.5145
6400/9333 [===================>..........] - ETA: 3:18 - loss: 0.6974 - acc: 0.5144
6464/9333 [===================>..........] - ETA: 3:14 - loss: 0.6972 - acc: 0.5150
6528/9333 [===================>..........] - ETA: 3:10 - loss: 0.6972 - acc: 0.5149
6592/9333 [====================>.........] - ETA: 3:05 - loss: 0.6970 - acc: 0.5155
6656/9333 [====================>.........] - ETA: 3:01 - loss: 0.6972 - acc: 0.5152
6720/9333 [====================>.........] - ETA: 2:57 - loss: 0.6973 - acc: 0.5144
6784/9333 [====================>.........] - ETA: 2:53 - loss: 0.6971 - acc: 0.5147
6848/9333 [=====================>........] - ETA: 2:49 - loss: 0.6968 - acc: 0.5152
6912/9333 [=====================>........] - ETA: 2:44 - loss: 0.6969 - acc: 0.5156
6976/9333 [=====================>........] - ETA: 2:40 - loss: 0.6972 - acc: 0.5142
7040/9333 [=====================>........] - ETA: 2:35 - loss: 0.6970 - acc: 0.5148
7104/9333 [=====================>........] - ETA: 2:31 - loss: 0.6971 - acc: 0.5152
7168/9333 [======================>.......] - ETA: 2:27 - loss: 0.6970 - acc: 0.5153
7232/9333 [======================>.......] - ETA: 2:22 - loss: 0.6967 - acc: 0.5169
7296/9333 [======================>.......] - ETA: 2:18 - loss: 0.6968 - acc: 0.5159
7360/9333 [======================>.......] - ETA: 2:14 - loss: 0.6967 - acc: 0.5158
7424/9333 [======================>.......] - ETA: 2:09 - loss: 0.6965 - acc: 0.5160
7488/9333 [=======================>......] - ETA: 2:05 - loss: 0.6965 - acc: 0.5158
7552/9333 [=======================>......] - ETA: 2:00 - loss: 0.6964 - acc: 0.5160
7616/9333 [=======================>......] - ETA: 1:55 - loss: 0.6965 - acc: 0.5163
7680/9333 [=======================>......] - ETA: 1:51 - loss: 0.6966 - acc: 0.5152
7744/9333 [=======================>......] - ETA: 1:46 - loss: 0.6965 - acc: 0.5160
7808/9333 [========================>.....] - ETA: 1:42 - loss: 0.6964 - acc: 0.5165
7872/9333 [========================>.....] - ETA: 1:37 - loss: 0.6965 - acc: 0.5166
7936/9333 [========================>.....] - ETA: 1:33 - loss: 0.6965 - acc: 0.5161
8000/9333 [========================>.....] - ETA: 1:28 - loss: 0.6965 - acc: 0.5164
8064/9333 [========================>.....] - ETA: 1:24 - loss: 0.6965 - acc: 0.5162
8128/9333 [=========================>....] - ETA: 1:19 - loss: 0.6966 - acc: 0.5161
8192/9333 [=========================>....] - ETA: 1:15 - loss: 0.6965 - acc: 0.5162
8256/9333 [=========================>....] - ETA: 1:11 - loss: 0.6965 - acc: 0.5159
8320/9333 [=========================>....] - ETA: 1:06 - loss: 0.6966 - acc: 0.5156
8384/9333 [=========================>....] - ETA: 1:02 - loss: 0.6967 - acc: 0.5153
8448/9333 [==========================>...] - ETA: 58s - loss: 0.6967 - acc: 0.5148 
8512/9333 [==========================>...] - ETA: 53s - loss: 0.6966 - acc: 0.5155
8576/9333 [==========================>...] - ETA: 49s - loss: 0.6965 - acc: 0.5156
8640/9333 [==========================>...] - ETA: 45s - loss: 0.6965 - acc: 0.5154
8704/9333 [==========================>...] - ETA: 41s - loss: 0.6962 - acc: 0.5163
8768/9333 [===========================>..] - ETA: 36s - loss: 0.6962 - acc: 0.5162
8832/9333 [===========================>..] - ETA: 32s - loss: 0.6960 - acc: 0.5169
8896/9333 [===========================>..] - ETA: 28s - loss: 0.6962 - acc: 0.5165
8960/9333 [===========================>..] - ETA: 24s - loss: 0.6962 - acc: 0.5166
9024/9333 [============================>.] - ETA: 19s - loss: 0.6959 - acc: 0.5178
9088/9333 [============================>.] - ETA: 15s - loss: 0.6959 - acc: 0.5179
9152/9333 [============================>.] - ETA: 11s - loss: 0.6960 - acc: 0.5176
9216/9333 [============================>.] - ETA: 7s - loss: 0.6960 - acc: 0.5179 
9280/9333 [============================>.] - ETA: 3s - loss: 0.6961 - acc: 0.5172
9333/9333 [==============================] - 618s 66ms/step - loss: 0.6960 - acc: 0.5175 - val_loss: 0.6859 - val_acc: 0.5477

Epoch 00002: val_acc improved from 0.50627 to 0.54773, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window08/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 3/10

  64/9333 [..............................] - ETA: 7:51 - loss: 0.6705 - acc: 0.5938
 128/9333 [..............................] - ETA: 7:29 - loss: 0.6869 - acc: 0.4922
 192/9333 [..............................] - ETA: 7:12 - loss: 0.6797 - acc: 0.5000
 256/9333 [..............................] - ETA: 7:11 - loss: 0.6877 - acc: 0.5000
 320/9333 [>.............................] - ETA: 7:00 - loss: 0.6859 - acc: 0.5188
 384/9333 [>.............................] - ETA: 7:01 - loss: 0.6885 - acc: 0.5234
 448/9333 [>.............................] - ETA: 7:04 - loss: 0.6918 - acc: 0.5089
 512/9333 [>.............................] - ETA: 7:06 - loss: 0.6914 - acc: 0.5137
 576/9333 [>.............................] - ETA: 7:01 - loss: 0.6906 - acc: 0.5191
 640/9333 [=>............................] - ETA: 6:58 - loss: 0.6938 - acc: 0.5156
 704/9333 [=>............................] - ETA: 6:56 - loss: 0.6956 - acc: 0.5185
 768/9333 [=>............................] - ETA: 6:53 - loss: 0.6951 - acc: 0.5143
 832/9333 [=>............................] - ETA: 6:54 - loss: 0.6948 - acc: 0.5192
 896/9333 [=>............................] - ETA: 6:53 - loss: 0.6929 - acc: 0.5257
 960/9333 [==>...........................] - ETA: 6:48 - loss: 0.6913 - acc: 0.5292
1024/9333 [==>...........................] - ETA: 6:45 - loss: 0.6928 - acc: 0.5215
1088/9333 [==>...........................] - ETA: 6:39 - loss: 0.6928 - acc: 0.5193
1152/9333 [==>...........................] - ETA: 6:39 - loss: 0.6938 - acc: 0.5182
1216/9333 [==>...........................] - ETA: 6:38 - loss: 0.6931 - acc: 0.5189
1280/9333 [===>..........................] - ETA: 6:34 - loss: 0.6917 - acc: 0.5242
1344/9333 [===>..........................] - ETA: 6:30 - loss: 0.6917 - acc: 0.5253
1408/9333 [===>..........................] - ETA: 6:26 - loss: 0.6926 - acc: 0.5220
1472/9333 [===>..........................] - ETA: 6:20 - loss: 0.6914 - acc: 0.5251
1536/9333 [===>..........................] - ETA: 6:18 - loss: 0.6917 - acc: 0.5241
1600/9333 [====>.........................] - ETA: 6:18 - loss: 0.6906 - acc: 0.5281
1664/9333 [====>.........................] - ETA: 6:14 - loss: 0.6908 - acc: 0.5288
1728/9333 [====>.........................] - ETA: 6:10 - loss: 0.6895 - acc: 0.5312
1792/9333 [====>.........................] - ETA: 6:07 - loss: 0.6897 - acc: 0.5307
1856/9333 [====>.........................] - ETA: 6:03 - loss: 0.6892 - acc: 0.5329
1920/9333 [=====>........................] - ETA: 5:59 - loss: 0.6903 - acc: 0.5286
1984/9333 [=====>........................] - ETA: 5:55 - loss: 0.6909 - acc: 0.5307
2048/9333 [=====>........................] - ETA: 5:52 - loss: 0.6912 - acc: 0.5298
2112/9333 [=====>........................] - ETA: 5:48 - loss: 0.6914 - acc: 0.5294
2176/9333 [=====>........................] - ETA: 5:45 - loss: 0.6925 - acc: 0.5267
2240/9333 [======>.......................] - ETA: 5:42 - loss: 0.6918 - acc: 0.5286
2304/9333 [======>.......................] - ETA: 5:39 - loss: 0.6931 - acc: 0.5260
2368/9333 [======>.......................] - ETA: 5:36 - loss: 0.6916 - acc: 0.5287
2432/9333 [======>.......................] - ETA: 5:32 - loss: 0.6924 - acc: 0.5267
2496/9333 [=======>......................] - ETA: 5:29 - loss: 0.6929 - acc: 0.5260
2560/9333 [=======>......................] - ETA: 5:26 - loss: 0.6929 - acc: 0.5262
2624/9333 [=======>......................] - ETA: 5:24 - loss: 0.6935 - acc: 0.5240
2688/9333 [=======>......................] - ETA: 5:20 - loss: 0.6938 - acc: 0.5227
2752/9333 [=======>......................] - ETA: 5:18 - loss: 0.6941 - acc: 0.5207
2816/9333 [========>.....................] - ETA: 5:14 - loss: 0.6939 - acc: 0.5213
2880/9333 [========>.....................] - ETA: 5:11 - loss: 0.6936 - acc: 0.5208
2944/9333 [========>.....................] - ETA: 5:07 - loss: 0.6935 - acc: 0.5200
3008/9333 [========>.....................] - ETA: 5:04 - loss: 0.6933 - acc: 0.5223
3072/9333 [========>.....................] - ETA: 5:02 - loss: 0.6932 - acc: 0.5228
3136/9333 [=========>....................] - ETA: 4:59 - loss: 0.6930 - acc: 0.5255
3200/9333 [=========>....................] - ETA: 4:56 - loss: 0.6929 - acc: 0.5272
3264/9333 [=========>....................] - ETA: 4:58 - loss: 0.6930 - acc: 0.5270
3328/9333 [=========>....................] - ETA: 4:55 - loss: 0.6934 - acc: 0.5255
3392/9333 [=========>....................] - ETA: 4:53 - loss: 0.6931 - acc: 0.5268
3456/9333 [==========>...................] - ETA: 4:51 - loss: 0.6937 - acc: 0.5243
3520/9333 [==========>...................] - ETA: 4:48 - loss: 0.6935 - acc: 0.5247
3584/9333 [==========>...................] - ETA: 4:44 - loss: 0.6933 - acc: 0.5251
3648/9333 [==========>...................] - ETA: 4:41 - loss: 0.6936 - acc: 0.5241
3712/9333 [==========>...................] - ETA: 4:37 - loss: 0.6940 - acc: 0.5226
3776/9333 [===========>..................] - ETA: 4:34 - loss: 0.6941 - acc: 0.5220
3840/9333 [===========>..................] - ETA: 4:30 - loss: 0.6940 - acc: 0.5219
3904/9333 [===========>..................] - ETA: 4:27 - loss: 0.6940 - acc: 0.5225
3968/9333 [===========>..................] - ETA: 4:24 - loss: 0.6942 - acc: 0.5219
4032/9333 [===========>..................] - ETA: 4:20 - loss: 0.6943 - acc: 0.5211
4096/9333 [============>.................] - ETA: 4:18 - loss: 0.6942 - acc: 0.5203
4160/9333 [============>.................] - ETA: 4:14 - loss: 0.6945 - acc: 0.5197
4224/9333 [============>.................] - ETA: 4:11 - loss: 0.6954 - acc: 0.5173
4288/9333 [============>.................] - ETA: 4:08 - loss: 0.6959 - acc: 0.5161
4352/9333 [============>.................] - ETA: 4:04 - loss: 0.6961 - acc: 0.5156
4416/9333 [=============>................] - ETA: 4:01 - loss: 0.6963 - acc: 0.5159
4480/9333 [=============>................] - ETA: 3:58 - loss: 0.6961 - acc: 0.5167
4544/9333 [=============>................] - ETA: 3:55 - loss: 0.6961 - acc: 0.5172
4608/9333 [=============>................] - ETA: 3:52 - loss: 0.6960 - acc: 0.5180
4672/9333 [==============>...............] - ETA: 3:48 - loss: 0.6962 - acc: 0.5169
4736/9333 [==============>...............] - ETA: 3:45 - loss: 0.6960 - acc: 0.5175
4800/9333 [==============>...............] - ETA: 3:42 - loss: 0.6960 - acc: 0.5179
4864/9333 [==============>...............] - ETA: 3:39 - loss: 0.6958 - acc: 0.5181
4928/9333 [==============>...............] - ETA: 3:36 - loss: 0.6959 - acc: 0.5175
4992/9333 [===============>..............] - ETA: 3:33 - loss: 0.6960 - acc: 0.5170
5056/9333 [===============>..............] - ETA: 3:29 - loss: 0.6959 - acc: 0.5172
5120/9333 [===============>..............] - ETA: 3:26 - loss: 0.6963 - acc: 0.5154
5184/9333 [===============>..............] - ETA: 3:23 - loss: 0.6962 - acc: 0.5158
5248/9333 [===============>..............] - ETA: 3:20 - loss: 0.6963 - acc: 0.5158
5312/9333 [================>.............] - ETA: 3:17 - loss: 0.6964 - acc: 0.5154
5376/9333 [================>.............] - ETA: 3:14 - loss: 0.6963 - acc: 0.5154
5440/9333 [================>.............] - ETA: 3:10 - loss: 0.6962 - acc: 0.5154
5504/9333 [================>.............] - ETA: 3:07 - loss: 0.6960 - acc: 0.5160
5568/9333 [================>.............] - ETA: 3:04 - loss: 0.6960 - acc: 0.5154
5632/9333 [=================>............] - ETA: 3:01 - loss: 0.6959 - acc: 0.5140
5696/9333 [=================>............] - ETA: 2:57 - loss: 0.6960 - acc: 0.5137
5760/9333 [=================>............] - ETA: 2:54 - loss: 0.6958 - acc: 0.5139
5824/9333 [=================>............] - ETA: 2:51 - loss: 0.6957 - acc: 0.5146
5888/9333 [=================>............] - ETA: 2:48 - loss: 0.6956 - acc: 0.5144
5952/9333 [==================>...........] - ETA: 2:45 - loss: 0.6956 - acc: 0.5134
6016/9333 [==================>...........] - ETA: 2:42 - loss: 0.6954 - acc: 0.5141
6080/9333 [==================>...........] - ETA: 2:39 - loss: 0.6954 - acc: 0.5145
6144/9333 [==================>...........] - ETA: 2:36 - loss: 0.6954 - acc: 0.5146
6208/9333 [==================>...........] - ETA: 2:32 - loss: 0.6954 - acc: 0.5147
6272/9333 [===================>..........] - ETA: 2:29 - loss: 0.6954 - acc: 0.5142
6336/9333 [===================>..........] - ETA: 2:26 - loss: 0.6956 - acc: 0.5137
6400/9333 [===================>..........] - ETA: 2:23 - loss: 0.6955 - acc: 0.5139
6464/9333 [===================>..........] - ETA: 2:20 - loss: 0.6957 - acc: 0.5135
6528/9333 [===================>..........] - ETA: 2:17 - loss: 0.6959 - acc: 0.5124
6592/9333 [====================>.........] - ETA: 2:13 - loss: 0.6958 - acc: 0.5132
6656/9333 [====================>.........] - ETA: 2:10 - loss: 0.6957 - acc: 0.5134
6720/9333 [====================>.........] - ETA: 2:07 - loss: 0.6955 - acc: 0.5143
6784/9333 [====================>.........] - ETA: 2:04 - loss: 0.6953 - acc: 0.5149
6848/9333 [=====================>........] - ETA: 2:01 - loss: 0.6952 - acc: 0.5147
6912/9333 [=====================>........] - ETA: 1:58 - loss: 0.6952 - acc: 0.5148
6976/9333 [=====================>........] - ETA: 1:55 - loss: 0.6953 - acc: 0.5146
7040/9333 [=====================>........] - ETA: 1:52 - loss: 0.6954 - acc: 0.5138
7104/9333 [=====================>........] - ETA: 1:48 - loss: 0.6952 - acc: 0.5145
7168/9333 [======================>.......] - ETA: 1:45 - loss: 0.6953 - acc: 0.5146
7232/9333 [======================>.......] - ETA: 1:42 - loss: 0.6950 - acc: 0.5156
7296/9333 [======================>.......] - ETA: 1:39 - loss: 0.6950 - acc: 0.5154
7360/9333 [======================>.......] - ETA: 1:36 - loss: 0.6951 - acc: 0.5145
7424/9333 [======================>.......] - ETA: 1:33 - loss: 0.6950 - acc: 0.5145
7488/9333 [=======================>......] - ETA: 1:30 - loss: 0.6950 - acc: 0.5147
7552/9333 [=======================>......] - ETA: 1:26 - loss: 0.6949 - acc: 0.5146
7616/9333 [=======================>......] - ETA: 1:23 - loss: 0.6950 - acc: 0.5143
7680/9333 [=======================>......] - ETA: 1:20 - loss: 0.6949 - acc: 0.5141
7744/9333 [=======================>......] - ETA: 1:17 - loss: 0.6949 - acc: 0.5145
7808/9333 [========================>.....] - ETA: 1:14 - loss: 0.6950 - acc: 0.5145
7872/9333 [========================>.....] - ETA: 1:11 - loss: 0.6950 - acc: 0.5142
7936/9333 [========================>.....] - ETA: 1:08 - loss: 0.6950 - acc: 0.5144
8000/9333 [========================>.....] - ETA: 1:05 - loss: 0.6951 - acc: 0.5136
8064/9333 [========================>.....] - ETA: 1:01 - loss: 0.6951 - acc: 0.5139
8128/9333 [=========================>....] - ETA: 58s - loss: 0.6952 - acc: 0.5135 
8192/9333 [=========================>....] - ETA: 55s - loss: 0.6954 - acc: 0.5133
8256/9333 [=========================>....] - ETA: 52s - loss: 0.6954 - acc: 0.5137
8320/9333 [=========================>....] - ETA: 49s - loss: 0.6950 - acc: 0.5148
8384/9333 [=========================>....] - ETA: 46s - loss: 0.6951 - acc: 0.5147
8448/9333 [==========================>...] - ETA: 43s - loss: 0.6950 - acc: 0.5150
8512/9333 [==========================>...] - ETA: 40s - loss: 0.6949 - acc: 0.5155
8576/9333 [==========================>...] - ETA: 37s - loss: 0.6949 - acc: 0.5157
8640/9333 [==========================>...] - ETA: 34s - loss: 0.6949 - acc: 0.5161
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6949 - acc: 0.5165
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6948 - acc: 0.5167
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6946 - acc: 0.5174
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6946 - acc: 0.5173
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6944 - acc: 0.5179
9024/9333 [============================>.] - ETA: 15s - loss: 0.6942 - acc: 0.5184
9088/9333 [============================>.] - ETA: 12s - loss: 0.6940 - acc: 0.5187
9152/9333 [============================>.] - ETA: 8s - loss: 0.6939 - acc: 0.5193 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6938 - acc: 0.5203
9280/9333 [============================>.] - ETA: 2s - loss: 0.6936 - acc: 0.5206
9333/9333 [==============================] - 479s 51ms/step - loss: 0.6936 - acc: 0.5203 - val_loss: 0.6938 - val_acc: 0.5352

Epoch 00003: val_acc did not improve from 0.54773
Epoch 4/10

  64/9333 [..............................] - ETA: 8:11 - loss: 0.7033 - acc: 0.5469
 128/9333 [..............................] - ETA: 8:05 - loss: 0.6915 - acc: 0.5703
 192/9333 [..............................] - ETA: 7:47 - loss: 0.6929 - acc: 0.5781
 256/9333 [..............................] - ETA: 7:38 - loss: 0.6933 - acc: 0.5586
 320/9333 [>.............................] - ETA: 7:31 - loss: 0.6883 - acc: 0.5563
 384/9333 [>.............................] - ETA: 7:38 - loss: 0.6903 - acc: 0.5547
 448/9333 [>.............................] - ETA: 7:29 - loss: 0.6931 - acc: 0.5558
 512/9333 [>.............................] - ETA: 7:23 - loss: 0.6962 - acc: 0.5469
 576/9333 [>.............................] - ETA: 7:26 - loss: 0.6958 - acc: 0.5451
 640/9333 [=>............................] - ETA: 7:28 - loss: 0.6984 - acc: 0.5391
 704/9333 [=>............................] - ETA: 7:29 - loss: 0.6975 - acc: 0.5426
 768/9333 [=>............................] - ETA: 7:24 - loss: 0.6961 - acc: 0.5391
 832/9333 [=>............................] - ETA: 7:21 - loss: 0.6947 - acc: 0.5373
 896/9333 [=>............................] - ETA: 7:17 - loss: 0.6928 - acc: 0.5435
 960/9333 [==>...........................] - ETA: 7:12 - loss: 0.6915 - acc: 0.5490
1024/9333 [==>...........................] - ETA: 7:05 - loss: 0.6908 - acc: 0.5527
1088/9333 [==>...........................] - ETA: 7:01 - loss: 0.6912 - acc: 0.5551
1152/9333 [==>...........................] - ETA: 6:57 - loss: 0.6906 - acc: 0.5564
1216/9333 [==>...........................] - ETA: 6:52 - loss: 0.6902 - acc: 0.5559
1280/9333 [===>..........................] - ETA: 6:51 - loss: 0.6892 - acc: 0.5594
1344/9333 [===>..........................] - ETA: 6:55 - loss: 0.6880 - acc: 0.5580
1408/9333 [===>..........................] - ETA: 6:56 - loss: 0.6883 - acc: 0.5540
1472/9333 [===>..........................] - ETA: 6:50 - loss: 0.6874 - acc: 0.5571
1536/9333 [===>..........................] - ETA: 6:47 - loss: 0.6867 - acc: 0.5573
1600/9333 [====>.........................] - ETA: 6:44 - loss: 0.6868 - acc: 0.5569
1664/9333 [====>.........................] - ETA: 6:41 - loss: 0.6879 - acc: 0.5529
1728/9333 [====>.........................] - ETA: 6:38 - loss: 0.6874 - acc: 0.5538
1792/9333 [====>.........................] - ETA: 6:36 - loss: 0.6885 - acc: 0.5485
1856/9333 [====>.........................] - ETA: 6:32 - loss: 0.6891 - acc: 0.5490
1920/9333 [=====>........................] - ETA: 6:28 - loss: 0.6903 - acc: 0.5458
1984/9333 [=====>........................] - ETA: 6:23 - loss: 0.6909 - acc: 0.5433
2048/9333 [=====>........................] - ETA: 6:19 - loss: 0.6905 - acc: 0.5464
2112/9333 [=====>........................] - ETA: 6:15 - loss: 0.6910 - acc: 0.5455
2176/9333 [=====>........................] - ETA: 6:12 - loss: 0.6906 - acc: 0.5469
2240/9333 [======>.......................] - ETA: 6:09 - loss: 0.6904 - acc: 0.5464
2304/9333 [======>.......................] - ETA: 6:06 - loss: 0.6903 - acc: 0.5443
2368/9333 [======>.......................] - ETA: 6:03 - loss: 0.6895 - acc: 0.5469
2432/9333 [======>.......................] - ETA: 6:00 - loss: 0.6896 - acc: 0.5461
2496/9333 [=======>......................] - ETA: 5:57 - loss: 0.6890 - acc: 0.5485
2560/9333 [=======>......................] - ETA: 5:54 - loss: 0.6890 - acc: 0.5484
2624/9333 [=======>......................] - ETA: 5:50 - loss: 0.6884 - acc: 0.5503
2688/9333 [=======>......................] - ETA: 5:46 - loss: 0.6885 - acc: 0.5484
2752/9333 [=======>......................] - ETA: 5:42 - loss: 0.6883 - acc: 0.5483
2816/9333 [========>.....................] - ETA: 5:39 - loss: 0.6879 - acc: 0.5497
2880/9333 [========>.....................] - ETA: 5:35 - loss: 0.6876 - acc: 0.5503
2944/9333 [========>.....................] - ETA: 5:33 - loss: 0.6879 - acc: 0.5496
3008/9333 [========>.....................] - ETA: 5:29 - loss: 0.6881 - acc: 0.5485
3072/9333 [========>.....................] - ETA: 5:25 - loss: 0.6883 - acc: 0.5482
3136/9333 [=========>....................] - ETA: 5:21 - loss: 0.6888 - acc: 0.5462
3200/9333 [=========>....................] - ETA: 5:17 - loss: 0.6887 - acc: 0.5466
3264/9333 [=========>....................] - ETA: 5:14 - loss: 0.6885 - acc: 0.5463
3328/9333 [=========>....................] - ETA: 5:12 - loss: 0.6885 - acc: 0.5472
3392/9333 [=========>....................] - ETA: 5:09 - loss: 0.6886 - acc: 0.5460
3456/9333 [==========>...................] - ETA: 5:05 - loss: 0.6886 - acc: 0.5469
3520/9333 [==========>...................] - ETA: 5:01 - loss: 0.6883 - acc: 0.5483
3584/9333 [==========>...................] - ETA: 4:57 - loss: 0.6877 - acc: 0.5488
3648/9333 [==========>...................] - ETA: 4:54 - loss: 0.6879 - acc: 0.5485
3712/9333 [==========>...................] - ETA: 4:50 - loss: 0.6880 - acc: 0.5488
3776/9333 [===========>..................] - ETA: 4:47 - loss: 0.6887 - acc: 0.5469
3840/9333 [===========>..................] - ETA: 4:44 - loss: 0.6887 - acc: 0.5474
3904/9333 [===========>..................] - ETA: 4:41 - loss: 0.6889 - acc: 0.5476
3968/9333 [===========>..................] - ETA: 4:38 - loss: 0.6894 - acc: 0.5464
4032/9333 [===========>..................] - ETA: 4:34 - loss: 0.6895 - acc: 0.5459
4096/9333 [============>.................] - ETA: 4:32 - loss: 0.6899 - acc: 0.5444
4160/9333 [============>.................] - ETA: 4:28 - loss: 0.6901 - acc: 0.5428
4224/9333 [============>.................] - ETA: 4:25 - loss: 0.6900 - acc: 0.5431
4288/9333 [============>.................] - ETA: 4:22 - loss: 0.6899 - acc: 0.5436
4352/9333 [============>.................] - ETA: 4:19 - loss: 0.6899 - acc: 0.5437
4416/9333 [=============>................] - ETA: 4:15 - loss: 0.6903 - acc: 0.5421
4480/9333 [=============>................] - ETA: 4:12 - loss: 0.6904 - acc: 0.5417
4544/9333 [=============>................] - ETA: 4:09 - loss: 0.6907 - acc: 0.5401
4608/9333 [=============>................] - ETA: 4:05 - loss: 0.6904 - acc: 0.5406
4672/9333 [==============>...............] - ETA: 4:02 - loss: 0.6901 - acc: 0.5400
4736/9333 [==============>...............] - ETA: 3:59 - loss: 0.6905 - acc: 0.5389
4800/9333 [==============>...............] - ETA: 3:55 - loss: 0.6906 - acc: 0.5381
4864/9333 [==============>...............] - ETA: 3:52 - loss: 0.6905 - acc: 0.5387
4928/9333 [==============>...............] - ETA: 3:49 - loss: 0.6905 - acc: 0.5379
4992/9333 [===============>..............] - ETA: 3:45 - loss: 0.6903 - acc: 0.5379
5056/9333 [===============>..............] - ETA: 3:42 - loss: 0.6903 - acc: 0.5370
5120/9333 [===============>..............] - ETA: 3:38 - loss: 0.6899 - acc: 0.5377
5184/9333 [===============>..............] - ETA: 3:35 - loss: 0.6901 - acc: 0.5368
5248/9333 [===============>..............] - ETA: 3:32 - loss: 0.6903 - acc: 0.5356
5312/9333 [================>.............] - ETA: 3:28 - loss: 0.6906 - acc: 0.5348
5376/9333 [================>.............] - ETA: 3:25 - loss: 0.6903 - acc: 0.5361
5440/9333 [================>.............] - ETA: 3:21 - loss: 0.6903 - acc: 0.5357
5504/9333 [================>.............] - ETA: 3:18 - loss: 0.6905 - acc: 0.5356
5568/9333 [================>.............] - ETA: 3:14 - loss: 0.6903 - acc: 0.5363
5632/9333 [=================>............] - ETA: 3:11 - loss: 0.6905 - acc: 0.5353
5696/9333 [=================>............] - ETA: 3:07 - loss: 0.6903 - acc: 0.5358
5760/9333 [=================>............] - ETA: 3:04 - loss: 0.6902 - acc: 0.5365
5824/9333 [=================>............] - ETA: 3:00 - loss: 0.6899 - acc: 0.5367
5888/9333 [=================>............] - ETA: 2:57 - loss: 0.6899 - acc: 0.5372
5952/9333 [==================>...........] - ETA: 2:53 - loss: 0.6899 - acc: 0.5380
6016/9333 [==================>...........] - ETA: 2:50 - loss: 0.6899 - acc: 0.5377
6080/9333 [==================>...........] - ETA: 2:47 - loss: 0.6903 - acc: 0.5362
6144/9333 [==================>...........] - ETA: 2:43 - loss: 0.6903 - acc: 0.5368
6208/9333 [==================>...........] - ETA: 2:40 - loss: 0.6905 - acc: 0.5367
6272/9333 [===================>..........] - ETA: 2:36 - loss: 0.6908 - acc: 0.5359
6336/9333 [===================>..........] - ETA: 2:33 - loss: 0.6908 - acc: 0.5355
6400/9333 [===================>..........] - ETA: 2:30 - loss: 0.6908 - acc: 0.5358
6464/9333 [===================>..........] - ETA: 2:26 - loss: 0.6910 - acc: 0.5353
6528/9333 [===================>..........] - ETA: 2:23 - loss: 0.6907 - acc: 0.5362
6592/9333 [====================>.........] - ETA: 2:20 - loss: 0.6908 - acc: 0.5358
6656/9333 [====================>.........] - ETA: 2:16 - loss: 0.6910 - acc: 0.5352
6720/9333 [====================>.........] - ETA: 2:13 - loss: 0.6909 - acc: 0.5356
6784/9333 [====================>.........] - ETA: 2:09 - loss: 0.6908 - acc: 0.5360
6848/9333 [=====================>........] - ETA: 2:06 - loss: 0.6908 - acc: 0.5362
6912/9333 [=====================>........] - ETA: 2:03 - loss: 0.6908 - acc: 0.5363
6976/9333 [=====================>........] - ETA: 1:59 - loss: 0.6908 - acc: 0.5360
7040/9333 [=====================>........] - ETA: 1:56 - loss: 0.6909 - acc: 0.5352
7104/9333 [=====================>........] - ETA: 1:53 - loss: 0.6910 - acc: 0.5349
7168/9333 [======================>.......] - ETA: 1:50 - loss: 0.6912 - acc: 0.5342
7232/9333 [======================>.......] - ETA: 1:46 - loss: 0.6913 - acc: 0.5339
7296/9333 [======================>.......] - ETA: 1:43 - loss: 0.6913 - acc: 0.5330
7360/9333 [======================>.......] - ETA: 1:40 - loss: 0.6913 - acc: 0.5332
7424/9333 [======================>.......] - ETA: 1:36 - loss: 0.6912 - acc: 0.5337
7488/9333 [=======================>......] - ETA: 1:33 - loss: 0.6911 - acc: 0.5339
7552/9333 [=======================>......] - ETA: 1:30 - loss: 0.6909 - acc: 0.5347
7616/9333 [=======================>......] - ETA: 1:27 - loss: 0.6909 - acc: 0.5349
7680/9333 [=======================>......] - ETA: 1:23 - loss: 0.6907 - acc: 0.5355
7744/9333 [=======================>......] - ETA: 1:20 - loss: 0.6906 - acc: 0.5363
7808/9333 [========================>.....] - ETA: 1:17 - loss: 0.6906 - acc: 0.5364
7872/9333 [========================>.....] - ETA: 1:13 - loss: 0.6905 - acc: 0.5366
7936/9333 [========================>.....] - ETA: 1:10 - loss: 0.6907 - acc: 0.5353
8000/9333 [========================>.....] - ETA: 1:07 - loss: 0.6909 - acc: 0.5349
8064/9333 [========================>.....] - ETA: 1:04 - loss: 0.6909 - acc: 0.5347
8128/9333 [=========================>....] - ETA: 1:00 - loss: 0.6908 - acc: 0.5348
8192/9333 [=========================>....] - ETA: 57s - loss: 0.6907 - acc: 0.5349 
8256/9333 [=========================>....] - ETA: 54s - loss: 0.6907 - acc: 0.5350
8320/9333 [=========================>....] - ETA: 51s - loss: 0.6906 - acc: 0.5351
8384/9333 [=========================>....] - ETA: 47s - loss: 0.6906 - acc: 0.5349
8448/9333 [==========================>...] - ETA: 44s - loss: 0.6907 - acc: 0.5348
8512/9333 [==========================>...] - ETA: 41s - loss: 0.6907 - acc: 0.5342
8576/9333 [==========================>...] - ETA: 38s - loss: 0.6907 - acc: 0.5337
8640/9333 [==========================>...] - ETA: 34s - loss: 0.6908 - acc: 0.5332
8704/9333 [==========================>...] - ETA: 31s - loss: 0.6906 - acc: 0.5340
8768/9333 [===========================>..] - ETA: 28s - loss: 0.6905 - acc: 0.5342
8832/9333 [===========================>..] - ETA: 25s - loss: 0.6905 - acc: 0.5345
8896/9333 [===========================>..] - ETA: 22s - loss: 0.6905 - acc: 0.5350
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6904 - acc: 0.5355
9024/9333 [============================>.] - ETA: 15s - loss: 0.6905 - acc: 0.5348
9088/9333 [============================>.] - ETA: 12s - loss: 0.6906 - acc: 0.5342
9152/9333 [============================>.] - ETA: 9s - loss: 0.6906 - acc: 0.5338 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6907 - acc: 0.5340
9280/9333 [============================>.] - ETA: 2s - loss: 0.6906 - acc: 0.5346
9333/9333 [==============================] - 488s 52ms/step - loss: 0.6908 - acc: 0.5338 - val_loss: 0.6830 - val_acc: 0.5506

Epoch 00004: val_acc improved from 0.54773 to 0.55063, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window08/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 5/10

  64/9333 [..............................] - ETA: 7:07 - loss: 0.6803 - acc: 0.5781
 128/9333 [..............................] - ETA: 7:11 - loss: 0.6856 - acc: 0.5703
 192/9333 [..............................] - ETA: 7:07 - loss: 0.6839 - acc: 0.5573
 256/9333 [..............................] - ETA: 7:22 - loss: 0.6915 - acc: 0.5508
 320/9333 [>.............................] - ETA: 7:18 - loss: 0.6912 - acc: 0.5375
 384/9333 [>.............................] - ETA: 7:19 - loss: 0.6897 - acc: 0.5260
 448/9333 [>.............................] - ETA: 7:12 - loss: 0.6941 - acc: 0.5223
 512/9333 [>.............................] - ETA: 7:07 - loss: 0.6940 - acc: 0.5254
 576/9333 [>.............................] - ETA: 7:03 - loss: 0.6931 - acc: 0.5312
 640/9333 [=>............................] - ETA: 6:59 - loss: 0.6932 - acc: 0.5297
 704/9333 [=>............................] - ETA: 6:53 - loss: 0.6920 - acc: 0.5355
 768/9333 [=>............................] - ETA: 6:52 - loss: 0.6940 - acc: 0.5326
 832/9333 [=>............................] - ETA: 6:47 - loss: 0.6936 - acc: 0.5337
 896/9333 [=>............................] - ETA: 6:44 - loss: 0.6936 - acc: 0.5335
 960/9333 [==>...........................] - ETA: 6:41 - loss: 0.6926 - acc: 0.5406
1024/9333 [==>...........................] - ETA: 6:39 - loss: 0.6930 - acc: 0.5410
1088/9333 [==>...........................] - ETA: 6:35 - loss: 0.6924 - acc: 0.5404
1152/9333 [==>...........................] - ETA: 6:35 - loss: 0.6926 - acc: 0.5382
1216/9333 [==>...........................] - ETA: 6:31 - loss: 0.6927 - acc: 0.5403
1280/9333 [===>..........................] - ETA: 6:29 - loss: 0.6927 - acc: 0.5367
1344/9333 [===>..........................] - ETA: 6:25 - loss: 0.6918 - acc: 0.5379
1408/9333 [===>..........................] - ETA: 6:21 - loss: 0.6912 - acc: 0.5398
1472/9333 [===>..........................] - ETA: 6:17 - loss: 0.6914 - acc: 0.5401
1536/9333 [===>..........................] - ETA: 6:14 - loss: 0.6915 - acc: 0.5404
1600/9333 [====>.........................] - ETA: 6:11 - loss: 0.6919 - acc: 0.5406
1664/9333 [====>.........................] - ETA: 6:09 - loss: 0.6912 - acc: 0.5421
1728/9333 [====>.........................] - ETA: 6:05 - loss: 0.6922 - acc: 0.5394
1792/9333 [====>.........................] - ETA: 6:02 - loss: 0.6916 - acc: 0.5396
1856/9333 [====>.........................] - ETA: 5:59 - loss: 0.6905 - acc: 0.5431
1920/9333 [=====>........................] - ETA: 5:58 - loss: 0.6901 - acc: 0.5432
1984/9333 [=====>........................] - ETA: 5:55 - loss: 0.6904 - acc: 0.5418
2048/9333 [=====>........................] - ETA: 5:52 - loss: 0.6896 - acc: 0.5435
2112/9333 [=====>........................] - ETA: 5:48 - loss: 0.6904 - acc: 0.5402
2176/9333 [=====>........................] - ETA: 5:45 - loss: 0.6900 - acc: 0.5423
2240/9333 [======>.......................] - ETA: 5:42 - loss: 0.6899 - acc: 0.5424
2304/9333 [======>.......................] - ETA: 5:39 - loss: 0.6900 - acc: 0.5417
2368/9333 [======>.......................] - ETA: 5:36 - loss: 0.6902 - acc: 0.5380
2432/9333 [======>.......................] - ETA: 5:33 - loss: 0.6897 - acc: 0.5395
2496/9333 [=======>......................] - ETA: 5:30 - loss: 0.6903 - acc: 0.5397
2560/9333 [=======>......................] - ETA: 5:27 - loss: 0.6904 - acc: 0.5395
2624/9333 [=======>......................] - ETA: 5:23 - loss: 0.6901 - acc: 0.5408
2688/9333 [=======>......................] - ETA: 5:20 - loss: 0.6907 - acc: 0.5391
2752/9333 [=======>......................] - ETA: 5:17 - loss: 0.6899 - acc: 0.5411
2816/9333 [========>.....................] - ETA: 5:14 - loss: 0.6898 - acc: 0.5419
2880/9333 [========>.....................] - ETA: 5:11 - loss: 0.6896 - acc: 0.5420
2944/9333 [========>.....................] - ETA: 5:08 - loss: 0.6899 - acc: 0.5411
3008/9333 [========>.....................] - ETA: 5:05 - loss: 0.6902 - acc: 0.5409
3072/9333 [========>.....................] - ETA: 5:01 - loss: 0.6897 - acc: 0.5410
3136/9333 [=========>....................] - ETA: 4:58 - loss: 0.6901 - acc: 0.5399
3200/9333 [=========>....................] - ETA: 4:56 - loss: 0.6898 - acc: 0.5400
3264/9333 [=========>....................] - ETA: 4:53 - loss: 0.6898 - acc: 0.5401
3328/9333 [=========>....................] - ETA: 4:50 - loss: 0.6899 - acc: 0.5412
3392/9333 [=========>....................] - ETA: 4:47 - loss: 0.6897 - acc: 0.5413
3456/9333 [==========>...................] - ETA: 4:44 - loss: 0.6901 - acc: 0.5408
3520/9333 [==========>...................] - ETA: 4:40 - loss: 0.6899 - acc: 0.5406
3584/9333 [==========>...................] - ETA: 4:38 - loss: 0.6904 - acc: 0.5382
3648/9333 [==========>...................] - ETA: 4:35 - loss: 0.6902 - acc: 0.5397
3712/9333 [==========>...................] - ETA: 4:32 - loss: 0.6901 - acc: 0.5391
3776/9333 [===========>..................] - ETA: 4:29 - loss: 0.6899 - acc: 0.5403
3840/9333 [===========>..................] - ETA: 4:25 - loss: 0.6902 - acc: 0.5380
3904/9333 [===========>..................] - ETA: 4:22 - loss: 0.6899 - acc: 0.5382
3968/9333 [===========>..................] - ETA: 4:19 - loss: 0.6899 - acc: 0.5383
4032/9333 [===========>..................] - ETA: 4:16 - loss: 0.6898 - acc: 0.5392
4096/9333 [============>.................] - ETA: 4:13 - loss: 0.6898 - acc: 0.5386
4160/9333 [============>.................] - ETA: 4:10 - loss: 0.6895 - acc: 0.5389
4224/9333 [============>.................] - ETA: 4:07 - loss: 0.6892 - acc: 0.5398
4288/9333 [============>.................] - ETA: 4:04 - loss: 0.6889 - acc: 0.5415
4352/9333 [============>.................] - ETA: 4:02 - loss: 0.6884 - acc: 0.5439
4416/9333 [=============>................] - ETA: 3:59 - loss: 0.6883 - acc: 0.5442
4480/9333 [=============>................] - ETA: 3:56 - loss: 0.6884 - acc: 0.5440
4544/9333 [=============>................] - ETA: 3:53 - loss: 0.6882 - acc: 0.5445
4608/9333 [=============>................] - ETA: 3:50 - loss: 0.6884 - acc: 0.5443
4672/9333 [==============>...............] - ETA: 3:47 - loss: 0.6887 - acc: 0.5430
4736/9333 [==============>...............] - ETA: 3:44 - loss: 0.6885 - acc: 0.5443
4800/9333 [==============>...............] - ETA: 3:41 - loss: 0.6886 - acc: 0.5433
4864/9333 [==============>...............] - ETA: 3:38 - loss: 0.6886 - acc: 0.5442
4928/9333 [==============>...............] - ETA: 3:36 - loss: 0.6889 - acc: 0.5432
4992/9333 [===============>..............] - ETA: 3:33 - loss: 0.6890 - acc: 0.5433
5056/9333 [===============>..............] - ETA: 3:29 - loss: 0.6892 - acc: 0.5429
5120/9333 [===============>..............] - ETA: 3:26 - loss: 0.6894 - acc: 0.5418
5184/9333 [===============>..............] - ETA: 3:23 - loss: 0.6894 - acc: 0.5419
5248/9333 [===============>..............] - ETA: 3:21 - loss: 0.6895 - acc: 0.5419
5312/9333 [================>.............] - ETA: 3:18 - loss: 0.6891 - acc: 0.5431
5376/9333 [================>.............] - ETA: 3:15 - loss: 0.6894 - acc: 0.5424
5440/9333 [================>.............] - ETA: 3:12 - loss: 0.6896 - acc: 0.5410
5504/9333 [================>.............] - ETA: 3:08 - loss: 0.6894 - acc: 0.5411
5568/9333 [================>.............] - ETA: 3:05 - loss: 0.6894 - acc: 0.5408
5632/9333 [=================>............] - ETA: 3:02 - loss: 0.6894 - acc: 0.5408
5696/9333 [=================>............] - ETA: 2:59 - loss: 0.6893 - acc: 0.5407
5760/9333 [=================>............] - ETA: 2:56 - loss: 0.6892 - acc: 0.5413
5824/9333 [=================>............] - ETA: 2:53 - loss: 0.6888 - acc: 0.5426
5888/9333 [=================>............] - ETA: 2:50 - loss: 0.6891 - acc: 0.5414
5952/9333 [==================>...........] - ETA: 2:47 - loss: 0.6892 - acc: 0.5412
6016/9333 [==================>...........] - ETA: 2:44 - loss: 0.6892 - acc: 0.5404
6080/9333 [==================>...........] - ETA: 2:41 - loss: 0.6892 - acc: 0.5400
6144/9333 [==================>...........] - ETA: 2:38 - loss: 0.6894 - acc: 0.5394
6208/9333 [==================>...........] - ETA: 2:35 - loss: 0.6894 - acc: 0.5388
6272/9333 [===================>..........] - ETA: 2:32 - loss: 0.6897 - acc: 0.5383
6336/9333 [===================>..........] - ETA: 2:29 - loss: 0.6896 - acc: 0.5391
6400/9333 [===================>..........] - ETA: 2:26 - loss: 0.6893 - acc: 0.5395
6464/9333 [===================>..........] - ETA: 2:23 - loss: 0.6896 - acc: 0.5391
6528/9333 [===================>..........] - ETA: 2:19 - loss: 0.6895 - acc: 0.5389
6592/9333 [====================>.........] - ETA: 2:16 - loss: 0.6893 - acc: 0.5391
6656/9333 [====================>.........] - ETA: 2:13 - loss: 0.6891 - acc: 0.5391
6720/9333 [====================>.........] - ETA: 2:10 - loss: 0.6891 - acc: 0.5390
6784/9333 [====================>.........] - ETA: 2:07 - loss: 0.6891 - acc: 0.5394
6848/9333 [=====================>........] - ETA: 2:04 - loss: 0.6890 - acc: 0.5397
6912/9333 [=====================>........] - ETA: 2:00 - loss: 0.6888 - acc: 0.5408
6976/9333 [=====================>........] - ETA: 1:57 - loss: 0.6887 - acc: 0.5406
7040/9333 [=====================>........] - ETA: 1:54 - loss: 0.6888 - acc: 0.5403
7104/9333 [=====================>........] - ETA: 1:51 - loss: 0.6888 - acc: 0.5410
7168/9333 [======================>.......] - ETA: 1:47 - loss: 0.6886 - acc: 0.5410
7232/9333 [======================>.......] - ETA: 1:44 - loss: 0.6887 - acc: 0.5412
7296/9333 [======================>.......] - ETA: 1:41 - loss: 0.6885 - acc: 0.5415
7360/9333 [======================>.......] - ETA: 1:38 - loss: 0.6886 - acc: 0.5414
7424/9333 [======================>.......] - ETA: 1:34 - loss: 0.6884 - acc: 0.5422
7488/9333 [=======================>......] - ETA: 1:31 - loss: 0.6886 - acc: 0.5415
7552/9333 [=======================>......] - ETA: 1:28 - loss: 0.6888 - acc: 0.5412
7616/9333 [=======================>......] - ETA: 1:25 - loss: 0.6889 - acc: 0.5410
7680/9333 [=======================>......] - ETA: 1:22 - loss: 0.6886 - acc: 0.5414
7744/9333 [=======================>......] - ETA: 1:18 - loss: 0.6885 - acc: 0.5421
7808/9333 [========================>.....] - ETA: 1:15 - loss: 0.6887 - acc: 0.5415
7872/9333 [========================>.....] - ETA: 1:12 - loss: 0.6887 - acc: 0.5413
7936/9333 [========================>.....] - ETA: 1:09 - loss: 0.6885 - acc: 0.5418
8000/9333 [========================>.....] - ETA: 1:05 - loss: 0.6887 - acc: 0.5415
8064/9333 [========================>.....] - ETA: 1:02 - loss: 0.6887 - acc: 0.5414
8128/9333 [=========================>....] - ETA: 59s - loss: 0.6888 - acc: 0.5410 
8192/9333 [=========================>....] - ETA: 56s - loss: 0.6887 - acc: 0.5415
8256/9333 [=========================>....] - ETA: 53s - loss: 0.6890 - acc: 0.5409
8320/9333 [=========================>....] - ETA: 50s - loss: 0.6890 - acc: 0.5419
8384/9333 [=========================>....] - ETA: 46s - loss: 0.6890 - acc: 0.5415
8448/9333 [==========================>...] - ETA: 43s - loss: 0.6892 - acc: 0.5410
8512/9333 [==========================>...] - ETA: 40s - loss: 0.6890 - acc: 0.5410
8576/9333 [==========================>...] - ETA: 37s - loss: 0.6890 - acc: 0.5410
8640/9333 [==========================>...] - ETA: 34s - loss: 0.6891 - acc: 0.5404
8704/9333 [==========================>...] - ETA: 31s - loss: 0.6892 - acc: 0.5402
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6892 - acc: 0.5401
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6891 - acc: 0.5397
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6891 - acc: 0.5398
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6891 - acc: 0.5403
9024/9333 [============================>.] - ETA: 15s - loss: 0.6891 - acc: 0.5398
9088/9333 [============================>.] - ETA: 12s - loss: 0.6890 - acc: 0.5401
9152/9333 [============================>.] - ETA: 8s - loss: 0.6891 - acc: 0.5399 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6892 - acc: 0.5393
9280/9333 [============================>.] - ETA: 2s - loss: 0.6894 - acc: 0.5383
9333/9333 [==============================] - 481s 52ms/step - loss: 0.6894 - acc: 0.5381 - val_loss: 0.6841 - val_acc: 0.5593

Epoch 00005: val_acc improved from 0.55063 to 0.55931, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window08/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 6/10

  64/9333 [..............................] - ETA: 7:10 - loss: 0.7001 - acc: 0.4844
 128/9333 [..............................] - ETA: 7:48 - loss: 0.6993 - acc: 0.4844
 192/9333 [..............................] - ETA: 7:38 - loss: 0.6812 - acc: 0.5625
 256/9333 [..............................] - ETA: 7:36 - loss: 0.6817 - acc: 0.5430
 320/9333 [>.............................] - ETA: 7:26 - loss: 0.6796 - acc: 0.5625
 384/9333 [>.............................] - ETA: 7:21 - loss: 0.6792 - acc: 0.5547
 448/9333 [>.............................] - ETA: 7:11 - loss: 0.6782 - acc: 0.5536
 512/9333 [>.............................] - ETA: 7:07 - loss: 0.6792 - acc: 0.5449
 576/9333 [>.............................] - ETA: 7:12 - loss: 0.6824 - acc: 0.5417
 640/9333 [=>............................] - ETA: 7:20 - loss: 0.6838 - acc: 0.5406
 704/9333 [=>............................] - ETA: 7:24 - loss: 0.6815 - acc: 0.5483
 768/9333 [=>............................] - ETA: 7:20 - loss: 0.6834 - acc: 0.5430
 832/9333 [=>............................] - ETA: 7:13 - loss: 0.6852 - acc: 0.5361
 896/9333 [=>............................] - ETA: 7:13 - loss: 0.6865 - acc: 0.5290
 960/9333 [==>...........................] - ETA: 7:11 - loss: 0.6876 - acc: 0.5281
1024/9333 [==>...........................] - ETA: 7:09 - loss: 0.6875 - acc: 0.5244
1088/9333 [==>...........................] - ETA: 7:03 - loss: 0.6853 - acc: 0.5303
1152/9333 [==>...........................] - ETA: 6:59 - loss: 0.6848 - acc: 0.5339
1216/9333 [==>...........................] - ETA: 6:53 - loss: 0.6844 - acc: 0.5321
1280/9333 [===>..........................] - ETA: 6:52 - loss: 0.6839 - acc: 0.5367
1344/9333 [===>..........................] - ETA: 6:47 - loss: 0.6834 - acc: 0.5379
1408/9333 [===>..........................] - ETA: 6:43 - loss: 0.6843 - acc: 0.5369
1472/9333 [===>..........................] - ETA: 6:37 - loss: 0.6831 - acc: 0.5414
1536/9333 [===>..........................] - ETA: 6:33 - loss: 0.6816 - acc: 0.5462
1600/9333 [====>.........................] - ETA: 6:29 - loss: 0.6808 - acc: 0.5500
1664/9333 [====>.........................] - ETA: 6:29 - loss: 0.6818 - acc: 0.5475
1728/9333 [====>.........................] - ETA: 6:28 - loss: 0.6828 - acc: 0.5463
1792/9333 [====>.........................] - ETA: 6:27 - loss: 0.6818 - acc: 0.5502
1856/9333 [====>.........................] - ETA: 6:25 - loss: 0.6820 - acc: 0.5523
1920/9333 [=====>........................] - ETA: 6:21 - loss: 0.6839 - acc: 0.5474
1984/9333 [=====>........................] - ETA: 6:16 - loss: 0.6833 - acc: 0.5489
2048/9333 [=====>........................] - ETA: 6:13 - loss: 0.6833 - acc: 0.5493
2112/9333 [=====>........................] - ETA: 6:09 - loss: 0.6840 - acc: 0.5488
2176/9333 [=====>........................] - ETA: 6:08 - loss: 0.6848 - acc: 0.5455
2240/9333 [======>.......................] - ETA: 6:04 - loss: 0.6854 - acc: 0.5420
2304/9333 [======>.......................] - ETA: 6:01 - loss: 0.6859 - acc: 0.5404
2368/9333 [======>.......................] - ETA: 5:58 - loss: 0.6866 - acc: 0.5389
2432/9333 [======>.......................] - ETA: 5:55 - loss: 0.6864 - acc: 0.5382
2496/9333 [=======>......................] - ETA: 5:51 - loss: 0.6860 - acc: 0.5401
2560/9333 [=======>......................] - ETA: 5:47 - loss: 0.6866 - acc: 0.5406
2624/9333 [=======>......................] - ETA: 5:43 - loss: 0.6865 - acc: 0.5427
2688/9333 [=======>......................] - ETA: 5:40 - loss: 0.6861 - acc: 0.5439
2752/9333 [=======>......................] - ETA: 5:37 - loss: 0.6861 - acc: 0.5425
2816/9333 [========>.....................] - ETA: 5:34 - loss: 0.6856 - acc: 0.5451
2880/9333 [========>.....................] - ETA: 5:30 - loss: 0.6853 - acc: 0.5458
2944/9333 [========>.....................] - ETA: 5:27 - loss: 0.6852 - acc: 0.5459
3008/9333 [========>.....................] - ETA: 5:23 - loss: 0.6852 - acc: 0.5469
3072/9333 [========>.....................] - ETA: 5:21 - loss: 0.6852 - acc: 0.5475
3136/9333 [=========>....................] - ETA: 5:17 - loss: 0.6851 - acc: 0.5475
3200/9333 [=========>....................] - ETA: 5:13 - loss: 0.6848 - acc: 0.5484
3264/9333 [=========>....................] - ETA: 5:09 - loss: 0.6847 - acc: 0.5490
3328/9333 [=========>....................] - ETA: 5:06 - loss: 0.6850 - acc: 0.5484
3392/9333 [=========>....................] - ETA: 5:03 - loss: 0.6852 - acc: 0.5472
3456/9333 [==========>...................] - ETA: 4:59 - loss: 0.6852 - acc: 0.5463
3520/9333 [==========>...................] - ETA: 4:57 - loss: 0.6851 - acc: 0.5455
3584/9333 [==========>...................] - ETA: 4:54 - loss: 0.6847 - acc: 0.5463
3648/9333 [==========>...................] - ETA: 4:50 - loss: 0.6847 - acc: 0.5458
3712/9333 [==========>...................] - ETA: 4:47 - loss: 0.6850 - acc: 0.5458
3776/9333 [===========>..................] - ETA: 4:44 - loss: 0.6855 - acc: 0.5453
3840/9333 [===========>..................] - ETA: 4:41 - loss: 0.6854 - acc: 0.5453
3904/9333 [===========>..................] - ETA: 4:38 - loss: 0.6853 - acc: 0.5456
3968/9333 [===========>..................] - ETA: 4:34 - loss: 0.6854 - acc: 0.5456
4032/9333 [===========>..................] - ETA: 4:31 - loss: 0.6855 - acc: 0.5454
4096/9333 [============>.................] - ETA: 4:27 - loss: 0.6854 - acc: 0.5454
4160/9333 [============>.................] - ETA: 4:24 - loss: 0.6861 - acc: 0.5435
4224/9333 [============>.................] - ETA: 4:21 - loss: 0.6861 - acc: 0.5436
4288/9333 [============>.................] - ETA: 4:17 - loss: 0.6861 - acc: 0.5438
4352/9333 [============>.................] - ETA: 4:14 - loss: 0.6861 - acc: 0.5434
4416/9333 [=============>................] - ETA: 4:11 - loss: 0.6861 - acc: 0.5437
4480/9333 [=============>................] - ETA: 4:08 - loss: 0.6856 - acc: 0.5462
4544/9333 [=============>................] - ETA: 4:04 - loss: 0.6857 - acc: 0.5464
4608/9333 [=============>................] - ETA: 4:01 - loss: 0.6861 - acc: 0.5449
4672/9333 [==============>...............] - ETA: 3:58 - loss: 0.6864 - acc: 0.5445
4736/9333 [==============>...............] - ETA: 3:54 - loss: 0.6864 - acc: 0.5450
4800/9333 [==============>...............] - ETA: 3:52 - loss: 0.6864 - acc: 0.5458
4864/9333 [==============>...............] - ETA: 3:48 - loss: 0.6867 - acc: 0.5456
4928/9333 [==============>...............] - ETA: 3:45 - loss: 0.6868 - acc: 0.5448
4992/9333 [===============>..............] - ETA: 3:42 - loss: 0.6869 - acc: 0.5445
5056/9333 [===============>..............] - ETA: 3:39 - loss: 0.6869 - acc: 0.5441
5120/9333 [===============>..............] - ETA: 3:35 - loss: 0.6870 - acc: 0.5443
5184/9333 [===============>..............] - ETA: 3:32 - loss: 0.6870 - acc: 0.5448
5248/9333 [===============>..............] - ETA: 3:29 - loss: 0.6870 - acc: 0.5448
5312/9333 [================>.............] - ETA: 3:25 - loss: 0.6870 - acc: 0.5448
5376/9333 [================>.............] - ETA: 3:22 - loss: 0.6868 - acc: 0.5456
5440/9333 [================>.............] - ETA: 3:18 - loss: 0.6869 - acc: 0.5452
5504/9333 [================>.............] - ETA: 3:15 - loss: 0.6871 - acc: 0.5441
5568/9333 [================>.............] - ETA: 3:11 - loss: 0.6871 - acc: 0.5445
5632/9333 [=================>............] - ETA: 3:08 - loss: 0.6871 - acc: 0.5446
5696/9333 [=================>............] - ETA: 3:05 - loss: 0.6872 - acc: 0.5439
5760/9333 [=================>............] - ETA: 3:02 - loss: 0.6871 - acc: 0.5446
5824/9333 [=================>............] - ETA: 2:58 - loss: 0.6871 - acc: 0.5452
5888/9333 [=================>............] - ETA: 2:55 - loss: 0.6870 - acc: 0.5460
5952/9333 [==================>...........] - ETA: 2:51 - loss: 0.6870 - acc: 0.5465
6016/9333 [==================>...........] - ETA: 2:48 - loss: 0.6868 - acc: 0.5475
6080/9333 [==================>...........] - ETA: 2:45 - loss: 0.6868 - acc: 0.5477
6144/9333 [==================>...........] - ETA: 2:41 - loss: 0.6868 - acc: 0.5477
6208/9333 [==================>...........] - ETA: 2:38 - loss: 0.6871 - acc: 0.5462
6272/9333 [===================>..........] - ETA: 2:35 - loss: 0.6875 - acc: 0.5443
6336/9333 [===================>..........] - ETA: 2:31 - loss: 0.6876 - acc: 0.5432
6400/9333 [===================>..........] - ETA: 2:28 - loss: 0.6874 - acc: 0.5447
6464/9333 [===================>..........] - ETA: 2:25 - loss: 0.6874 - acc: 0.5438
6528/9333 [===================>..........] - ETA: 2:22 - loss: 0.6875 - acc: 0.5438
6592/9333 [====================>.........] - ETA: 2:18 - loss: 0.6874 - acc: 0.5443
6656/9333 [====================>.........] - ETA: 2:15 - loss: 0.6875 - acc: 0.5440
6720/9333 [====================>.........] - ETA: 2:11 - loss: 0.6874 - acc: 0.5446
6784/9333 [====================>.........] - ETA: 2:08 - loss: 0.6874 - acc: 0.5442
6848/9333 [=====================>........] - ETA: 2:05 - loss: 0.6874 - acc: 0.5444
6912/9333 [=====================>........] - ETA: 2:01 - loss: 0.6875 - acc: 0.5438
6976/9333 [=====================>........] - ETA: 1:58 - loss: 0.6876 - acc: 0.5436
7040/9333 [=====================>........] - ETA: 1:55 - loss: 0.6875 - acc: 0.5435
7104/9333 [=====================>........] - ETA: 1:52 - loss: 0.6875 - acc: 0.5438
7168/9333 [======================>.......] - ETA: 1:48 - loss: 0.6876 - acc: 0.5442
7232/9333 [======================>.......] - ETA: 1:45 - loss: 0.6875 - acc: 0.5447
7296/9333 [======================>.......] - ETA: 1:42 - loss: 0.6875 - acc: 0.5448
7360/9333 [======================>.......] - ETA: 1:38 - loss: 0.6875 - acc: 0.5447
7424/9333 [======================>.......] - ETA: 1:35 - loss: 0.6875 - acc: 0.5449
7488/9333 [=======================>......] - ETA: 1:32 - loss: 0.6880 - acc: 0.5437
7552/9333 [=======================>......] - ETA: 1:29 - loss: 0.6880 - acc: 0.5438
7616/9333 [=======================>......] - ETA: 1:26 - loss: 0.6881 - acc: 0.5428
7680/9333 [=======================>......] - ETA: 1:22 - loss: 0.6881 - acc: 0.5432
7744/9333 [=======================>......] - ETA: 1:19 - loss: 0.6882 - acc: 0.5427
7808/9333 [========================>.....] - ETA: 1:16 - loss: 0.6880 - acc: 0.5434
7872/9333 [========================>.....] - ETA: 1:13 - loss: 0.6880 - acc: 0.5437
7936/9333 [========================>.....] - ETA: 1:09 - loss: 0.6879 - acc: 0.5437
8000/9333 [========================>.....] - ETA: 1:06 - loss: 0.6880 - acc: 0.5439
8064/9333 [========================>.....] - ETA: 1:03 - loss: 0.6879 - acc: 0.5444
8128/9333 [=========================>....] - ETA: 1:00 - loss: 0.6878 - acc: 0.5445
8192/9333 [=========================>....] - ETA: 56s - loss: 0.6879 - acc: 0.5441 
8256/9333 [=========================>....] - ETA: 53s - loss: 0.6877 - acc: 0.5446
8320/9333 [=========================>....] - ETA: 50s - loss: 0.6876 - acc: 0.5448
8384/9333 [=========================>....] - ETA: 47s - loss: 0.6876 - acc: 0.5444
8448/9333 [==========================>...] - ETA: 44s - loss: 0.6874 - acc: 0.5445
8512/9333 [==========================>...] - ETA: 40s - loss: 0.6874 - acc: 0.5443
8576/9333 [==========================>...] - ETA: 37s - loss: 0.6875 - acc: 0.5443
8640/9333 [==========================>...] - ETA: 34s - loss: 0.6874 - acc: 0.5449
8704/9333 [==========================>...] - ETA: 31s - loss: 0.6874 - acc: 0.5450
8768/9333 [===========================>..] - ETA: 28s - loss: 0.6875 - acc: 0.5445
8832/9333 [===========================>..] - ETA: 25s - loss: 0.6875 - acc: 0.5443
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6873 - acc: 0.5451
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6873 - acc: 0.5458
9024/9333 [============================>.] - ETA: 15s - loss: 0.6873 - acc: 0.5460
9088/9333 [============================>.] - ETA: 12s - loss: 0.6874 - acc: 0.5459
9152/9333 [============================>.] - ETA: 9s - loss: 0.6876 - acc: 0.5453 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6877 - acc: 0.5451
9280/9333 [============================>.] - ETA: 2s - loss: 0.6876 - acc: 0.5459
9333/9333 [==============================] - 484s 52ms/step - loss: 0.6877 - acc: 0.5458 - val_loss: 0.6971 - val_acc: 0.5227

Epoch 00006: val_acc did not improve from 0.55931
Epoch 7/10

  64/9333 [..............................] - ETA: 7:26 - loss: 0.6731 - acc: 0.5469
 128/9333 [..............................] - ETA: 7:36 - loss: 0.6940 - acc: 0.5234
 192/9333 [..............................] - ETA: 7:20 - loss: 0.6927 - acc: 0.5312
 256/9333 [..............................] - ETA: 7:16 - loss: 0.6914 - acc: 0.5391
 320/9333 [>.............................] - ETA: 7:11 - loss: 0.6877 - acc: 0.5469
 384/9333 [>.............................] - ETA: 7:11 - loss: 0.6897 - acc: 0.5521
 448/9333 [>.............................] - ETA: 7:00 - loss: 0.6902 - acc: 0.5580
 512/9333 [>.............................] - ETA: 7:01 - loss: 0.6885 - acc: 0.5605
 576/9333 [>.............................] - ETA: 7:41 - loss: 0.6910 - acc: 0.5538
 640/9333 [=>............................] - ETA: 7:34 - loss: 0.6918 - acc: 0.5500
 704/9333 [=>............................] - ETA: 7:35 - loss: 0.6911 - acc: 0.5483
 768/9333 [=>............................] - ETA: 7:39 - loss: 0.6923 - acc: 0.5417
 832/9333 [=>............................] - ETA: 7:29 - loss: 0.6899 - acc: 0.5481
 896/9333 [=>............................] - ETA: 7:21 - loss: 0.6870 - acc: 0.5558
 960/9333 [==>...........................] - ETA: 7:16 - loss: 0.6896 - acc: 0.5479
1024/9333 [==>...........................] - ETA: 7:14 - loss: 0.6896 - acc: 0.5498
1088/9333 [==>...........................] - ETA: 7:08 - loss: 0.6880 - acc: 0.5515
1152/9333 [==>...........................] - ETA: 7:03 - loss: 0.6867 - acc: 0.5556
1216/9333 [==>...........................] - ETA: 6:56 - loss: 0.6874 - acc: 0.5543
1280/9333 [===>..........................] - ETA: 6:50 - loss: 0.6876 - acc: 0.5539
1344/9333 [===>..........................] - ETA: 6:43 - loss: 0.6877 - acc: 0.5528
1408/9333 [===>..........................] - ETA: 6:39 - loss: 0.6877 - acc: 0.5526
1472/9333 [===>..........................] - ETA: 6:33 - loss: 0.6889 - acc: 0.5516
1536/9333 [===>..........................] - ETA: 6:27 - loss: 0.6890 - acc: 0.5488
1600/9333 [====>.........................] - ETA: 6:22 - loss: 0.6894 - acc: 0.5487
1664/9333 [====>.........................] - ETA: 6:17 - loss: 0.6882 - acc: 0.5541
1728/9333 [====>.........................] - ETA: 6:12 - loss: 0.6888 - acc: 0.5486
1792/9333 [====>.........................] - ETA: 6:08 - loss: 0.6887 - acc: 0.5485
1856/9333 [====>.........................] - ETA: 6:03 - loss: 0.6883 - acc: 0.5480
1920/9333 [=====>........................] - ETA: 5:59 - loss: 0.6881 - acc: 0.5464
1984/9333 [=====>........................] - ETA: 5:55 - loss: 0.6876 - acc: 0.5484
2048/9333 [=====>........................] - ETA: 5:51 - loss: 0.6872 - acc: 0.5527
2112/9333 [=====>........................] - ETA: 5:47 - loss: 0.6875 - acc: 0.5511
2176/9333 [=====>........................] - ETA: 5:43 - loss: 0.6869 - acc: 0.5528
2240/9333 [======>.......................] - ETA: 5:39 - loss: 0.6868 - acc: 0.5527
2304/9333 [======>.......................] - ETA: 5:36 - loss: 0.6860 - acc: 0.5538
2368/9333 [======>.......................] - ETA: 5:31 - loss: 0.6862 - acc: 0.5557
2432/9333 [======>.......................] - ETA: 5:28 - loss: 0.6863 - acc: 0.5539
2496/9333 [=======>......................] - ETA: 5:24 - loss: 0.6867 - acc: 0.5541
2560/9333 [=======>......................] - ETA: 5:20 - loss: 0.6860 - acc: 0.5551
2624/9333 [=======>......................] - ETA: 5:16 - loss: 0.6857 - acc: 0.5568
2688/9333 [=======>......................] - ETA: 5:13 - loss: 0.6856 - acc: 0.5580
2752/9333 [=======>......................] - ETA: 5:08 - loss: 0.6861 - acc: 0.5560
2816/9333 [========>.....................] - ETA: 5:05 - loss: 0.6855 - acc: 0.5568
2880/9333 [========>.....................] - ETA: 5:01 - loss: 0.6862 - acc: 0.5549
2944/9333 [========>.....................] - ETA: 4:58 - loss: 0.6860 - acc: 0.5557
3008/9333 [========>.....................] - ETA: 4:55 - loss: 0.6863 - acc: 0.5535
3072/9333 [========>.....................] - ETA: 4:51 - loss: 0.6857 - acc: 0.5547
3136/9333 [=========>....................] - ETA: 4:48 - loss: 0.6857 - acc: 0.5539
3200/9333 [=========>....................] - ETA: 4:44 - loss: 0.6856 - acc: 0.5541
3264/9333 [=========>....................] - ETA: 4:43 - loss: 0.6855 - acc: 0.5530
3328/9333 [=========>....................] - ETA: 4:40 - loss: 0.6848 - acc: 0.5559
3392/9333 [=========>....................] - ETA: 4:38 - loss: 0.6852 - acc: 0.5548
3456/9333 [==========>...................] - ETA: 4:35 - loss: 0.6863 - acc: 0.5515
3520/9333 [==========>...................] - ETA: 4:32 - loss: 0.6860 - acc: 0.5520
3584/9333 [==========>...................] - ETA: 4:28 - loss: 0.6862 - acc: 0.5525
3648/9333 [==========>...................] - ETA: 4:27 - loss: 0.6859 - acc: 0.5532
3712/9333 [==========>...................] - ETA: 4:23 - loss: 0.6859 - acc: 0.5533
3776/9333 [===========>..................] - ETA: 4:20 - loss: 0.6863 - acc: 0.5516
3840/9333 [===========>..................] - ETA: 4:17 - loss: 0.6862 - acc: 0.5510
3904/9333 [===========>..................] - ETA: 4:14 - loss: 0.6861 - acc: 0.5510
3968/9333 [===========>..................] - ETA: 4:11 - loss: 0.6869 - acc: 0.5486
4032/9333 [===========>..................] - ETA: 4:08 - loss: 0.6866 - acc: 0.5491
4096/9333 [============>.................] - ETA: 4:05 - loss: 0.6865 - acc: 0.5498
4160/9333 [============>.................] - ETA: 4:02 - loss: 0.6868 - acc: 0.5481
4224/9333 [============>.................] - ETA: 3:59 - loss: 0.6866 - acc: 0.5495
4288/9333 [============>.................] - ETA: 3:56 - loss: 0.6861 - acc: 0.5501
4352/9333 [============>.................] - ETA: 3:53 - loss: 0.6856 - acc: 0.5510
4416/9333 [=============>................] - ETA: 3:50 - loss: 0.6861 - acc: 0.5500
4480/9333 [=============>................] - ETA: 3:47 - loss: 0.6863 - acc: 0.5498
4544/9333 [=============>................] - ETA: 3:44 - loss: 0.6864 - acc: 0.5493
4608/9333 [=============>................] - ETA: 3:42 - loss: 0.6866 - acc: 0.5493
4672/9333 [==============>...............] - ETA: 3:39 - loss: 0.6867 - acc: 0.5486
4736/9333 [==============>...............] - ETA: 3:36 - loss: 0.6871 - acc: 0.5473
4800/9333 [==============>...............] - ETA: 3:33 - loss: 0.6870 - acc: 0.5477
4864/9333 [==============>...............] - ETA: 3:30 - loss: 0.6871 - acc: 0.5475
4928/9333 [==============>...............] - ETA: 3:27 - loss: 0.6872 - acc: 0.5483
4992/9333 [===============>..............] - ETA: 3:24 - loss: 0.6876 - acc: 0.5465
5056/9333 [===============>..............] - ETA: 3:21 - loss: 0.6875 - acc: 0.5473
5120/9333 [===============>..............] - ETA: 3:18 - loss: 0.6879 - acc: 0.5463
5184/9333 [===============>..............] - ETA: 3:15 - loss: 0.6876 - acc: 0.5467
5248/9333 [===============>..............] - ETA: 3:12 - loss: 0.6877 - acc: 0.5461
5312/9333 [================>.............] - ETA: 3:09 - loss: 0.6876 - acc: 0.5465
5376/9333 [================>.............] - ETA: 3:06 - loss: 0.6877 - acc: 0.5461
5440/9333 [================>.............] - ETA: 3:04 - loss: 0.6878 - acc: 0.5450
5504/9333 [================>.............] - ETA: 3:01 - loss: 0.6876 - acc: 0.5460
5568/9333 [================>.............] - ETA: 2:58 - loss: 0.6877 - acc: 0.5456
5632/9333 [=================>............] - ETA: 2:55 - loss: 0.6877 - acc: 0.5453
5696/9333 [=================>............] - ETA: 2:52 - loss: 0.6878 - acc: 0.5451
5760/9333 [=================>............] - ETA: 2:50 - loss: 0.6879 - acc: 0.5446
5824/9333 [=================>............] - ETA: 2:47 - loss: 0.6880 - acc: 0.5441
5888/9333 [=================>............] - ETA: 2:44 - loss: 0.6881 - acc: 0.5438
5952/9333 [==================>...........] - ETA: 2:41 - loss: 0.6879 - acc: 0.5449
6016/9333 [==================>...........] - ETA: 2:38 - loss: 0.6879 - acc: 0.5450
6080/9333 [==================>...........] - ETA: 2:36 - loss: 0.6879 - acc: 0.5459
6144/9333 [==================>...........] - ETA: 2:33 - loss: 0.6879 - acc: 0.5461
6208/9333 [==================>...........] - ETA: 2:30 - loss: 0.6877 - acc: 0.5470
6272/9333 [===================>..........] - ETA: 2:27 - loss: 0.6878 - acc: 0.5464
6336/9333 [===================>..........] - ETA: 2:24 - loss: 0.6878 - acc: 0.5467
6400/9333 [===================>..........] - ETA: 2:21 - loss: 0.6876 - acc: 0.5470
6464/9333 [===================>..........] - ETA: 2:18 - loss: 0.6877 - acc: 0.5463
6528/9333 [===================>..........] - ETA: 2:15 - loss: 0.6875 - acc: 0.5466
6592/9333 [====================>.........] - ETA: 2:12 - loss: 0.6876 - acc: 0.5461
6656/9333 [====================>.........] - ETA: 2:09 - loss: 0.6878 - acc: 0.5454
6720/9333 [====================>.........] - ETA: 2:06 - loss: 0.6878 - acc: 0.5454
6784/9333 [====================>.........] - ETA: 2:03 - loss: 0.6878 - acc: 0.5451
6848/9333 [=====================>........] - ETA: 2:00 - loss: 0.6879 - acc: 0.5447
6912/9333 [=====================>........] - ETA: 1:57 - loss: 0.6878 - acc: 0.5447
6976/9333 [=====================>........] - ETA: 1:54 - loss: 0.6876 - acc: 0.5456
7040/9333 [=====================>........] - ETA: 1:51 - loss: 0.6875 - acc: 0.5462
7104/9333 [=====================>........] - ETA: 1:48 - loss: 0.6874 - acc: 0.5469
7168/9333 [======================>.......] - ETA: 1:45 - loss: 0.6874 - acc: 0.5465
7232/9333 [======================>.......] - ETA: 1:42 - loss: 0.6875 - acc: 0.5463
7296/9333 [======================>.......] - ETA: 1:39 - loss: 0.6877 - acc: 0.5458
7360/9333 [======================>.......] - ETA: 1:36 - loss: 0.6875 - acc: 0.5465
7424/9333 [======================>.......] - ETA: 1:33 - loss: 0.6875 - acc: 0.5471
7488/9333 [=======================>......] - ETA: 1:29 - loss: 0.6874 - acc: 0.5477
7552/9333 [=======================>......] - ETA: 1:27 - loss: 0.6875 - acc: 0.5473
7616/9333 [=======================>......] - ETA: 1:24 - loss: 0.6873 - acc: 0.5485
7680/9333 [=======================>......] - ETA: 1:20 - loss: 0.6874 - acc: 0.5486
7744/9333 [=======================>......] - ETA: 1:17 - loss: 0.6873 - acc: 0.5484
7808/9333 [========================>.....] - ETA: 1:14 - loss: 0.6875 - acc: 0.5474
7872/9333 [========================>.....] - ETA: 1:11 - loss: 0.6874 - acc: 0.5478
7936/9333 [========================>.....] - ETA: 1:08 - loss: 0.6872 - acc: 0.5483
8000/9333 [========================>.....] - ETA: 1:05 - loss: 0.6872 - acc: 0.5479
8064/9333 [========================>.....] - ETA: 1:02 - loss: 0.6871 - acc: 0.5484
8128/9333 [=========================>....] - ETA: 58s - loss: 0.6873 - acc: 0.5482 
8192/9333 [=========================>....] - ETA: 55s - loss: 0.6873 - acc: 0.5480
8256/9333 [=========================>....] - ETA: 52s - loss: 0.6873 - acc: 0.5475
8320/9333 [=========================>....] - ETA: 49s - loss: 0.6874 - acc: 0.5469
8384/9333 [=========================>....] - ETA: 46s - loss: 0.6875 - acc: 0.5464
8448/9333 [==========================>...] - ETA: 43s - loss: 0.6873 - acc: 0.5464
8512/9333 [==========================>...] - ETA: 40s - loss: 0.6876 - acc: 0.5457
8576/9333 [==========================>...] - ETA: 37s - loss: 0.6876 - acc: 0.5455
8640/9333 [==========================>...] - ETA: 34s - loss: 0.6876 - acc: 0.5457
8704/9333 [==========================>...] - ETA: 31s - loss: 0.6877 - acc: 0.5454
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6877 - acc: 0.5455
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6876 - acc: 0.5456
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6875 - acc: 0.5453
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6876 - acc: 0.5456
9024/9333 [============================>.] - ETA: 15s - loss: 0.6875 - acc: 0.5460
9088/9333 [============================>.] - ETA: 12s - loss: 0.6875 - acc: 0.5457
9152/9333 [============================>.] - ETA: 8s - loss: 0.6876 - acc: 0.5452 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6878 - acc: 0.5443
9280/9333 [============================>.] - ETA: 2s - loss: 0.6876 - acc: 0.5450
9333/9333 [==============================] - 484s 52ms/step - loss: 0.6876 - acc: 0.5448 - val_loss: 0.6830 - val_acc: 0.5526

Epoch 00007: val_acc did not improve from 0.55931
Epoch 8/10

  64/9333 [..............................] - ETA: 7:10 - loss: 0.7009 - acc: 0.5469
 128/9333 [..............................] - ETA: 8:34 - loss: 0.6939 - acc: 0.5547
 192/9333 [..............................] - ETA: 8:23 - loss: 0.6853 - acc: 0.5885
 256/9333 [..............................] - ETA: 8:09 - loss: 0.6927 - acc: 0.5430
 320/9333 [>.............................] - ETA: 7:57 - loss: 0.6922 - acc: 0.5406
 384/9333 [>.............................] - ETA: 7:56 - loss: 0.6915 - acc: 0.5365
 448/9333 [>.............................] - ETA: 7:54 - loss: 0.6906 - acc: 0.5402
 512/9333 [>.............................] - ETA: 7:53 - loss: 0.6919 - acc: 0.5352
 576/9333 [>.............................] - ETA: 7:47 - loss: 0.6911 - acc: 0.5365
 640/9333 [=>............................] - ETA: 7:41 - loss: 0.6900 - acc: 0.5375
 704/9333 [=>............................] - ETA: 7:34 - loss: 0.6928 - acc: 0.5327
 768/9333 [=>............................] - ETA: 7:29 - loss: 0.6948 - acc: 0.5260
 832/9333 [=>............................] - ETA: 7:26 - loss: 0.6915 - acc: 0.5361
 896/9333 [=>............................] - ETA: 7:23 - loss: 0.6908 - acc: 0.5357
 960/9333 [==>...........................] - ETA: 7:23 - loss: 0.6913 - acc: 0.5323
1024/9333 [==>...........................] - ETA: 7:20 - loss: 0.6899 - acc: 0.5381
1088/9333 [==>...........................] - ETA: 7:14 - loss: 0.6900 - acc: 0.5349
1152/9333 [==>...........................] - ETA: 7:10 - loss: 0.6894 - acc: 0.5391
1216/9333 [==>...........................] - ETA: 7:06 - loss: 0.6892 - acc: 0.5378
1280/9333 [===>..........................] - ETA: 7:07 - loss: 0.6892 - acc: 0.5367
1344/9333 [===>..........................] - ETA: 7:02 - loss: 0.6893 - acc: 0.5335
1408/9333 [===>..........................] - ETA: 6:59 - loss: 0.6883 - acc: 0.5355
1472/9333 [===>..........................] - ETA: 6:53 - loss: 0.6885 - acc: 0.5380
1536/9333 [===>..........................] - ETA: 6:49 - loss: 0.6882 - acc: 0.5410
1600/9333 [====>.........................] - ETA: 6:44 - loss: 0.6864 - acc: 0.5487
1664/9333 [====>.........................] - ETA: 6:39 - loss: 0.6866 - acc: 0.5493
1728/9333 [====>.........................] - ETA: 6:35 - loss: 0.6864 - acc: 0.5509
1792/9333 [====>.........................] - ETA: 6:31 - loss: 0.6866 - acc: 0.5491
1856/9333 [====>.........................] - ETA: 6:26 - loss: 0.6873 - acc: 0.5485
1920/9333 [=====>........................] - ETA: 6:22 - loss: 0.6875 - acc: 0.5505
1984/9333 [=====>........................] - ETA: 6:18 - loss: 0.6877 - acc: 0.5504
2048/9333 [=====>........................] - ETA: 6:14 - loss: 0.6870 - acc: 0.5508
2112/9333 [=====>........................] - ETA: 6:13 - loss: 0.6870 - acc: 0.5497
2176/9333 [=====>........................] - ETA: 6:09 - loss: 0.6871 - acc: 0.5492
2240/9333 [======>.......................] - ETA: 6:06 - loss: 0.6870 - acc: 0.5500
2304/9333 [======>.......................] - ETA: 6:03 - loss: 0.6873 - acc: 0.5495
2368/9333 [======>.......................] - ETA: 5:59 - loss: 0.6871 - acc: 0.5498
2432/9333 [======>.......................] - ETA: 5:57 - loss: 0.6876 - acc: 0.5481
2496/9333 [=======>......................] - ETA: 5:54 - loss: 0.6875 - acc: 0.5465
2560/9333 [=======>......................] - ETA: 5:52 - loss: 0.6874 - acc: 0.5477
2624/9333 [=======>......................] - ETA: 5:48 - loss: 0.6877 - acc: 0.5465
2688/9333 [=======>......................] - ETA: 5:44 - loss: 0.6876 - acc: 0.5480
2752/9333 [=======>......................] - ETA: 5:40 - loss: 0.6875 - acc: 0.5476
2816/9333 [========>.....................] - ETA: 5:39 - loss: 0.6876 - acc: 0.5479
2880/9333 [========>.....................] - ETA: 5:35 - loss: 0.6876 - acc: 0.5486
2944/9333 [========>.....................] - ETA: 5:33 - loss: 0.6881 - acc: 0.5476
3008/9333 [========>.....................] - ETA: 5:28 - loss: 0.6885 - acc: 0.5465
3072/9333 [========>.....................] - ETA: 5:25 - loss: 0.6880 - acc: 0.5482
3136/9333 [=========>....................] - ETA: 5:21 - loss: 0.6878 - acc: 0.5485
3200/9333 [=========>....................] - ETA: 5:18 - loss: 0.6880 - acc: 0.5487
3264/9333 [=========>....................] - ETA: 5:15 - loss: 0.6884 - acc: 0.5478
3328/9333 [=========>....................] - ETA: 5:12 - loss: 0.6883 - acc: 0.5475
3392/9333 [=========>....................] - ETA: 5:07 - loss: 0.6891 - acc: 0.5445
3456/9333 [==========>...................] - ETA: 5:03 - loss: 0.6885 - acc: 0.5460
3520/9333 [==========>...................] - ETA: 5:00 - loss: 0.6877 - acc: 0.5472
3584/9333 [==========>...................] - ETA: 4:59 - loss: 0.6877 - acc: 0.5472
3648/9333 [==========>...................] - ETA: 4:55 - loss: 0.6881 - acc: 0.5458
3712/9333 [==========>...................] - ETA: 4:51 - loss: 0.6875 - acc: 0.5490
3776/9333 [===========>..................] - ETA: 4:47 - loss: 0.6871 - acc: 0.5493
3840/9333 [===========>..................] - ETA: 4:44 - loss: 0.6865 - acc: 0.5505
3904/9333 [===========>..................] - ETA: 4:40 - loss: 0.6860 - acc: 0.5525
3968/9333 [===========>..................] - ETA: 4:37 - loss: 0.6856 - acc: 0.5537
4032/9333 [===========>..................] - ETA: 4:33 - loss: 0.6858 - acc: 0.5528
4096/9333 [============>.................] - ETA: 4:30 - loss: 0.6858 - acc: 0.5540
4160/9333 [============>.................] - ETA: 4:26 - loss: 0.6856 - acc: 0.5546
4224/9333 [============>.................] - ETA: 4:22 - loss: 0.6855 - acc: 0.5554
4288/9333 [============>.................] - ETA: 4:18 - loss: 0.6860 - acc: 0.5525
4352/9333 [============>.................] - ETA: 4:15 - loss: 0.6853 - acc: 0.5551
4416/9333 [=============>................] - ETA: 4:12 - loss: 0.6851 - acc: 0.5550
4480/9333 [=============>................] - ETA: 4:08 - loss: 0.6853 - acc: 0.5547
4544/9333 [=============>................] - ETA: 4:05 - loss: 0.6851 - acc: 0.5550
4608/9333 [=============>................] - ETA: 4:01 - loss: 0.6859 - acc: 0.5540
4672/9333 [==============>...............] - ETA: 3:58 - loss: 0.6854 - acc: 0.5550
4736/9333 [==============>...............] - ETA: 3:54 - loss: 0.6851 - acc: 0.5562
4800/9333 [==============>...............] - ETA: 3:50 - loss: 0.6845 - acc: 0.5579
4864/9333 [==============>...............] - ETA: 3:47 - loss: 0.6848 - acc: 0.5565
4928/9333 [==============>...............] - ETA: 3:43 - loss: 0.6845 - acc: 0.5572
4992/9333 [===============>..............] - ETA: 3:40 - loss: 0.6845 - acc: 0.5573
5056/9333 [===============>..............] - ETA: 3:37 - loss: 0.6848 - acc: 0.5578
5120/9333 [===============>..............] - ETA: 3:33 - loss: 0.6850 - acc: 0.5574
5184/9333 [===============>..............] - ETA: 3:30 - loss: 0.6851 - acc: 0.5577
5248/9333 [===============>..............] - ETA: 3:26 - loss: 0.6849 - acc: 0.5583
5312/9333 [================>.............] - ETA: 3:23 - loss: 0.6846 - acc: 0.5589
5376/9333 [================>.............] - ETA: 3:20 - loss: 0.6848 - acc: 0.5580
5440/9333 [================>.............] - ETA: 3:16 - loss: 0.6852 - acc: 0.5570
5504/9333 [================>.............] - ETA: 3:13 - loss: 0.6853 - acc: 0.5580
5568/9333 [================>.............] - ETA: 3:09 - loss: 0.6850 - acc: 0.5593
5632/9333 [=================>............] - ETA: 3:06 - loss: 0.6852 - acc: 0.5582
5696/9333 [=================>............] - ETA: 3:03 - loss: 0.6853 - acc: 0.5572
5760/9333 [=================>............] - ETA: 3:00 - loss: 0.6853 - acc: 0.5568
5824/9333 [=================>............] - ETA: 2:56 - loss: 0.6851 - acc: 0.5570
5888/9333 [=================>............] - ETA: 2:53 - loss: 0.6852 - acc: 0.5569
5952/9333 [==================>...........] - ETA: 2:50 - loss: 0.6853 - acc: 0.5566
6016/9333 [==================>...........] - ETA: 2:46 - loss: 0.6851 - acc: 0.5570
6080/9333 [==================>...........] - ETA: 2:43 - loss: 0.6850 - acc: 0.5567
6144/9333 [==================>...........] - ETA: 2:40 - loss: 0.6847 - acc: 0.5583
6208/9333 [==================>...........] - ETA: 2:37 - loss: 0.6848 - acc: 0.5577
6272/9333 [===================>..........] - ETA: 2:33 - loss: 0.6849 - acc: 0.5580
6336/9333 [===================>..........] - ETA: 2:30 - loss: 0.6849 - acc: 0.5576
6400/9333 [===================>..........] - ETA: 2:26 - loss: 0.6846 - acc: 0.5587
6464/9333 [===================>..........] - ETA: 2:23 - loss: 0.6846 - acc: 0.5591
6528/9333 [===================>..........] - ETA: 2:20 - loss: 0.6846 - acc: 0.5584
6592/9333 [====================>.........] - ETA: 2:17 - loss: 0.6847 - acc: 0.5579
6656/9333 [====================>.........] - ETA: 2:13 - loss: 0.6848 - acc: 0.5578
6720/9333 [====================>.........] - ETA: 2:10 - loss: 0.6848 - acc: 0.5574
6784/9333 [====================>.........] - ETA: 2:07 - loss: 0.6848 - acc: 0.5568
6848/9333 [=====================>........] - ETA: 2:03 - loss: 0.6848 - acc: 0.5565
6912/9333 [=====================>........] - ETA: 2:00 - loss: 0.6849 - acc: 0.5566
6976/9333 [=====================>........] - ETA: 1:57 - loss: 0.6852 - acc: 0.5562
7040/9333 [=====================>........] - ETA: 1:54 - loss: 0.6851 - acc: 0.5561
7104/9333 [=====================>........] - ETA: 1:51 - loss: 0.6853 - acc: 0.5552
7168/9333 [======================>.......] - ETA: 1:48 - loss: 0.6852 - acc: 0.5555
7232/9333 [======================>.......] - ETA: 1:44 - loss: 0.6852 - acc: 0.5559
7296/9333 [======================>.......] - ETA: 1:41 - loss: 0.6853 - acc: 0.5558
7360/9333 [======================>.......] - ETA: 1:38 - loss: 0.6853 - acc: 0.5550
7424/9333 [======================>.......] - ETA: 1:35 - loss: 0.6854 - acc: 0.5546
7488/9333 [=======================>......] - ETA: 1:32 - loss: 0.6853 - acc: 0.5542
7552/9333 [=======================>......] - ETA: 1:28 - loss: 0.6853 - acc: 0.5539
7616/9333 [=======================>......] - ETA: 1:25 - loss: 0.6852 - acc: 0.5544
7680/9333 [=======================>......] - ETA: 1:22 - loss: 0.6851 - acc: 0.5551
7744/9333 [=======================>......] - ETA: 1:19 - loss: 0.6851 - acc: 0.5551
7808/9333 [========================>.....] - ETA: 1:16 - loss: 0.6854 - acc: 0.5542
7872/9333 [========================>.....] - ETA: 1:13 - loss: 0.6854 - acc: 0.5540
7936/9333 [========================>.....] - ETA: 1:09 - loss: 0.6856 - acc: 0.5532
8000/9333 [========================>.....] - ETA: 1:06 - loss: 0.6859 - acc: 0.5526
8064/9333 [========================>.....] - ETA: 1:03 - loss: 0.6858 - acc: 0.5527
8128/9333 [=========================>....] - ETA: 1:00 - loss: 0.6859 - acc: 0.5523
8192/9333 [=========================>....] - ETA: 57s - loss: 0.6858 - acc: 0.5527 
8256/9333 [=========================>....] - ETA: 54s - loss: 0.6856 - acc: 0.5532
8320/9333 [=========================>....] - ETA: 50s - loss: 0.6859 - acc: 0.5525
8384/9333 [=========================>....] - ETA: 47s - loss: 0.6857 - acc: 0.5532
8448/9333 [==========================>...] - ETA: 44s - loss: 0.6858 - acc: 0.5528
8512/9333 [==========================>...] - ETA: 41s - loss: 0.6859 - acc: 0.5525
8576/9333 [==========================>...] - ETA: 38s - loss: 0.6860 - acc: 0.5519
8640/9333 [==========================>...] - ETA: 34s - loss: 0.6860 - acc: 0.5524
8704/9333 [==========================>...] - ETA: 31s - loss: 0.6859 - acc: 0.5524
8768/9333 [===========================>..] - ETA: 28s - loss: 0.6860 - acc: 0.5520
8832/9333 [===========================>..] - ETA: 25s - loss: 0.6861 - acc: 0.5519
8896/9333 [===========================>..] - ETA: 22s - loss: 0.6860 - acc: 0.5518
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6860 - acc: 0.5516
9024/9333 [============================>.] - ETA: 15s - loss: 0.6859 - acc: 0.5524
9088/9333 [============================>.] - ETA: 12s - loss: 0.6858 - acc: 0.5525
9152/9333 [============================>.] - ETA: 9s - loss: 0.6858 - acc: 0.5528 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6858 - acc: 0.5528
9280/9333 [============================>.] - ETA: 2s - loss: 0.6857 - acc: 0.5533
9333/9333 [==============================] - 497s 53ms/step - loss: 0.6859 - acc: 0.5531 - val_loss: 0.6836 - val_acc: 0.5670

Epoch 00008: val_acc improved from 0.55931 to 0.56702, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window08/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 9/10

  64/9333 [..............................] - ETA: 7:03 - loss: 0.6984 - acc: 0.5000
 128/9333 [..............................] - ETA: 7:27 - loss: 0.6966 - acc: 0.5156
 192/9333 [..............................] - ETA: 7:34 - loss: 0.6975 - acc: 0.5208
 256/9333 [..............................] - ETA: 8:44 - loss: 0.6952 - acc: 0.5234
 320/9333 [>.............................] - ETA: 8:45 - loss: 0.6941 - acc: 0.5250
 384/9333 [>.............................] - ETA: 8:38 - loss: 0.6923 - acc: 0.5339
 448/9333 [>.............................] - ETA: 8:28 - loss: 0.6901 - acc: 0.5402
 512/9333 [>.............................] - ETA: 8:11 - loss: 0.6919 - acc: 0.5312
 576/9333 [>.............................] - ETA: 7:59 - loss: 0.6894 - acc: 0.5451
 640/9333 [=>............................] - ETA: 7:48 - loss: 0.6903 - acc: 0.5406
 704/9333 [=>............................] - ETA: 7:39 - loss: 0.6881 - acc: 0.5426
 768/9333 [=>............................] - ETA: 7:29 - loss: 0.6885 - acc: 0.5404
 832/9333 [=>............................] - ETA: 7:29 - loss: 0.6900 - acc: 0.5337
 896/9333 [=>............................] - ETA: 7:29 - loss: 0.6913 - acc: 0.5312
 960/9333 [==>...........................] - ETA: 7:27 - loss: 0.6916 - acc: 0.5312
1024/9333 [==>...........................] - ETA: 7:25 - loss: 0.6908 - acc: 0.5342
1088/9333 [==>...........................] - ETA: 7:26 - loss: 0.6900 - acc: 0.5377
1152/9333 [==>...........................] - ETA: 7:20 - loss: 0.6898 - acc: 0.5408
1216/9333 [==>...........................] - ETA: 7:13 - loss: 0.6893 - acc: 0.5428
1280/9333 [===>..........................] - ETA: 7:07 - loss: 0.6891 - acc: 0.5422
1344/9333 [===>..........................] - ETA: 7:03 - loss: 0.6891 - acc: 0.5432
1408/9333 [===>..........................] - ETA: 6:57 - loss: 0.6875 - acc: 0.5476
1472/9333 [===>..........................] - ETA: 6:54 - loss: 0.6877 - acc: 0.5503
1536/9333 [===>..........................] - ETA: 6:51 - loss: 0.6879 - acc: 0.5501
1600/9333 [====>.........................] - ETA: 6:49 - loss: 0.6873 - acc: 0.5544
1664/9333 [====>.........................] - ETA: 6:44 - loss: 0.6875 - acc: 0.5523
1728/9333 [====>.........................] - ETA: 6:41 - loss: 0.6878 - acc: 0.5503
1792/9333 [====>.........................] - ETA: 6:38 - loss: 0.6882 - acc: 0.5491
1856/9333 [====>.........................] - ETA: 6:33 - loss: 0.6876 - acc: 0.5517
1920/9333 [=====>........................] - ETA: 6:28 - loss: 0.6869 - acc: 0.5521
1984/9333 [=====>........................] - ETA: 6:23 - loss: 0.6864 - acc: 0.5554
2048/9333 [=====>........................] - ETA: 6:17 - loss: 0.6858 - acc: 0.5562
2112/9333 [=====>........................] - ETA: 6:12 - loss: 0.6858 - acc: 0.5563
2176/9333 [=====>........................] - ETA: 6:07 - loss: 0.6865 - acc: 0.5547
2240/9333 [======>.......................] - ETA: 6:03 - loss: 0.6860 - acc: 0.5563
2304/9333 [======>.......................] - ETA: 5:59 - loss: 0.6861 - acc: 0.5564
2368/9333 [======>.......................] - ETA: 5:55 - loss: 0.6869 - acc: 0.5557
2432/9333 [======>.......................] - ETA: 5:53 - loss: 0.6860 - acc: 0.5567
2496/9333 [=======>......................] - ETA: 5:50 - loss: 0.6849 - acc: 0.5593
2560/9333 [=======>......................] - ETA: 5:49 - loss: 0.6849 - acc: 0.5594
2624/9333 [=======>......................] - ETA: 5:46 - loss: 0.6848 - acc: 0.5595
2688/9333 [=======>......................] - ETA: 5:42 - loss: 0.6856 - acc: 0.5562
2752/9333 [=======>......................] - ETA: 5:39 - loss: 0.6855 - acc: 0.5578
2816/9333 [========>.....................] - ETA: 5:36 - loss: 0.6856 - acc: 0.5579
2880/9333 [========>.....................] - ETA: 5:31 - loss: 0.6859 - acc: 0.5580
2944/9333 [========>.....................] - ETA: 5:29 - loss: 0.6856 - acc: 0.5594
3008/9333 [========>.....................] - ETA: 5:24 - loss: 0.6857 - acc: 0.5592
3072/9333 [========>.....................] - ETA: 5:20 - loss: 0.6859 - acc: 0.5583
3136/9333 [=========>....................] - ETA: 5:17 - loss: 0.6861 - acc: 0.5580
3200/9333 [=========>....................] - ETA: 5:12 - loss: 0.6863 - acc: 0.5563
3264/9333 [=========>....................] - ETA: 5:08 - loss: 0.6861 - acc: 0.5561
3328/9333 [=========>....................] - ETA: 5:04 - loss: 0.6859 - acc: 0.5574
3392/9333 [=========>....................] - ETA: 5:02 - loss: 0.6865 - acc: 0.5548
3456/9333 [==========>...................] - ETA: 4:59 - loss: 0.6862 - acc: 0.5556
3520/9333 [==========>...................] - ETA: 4:56 - loss: 0.6856 - acc: 0.5565
3584/9333 [==========>...................] - ETA: 4:54 - loss: 0.6869 - acc: 0.5527
3648/9333 [==========>...................] - ETA: 4:50 - loss: 0.6865 - acc: 0.5521
3712/9333 [==========>...................] - ETA: 4:47 - loss: 0.6869 - acc: 0.5506
3776/9333 [===========>..................] - ETA: 4:45 - loss: 0.6867 - acc: 0.5511
3840/9333 [===========>..................] - ETA: 4:42 - loss: 0.6871 - acc: 0.5500
3904/9333 [===========>..................] - ETA: 4:39 - loss: 0.6870 - acc: 0.5494
3968/9333 [===========>..................] - ETA: 4:35 - loss: 0.6871 - acc: 0.5486
4032/9333 [===========>..................] - ETA: 4:32 - loss: 0.6868 - acc: 0.5496
4096/9333 [============>.................] - ETA: 4:28 - loss: 0.6869 - acc: 0.5491
4160/9333 [============>.................] - ETA: 4:24 - loss: 0.6867 - acc: 0.5495
4224/9333 [============>.................] - ETA: 4:21 - loss: 0.6867 - acc: 0.5497
4288/9333 [============>.................] - ETA: 4:18 - loss: 0.6872 - acc: 0.5490
4352/9333 [============>.................] - ETA: 4:14 - loss: 0.6872 - acc: 0.5487
4416/9333 [=============>................] - ETA: 4:11 - loss: 0.6869 - acc: 0.5496
4480/9333 [=============>................] - ETA: 4:08 - loss: 0.6874 - acc: 0.5480
4544/9333 [=============>................] - ETA: 4:05 - loss: 0.6875 - acc: 0.5471
4608/9333 [=============>................] - ETA: 4:02 - loss: 0.6878 - acc: 0.5460
4672/9333 [==============>...............] - ETA: 3:59 - loss: 0.6876 - acc: 0.5464
4736/9333 [==============>...............] - ETA: 3:56 - loss: 0.6877 - acc: 0.5465
4800/9333 [==============>...............] - ETA: 3:52 - loss: 0.6879 - acc: 0.5454
4864/9333 [==============>...............] - ETA: 3:49 - loss: 0.6876 - acc: 0.5471
4928/9333 [==============>...............] - ETA: 3:46 - loss: 0.6875 - acc: 0.5467
4992/9333 [===============>..............] - ETA: 3:44 - loss: 0.6875 - acc: 0.5477
5056/9333 [===============>..............] - ETA: 3:40 - loss: 0.6875 - acc: 0.5477
5120/9333 [===============>..............] - ETA: 3:37 - loss: 0.6876 - acc: 0.5475
5184/9333 [===============>..............] - ETA: 3:33 - loss: 0.6874 - acc: 0.5473
5248/9333 [===============>..............] - ETA: 3:31 - loss: 0.6873 - acc: 0.5473
5312/9333 [================>.............] - ETA: 3:28 - loss: 0.6875 - acc: 0.5469
5376/9333 [================>.............] - ETA: 3:25 - loss: 0.6876 - acc: 0.5465
5440/9333 [================>.............] - ETA: 3:22 - loss: 0.6875 - acc: 0.5461
5504/9333 [================>.............] - ETA: 3:18 - loss: 0.6875 - acc: 0.5461
5568/9333 [================>.............] - ETA: 3:15 - loss: 0.6872 - acc: 0.5469
5632/9333 [=================>............] - ETA: 3:13 - loss: 0.6876 - acc: 0.5453
5696/9333 [=================>............] - ETA: 3:09 - loss: 0.6876 - acc: 0.5458
5760/9333 [=================>............] - ETA: 3:06 - loss: 0.6873 - acc: 0.5462
5824/9333 [=================>............] - ETA: 3:03 - loss: 0.6870 - acc: 0.5474
5888/9333 [=================>............] - ETA: 3:00 - loss: 0.6870 - acc: 0.5467
5952/9333 [==================>...........] - ETA: 2:57 - loss: 0.6870 - acc: 0.5467
6016/9333 [==================>...........] - ETA: 2:54 - loss: 0.6868 - acc: 0.5482
6080/9333 [==================>...........] - ETA: 2:51 - loss: 0.6867 - acc: 0.5480
6144/9333 [==================>...........] - ETA: 2:48 - loss: 0.6866 - acc: 0.5482
6208/9333 [==================>...........] - ETA: 2:45 - loss: 0.6868 - acc: 0.5475
6272/9333 [===================>..........] - ETA: 2:42 - loss: 0.6868 - acc: 0.5478
6336/9333 [===================>..........] - ETA: 2:39 - loss: 0.6870 - acc: 0.5475
6400/9333 [===================>..........] - ETA: 2:36 - loss: 0.6869 - acc: 0.5486
6464/9333 [===================>..........] - ETA: 2:32 - loss: 0.6866 - acc: 0.5490
6528/9333 [===================>..........] - ETA: 2:29 - loss: 0.6863 - acc: 0.5487
6592/9333 [====================>.........] - ETA: 2:26 - loss: 0.6861 - acc: 0.5492
6656/9333 [====================>.........] - ETA: 2:23 - loss: 0.6861 - acc: 0.5491
6720/9333 [====================>.........] - ETA: 2:19 - loss: 0.6863 - acc: 0.5490
6784/9333 [====================>.........] - ETA: 2:16 - loss: 0.6861 - acc: 0.5495
6848/9333 [=====================>........] - ETA: 2:13 - loss: 0.6861 - acc: 0.5491
6912/9333 [=====================>........] - ETA: 2:09 - loss: 0.6862 - acc: 0.5495
6976/9333 [=====================>........] - ETA: 2:06 - loss: 0.6863 - acc: 0.5487
7040/9333 [=====================>........] - ETA: 2:03 - loss: 0.6862 - acc: 0.5493
7104/9333 [=====================>........] - ETA: 1:59 - loss: 0.6863 - acc: 0.5495
7168/9333 [======================>.......] - ETA: 1:56 - loss: 0.6861 - acc: 0.5498
7232/9333 [======================>.......] - ETA: 1:52 - loss: 0.6859 - acc: 0.5502
7296/9333 [======================>.......] - ETA: 1:49 - loss: 0.6856 - acc: 0.5510
7360/9333 [======================>.......] - ETA: 1:45 - loss: 0.6858 - acc: 0.5508
7424/9333 [======================>.......] - ETA: 1:42 - loss: 0.6860 - acc: 0.5508
7488/9333 [=======================>......] - ETA: 1:38 - loss: 0.6861 - acc: 0.5506
7552/9333 [=======================>......] - ETA: 1:35 - loss: 0.6861 - acc: 0.5514
7616/9333 [=======================>......] - ETA: 1:32 - loss: 0.6860 - acc: 0.5516
7680/9333 [=======================>......] - ETA: 1:28 - loss: 0.6857 - acc: 0.5523
7744/9333 [=======================>......] - ETA: 1:25 - loss: 0.6860 - acc: 0.5519
7808/9333 [========================>.....] - ETA: 1:22 - loss: 0.6861 - acc: 0.5514
7872/9333 [========================>.....] - ETA: 1:18 - loss: 0.6860 - acc: 0.5513
7936/9333 [========================>.....] - ETA: 1:15 - loss: 0.6858 - acc: 0.5519
8000/9333 [========================>.....] - ETA: 1:12 - loss: 0.6859 - acc: 0.5519
8064/9333 [========================>.....] - ETA: 1:08 - loss: 0.6859 - acc: 0.5512
8128/9333 [=========================>....] - ETA: 1:05 - loss: 0.6858 - acc: 0.5507
8192/9333 [=========================>....] - ETA: 1:01 - loss: 0.6858 - acc: 0.5509
8256/9333 [=========================>....] - ETA: 58s - loss: 0.6858 - acc: 0.5506 
8320/9333 [=========================>....] - ETA: 54s - loss: 0.6857 - acc: 0.5511
8384/9333 [=========================>....] - ETA: 51s - loss: 0.6855 - acc: 0.5515
8448/9333 [==========================>...] - ETA: 48s - loss: 0.6856 - acc: 0.5514
8512/9333 [==========================>...] - ETA: 44s - loss: 0.6855 - acc: 0.5517
8576/9333 [==========================>...] - ETA: 41s - loss: 0.6855 - acc: 0.5518
8640/9333 [==========================>...] - ETA: 37s - loss: 0.6855 - acc: 0.5516
8704/9333 [==========================>...] - ETA: 34s - loss: 0.6858 - acc: 0.5511
8768/9333 [===========================>..] - ETA: 30s - loss: 0.6860 - acc: 0.5505
8832/9333 [===========================>..] - ETA: 27s - loss: 0.6857 - acc: 0.5519
8896/9333 [===========================>..] - ETA: 23s - loss: 0.6858 - acc: 0.5519
8960/9333 [===========================>..] - ETA: 20s - loss: 0.6860 - acc: 0.5518
9024/9333 [============================>.] - ETA: 16s - loss: 0.6859 - acc: 0.5521
9088/9333 [============================>.] - ETA: 13s - loss: 0.6857 - acc: 0.5527
9152/9333 [============================>.] - ETA: 9s - loss: 0.6855 - acc: 0.5533 
9216/9333 [============================>.] - ETA: 6s - loss: 0.6856 - acc: 0.5533
9280/9333 [============================>.] - ETA: 2s - loss: 0.6857 - acc: 0.5536
9333/9333 [==============================] - 529s 57ms/step - loss: 0.6856 - acc: 0.5538 - val_loss: 0.6849 - val_acc: 0.5526

Epoch 00009: val_acc did not improve from 0.56702
Epoch 10/10

  64/9333 [..............................] - ETA: 8:55 - loss: 0.6772 - acc: 0.5781
 128/9333 [..............................] - ETA: 8:56 - loss: 0.6580 - acc: 0.6094
 192/9333 [..............................] - ETA: 8:43 - loss: 0.6641 - acc: 0.5938
 256/9333 [..............................] - ETA: 8:35 - loss: 0.6699 - acc: 0.5781
 320/9333 [>.............................] - ETA: 8:26 - loss: 0.6771 - acc: 0.5750
 384/9333 [>.............................] - ETA: 8:35 - loss: 0.6781 - acc: 0.5703
 448/9333 [>.............................] - ETA: 8:27 - loss: 0.6766 - acc: 0.5759
 512/9333 [>.............................] - ETA: 8:27 - loss: 0.6773 - acc: 0.5820
 576/9333 [>.............................] - ETA: 8:21 - loss: 0.6807 - acc: 0.5642
 640/9333 [=>............................] - ETA: 8:17 - loss: 0.6805 - acc: 0.5656
 704/9333 [=>............................] - ETA: 8:12 - loss: 0.6826 - acc: 0.5554
 768/9333 [=>............................] - ETA: 8:05 - loss: 0.6827 - acc: 0.5573
 832/9333 [=>............................] - ETA: 7:56 - loss: 0.6808 - acc: 0.5637
 896/9333 [=>............................] - ETA: 7:48 - loss: 0.6812 - acc: 0.5603
 960/9333 [==>...........................] - ETA: 7:42 - loss: 0.6808 - acc: 0.5635
1024/9333 [==>...........................] - ETA: 7:35 - loss: 0.6782 - acc: 0.5723
1088/9333 [==>...........................] - ETA: 7:33 - loss: 0.6777 - acc: 0.5717
1152/9333 [==>...........................] - ETA: 7:27 - loss: 0.6804 - acc: 0.5625
1216/9333 [==>...........................] - ETA: 7:24 - loss: 0.6794 - acc: 0.5641
1280/9333 [===>..........................] - ETA: 7:22 - loss: 0.6796 - acc: 0.5672
1344/9333 [===>..........................] - ETA: 7:19 - loss: 0.6801 - acc: 0.5647
1408/9333 [===>..........................] - ETA: 7:19 - loss: 0.6813 - acc: 0.5611
1472/9333 [===>..........................] - ETA: 7:18 - loss: 0.6826 - acc: 0.5591
1536/9333 [===>..........................] - ETA: 7:15 - loss: 0.6826 - acc: 0.5592
1600/9333 [====>.........................] - ETA: 7:12 - loss: 0.6827 - acc: 0.5594
1664/9333 [====>.........................] - ETA: 7:08 - loss: 0.6832 - acc: 0.5565
1728/9333 [====>.........................] - ETA: 7:05 - loss: 0.6836 - acc: 0.5573
1792/9333 [====>.........................] - ETA: 7:03 - loss: 0.6834 - acc: 0.5586
1856/9333 [====>.........................] - ETA: 7:00 - loss: 0.6841 - acc: 0.5593
1920/9333 [=====>........................] - ETA: 6:57 - loss: 0.6832 - acc: 0.5620
1984/9333 [=====>........................] - ETA: 6:54 - loss: 0.6818 - acc: 0.5650
2048/9333 [=====>........................] - ETA: 6:52 - loss: 0.6828 - acc: 0.5625
2112/9333 [=====>........................] - ETA: 6:48 - loss: 0.6825 - acc: 0.5644
2176/9333 [=====>........................] - ETA: 6:47 - loss: 0.6824 - acc: 0.5653
2240/9333 [======>.......................] - ETA: 6:42 - loss: 0.6831 - acc: 0.5643
2304/9333 [======>.......................] - ETA: 6:39 - loss: 0.6831 - acc: 0.5629
2368/9333 [======>.......................] - ETA: 6:35 - loss: 0.6828 - acc: 0.5642
2432/9333 [======>.......................] - ETA: 6:31 - loss: 0.6830 - acc: 0.5633
2496/9333 [=======>......................] - ETA: 6:26 - loss: 0.6824 - acc: 0.5649
2560/9333 [=======>......................] - ETA: 6:24 - loss: 0.6823 - acc: 0.5648
2624/9333 [=======>......................] - ETA: 6:21 - loss: 0.6820 - acc: 0.5655
2688/9333 [=======>......................] - ETA: 6:18 - loss: 0.6819 - acc: 0.5651
2752/9333 [=======>......................] - ETA: 6:14 - loss: 0.6816 - acc: 0.5661
2816/9333 [========>.....................] - ETA: 6:10 - loss: 0.6824 - acc: 0.5643
2880/9333 [========>.....................] - ETA: 6:05 - loss: 0.6834 - acc: 0.5618
2944/9333 [========>.....................] - ETA: 6:02 - loss: 0.6838 - acc: 0.5611
3008/9333 [========>.....................] - ETA: 5:59 - loss: 0.6836 - acc: 0.5612
3072/9333 [========>.....................] - ETA: 5:55 - loss: 0.6846 - acc: 0.5592
3136/9333 [=========>....................] - ETA: 5:52 - loss: 0.6851 - acc: 0.5587
3200/9333 [=========>....................] - ETA: 5:47 - loss: 0.6852 - acc: 0.5578
3264/9333 [=========>....................] - ETA: 5:45 - loss: 0.6847 - acc: 0.5582
3328/9333 [=========>....................] - ETA: 5:42 - loss: 0.6854 - acc: 0.5556
3392/9333 [=========>....................] - ETA: 5:38 - loss: 0.6856 - acc: 0.5548
3456/9333 [==========>...................] - ETA: 5:34 - loss: 0.6859 - acc: 0.5541
3520/9333 [==========>...................] - ETA: 5:30 - loss: 0.6860 - acc: 0.5537
3584/9333 [==========>...................] - ETA: 5:33 - loss: 0.6862 - acc: 0.5527
3648/9333 [==========>...................] - ETA: 5:31 - loss: 0.6858 - acc: 0.5537
3712/9333 [==========>...................] - ETA: 5:26 - loss: 0.6858 - acc: 0.5539
3776/9333 [===========>..................] - ETA: 5:22 - loss: 0.6857 - acc: 0.5551
3840/9333 [===========>..................] - ETA: 5:18 - loss: 0.6856 - acc: 0.5552
3904/9333 [===========>..................] - ETA: 5:13 - loss: 0.6858 - acc: 0.5551
3968/9333 [===========>..................] - ETA: 5:09 - loss: 0.6857 - acc: 0.5557
4032/9333 [===========>..................] - ETA: 5:05 - loss: 0.6852 - acc: 0.5565
4096/9333 [============>.................] - ETA: 5:00 - loss: 0.6852 - acc: 0.5554
4160/9333 [============>.................] - ETA: 4:56 - loss: 0.6853 - acc: 0.5550
4224/9333 [============>.................] - ETA: 4:51 - loss: 0.6855 - acc: 0.5533
4288/9333 [============>.................] - ETA: 4:48 - loss: 0.6859 - acc: 0.5525
4352/9333 [============>.................] - ETA: 4:44 - loss: 0.6861 - acc: 0.5528
4416/9333 [=============>................] - ETA: 4:39 - loss: 0.6859 - acc: 0.5537
4480/9333 [=============>................] - ETA: 4:35 - loss: 0.6856 - acc: 0.5529
4544/9333 [=============>................] - ETA: 4:30 - loss: 0.6857 - acc: 0.5524
4608/9333 [=============>................] - ETA: 4:26 - loss: 0.6856 - acc: 0.5516
4672/9333 [==============>...............] - ETA: 4:22 - loss: 0.6858 - acc: 0.5514
4736/9333 [==============>...............] - ETA: 4:18 - loss: 0.6856 - acc: 0.5530
4800/9333 [==============>...............] - ETA: 4:14 - loss: 0.6857 - acc: 0.5531
4864/9333 [==============>...............] - ETA: 4:10 - loss: 0.6856 - acc: 0.5530
4928/9333 [==============>...............] - ETA: 4:06 - loss: 0.6858 - acc: 0.5530
4992/9333 [===============>..............] - ETA: 4:02 - loss: 0.6858 - acc: 0.5531
5056/9333 [===============>..............] - ETA: 3:57 - loss: 0.6858 - acc: 0.5528
5120/9333 [===============>..............] - ETA: 3:54 - loss: 0.6856 - acc: 0.5533
5184/9333 [===============>..............] - ETA: 3:49 - loss: 0.6855 - acc: 0.5536
5248/9333 [===============>..............] - ETA: 3:45 - loss: 0.6853 - acc: 0.5549
5312/9333 [================>.............] - ETA: 3:41 - loss: 0.6850 - acc: 0.5563
5376/9333 [================>.............] - ETA: 3:37 - loss: 0.6851 - acc: 0.5564
5440/9333 [================>.............] - ETA: 3:33 - loss: 0.6853 - acc: 0.5546
5504/9333 [================>.............] - ETA: 3:30 - loss: 0.6855 - acc: 0.5532
5568/9333 [================>.............] - ETA: 3:26 - loss: 0.6854 - acc: 0.5541
5632/9333 [=================>............] - ETA: 3:22 - loss: 0.6851 - acc: 0.5545
5696/9333 [=================>............] - ETA: 3:18 - loss: 0.6849 - acc: 0.5553
5760/9333 [=================>............] - ETA: 3:15 - loss: 0.6844 - acc: 0.5569
5824/9333 [=================>............] - ETA: 3:11 - loss: 0.6842 - acc: 0.5572
5888/9333 [=================>............] - ETA: 3:07 - loss: 0.6844 - acc: 0.5566
5952/9333 [==================>...........] - ETA: 3:03 - loss: 0.6842 - acc: 0.5570
6016/9333 [==================>...........] - ETA: 3:00 - loss: 0.6844 - acc: 0.5570
6080/9333 [==================>...........] - ETA: 2:56 - loss: 0.6841 - acc: 0.5577
6144/9333 [==================>...........] - ETA: 2:52 - loss: 0.6842 - acc: 0.5573
6208/9333 [==================>...........] - ETA: 2:49 - loss: 0.6841 - acc: 0.5570
6272/9333 [===================>..........] - ETA: 2:45 - loss: 0.6843 - acc: 0.5563
6336/9333 [===================>..........] - ETA: 2:41 - loss: 0.6842 - acc: 0.5568
6400/9333 [===================>..........] - ETA: 2:38 - loss: 0.6843 - acc: 0.5569
6464/9333 [===================>..........] - ETA: 2:34 - loss: 0.6842 - acc: 0.5574
6528/9333 [===================>..........] - ETA: 2:30 - loss: 0.6842 - acc: 0.5573
6592/9333 [====================>.........] - ETA: 2:27 - loss: 0.6843 - acc: 0.5575
6656/9333 [====================>.........] - ETA: 2:23 - loss: 0.6842 - acc: 0.5575
6720/9333 [====================>.........] - ETA: 2:20 - loss: 0.6841 - acc: 0.5576
6784/9333 [====================>.........] - ETA: 2:16 - loss: 0.6839 - acc: 0.5581
6848/9333 [=====================>........] - ETA: 2:12 - loss: 0.6843 - acc: 0.5571
6912/9333 [=====================>........] - ETA: 2:09 - loss: 0.6841 - acc: 0.5577
6976/9333 [=====================>........] - ETA: 2:05 - loss: 0.6840 - acc: 0.5586
7040/9333 [=====================>........] - ETA: 2:02 - loss: 0.6840 - acc: 0.5585
7104/9333 [=====================>........] - ETA: 1:58 - loss: 0.6840 - acc: 0.5586
7168/9333 [======================>.......] - ETA: 1:55 - loss: 0.6840 - acc: 0.5586
7232/9333 [======================>.......] - ETA: 1:51 - loss: 0.6841 - acc: 0.5584
7296/9333 [======================>.......] - ETA: 1:48 - loss: 0.6840 - acc: 0.5588
7360/9333 [======================>.......] - ETA: 1:44 - loss: 0.6842 - acc: 0.5584
7424/9333 [======================>.......] - ETA: 1:41 - loss: 0.6841 - acc: 0.5587
7488/9333 [=======================>......] - ETA: 1:37 - loss: 0.6842 - acc: 0.5586
7552/9333 [=======================>......] - ETA: 1:34 - loss: 0.6841 - acc: 0.5592
7616/9333 [=======================>......] - ETA: 1:30 - loss: 0.6841 - acc: 0.5588
7680/9333 [=======================>......] - ETA: 1:27 - loss: 0.6843 - acc: 0.5579
7744/9333 [=======================>......] - ETA: 1:24 - loss: 0.6844 - acc: 0.5577
7808/9333 [========================>.....] - ETA: 1:20 - loss: 0.6844 - acc: 0.5572
7872/9333 [========================>.....] - ETA: 1:17 - loss: 0.6845 - acc: 0.5568
7936/9333 [========================>.....] - ETA: 1:14 - loss: 0.6846 - acc: 0.5565
8000/9333 [========================>.....] - ETA: 1:10 - loss: 0.6847 - acc: 0.5573
8064/9333 [========================>.....] - ETA: 1:07 - loss: 0.6845 - acc: 0.5577
8128/9333 [=========================>....] - ETA: 1:04 - loss: 0.6843 - acc: 0.5576
8192/9333 [=========================>....] - ETA: 1:00 - loss: 0.6843 - acc: 0.5581
8256/9333 [=========================>....] - ETA: 57s - loss: 0.6844 - acc: 0.5580 
8320/9333 [=========================>....] - ETA: 53s - loss: 0.6845 - acc: 0.5573
8384/9333 [=========================>....] - ETA: 50s - loss: 0.6844 - acc: 0.5571
8448/9333 [==========================>...] - ETA: 46s - loss: 0.6843 - acc: 0.5574
8512/9333 [==========================>...] - ETA: 43s - loss: 0.6845 - acc: 0.5571
8576/9333 [==========================>...] - ETA: 40s - loss: 0.6845 - acc: 0.5569
8640/9333 [==========================>...] - ETA: 36s - loss: 0.6846 - acc: 0.5568
8704/9333 [==========================>...] - ETA: 33s - loss: 0.6845 - acc: 0.5565
8768/9333 [===========================>..] - ETA: 29s - loss: 0.6843 - acc: 0.5570
8832/9333 [===========================>..] - ETA: 26s - loss: 0.6842 - acc: 0.5575
8896/9333 [===========================>..] - ETA: 23s - loss: 0.6842 - acc: 0.5574
8960/9333 [===========================>..] - ETA: 19s - loss: 0.6843 - acc: 0.5574
9024/9333 [============================>.] - ETA: 16s - loss: 0.6842 - acc: 0.5572
9088/9333 [============================>.] - ETA: 12s - loss: 0.6840 - acc: 0.5579
9152/9333 [============================>.] - ETA: 9s - loss: 0.6840 - acc: 0.5581 
9216/9333 [============================>.] - ETA: 6s - loss: 0.6840 - acc: 0.5582
9280/9333 [============================>.] - ETA: 2s - loss: 0.6840 - acc: 0.5582
9333/9333 [==============================] - 508s 54ms/step - loss: 0.6841 - acc: 0.5581 - val_loss: 0.6891 - val_acc: 0.5313

Epoch 00010: val_acc did not improve from 0.56702
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f423c256dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f423c256dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f423c1ff7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f423c1ff7d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4234601d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4234601d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42341f1310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42341f1310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42341d5ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42341d5ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42143ad350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42143ad350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d441fc210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3d441fc210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ce46e4ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ce46e4ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42147376d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f42147376d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3aac440550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3aac440550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4234236950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4234236950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f423415b9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f423415b9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f423410eb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f423410eb10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f421458ddd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f421458ddd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4214553c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4214553c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4234100cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4234100cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42340be4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42340be4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42142d0950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42142d0950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4214254890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4214254890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4214106e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4214106e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42141e5950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f42141e5950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4214362290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4214362290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c47608d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c47608d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4214154150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4214154150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41c46c8d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41c46c8d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c44d6950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c44d6950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f421428ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f421428ba50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c468ebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c468ebd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41c47325d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41c47325d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41c42db2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41c42db2d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c44aeb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c44aeb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42141dbd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f42141dbd10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c433ea90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c433ea90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41c43cdb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41c43cdb90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41a4778e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41a4778e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41a47af590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41a47af590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41c4760250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41c4760250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c4361a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41c4361a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41c4129990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41c4129990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41a466ea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f41a466ea50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40c80aacd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40c80aacd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41a43e3a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f41a43e3a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41a43d4090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41a43d4090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f40a4775790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f40a4775790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4088646bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4088646bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40c803f750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40c803f750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40a46e8ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40a46e8ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41a4595910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41a4595910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41a43cef90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f41a43cef90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4088367ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4088367ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4088203250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4088203250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40886aebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40886aebd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4088358d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4088358d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4088116890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4088116890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f408809a810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f408809a810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4088558790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4088558790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4088116710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4088116710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40880e2f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40880e2f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f40647cd190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f40647cd190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f406449f290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f406449f290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f408809a490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f408809a490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40880fc990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40880fc990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4064575990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4064575990>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 17:26
 128/2592 [>.............................] - ETA: 9:01 
 192/2592 [=>............................] - ETA: 6:08
 256/2592 [=>............................] - ETA: 4:41
 320/2592 [==>...........................] - ETA: 3:48
 384/2592 [===>..........................] - ETA: 3:13
 448/2592 [====>.........................] - ETA: 2:47
 512/2592 [====>.........................] - ETA: 2:27
 576/2592 [=====>........................] - ETA: 2:12
 640/2592 [======>.......................] - ETA: 2:01
 704/2592 [=======>......................] - ETA: 1:50
 768/2592 [=======>......................] - ETA: 1:41
 832/2592 [========>.....................] - ETA: 1:33
 896/2592 [=========>....................] - ETA: 1:26
 960/2592 [==========>...................] - ETA: 1:19
1024/2592 [==========>...................] - ETA: 1:14
1088/2592 [===========>..................] - ETA: 1:08
1152/2592 [============>.................] - ETA: 1:03
1216/2592 [=============>................] - ETA: 59s 
1280/2592 [=============>................] - ETA: 55s
1344/2592 [==============>...............] - ETA: 51s
1408/2592 [===============>..............] - ETA: 48s
1472/2592 [================>.............] - ETA: 44s
1536/2592 [================>.............] - ETA: 41s
1600/2592 [=================>............] - ETA: 38s
1664/2592 [==================>...........] - ETA: 35s
1728/2592 [===================>..........] - ETA: 32s
1792/2592 [===================>..........] - ETA: 29s
1856/2592 [====================>.........] - ETA: 26s
1920/2592 [=====================>........] - ETA: 24s
1984/2592 [=====================>........] - ETA: 21s
2048/2592 [======================>.......] - ETA: 19s
2112/2592 [=======================>......] - ETA: 16s
2176/2592 [========================>.....] - ETA: 14s
2240/2592 [========================>.....] - ETA: 12s
2304/2592 [=========================>....] - ETA: 9s 
2368/2592 [==========================>...] - ETA: 7s
2432/2592 [===========================>..] - ETA: 5s
2496/2592 [===========================>..] - ETA: 3s
2560/2592 [============================>.] - ETA: 1s
2592/2592 [==============================] - 85s 33ms/step
loss: 0.6823648619063106
acc: 0.5679012345679012
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3b6421bf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3b6421bf10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3b6421dd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3b6421dd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f402409a110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f402409a110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f40241e3550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f40241e3550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42342c3290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f42342c3290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f423c235510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f423c235510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40241e35d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40241e35d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4024311ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4024311ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ce4058850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ce4058850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f423c15d1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f423c15d1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3cc4728390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3cc4728390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3ce405f690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3ce405f690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f423c0c0fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f423c0c0fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4234527a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4234527a10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4234679c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4234679c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41a47b9290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f41a47b9290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f423c0ce990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f423c0ce990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f423447d290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f423447d290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f423462a190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f423462a190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b446fe6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b446fe6d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b64120850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b64120850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f423477cb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f423477cb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b4476efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b4476efd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3aac5eced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3aac5eced0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b44421650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b44421650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b445443d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b445443d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f4469efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3f4469efd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b442cec50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b442cec50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b44269ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b44269ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b440c1190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b440c1190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b441507d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b441507d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3aac6ad810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3aac6ad810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b44263b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b44263b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b441ed150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b441ed150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b2459c050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b2459c050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b44270150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b44270150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b441414d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b441414d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b243c1950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b243c1950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b24623790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b24623790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b241ffdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b241ffdd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b243e3d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b243e3d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b2439a350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b2439a350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b242b7c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b242b7c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b24357f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b24357f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b0471b250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b0471b250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b04634610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b04634610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b243575d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b243575d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b046c4290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b046c4290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b044c6e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b044c6e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b04381a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b04381a10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b04714790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b04714790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b2404cb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b2404cb10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b04438dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b04438dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b0444c0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b0444c0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b04158390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3b04158390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b041e8d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b041e8d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b040d4310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b040d4310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b041e8fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b041e8fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ae4695050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ae4695050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ae45b6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ae45b6a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ae44580d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ae44580d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b04735610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b04735610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b041f4190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b041f4190>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 2:34:32 - loss: 0.7097 - acc: 0.5000
 128/9333 [..............................] - ETA: 1:20:51 - loss: 0.7208 - acc: 0.4844
 192/9333 [..............................] - ETA: 56:50 - loss: 0.7359 - acc: 0.4688  
 256/9333 [..............................] - ETA: 44:23 - loss: 0.7293 - acc: 0.4727
 320/9333 [>.............................] - ETA: 36:52 - loss: 0.7394 - acc: 0.4656
 384/9333 [>.............................] - ETA: 31:50 - loss: 0.7421 - acc: 0.4844
 448/9333 [>.............................] - ETA: 28:10 - loss: 0.7301 - acc: 0.4911
 512/9333 [>.............................] - ETA: 25:51 - loss: 0.7324 - acc: 0.4941
 576/9333 [>.............................] - ETA: 23:44 - loss: 0.7376 - acc: 0.4948
 640/9333 [=>............................] - ETA: 22:01 - loss: 0.7432 - acc: 0.5016
 704/9333 [=>............................] - ETA: 20:40 - loss: 0.7421 - acc: 0.5043
 768/9333 [=>............................] - ETA: 19:25 - loss: 0.7419 - acc: 0.5026
 832/9333 [=>............................] - ETA: 18:21 - loss: 0.7385 - acc: 0.5084
 896/9333 [=>............................] - ETA: 17:29 - loss: 0.7436 - acc: 0.5067
 960/9333 [==>...........................] - ETA: 16:41 - loss: 0.7481 - acc: 0.5083
1024/9333 [==>...........................] - ETA: 15:59 - loss: 0.7417 - acc: 0.5156
1088/9333 [==>...........................] - ETA: 15:24 - loss: 0.7423 - acc: 0.5129
1152/9333 [==>...........................] - ETA: 14:55 - loss: 0.7449 - acc: 0.5122
1216/9333 [==>...........................] - ETA: 14:26 - loss: 0.7450 - acc: 0.5066
1280/9333 [===>..........................] - ETA: 14:00 - loss: 0.7445 - acc: 0.5039
1344/9333 [===>..........................] - ETA: 13:34 - loss: 0.7449 - acc: 0.5045
1408/9333 [===>..........................] - ETA: 13:09 - loss: 0.7432 - acc: 0.5071
1472/9333 [===>..........................] - ETA: 12:46 - loss: 0.7388 - acc: 0.5122
1536/9333 [===>..........................] - ETA: 12:25 - loss: 0.7394 - acc: 0.5098
1600/9333 [====>.........................] - ETA: 12:07 - loss: 0.7377 - acc: 0.5100
1664/9333 [====>.........................] - ETA: 11:48 - loss: 0.7385 - acc: 0.5078
1728/9333 [====>.........................] - ETA: 11:31 - loss: 0.7381 - acc: 0.5075
1792/9333 [====>.........................] - ETA: 11:15 - loss: 0.7377 - acc: 0.5056
1856/9333 [====>.........................] - ETA: 10:59 - loss: 0.7378 - acc: 0.5054
1920/9333 [=====>........................] - ETA: 10:44 - loss: 0.7371 - acc: 0.5062
1984/9333 [=====>........................] - ETA: 10:30 - loss: 0.7344 - acc: 0.5091
2048/9333 [=====>........................] - ETA: 10:18 - loss: 0.7335 - acc: 0.5122
2112/9333 [=====>........................] - ETA: 10:06 - loss: 0.7354 - acc: 0.5090
2176/9333 [=====>........................] - ETA: 9:54 - loss: 0.7355 - acc: 0.5078 
2240/9333 [======>.......................] - ETA: 9:45 - loss: 0.7332 - acc: 0.5112
2304/9333 [======>.......................] - ETA: 9:33 - loss: 0.7315 - acc: 0.5130
2368/9333 [======>.......................] - ETA: 9:21 - loss: 0.7311 - acc: 0.5139
2432/9333 [======>.......................] - ETA: 9:11 - loss: 0.7308 - acc: 0.5140
2496/9333 [=======>......................] - ETA: 9:00 - loss: 0.7310 - acc: 0.5136
2560/9333 [=======>......................] - ETA: 8:52 - loss: 0.7303 - acc: 0.5145
2624/9333 [=======>......................] - ETA: 8:43 - loss: 0.7309 - acc: 0.5111
2688/9333 [=======>......................] - ETA: 8:33 - loss: 0.7308 - acc: 0.5108
2752/9333 [=======>......................] - ETA: 8:25 - loss: 0.7304 - acc: 0.5120
2816/9333 [========>.....................] - ETA: 8:17 - loss: 0.7299 - acc: 0.5117
2880/9333 [========>.....................] - ETA: 8:08 - loss: 0.7294 - acc: 0.5132
2944/9333 [========>.....................] - ETA: 8:01 - loss: 0.7296 - acc: 0.5109
3008/9333 [========>.....................] - ETA: 7:53 - loss: 0.7300 - acc: 0.5096
3072/9333 [========>.....................] - ETA: 7:44 - loss: 0.7293 - acc: 0.5098
3136/9333 [=========>....................] - ETA: 7:38 - loss: 0.7298 - acc: 0.5089
3200/9333 [=========>....................] - ETA: 7:30 - loss: 0.7299 - acc: 0.5088
3264/9333 [=========>....................] - ETA: 7:23 - loss: 0.7300 - acc: 0.5083
3328/9333 [=========>....................] - ETA: 7:16 - loss: 0.7303 - acc: 0.5066
3392/9333 [=========>....................] - ETA: 7:09 - loss: 0.7300 - acc: 0.5074
3456/9333 [==========>...................] - ETA: 7:03 - loss: 0.7296 - acc: 0.5072
3520/9333 [==========>...................] - ETA: 6:56 - loss: 0.7298 - acc: 0.5060
3584/9333 [==========>...................] - ETA: 6:50 - loss: 0.7293 - acc: 0.5064
3648/9333 [==========>...................] - ETA: 6:43 - loss: 0.7299 - acc: 0.5041
3712/9333 [==========>...................] - ETA: 6:37 - loss: 0.7294 - acc: 0.5040
3776/9333 [===========>..................] - ETA: 6:31 - loss: 0.7292 - acc: 0.5042
3840/9333 [===========>..................] - ETA: 6:25 - loss: 0.7286 - acc: 0.5057
3904/9333 [===========>..................] - ETA: 6:18 - loss: 0.7283 - acc: 0.5054
3968/9333 [===========>..................] - ETA: 6:12 - loss: 0.7285 - acc: 0.5055
4032/9333 [===========>..................] - ETA: 6:06 - loss: 0.7275 - acc: 0.5087
4096/9333 [============>.................] - ETA: 6:00 - loss: 0.7272 - acc: 0.5083
4160/9333 [============>.................] - ETA: 5:55 - loss: 0.7267 - acc: 0.5096
4224/9333 [============>.................] - ETA: 5:49 - loss: 0.7271 - acc: 0.5080
4288/9333 [============>.................] - ETA: 5:47 - loss: 0.7261 - acc: 0.5103
4352/9333 [============>.................] - ETA: 5:42 - loss: 0.7261 - acc: 0.5099
4416/9333 [=============>................] - ETA: 5:36 - loss: 0.7254 - acc: 0.5104
4480/9333 [=============>................] - ETA: 5:30 - loss: 0.7252 - acc: 0.5098
4544/9333 [=============>................] - ETA: 5:25 - loss: 0.7249 - acc: 0.5099
4608/9333 [=============>................] - ETA: 5:19 - loss: 0.7248 - acc: 0.5082
4672/9333 [==============>...............] - ETA: 5:14 - loss: 0.7245 - acc: 0.5081
4736/9333 [==============>...............] - ETA: 5:08 - loss: 0.7241 - acc: 0.5082
4800/9333 [==============>...............] - ETA: 5:03 - loss: 0.7246 - acc: 0.5077
4864/9333 [==============>...............] - ETA: 4:58 - loss: 0.7240 - acc: 0.5086
4928/9333 [==============>...............] - ETA: 4:53 - loss: 0.7241 - acc: 0.5083
4992/9333 [===============>..............] - ETA: 4:47 - loss: 0.7246 - acc: 0.5066
5056/9333 [===============>..............] - ETA: 4:42 - loss: 0.7244 - acc: 0.5069
5120/9333 [===============>..............] - ETA: 4:37 - loss: 0.7244 - acc: 0.5064
5184/9333 [===============>..............] - ETA: 4:32 - loss: 0.7241 - acc: 0.5071
5248/9333 [===============>..............] - ETA: 4:27 - loss: 0.7241 - acc: 0.5061
5312/9333 [================>.............] - ETA: 4:22 - loss: 0.7237 - acc: 0.5066
5376/9333 [================>.............] - ETA: 4:17 - loss: 0.7241 - acc: 0.5058
5440/9333 [================>.............] - ETA: 4:12 - loss: 0.7232 - acc: 0.5074
5504/9333 [================>.............] - ETA: 4:08 - loss: 0.7228 - acc: 0.5078
5568/9333 [================>.............] - ETA: 4:03 - loss: 0.7228 - acc: 0.5066
5632/9333 [=================>............] - ETA: 3:58 - loss: 0.7223 - acc: 0.5069
5696/9333 [=================>............] - ETA: 3:53 - loss: 0.7217 - acc: 0.5091
5760/9333 [=================>............] - ETA: 3:49 - loss: 0.7215 - acc: 0.5092
5824/9333 [=================>............] - ETA: 3:44 - loss: 0.7212 - acc: 0.5089
5888/9333 [=================>............] - ETA: 3:40 - loss: 0.7212 - acc: 0.5090
5952/9333 [==================>...........] - ETA: 3:35 - loss: 0.7210 - acc: 0.5089
6016/9333 [==================>...........] - ETA: 3:31 - loss: 0.7213 - acc: 0.5078
6080/9333 [==================>...........] - ETA: 3:26 - loss: 0.7214 - acc: 0.5076
6144/9333 [==================>...........] - ETA: 3:22 - loss: 0.7212 - acc: 0.5078
6208/9333 [==================>...........] - ETA: 3:17 - loss: 0.7212 - acc: 0.5074
6272/9333 [===================>..........] - ETA: 3:13 - loss: 0.7210 - acc: 0.5070
6336/9333 [===================>..........] - ETA: 3:08 - loss: 0.7207 - acc: 0.5077
6400/9333 [===================>..........] - ETA: 3:04 - loss: 0.7205 - acc: 0.5080
6464/9333 [===================>..........] - ETA: 3:00 - loss: 0.7201 - acc: 0.5080
6528/9333 [===================>..........] - ETA: 2:55 - loss: 0.7201 - acc: 0.5077
6592/9333 [====================>.........] - ETA: 2:51 - loss: 0.7198 - acc: 0.5079
6656/9333 [====================>.........] - ETA: 2:47 - loss: 0.7198 - acc: 0.5072
6720/9333 [====================>.........] - ETA: 2:42 - loss: 0.7195 - acc: 0.5076
6784/9333 [====================>.........] - ETA: 2:38 - loss: 0.7195 - acc: 0.5074
6848/9333 [=====================>........] - ETA: 2:34 - loss: 0.7192 - acc: 0.5083
6912/9333 [=====================>........] - ETA: 2:30 - loss: 0.7191 - acc: 0.5081
6976/9333 [=====================>........] - ETA: 2:26 - loss: 0.7187 - acc: 0.5092
7040/9333 [=====================>........] - ETA: 2:21 - loss: 0.7186 - acc: 0.5092
7104/9333 [=====================>........] - ETA: 2:17 - loss: 0.7183 - acc: 0.5094
7168/9333 [======================>.......] - ETA: 2:13 - loss: 0.7181 - acc: 0.5095
7232/9333 [======================>.......] - ETA: 2:09 - loss: 0.7179 - acc: 0.5095
7296/9333 [======================>.......] - ETA: 2:05 - loss: 0.7172 - acc: 0.5114
7360/9333 [======================>.......] - ETA: 2:01 - loss: 0.7173 - acc: 0.5107
7424/9333 [======================>.......] - ETA: 1:57 - loss: 0.7169 - acc: 0.5116
7488/9333 [=======================>......] - ETA: 1:53 - loss: 0.7167 - acc: 0.5124
7552/9333 [=======================>......] - ETA: 1:48 - loss: 0.7168 - acc: 0.5120
7616/9333 [=======================>......] - ETA: 1:44 - loss: 0.7168 - acc: 0.5112
7680/9333 [=======================>......] - ETA: 1:40 - loss: 0.7169 - acc: 0.5109
7744/9333 [=======================>......] - ETA: 1:36 - loss: 0.7167 - acc: 0.5108
7808/9333 [========================>.....] - ETA: 1:32 - loss: 0.7165 - acc: 0.5111
7872/9333 [========================>.....] - ETA: 1:28 - loss: 0.7164 - acc: 0.5109
7936/9333 [========================>.....] - ETA: 1:24 - loss: 0.7161 - acc: 0.5107
8000/9333 [========================>.....] - ETA: 1:20 - loss: 0.7160 - acc: 0.5110
8064/9333 [========================>.....] - ETA: 1:16 - loss: 0.7158 - acc: 0.5115
8128/9333 [=========================>....] - ETA: 1:12 - loss: 0.7156 - acc: 0.5117
8192/9333 [=========================>....] - ETA: 1:08 - loss: 0.7151 - acc: 0.5127
8256/9333 [=========================>....] - ETA: 1:05 - loss: 0.7155 - acc: 0.5114
8320/9333 [=========================>....] - ETA: 1:01 - loss: 0.7155 - acc: 0.5113
8384/9333 [=========================>....] - ETA: 57s - loss: 0.7152 - acc: 0.5112 
8448/9333 [==========================>...] - ETA: 53s - loss: 0.7151 - acc: 0.5121
8512/9333 [==========================>...] - ETA: 49s - loss: 0.7151 - acc: 0.5115
8576/9333 [==========================>...] - ETA: 45s - loss: 0.7151 - acc: 0.5113
8640/9333 [==========================>...] - ETA: 41s - loss: 0.7152 - acc: 0.5113
8704/9333 [==========================>...] - ETA: 37s - loss: 0.7152 - acc: 0.5114
8768/9333 [===========================>..] - ETA: 33s - loss: 0.7153 - acc: 0.5105
8832/9333 [===========================>..] - ETA: 29s - loss: 0.7151 - acc: 0.5108
8896/9333 [===========================>..] - ETA: 26s - loss: 0.7146 - acc: 0.5117
8960/9333 [===========================>..] - ETA: 22s - loss: 0.7148 - acc: 0.5112
9024/9333 [============================>.] - ETA: 18s - loss: 0.7145 - acc: 0.5114
9088/9333 [============================>.] - ETA: 14s - loss: 0.7143 - acc: 0.5121
9152/9333 [============================>.] - ETA: 10s - loss: 0.7144 - acc: 0.5117
9216/9333 [============================>.] - ETA: 6s - loss: 0.7141 - acc: 0.5123 
9280/9333 [============================>.] - ETA: 3s - loss: 0.7137 - acc: 0.5131
9333/9333 [==============================] - 587s 63ms/step - loss: 0.7137 - acc: 0.5129 - val_loss: 0.6902 - val_acc: 0.5419

Epoch 00001: val_acc improved from -inf to 0.54195, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window09/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 8:25 - loss: 0.7074 - acc: 0.5312
 128/9333 [..............................] - ETA: 7:50 - loss: 0.7089 - acc: 0.5234
 192/9333 [..............................] - ETA: 7:46 - loss: 0.6973 - acc: 0.5417
 256/9333 [..............................] - ETA: 7:52 - loss: 0.6988 - acc: 0.5391
 320/9333 [>.............................] - ETA: 7:54 - loss: 0.6960 - acc: 0.5406
 384/9333 [>.............................] - ETA: 7:51 - loss: 0.6933 - acc: 0.5417
 448/9333 [>.............................] - ETA: 7:53 - loss: 0.6967 - acc: 0.5179
 512/9333 [>.............................] - ETA: 7:42 - loss: 0.7039 - acc: 0.5098
 576/9333 [>.............................] - ETA: 7:38 - loss: 0.7026 - acc: 0.5156
 640/9333 [=>............................] - ETA: 7:33 - loss: 0.6990 - acc: 0.5219
 704/9333 [=>............................] - ETA: 7:28 - loss: 0.6963 - acc: 0.5284
 768/9333 [=>............................] - ETA: 7:23 - loss: 0.6961 - acc: 0.5221
 832/9333 [=>............................] - ETA: 7:20 - loss: 0.6954 - acc: 0.5192
 896/9333 [=>............................] - ETA: 7:13 - loss: 0.6953 - acc: 0.5212
 960/9333 [==>...........................] - ETA: 7:09 - loss: 0.6956 - acc: 0.5198
1024/9333 [==>...........................] - ETA: 7:03 - loss: 0.6977 - acc: 0.5146
1088/9333 [==>...........................] - ETA: 7:05 - loss: 0.6987 - acc: 0.5156
1152/9333 [==>...........................] - ETA: 7:00 - loss: 0.6981 - acc: 0.5208
1216/9333 [==>...........................] - ETA: 6:55 - loss: 0.6969 - acc: 0.5222
1280/9333 [===>..........................] - ETA: 6:55 - loss: 0.6967 - acc: 0.5234
1344/9333 [===>..........................] - ETA: 6:49 - loss: 0.6965 - acc: 0.5260
1408/9333 [===>..........................] - ETA: 6:45 - loss: 0.6968 - acc: 0.5270
1472/9333 [===>..........................] - ETA: 6:40 - loss: 0.6953 - acc: 0.5292
1536/9333 [===>..........................] - ETA: 6:36 - loss: 0.6957 - acc: 0.5293
1600/9333 [====>.........................] - ETA: 6:31 - loss: 0.6953 - acc: 0.5312
1664/9333 [====>.........................] - ETA: 6:26 - loss: 0.6949 - acc: 0.5306
1728/9333 [====>.........................] - ETA: 6:22 - loss: 0.6957 - acc: 0.5295
1792/9333 [====>.........................] - ETA: 6:19 - loss: 0.6947 - acc: 0.5324
1856/9333 [====>.........................] - ETA: 6:15 - loss: 0.6945 - acc: 0.5334
1920/9333 [=====>........................] - ETA: 6:12 - loss: 0.6962 - acc: 0.5312
1984/9333 [=====>........................] - ETA: 6:10 - loss: 0.6974 - acc: 0.5267
2048/9333 [=====>........................] - ETA: 6:07 - loss: 0.6979 - acc: 0.5264
2112/9333 [=====>........................] - ETA: 6:04 - loss: 0.6973 - acc: 0.5256
2176/9333 [=====>........................] - ETA: 6:01 - loss: 0.6980 - acc: 0.5221
2240/9333 [======>.......................] - ETA: 5:58 - loss: 0.6973 - acc: 0.5241
2304/9333 [======>.......................] - ETA: 5:55 - loss: 0.6970 - acc: 0.5243
2368/9333 [======>.......................] - ETA: 5:52 - loss: 0.6972 - acc: 0.5228
2432/9333 [======>.......................] - ETA: 5:50 - loss: 0.6961 - acc: 0.5263
2496/9333 [=======>......................] - ETA: 5:46 - loss: 0.6958 - acc: 0.5268
2560/9333 [=======>......................] - ETA: 5:42 - loss: 0.6961 - acc: 0.5258
2624/9333 [=======>......................] - ETA: 5:39 - loss: 0.6960 - acc: 0.5248
2688/9333 [=======>......................] - ETA: 5:35 - loss: 0.6960 - acc: 0.5238
2752/9333 [=======>......................] - ETA: 5:31 - loss: 0.6960 - acc: 0.5222
2816/9333 [========>.....................] - ETA: 5:28 - loss: 0.6965 - acc: 0.5217
2880/9333 [========>.....................] - ETA: 5:24 - loss: 0.6966 - acc: 0.5212
2944/9333 [========>.....................] - ETA: 5:21 - loss: 0.6969 - acc: 0.5211
3008/9333 [========>.....................] - ETA: 5:18 - loss: 0.6966 - acc: 0.5226
3072/9333 [========>.....................] - ETA: 5:15 - loss: 0.6967 - acc: 0.5205
3136/9333 [=========>....................] - ETA: 5:13 - loss: 0.6964 - acc: 0.5207
3200/9333 [=========>....................] - ETA: 5:10 - loss: 0.6965 - acc: 0.5206
3264/9333 [=========>....................] - ETA: 5:08 - loss: 0.6967 - acc: 0.5196
3328/9333 [=========>....................] - ETA: 5:05 - loss: 0.6970 - acc: 0.5177
3392/9333 [=========>....................] - ETA: 5:02 - loss: 0.6975 - acc: 0.5144
3456/9333 [==========>...................] - ETA: 4:58 - loss: 0.6974 - acc: 0.5150
3520/9333 [==========>...................] - ETA: 4:55 - loss: 0.6974 - acc: 0.5153
3584/9333 [==========>...................] - ETA: 4:52 - loss: 0.6976 - acc: 0.5145
3648/9333 [==========>...................] - ETA: 4:49 - loss: 0.6976 - acc: 0.5137
3712/9333 [==========>...................] - ETA: 4:45 - loss: 0.6981 - acc: 0.5129
3776/9333 [===========>..................] - ETA: 4:42 - loss: 0.6980 - acc: 0.5148
3840/9333 [===========>..................] - ETA: 4:38 - loss: 0.6974 - acc: 0.5164
3904/9333 [===========>..................] - ETA: 4:35 - loss: 0.6976 - acc: 0.5164
3968/9333 [===========>..................] - ETA: 4:32 - loss: 0.6976 - acc: 0.5169
4032/9333 [===========>..................] - ETA: 4:29 - loss: 0.6977 - acc: 0.5164
4096/9333 [============>.................] - ETA: 4:26 - loss: 0.6979 - acc: 0.5156
4160/9333 [============>.................] - ETA: 4:24 - loss: 0.6982 - acc: 0.5156
4224/9333 [============>.................] - ETA: 4:21 - loss: 0.6984 - acc: 0.5142
4288/9333 [============>.................] - ETA: 4:19 - loss: 0.6979 - acc: 0.5166
4352/9333 [============>.................] - ETA: 4:16 - loss: 0.6977 - acc: 0.5177
4416/9333 [=============>................] - ETA: 4:13 - loss: 0.6975 - acc: 0.5177
4480/9333 [=============>................] - ETA: 4:09 - loss: 0.6975 - acc: 0.5174
4544/9333 [=============>................] - ETA: 4:06 - loss: 0.6971 - acc: 0.5178
4608/9333 [=============>................] - ETA: 4:03 - loss: 0.6972 - acc: 0.5180
4672/9333 [==============>...............] - ETA: 4:00 - loss: 0.6979 - acc: 0.5165
4736/9333 [==============>...............] - ETA: 3:56 - loss: 0.6979 - acc: 0.5158
4800/9333 [==============>...............] - ETA: 3:53 - loss: 0.6981 - acc: 0.5146
4864/9333 [==============>...............] - ETA: 3:50 - loss: 0.6981 - acc: 0.5140
4928/9333 [==============>...............] - ETA: 3:47 - loss: 0.6978 - acc: 0.5136
4992/9333 [===============>..............] - ETA: 3:44 - loss: 0.6978 - acc: 0.5138
5056/9333 [===============>..............] - ETA: 3:40 - loss: 0.6976 - acc: 0.5144
5120/9333 [===============>..............] - ETA: 3:37 - loss: 0.6976 - acc: 0.5148
5184/9333 [===============>..............] - ETA: 3:34 - loss: 0.6975 - acc: 0.5160
5248/9333 [===============>..............] - ETA: 3:30 - loss: 0.6977 - acc: 0.5156
5312/9333 [================>.............] - ETA: 3:27 - loss: 0.6980 - acc: 0.5147
5376/9333 [================>.............] - ETA: 3:24 - loss: 0.6980 - acc: 0.5145
5440/9333 [================>.............] - ETA: 3:20 - loss: 0.6980 - acc: 0.5145
5504/9333 [================>.............] - ETA: 3:17 - loss: 0.6980 - acc: 0.5144
5568/9333 [================>.............] - ETA: 3:14 - loss: 0.6982 - acc: 0.5136
5632/9333 [=================>............] - ETA: 3:11 - loss: 0.6982 - acc: 0.5138
5696/9333 [=================>............] - ETA: 3:07 - loss: 0.6981 - acc: 0.5142
5760/9333 [=================>............] - ETA: 3:04 - loss: 0.6978 - acc: 0.5158
5824/9333 [=================>............] - ETA: 3:01 - loss: 0.6978 - acc: 0.5161
5888/9333 [=================>............] - ETA: 2:57 - loss: 0.6975 - acc: 0.5168
5952/9333 [==================>...........] - ETA: 2:54 - loss: 0.6974 - acc: 0.5166
6016/9333 [==================>...........] - ETA: 2:51 - loss: 0.6976 - acc: 0.5161
6080/9333 [==================>...........] - ETA: 2:48 - loss: 0.6978 - acc: 0.5156
6144/9333 [==================>...........] - ETA: 2:44 - loss: 0.6978 - acc: 0.5151
6208/9333 [==================>...........] - ETA: 2:41 - loss: 0.6980 - acc: 0.5142
6272/9333 [===================>..........] - ETA: 2:38 - loss: 0.6980 - acc: 0.5143
6336/9333 [===================>..........] - ETA: 2:35 - loss: 0.6979 - acc: 0.5150
6400/9333 [===================>..........] - ETA: 2:31 - loss: 0.6979 - acc: 0.5153
6464/9333 [===================>..........] - ETA: 2:28 - loss: 0.6978 - acc: 0.5152
6528/9333 [===================>..........] - ETA: 2:25 - loss: 0.6978 - acc: 0.5149
6592/9333 [====================>.........] - ETA: 2:21 - loss: 0.6976 - acc: 0.5156
6656/9333 [====================>.........] - ETA: 2:18 - loss: 0.6975 - acc: 0.5156
6720/9333 [====================>.........] - ETA: 2:15 - loss: 0.6976 - acc: 0.5156
6784/9333 [====================>.........] - ETA: 2:11 - loss: 0.6975 - acc: 0.5156
6848/9333 [=====================>........] - ETA: 2:08 - loss: 0.6974 - acc: 0.5158
6912/9333 [=====================>........] - ETA: 2:04 - loss: 0.6973 - acc: 0.5159
6976/9333 [=====================>........] - ETA: 2:01 - loss: 0.6974 - acc: 0.5153
7040/9333 [=====================>........] - ETA: 1:58 - loss: 0.6973 - acc: 0.5156
7104/9333 [=====================>........] - ETA: 1:54 - loss: 0.6973 - acc: 0.5153
7168/9333 [======================>.......] - ETA: 1:51 - loss: 0.6973 - acc: 0.5151
7232/9333 [======================>.......] - ETA: 1:48 - loss: 0.6973 - acc: 0.5147
7296/9333 [======================>.......] - ETA: 1:45 - loss: 0.6970 - acc: 0.5156
7360/9333 [======================>.......] - ETA: 1:41 - loss: 0.6972 - acc: 0.5147
7424/9333 [======================>.......] - ETA: 1:38 - loss: 0.6970 - acc: 0.5152
7488/9333 [=======================>......] - ETA: 1:35 - loss: 0.6971 - acc: 0.5142
7552/9333 [=======================>......] - ETA: 1:31 - loss: 0.6973 - acc: 0.5142
7616/9333 [=======================>......] - ETA: 1:28 - loss: 0.6975 - acc: 0.5130
7680/9333 [=======================>......] - ETA: 1:25 - loss: 0.6975 - acc: 0.5126
7744/9333 [=======================>......] - ETA: 1:21 - loss: 0.6976 - acc: 0.5123
7808/9333 [========================>.....] - ETA: 1:18 - loss: 0.6976 - acc: 0.5127
7872/9333 [========================>.....] - ETA: 1:15 - loss: 0.6973 - acc: 0.5135
7936/9333 [========================>.....] - ETA: 1:11 - loss: 0.6972 - acc: 0.5134
8000/9333 [========================>.....] - ETA: 1:08 - loss: 0.6972 - acc: 0.5139
8064/9333 [========================>.....] - ETA: 1:05 - loss: 0.6971 - acc: 0.5143
8128/9333 [=========================>....] - ETA: 1:02 - loss: 0.6971 - acc: 0.5146
8192/9333 [=========================>....] - ETA: 58s - loss: 0.6971 - acc: 0.5143 
8256/9333 [=========================>....] - ETA: 55s - loss: 0.6968 - acc: 0.5159
8320/9333 [=========================>....] - ETA: 52s - loss: 0.6965 - acc: 0.5161
8384/9333 [=========================>....] - ETA: 48s - loss: 0.6964 - acc: 0.5161
8448/9333 [==========================>...] - ETA: 45s - loss: 0.6963 - acc: 0.5163
8512/9333 [==========================>...] - ETA: 42s - loss: 0.6962 - acc: 0.5169
8576/9333 [==========================>...] - ETA: 38s - loss: 0.6963 - acc: 0.5167
8640/9333 [==========================>...] - ETA: 35s - loss: 0.6964 - acc: 0.5169
8704/9333 [==========================>...] - ETA: 32s - loss: 0.6965 - acc: 0.5168
8768/9333 [===========================>..] - ETA: 29s - loss: 0.6967 - acc: 0.5164
8832/9333 [===========================>..] - ETA: 25s - loss: 0.6966 - acc: 0.5168
8896/9333 [===========================>..] - ETA: 22s - loss: 0.6968 - acc: 0.5163
8960/9333 [===========================>..] - ETA: 19s - loss: 0.6968 - acc: 0.5162
9024/9333 [============================>.] - ETA: 15s - loss: 0.6971 - acc: 0.5157
9088/9333 [============================>.] - ETA: 12s - loss: 0.6971 - acc: 0.5160
9152/9333 [============================>.] - ETA: 9s - loss: 0.6972 - acc: 0.5155 
9216/9333 [============================>.] - ETA: 6s - loss: 0.6970 - acc: 0.5157
9280/9333 [============================>.] - ETA: 2s - loss: 0.6969 - acc: 0.5155
9333/9333 [==============================] - 500s 54ms/step - loss: 0.6969 - acc: 0.5153 - val_loss: 0.6884 - val_acc: 0.5448

Epoch 00002: val_acc improved from 0.54195 to 0.54484, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window09/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 3/10

  64/9333 [..............................] - ETA: 7:07 - loss: 0.6923 - acc: 0.5156
 128/9333 [..............................] - ETA: 7:27 - loss: 0.6958 - acc: 0.5469
 192/9333 [..............................] - ETA: 7:25 - loss: 0.6911 - acc: 0.5469
 256/9333 [..............................] - ETA: 7:28 - loss: 0.6969 - acc: 0.5273
 320/9333 [>.............................] - ETA: 7:23 - loss: 0.6940 - acc: 0.5281
 384/9333 [>.............................] - ETA: 7:19 - loss: 0.6945 - acc: 0.5339
 448/9333 [>.............................] - ETA: 7:16 - loss: 0.6957 - acc: 0.5357
 512/9333 [>.............................] - ETA: 7:15 - loss: 0.6983 - acc: 0.5273
 576/9333 [>.............................] - ETA: 7:08 - loss: 0.6974 - acc: 0.5295
 640/9333 [=>............................] - ETA: 7:04 - loss: 0.6988 - acc: 0.5219
 704/9333 [=>............................] - ETA: 6:57 - loss: 0.6988 - acc: 0.5185
 768/9333 [=>............................] - ETA: 6:52 - loss: 0.6972 - acc: 0.5221
 832/9333 [=>............................] - ETA: 6:49 - loss: 0.6971 - acc: 0.5180
 896/9333 [=>............................] - ETA: 6:48 - loss: 0.6962 - acc: 0.5223
 960/9333 [==>...........................] - ETA: 6:45 - loss: 0.6959 - acc: 0.5250
1024/9333 [==>...........................] - ETA: 6:41 - loss: 0.6963 - acc: 0.5244
1088/9333 [==>...........................] - ETA: 6:35 - loss: 0.6964 - acc: 0.5230
1152/9333 [==>...........................] - ETA: 6:33 - loss: 0.6948 - acc: 0.5286
1216/9333 [==>...........................] - ETA: 6:29 - loss: 0.6941 - acc: 0.5329
1280/9333 [===>..........................] - ETA: 6:28 - loss: 0.6945 - acc: 0.5328
1344/9333 [===>..........................] - ETA: 6:27 - loss: 0.6935 - acc: 0.5350
1408/9333 [===>..........................] - ETA: 6:23 - loss: 0.6937 - acc: 0.5312
1472/9333 [===>..........................] - ETA: 6:19 - loss: 0.6924 - acc: 0.5353
1536/9333 [===>..........................] - ETA: 6:17 - loss: 0.6919 - acc: 0.5365
1600/9333 [====>.........................] - ETA: 6:13 - loss: 0.6924 - acc: 0.5363
1664/9333 [====>.........................] - ETA: 6:10 - loss: 0.6918 - acc: 0.5391
1728/9333 [====>.........................] - ETA: 6:08 - loss: 0.6919 - acc: 0.5399
1792/9333 [====>.........................] - ETA: 6:06 - loss: 0.6915 - acc: 0.5402
1856/9333 [====>.........................] - ETA: 6:03 - loss: 0.6910 - acc: 0.5404
1920/9333 [=====>........................] - ETA: 5:59 - loss: 0.6918 - acc: 0.5380
1984/9333 [=====>........................] - ETA: 5:57 - loss: 0.6915 - acc: 0.5393
2048/9333 [=====>........................] - ETA: 5:53 - loss: 0.6917 - acc: 0.5391
2112/9333 [=====>........................] - ETA: 5:49 - loss: 0.6905 - acc: 0.5431
2176/9333 [=====>........................] - ETA: 5:47 - loss: 0.6906 - acc: 0.5427
2240/9333 [======>.......................] - ETA: 5:44 - loss: 0.6910 - acc: 0.5411
2304/9333 [======>.......................] - ETA: 5:42 - loss: 0.6913 - acc: 0.5395
2368/9333 [======>.......................] - ETA: 5:38 - loss: 0.6914 - acc: 0.5410
2432/9333 [======>.......................] - ETA: 5:36 - loss: 0.6924 - acc: 0.5391
2496/9333 [=======>......................] - ETA: 5:34 - loss: 0.6918 - acc: 0.5409
2560/9333 [=======>......................] - ETA: 5:31 - loss: 0.6915 - acc: 0.5418
2624/9333 [=======>......................] - ETA: 5:27 - loss: 0.6914 - acc: 0.5419
2688/9333 [=======>......................] - ETA: 5:24 - loss: 0.6928 - acc: 0.5376
2752/9333 [=======>......................] - ETA: 5:20 - loss: 0.6924 - acc: 0.5378
2816/9333 [========>.....................] - ETA: 5:17 - loss: 0.6925 - acc: 0.5376
2880/9333 [========>.....................] - ETA: 5:14 - loss: 0.6933 - acc: 0.5354
2944/9333 [========>.....................] - ETA: 5:11 - loss: 0.6933 - acc: 0.5346
3008/9333 [========>.....................] - ETA: 5:09 - loss: 0.6928 - acc: 0.5356
3072/9333 [========>.....................] - ETA: 5:05 - loss: 0.6923 - acc: 0.5381
3136/9333 [=========>....................] - ETA: 5:02 - loss: 0.6927 - acc: 0.5354
3200/9333 [=========>....................] - ETA: 4:58 - loss: 0.6928 - acc: 0.5353
3264/9333 [=========>....................] - ETA: 4:56 - loss: 0.6928 - acc: 0.5365
3328/9333 [=========>....................] - ETA: 4:59 - loss: 0.6923 - acc: 0.5385
3392/9333 [=========>....................] - ETA: 4:56 - loss: 0.6927 - acc: 0.5369
3456/9333 [==========>...................] - ETA: 4:54 - loss: 0.6927 - acc: 0.5362
3520/9333 [==========>...................] - ETA: 4:51 - loss: 0.6929 - acc: 0.5358
3584/9333 [==========>...................] - ETA: 4:48 - loss: 0.6930 - acc: 0.5346
3648/9333 [==========>...................] - ETA: 4:45 - loss: 0.6931 - acc: 0.5351
3712/9333 [==========>...................] - ETA: 4:41 - loss: 0.6927 - acc: 0.5361
3776/9333 [===========>..................] - ETA: 4:38 - loss: 0.6925 - acc: 0.5371
3840/9333 [===========>..................] - ETA: 4:34 - loss: 0.6929 - acc: 0.5349
3904/9333 [===========>..................] - ETA: 4:31 - loss: 0.6938 - acc: 0.5328
3968/9333 [===========>..................] - ETA: 4:27 - loss: 0.6940 - acc: 0.5323
4032/9333 [===========>..................] - ETA: 4:24 - loss: 0.6938 - acc: 0.5327
4096/9333 [============>.................] - ETA: 4:21 - loss: 0.6940 - acc: 0.5308
4160/9333 [============>.................] - ETA: 4:18 - loss: 0.6944 - acc: 0.5300
4224/9333 [============>.................] - ETA: 4:14 - loss: 0.6944 - acc: 0.5305
4288/9333 [============>.................] - ETA: 4:11 - loss: 0.6942 - acc: 0.5315
4352/9333 [============>.................] - ETA: 4:08 - loss: 0.6940 - acc: 0.5324
4416/9333 [=============>................] - ETA: 4:04 - loss: 0.6938 - acc: 0.5322
4480/9333 [=============>................] - ETA: 4:01 - loss: 0.6937 - acc: 0.5324
4544/9333 [=============>................] - ETA: 3:58 - loss: 0.6938 - acc: 0.5319
4608/9333 [=============>................] - ETA: 3:54 - loss: 0.6942 - acc: 0.5308
4672/9333 [==============>...............] - ETA: 3:51 - loss: 0.6941 - acc: 0.5310
4736/9333 [==============>...............] - ETA: 3:48 - loss: 0.6937 - acc: 0.5323
4800/9333 [==============>...............] - ETA: 3:44 - loss: 0.6936 - acc: 0.5327
4864/9333 [==============>...............] - ETA: 3:41 - loss: 0.6933 - acc: 0.5337
4928/9333 [==============>...............] - ETA: 3:38 - loss: 0.6929 - acc: 0.5347
4992/9333 [===============>..............] - ETA: 3:34 - loss: 0.6930 - acc: 0.5343
5056/9333 [===============>..............] - ETA: 3:31 - loss: 0.6928 - acc: 0.5354
5120/9333 [===============>..............] - ETA: 3:28 - loss: 0.6924 - acc: 0.5363
5184/9333 [===============>..............] - ETA: 3:25 - loss: 0.6924 - acc: 0.5368
5248/9333 [===============>..............] - ETA: 3:22 - loss: 0.6926 - acc: 0.5364
5312/9333 [================>.............] - ETA: 3:18 - loss: 0.6926 - acc: 0.5361
5376/9333 [================>.............] - ETA: 3:15 - loss: 0.6923 - acc: 0.5372
5440/9333 [================>.............] - ETA: 3:12 - loss: 0.6922 - acc: 0.5371
5504/9333 [================>.............] - ETA: 3:09 - loss: 0.6923 - acc: 0.5374
5568/9333 [================>.............] - ETA: 3:06 - loss: 0.6923 - acc: 0.5359
5632/9333 [=================>............] - ETA: 3:02 - loss: 0.6923 - acc: 0.5360
5696/9333 [=================>............] - ETA: 2:59 - loss: 0.6924 - acc: 0.5360
5760/9333 [=================>............] - ETA: 2:56 - loss: 0.6925 - acc: 0.5361
5824/9333 [=================>............] - ETA: 2:53 - loss: 0.6924 - acc: 0.5357
5888/9333 [=================>............] - ETA: 2:49 - loss: 0.6926 - acc: 0.5353
5952/9333 [==================>...........] - ETA: 2:46 - loss: 0.6924 - acc: 0.5349
6016/9333 [==================>...........] - ETA: 2:43 - loss: 0.6921 - acc: 0.5357
6080/9333 [==================>...........] - ETA: 2:40 - loss: 0.6922 - acc: 0.5352
6144/9333 [==================>...........] - ETA: 2:37 - loss: 0.6922 - acc: 0.5358
6208/9333 [==================>...........] - ETA: 2:34 - loss: 0.6922 - acc: 0.5356
6272/9333 [===================>..........] - ETA: 2:31 - loss: 0.6919 - acc: 0.5360
6336/9333 [===================>..........] - ETA: 2:28 - loss: 0.6920 - acc: 0.5355
6400/9333 [===================>..........] - ETA: 2:24 - loss: 0.6918 - acc: 0.5359
6464/9333 [===================>..........] - ETA: 2:21 - loss: 0.6918 - acc: 0.5360
6528/9333 [===================>..........] - ETA: 2:18 - loss: 0.6921 - acc: 0.5352
6592/9333 [====================>.........] - ETA: 2:15 - loss: 0.6925 - acc: 0.5350
6656/9333 [====================>.........] - ETA: 2:12 - loss: 0.6924 - acc: 0.5356
6720/9333 [====================>.........] - ETA: 2:09 - loss: 0.6924 - acc: 0.5350
6784/9333 [====================>.........] - ETA: 2:05 - loss: 0.6927 - acc: 0.5343
6848/9333 [=====================>........] - ETA: 2:02 - loss: 0.6927 - acc: 0.5339
6912/9333 [=====================>........] - ETA: 1:59 - loss: 0.6928 - acc: 0.5327
6976/9333 [=====================>........] - ETA: 1:56 - loss: 0.6927 - acc: 0.5333
7040/9333 [=====================>........] - ETA: 1:53 - loss: 0.6928 - acc: 0.5321
7104/9333 [=====================>........] - ETA: 1:50 - loss: 0.6927 - acc: 0.5328
7168/9333 [======================>.......] - ETA: 1:46 - loss: 0.6927 - acc: 0.5328
7232/9333 [======================>.......] - ETA: 1:43 - loss: 0.6927 - acc: 0.5325
7296/9333 [======================>.......] - ETA: 1:40 - loss: 0.6927 - acc: 0.5325
7360/9333 [======================>.......] - ETA: 1:37 - loss: 0.6928 - acc: 0.5319
7424/9333 [======================>.......] - ETA: 1:34 - loss: 0.6931 - acc: 0.5312
7488/9333 [=======================>......] - ETA: 1:31 - loss: 0.6933 - acc: 0.5304
7552/9333 [=======================>......] - ETA: 1:27 - loss: 0.6933 - acc: 0.5305
7616/9333 [=======================>......] - ETA: 1:24 - loss: 0.6934 - acc: 0.5302
7680/9333 [=======================>......] - ETA: 1:21 - loss: 0.6934 - acc: 0.5297
7744/9333 [=======================>......] - ETA: 1:18 - loss: 0.6932 - acc: 0.5301
7808/9333 [========================>.....] - ETA: 1:15 - loss: 0.6932 - acc: 0.5296
7872/9333 [========================>.....] - ETA: 1:12 - loss: 0.6931 - acc: 0.5301
7936/9333 [========================>.....] - ETA: 1:08 - loss: 0.6932 - acc: 0.5301
8000/9333 [========================>.....] - ETA: 1:05 - loss: 0.6932 - acc: 0.5304
8064/9333 [========================>.....] - ETA: 1:02 - loss: 0.6932 - acc: 0.5303
8128/9333 [=========================>....] - ETA: 59s - loss: 0.6930 - acc: 0.5305 
8192/9333 [=========================>....] - ETA: 56s - loss: 0.6930 - acc: 0.5306
8256/9333 [=========================>....] - ETA: 53s - loss: 0.6929 - acc: 0.5308
8320/9333 [=========================>....] - ETA: 50s - loss: 0.6928 - acc: 0.5310
8384/9333 [=========================>....] - ETA: 46s - loss: 0.6927 - acc: 0.5315
8448/9333 [==========================>...] - ETA: 43s - loss: 0.6926 - acc: 0.5315
8512/9333 [==========================>...] - ETA: 40s - loss: 0.6926 - acc: 0.5309
8576/9333 [==========================>...] - ETA: 37s - loss: 0.6927 - acc: 0.5304
8640/9333 [==========================>...] - ETA: 34s - loss: 0.6927 - acc: 0.5308
8704/9333 [==========================>...] - ETA: 31s - loss: 0.6927 - acc: 0.5304
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6925 - acc: 0.5314
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6925 - acc: 0.5308
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6925 - acc: 0.5310
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6927 - acc: 0.5308
9024/9333 [============================>.] - ETA: 15s - loss: 0.6926 - acc: 0.5310
9088/9333 [============================>.] - ETA: 12s - loss: 0.6926 - acc: 0.5308
9152/9333 [============================>.] - ETA: 8s - loss: 0.6926 - acc: 0.5309 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6927 - acc: 0.5305
9280/9333 [============================>.] - ETA: 2s - loss: 0.6926 - acc: 0.5304
9333/9333 [==============================] - 483s 52ms/step - loss: 0.6925 - acc: 0.5310 - val_loss: 0.6925 - val_acc: 0.5217

Epoch 00003: val_acc did not improve from 0.54484
Epoch 4/10

  64/9333 [..............................] - ETA: 8:37 - loss: 0.6982 - acc: 0.5000
 128/9333 [..............................] - ETA: 7:59 - loss: 0.7125 - acc: 0.4453
 192/9333 [..............................] - ETA: 7:53 - loss: 0.7112 - acc: 0.4740
 256/9333 [..............................] - ETA: 7:39 - loss: 0.7072 - acc: 0.5000
 320/9333 [>.............................] - ETA: 7:29 - loss: 0.7061 - acc: 0.4906
 384/9333 [>.............................] - ETA: 7:19 - loss: 0.7035 - acc: 0.5104
 448/9333 [>.............................] - ETA: 7:27 - loss: 0.7027 - acc: 0.5000
 512/9333 [>.............................] - ETA: 7:18 - loss: 0.7021 - acc: 0.5098
 576/9333 [>.............................] - ETA: 7:15 - loss: 0.6997 - acc: 0.5191
 640/9333 [=>............................] - ETA: 7:15 - loss: 0.6993 - acc: 0.5266
 704/9333 [=>............................] - ETA: 7:12 - loss: 0.7000 - acc: 0.5170
 768/9333 [=>............................] - ETA: 7:12 - loss: 0.6995 - acc: 0.5169
 832/9333 [=>............................] - ETA: 7:09 - loss: 0.7012 - acc: 0.5036
 896/9333 [=>............................] - ETA: 7:07 - loss: 0.6998 - acc: 0.5100
 960/9333 [==>...........................] - ETA: 7:06 - loss: 0.6992 - acc: 0.5115
1024/9333 [==>...........................] - ETA: 7:01 - loss: 0.6980 - acc: 0.5186
1088/9333 [==>...........................] - ETA: 6:55 - loss: 0.6981 - acc: 0.5110
1152/9333 [==>...........................] - ETA: 6:56 - loss: 0.6976 - acc: 0.5113
1216/9333 [==>...........................] - ETA: 6:54 - loss: 0.6983 - acc: 0.5082
1280/9333 [===>..........................] - ETA: 6:50 - loss: 0.6977 - acc: 0.5109
1344/9333 [===>..........................] - ETA: 6:46 - loss: 0.6969 - acc: 0.5134
1408/9333 [===>..........................] - ETA: 6:42 - loss: 0.6968 - acc: 0.5135
1472/9333 [===>..........................] - ETA: 6:36 - loss: 0.6960 - acc: 0.5149
1536/9333 [===>..........................] - ETA: 6:36 - loss: 0.6963 - acc: 0.5137
1600/9333 [====>.........................] - ETA: 6:32 - loss: 0.6961 - acc: 0.5150
1664/9333 [====>.........................] - ETA: 6:29 - loss: 0.6965 - acc: 0.5150
1728/9333 [====>.........................] - ETA: 6:24 - loss: 0.6964 - acc: 0.5162
1792/9333 [====>.........................] - ETA: 6:21 - loss: 0.6960 - acc: 0.5173
1856/9333 [====>.........................] - ETA: 6:16 - loss: 0.6960 - acc: 0.5183
1920/9333 [=====>........................] - ETA: 6:12 - loss: 0.6967 - acc: 0.5172
1984/9333 [=====>........................] - ETA: 6:09 - loss: 0.6965 - acc: 0.5161
2048/9333 [=====>........................] - ETA: 6:06 - loss: 0.6973 - acc: 0.5137
2112/9333 [=====>........................] - ETA: 6:02 - loss: 0.6977 - acc: 0.5128
2176/9333 [=====>........................] - ETA: 5:59 - loss: 0.6976 - acc: 0.5161
2240/9333 [======>.......................] - ETA: 5:55 - loss: 0.6971 - acc: 0.5179
2304/9333 [======>.......................] - ETA: 5:51 - loss: 0.6965 - acc: 0.5191
2368/9333 [======>.......................] - ETA: 5:47 - loss: 0.6958 - acc: 0.5194
2432/9333 [======>.......................] - ETA: 5:44 - loss: 0.6956 - acc: 0.5214
2496/9333 [=======>......................] - ETA: 5:40 - loss: 0.6955 - acc: 0.5224
2560/9333 [=======>......................] - ETA: 5:36 - loss: 0.6953 - acc: 0.5242
2624/9333 [=======>......................] - ETA: 5:33 - loss: 0.6949 - acc: 0.5267
2688/9333 [=======>......................] - ETA: 5:29 - loss: 0.6946 - acc: 0.5264
2752/9333 [=======>......................] - ETA: 5:26 - loss: 0.6943 - acc: 0.5265
2816/9333 [========>.....................] - ETA: 5:22 - loss: 0.6947 - acc: 0.5252
2880/9333 [========>.....................] - ETA: 5:19 - loss: 0.6947 - acc: 0.5250
2944/9333 [========>.....................] - ETA: 5:15 - loss: 0.6954 - acc: 0.5234
3008/9333 [========>.....................] - ETA: 5:12 - loss: 0.6951 - acc: 0.5256
3072/9333 [========>.....................] - ETA: 5:11 - loss: 0.6947 - acc: 0.5277
3136/9333 [=========>....................] - ETA: 5:09 - loss: 0.6949 - acc: 0.5268
3200/9333 [=========>....................] - ETA: 5:05 - loss: 0.6947 - acc: 0.5272
3264/9333 [=========>....................] - ETA: 5:02 - loss: 0.6951 - acc: 0.5260
3328/9333 [=========>....................] - ETA: 4:59 - loss: 0.6949 - acc: 0.5270
3392/9333 [=========>....................] - ETA: 4:55 - loss: 0.6949 - acc: 0.5277
3456/9333 [==========>...................] - ETA: 4:51 - loss: 0.6948 - acc: 0.5269
3520/9333 [==========>...................] - ETA: 4:48 - loss: 0.6945 - acc: 0.5270
3584/9333 [==========>...................] - ETA: 4:44 - loss: 0.6942 - acc: 0.5276
3648/9333 [==========>...................] - ETA: 4:41 - loss: 0.6944 - acc: 0.5269
3712/9333 [==========>...................] - ETA: 4:38 - loss: 0.6944 - acc: 0.5267
3776/9333 [===========>..................] - ETA: 4:35 - loss: 0.6943 - acc: 0.5260
3840/9333 [===========>..................] - ETA: 4:31 - loss: 0.6945 - acc: 0.5255
3904/9333 [===========>..................] - ETA: 4:28 - loss: 0.6939 - acc: 0.5264
3968/9333 [===========>..................] - ETA: 4:25 - loss: 0.6938 - acc: 0.5265
4032/9333 [===========>..................] - ETA: 4:22 - loss: 0.6936 - acc: 0.5273
4096/9333 [============>.................] - ETA: 4:19 - loss: 0.6935 - acc: 0.5278
4160/9333 [============>.................] - ETA: 4:16 - loss: 0.6931 - acc: 0.5279
4224/9333 [============>.................] - ETA: 4:13 - loss: 0.6930 - acc: 0.5279
4288/9333 [============>.................] - ETA: 4:09 - loss: 0.6930 - acc: 0.5285
4352/9333 [============>.................] - ETA: 4:06 - loss: 0.6925 - acc: 0.5287
4416/9333 [=============>................] - ETA: 4:02 - loss: 0.6924 - acc: 0.5297
4480/9333 [=============>................] - ETA: 3:59 - loss: 0.6924 - acc: 0.5290
4544/9333 [=============>................] - ETA: 3:56 - loss: 0.6925 - acc: 0.5282
4608/9333 [=============>................] - ETA: 3:53 - loss: 0.6922 - acc: 0.5293
4672/9333 [==============>...............] - ETA: 3:50 - loss: 0.6918 - acc: 0.5312
4736/9333 [==============>...............] - ETA: 3:46 - loss: 0.6919 - acc: 0.5317
4800/9333 [==============>...............] - ETA: 3:43 - loss: 0.6923 - acc: 0.5308
4864/9333 [==============>...............] - ETA: 3:40 - loss: 0.6921 - acc: 0.5312
4928/9333 [==============>...............] - ETA: 3:37 - loss: 0.6925 - acc: 0.5300
4992/9333 [===============>..............] - ETA: 3:34 - loss: 0.6925 - acc: 0.5298
5056/9333 [===============>..............] - ETA: 3:30 - loss: 0.6920 - acc: 0.5314
5120/9333 [===============>..............] - ETA: 3:27 - loss: 0.6916 - acc: 0.5326
5184/9333 [===============>..............] - ETA: 3:24 - loss: 0.6913 - acc: 0.5347
5248/9333 [===============>..............] - ETA: 3:21 - loss: 0.6912 - acc: 0.5360
5312/9333 [================>.............] - ETA: 3:18 - loss: 0.6911 - acc: 0.5371
5376/9333 [================>.............] - ETA: 3:15 - loss: 0.6911 - acc: 0.5372
5440/9333 [================>.............] - ETA: 3:12 - loss: 0.6912 - acc: 0.5369
5504/9333 [================>.............] - ETA: 3:08 - loss: 0.6910 - acc: 0.5378
5568/9333 [================>.............] - ETA: 3:05 - loss: 0.6912 - acc: 0.5375
5632/9333 [=================>............] - ETA: 3:02 - loss: 0.6909 - acc: 0.5378
5696/9333 [=================>............] - ETA: 2:59 - loss: 0.6907 - acc: 0.5388
5760/9333 [=================>............] - ETA: 2:56 - loss: 0.6902 - acc: 0.5392
5824/9333 [=================>............] - ETA: 2:53 - loss: 0.6901 - acc: 0.5397
5888/9333 [=================>............] - ETA: 2:50 - loss: 0.6900 - acc: 0.5394
5952/9333 [==================>...........] - ETA: 2:46 - loss: 0.6898 - acc: 0.5393
6016/9333 [==================>...........] - ETA: 2:43 - loss: 0.6897 - acc: 0.5397
6080/9333 [==================>...........] - ETA: 2:40 - loss: 0.6895 - acc: 0.5403
6144/9333 [==================>...........] - ETA: 2:37 - loss: 0.6895 - acc: 0.5405
6208/9333 [==================>...........] - ETA: 2:34 - loss: 0.6891 - acc: 0.5416
6272/9333 [===================>..........] - ETA: 2:31 - loss: 0.6894 - acc: 0.5413
6336/9333 [===================>..........] - ETA: 2:27 - loss: 0.6893 - acc: 0.5414
6400/9333 [===================>..........] - ETA: 2:24 - loss: 0.6893 - acc: 0.5413
6464/9333 [===================>..........] - ETA: 2:21 - loss: 0.6892 - acc: 0.5418
6528/9333 [===================>..........] - ETA: 2:18 - loss: 0.6897 - acc: 0.5398
6592/9333 [====================>.........] - ETA: 2:15 - loss: 0.6898 - acc: 0.5393
6656/9333 [====================>.........] - ETA: 2:12 - loss: 0.6898 - acc: 0.5389
6720/9333 [====================>.........] - ETA: 2:09 - loss: 0.6896 - acc: 0.5393
6784/9333 [====================>.........] - ETA: 2:06 - loss: 0.6894 - acc: 0.5397
6848/9333 [=====================>........] - ETA: 2:02 - loss: 0.6896 - acc: 0.5388
6912/9333 [=====================>........] - ETA: 1:59 - loss: 0.6897 - acc: 0.5383
6976/9333 [=====================>........] - ETA: 1:56 - loss: 0.6895 - acc: 0.5391
7040/9333 [=====================>........] - ETA: 1:53 - loss: 0.6895 - acc: 0.5388
7104/9333 [=====================>........] - ETA: 1:50 - loss: 0.6893 - acc: 0.5394
7168/9333 [======================>.......] - ETA: 1:47 - loss: 0.6892 - acc: 0.5391
7232/9333 [======================>.......] - ETA: 1:44 - loss: 0.6893 - acc: 0.5387
7296/9333 [======================>.......] - ETA: 1:41 - loss: 0.6893 - acc: 0.5388
7360/9333 [======================>.......] - ETA: 1:37 - loss: 0.6893 - acc: 0.5390
7424/9333 [======================>.......] - ETA: 1:34 - loss: 0.6892 - acc: 0.5393
7488/9333 [=======================>......] - ETA: 1:31 - loss: 0.6893 - acc: 0.5390
7552/9333 [=======================>......] - ETA: 1:28 - loss: 0.6893 - acc: 0.5395
7616/9333 [=======================>......] - ETA: 1:25 - loss: 0.6891 - acc: 0.5394
7680/9333 [=======================>......] - ETA: 1:22 - loss: 0.6893 - acc: 0.5387
7744/9333 [=======================>......] - ETA: 1:19 - loss: 0.6894 - acc: 0.5386
7808/9333 [========================>.....] - ETA: 1:15 - loss: 0.6894 - acc: 0.5386
7872/9333 [========================>.....] - ETA: 1:12 - loss: 0.6896 - acc: 0.5376
7936/9333 [========================>.....] - ETA: 1:09 - loss: 0.6899 - acc: 0.5368
8000/9333 [========================>.....] - ETA: 1:06 - loss: 0.6898 - acc: 0.5373
8064/9333 [========================>.....] - ETA: 1:03 - loss: 0.6899 - acc: 0.5367
8128/9333 [=========================>....] - ETA: 59s - loss: 0.6899 - acc: 0.5369 
8192/9333 [=========================>....] - ETA: 56s - loss: 0.6899 - acc: 0.5367
8256/9333 [=========================>....] - ETA: 53s - loss: 0.6899 - acc: 0.5362
8320/9333 [=========================>....] - ETA: 50s - loss: 0.6900 - acc: 0.5357
8384/9333 [=========================>....] - ETA: 47s - loss: 0.6901 - acc: 0.5348
8448/9333 [==========================>...] - ETA: 44s - loss: 0.6900 - acc: 0.5349
8512/9333 [==========================>...] - ETA: 40s - loss: 0.6900 - acc: 0.5345
8576/9333 [==========================>...] - ETA: 37s - loss: 0.6900 - acc: 0.5347
8640/9333 [==========================>...] - ETA: 34s - loss: 0.6901 - acc: 0.5343
8704/9333 [==========================>...] - ETA: 31s - loss: 0.6902 - acc: 0.5334
8768/9333 [===========================>..] - ETA: 28s - loss: 0.6902 - acc: 0.5336
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6902 - acc: 0.5334
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6902 - acc: 0.5336
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6902 - acc: 0.5334
9024/9333 [============================>.] - ETA: 15s - loss: 0.6902 - acc: 0.5334
9088/9333 [============================>.] - ETA: 12s - loss: 0.6900 - acc: 0.5340
9152/9333 [============================>.] - ETA: 9s - loss: 0.6900 - acc: 0.5335 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6902 - acc: 0.5328
9280/9333 [============================>.] - ETA: 2s - loss: 0.6900 - acc: 0.5334
9333/9333 [==============================] - 485s 52ms/step - loss: 0.6900 - acc: 0.5333 - val_loss: 0.6867 - val_acc: 0.5304

Epoch 00004: val_acc did not improve from 0.54484
Epoch 5/10

  64/9333 [..............................] - ETA: 7:40 - loss: 0.6668 - acc: 0.6250
 128/9333 [..............................] - ETA: 7:24 - loss: 0.6794 - acc: 0.5391
 192/9333 [..............................] - ETA: 7:27 - loss: 0.6849 - acc: 0.5365
 256/9333 [..............................] - ETA: 7:39 - loss: 0.6854 - acc: 0.5234
 320/9333 [>.............................] - ETA: 7:22 - loss: 0.6894 - acc: 0.5125
 384/9333 [>.............................] - ETA: 7:17 - loss: 0.6903 - acc: 0.5234
 448/9333 [>.............................] - ETA: 7:09 - loss: 0.6903 - acc: 0.5246
 512/9333 [>.............................] - ETA: 7:09 - loss: 0.6903 - acc: 0.5234
 576/9333 [>.............................] - ETA: 7:01 - loss: 0.6911 - acc: 0.5226
 640/9333 [=>............................] - ETA: 6:56 - loss: 0.6917 - acc: 0.5172
 704/9333 [=>............................] - ETA: 6:49 - loss: 0.6902 - acc: 0.5256
 768/9333 [=>............................] - ETA: 6:43 - loss: 0.6898 - acc: 0.5273
 832/9333 [=>............................] - ETA: 6:40 - loss: 0.6901 - acc: 0.5300
 896/9333 [=>............................] - ETA: 6:35 - loss: 0.6911 - acc: 0.5279
 960/9333 [==>...........................] - ETA: 6:33 - loss: 0.6895 - acc: 0.5302
1024/9333 [==>...........................] - ETA: 6:27 - loss: 0.6896 - acc: 0.5332
1088/9333 [==>...........................] - ETA: 6:23 - loss: 0.6899 - acc: 0.5294
1152/9333 [==>...........................] - ETA: 6:23 - loss: 0.6882 - acc: 0.5365
1216/9333 [==>...........................] - ETA: 6:22 - loss: 0.6901 - acc: 0.5296
1280/9333 [===>..........................] - ETA: 6:22 - loss: 0.6871 - acc: 0.5375
1344/9333 [===>..........................] - ETA: 6:21 - loss: 0.6875 - acc: 0.5365
1408/9333 [===>..........................] - ETA: 6:18 - loss: 0.6879 - acc: 0.5334
1472/9333 [===>..........................] - ETA: 6:15 - loss: 0.6867 - acc: 0.5360
1536/9333 [===>..........................] - ETA: 6:11 - loss: 0.6859 - acc: 0.5378
1600/9333 [====>.........................] - ETA: 6:07 - loss: 0.6869 - acc: 0.5356
1664/9333 [====>.........................] - ETA: 6:04 - loss: 0.6870 - acc: 0.5367
1728/9333 [====>.........................] - ETA: 5:59 - loss: 0.6874 - acc: 0.5370
1792/9333 [====>.........................] - ETA: 5:57 - loss: 0.6875 - acc: 0.5379
1856/9333 [====>.........................] - ETA: 5:54 - loss: 0.6870 - acc: 0.5383
1920/9333 [=====>........................] - ETA: 5:51 - loss: 0.6875 - acc: 0.5359
1984/9333 [=====>........................] - ETA: 5:47 - loss: 0.6878 - acc: 0.5348
2048/9333 [=====>........................] - ETA: 5:43 - loss: 0.6882 - acc: 0.5327
2112/9333 [=====>........................] - ETA: 5:39 - loss: 0.6873 - acc: 0.5374
2176/9333 [=====>........................] - ETA: 5:35 - loss: 0.6872 - acc: 0.5381
2240/9333 [======>.......................] - ETA: 5:33 - loss: 0.6869 - acc: 0.5375
2304/9333 [======>.......................] - ETA: 5:31 - loss: 0.6874 - acc: 0.5378
2368/9333 [======>.......................] - ETA: 5:29 - loss: 0.6870 - acc: 0.5389
2432/9333 [======>.......................] - ETA: 5:26 - loss: 0.6867 - acc: 0.5395
2496/9333 [=======>......................] - ETA: 5:24 - loss: 0.6861 - acc: 0.5401
2560/9333 [=======>......................] - ETA: 5:21 - loss: 0.6869 - acc: 0.5387
2624/9333 [=======>......................] - ETA: 5:18 - loss: 0.6871 - acc: 0.5381
2688/9333 [=======>......................] - ETA: 5:16 - loss: 0.6859 - acc: 0.5413
2752/9333 [=======>......................] - ETA: 5:13 - loss: 0.6850 - acc: 0.5418
2816/9333 [========>.....................] - ETA: 5:11 - loss: 0.6855 - acc: 0.5408
2880/9333 [========>.....................] - ETA: 5:08 - loss: 0.6855 - acc: 0.5403
2944/9333 [========>.....................] - ETA: 5:05 - loss: 0.6856 - acc: 0.5391
3008/9333 [========>.....................] - ETA: 5:02 - loss: 0.6868 - acc: 0.5372
3072/9333 [========>.....................] - ETA: 4:59 - loss: 0.6871 - acc: 0.5374
3136/9333 [=========>....................] - ETA: 4:56 - loss: 0.6869 - acc: 0.5376
3200/9333 [=========>....................] - ETA: 4:53 - loss: 0.6866 - acc: 0.5391
3264/9333 [=========>....................] - ETA: 4:50 - loss: 0.6868 - acc: 0.5380
3328/9333 [=========>....................] - ETA: 4:48 - loss: 0.6870 - acc: 0.5388
3392/9333 [=========>....................] - ETA: 4:45 - loss: 0.6867 - acc: 0.5398
3456/9333 [==========>...................] - ETA: 4:43 - loss: 0.6873 - acc: 0.5391
3520/9333 [==========>...................] - ETA: 4:40 - loss: 0.6883 - acc: 0.5361
3584/9333 [==========>...................] - ETA: 4:38 - loss: 0.6885 - acc: 0.5349
3648/9333 [==========>...................] - ETA: 4:35 - loss: 0.6879 - acc: 0.5356
3712/9333 [==========>...................] - ETA: 4:31 - loss: 0.6880 - acc: 0.5364
3776/9333 [===========>..................] - ETA: 4:28 - loss: 0.6877 - acc: 0.5384
3840/9333 [===========>..................] - ETA: 4:25 - loss: 0.6878 - acc: 0.5375
3904/9333 [===========>..................] - ETA: 4:22 - loss: 0.6881 - acc: 0.5361
3968/9333 [===========>..................] - ETA: 4:19 - loss: 0.6881 - acc: 0.5358
4032/9333 [===========>..................] - ETA: 4:16 - loss: 0.6881 - acc: 0.5355
4096/9333 [============>.................] - ETA: 4:13 - loss: 0.6884 - acc: 0.5339
4160/9333 [============>.................] - ETA: 4:10 - loss: 0.6885 - acc: 0.5325
4224/9333 [============>.................] - ETA: 4:07 - loss: 0.6882 - acc: 0.5339
4288/9333 [============>.................] - ETA: 4:04 - loss: 0.6884 - acc: 0.5333
4352/9333 [============>.................] - ETA: 4:01 - loss: 0.6887 - acc: 0.5315
4416/9333 [=============>................] - ETA: 3:58 - loss: 0.6888 - acc: 0.5310
4480/9333 [=============>................] - ETA: 3:56 - loss: 0.6888 - acc: 0.5315
4544/9333 [=============>................] - ETA: 3:53 - loss: 0.6891 - acc: 0.5299
4608/9333 [=============>................] - ETA: 3:50 - loss: 0.6891 - acc: 0.5299
4672/9333 [==============>...............] - ETA: 3:47 - loss: 0.6891 - acc: 0.5302
4736/9333 [==============>...............] - ETA: 3:43 - loss: 0.6890 - acc: 0.5315
4800/9333 [==============>...............] - ETA: 3:40 - loss: 0.6889 - acc: 0.5323
4864/9333 [==============>...............] - ETA: 3:37 - loss: 0.6888 - acc: 0.5329
4928/9333 [==============>...............] - ETA: 3:34 - loss: 0.6887 - acc: 0.5329
4992/9333 [===============>..............] - ETA: 3:31 - loss: 0.6886 - acc: 0.5335
5056/9333 [===============>..............] - ETA: 3:28 - loss: 0.6890 - acc: 0.5330
5120/9333 [===============>..............] - ETA: 3:25 - loss: 0.6890 - acc: 0.5326
5184/9333 [===============>..............] - ETA: 3:21 - loss: 0.6890 - acc: 0.5328
5248/9333 [===============>..............] - ETA: 3:18 - loss: 0.6892 - acc: 0.5318
5312/9333 [================>.............] - ETA: 3:15 - loss: 0.6896 - acc: 0.5303
5376/9333 [================>.............] - ETA: 3:12 - loss: 0.6898 - acc: 0.5298
5440/9333 [================>.............] - ETA: 3:09 - loss: 0.6900 - acc: 0.5292
5504/9333 [================>.............] - ETA: 3:06 - loss: 0.6901 - acc: 0.5293
5568/9333 [================>.............] - ETA: 3:02 - loss: 0.6901 - acc: 0.5284
5632/9333 [=================>............] - ETA: 2:59 - loss: 0.6903 - acc: 0.5284
5696/9333 [=================>............] - ETA: 2:56 - loss: 0.6902 - acc: 0.5284
5760/9333 [=================>............] - ETA: 2:53 - loss: 0.6902 - acc: 0.5274
5824/9333 [=================>............] - ETA: 2:50 - loss: 0.6902 - acc: 0.5282
5888/9333 [=================>............] - ETA: 2:47 - loss: 0.6904 - acc: 0.5270
5952/9333 [==================>...........] - ETA: 2:44 - loss: 0.6903 - acc: 0.5276
6016/9333 [==================>...........] - ETA: 2:41 - loss: 0.6902 - acc: 0.5281
6080/9333 [==================>...........] - ETA: 2:37 - loss: 0.6900 - acc: 0.5294
6144/9333 [==================>...........] - ETA: 2:34 - loss: 0.6900 - acc: 0.5298
6208/9333 [==================>...........] - ETA: 2:31 - loss: 0.6900 - acc: 0.5298
6272/9333 [===================>..........] - ETA: 2:28 - loss: 0.6899 - acc: 0.5305
6336/9333 [===================>..........] - ETA: 2:25 - loss: 0.6898 - acc: 0.5303
6400/9333 [===================>..........] - ETA: 2:22 - loss: 0.6899 - acc: 0.5303
6464/9333 [===================>..........] - ETA: 2:19 - loss: 0.6902 - acc: 0.5291
6528/9333 [===================>..........] - ETA: 2:16 - loss: 0.6904 - acc: 0.5282
6592/9333 [====================>.........] - ETA: 2:13 - loss: 0.6905 - acc: 0.5279
6656/9333 [====================>.........] - ETA: 2:10 - loss: 0.6905 - acc: 0.5282
6720/9333 [====================>.........] - ETA: 2:07 - loss: 0.6904 - acc: 0.5287
6784/9333 [====================>.........] - ETA: 2:04 - loss: 0.6903 - acc: 0.5296
6848/9333 [=====================>........] - ETA: 2:01 - loss: 0.6903 - acc: 0.5294
6912/9333 [=====================>........] - ETA: 1:57 - loss: 0.6902 - acc: 0.5297
6976/9333 [=====================>........] - ETA: 1:54 - loss: 0.6901 - acc: 0.5305
7040/9333 [=====================>........] - ETA: 1:51 - loss: 0.6902 - acc: 0.5301
7104/9333 [=====================>........] - ETA: 1:48 - loss: 0.6899 - acc: 0.5312
7168/9333 [======================>.......] - ETA: 1:45 - loss: 0.6900 - acc: 0.5311
7232/9333 [======================>.......] - ETA: 1:42 - loss: 0.6898 - acc: 0.5319
7296/9333 [======================>.......] - ETA: 1:39 - loss: 0.6897 - acc: 0.5321
7360/9333 [======================>.......] - ETA: 1:36 - loss: 0.6896 - acc: 0.5321
7424/9333 [======================>.......] - ETA: 1:32 - loss: 0.6897 - acc: 0.5319
7488/9333 [=======================>......] - ETA: 1:29 - loss: 0.6896 - acc: 0.5323
7552/9333 [=======================>......] - ETA: 1:26 - loss: 0.6896 - acc: 0.5324
7616/9333 [=======================>......] - ETA: 1:23 - loss: 0.6896 - acc: 0.5324
7680/9333 [=======================>......] - ETA: 1:20 - loss: 0.6895 - acc: 0.5323
7744/9333 [=======================>......] - ETA: 1:17 - loss: 0.6896 - acc: 0.5325
7808/9333 [========================>.....] - ETA: 1:14 - loss: 0.6896 - acc: 0.5328
7872/9333 [========================>.....] - ETA: 1:11 - loss: 0.6897 - acc: 0.5324
7936/9333 [========================>.....] - ETA: 1:08 - loss: 0.6896 - acc: 0.5329
8000/9333 [========================>.....] - ETA: 1:04 - loss: 0.6896 - acc: 0.5330
8064/9333 [========================>.....] - ETA: 1:01 - loss: 0.6897 - acc: 0.5326
8128/9333 [=========================>....] - ETA: 58s - loss: 0.6895 - acc: 0.5332 
8192/9333 [=========================>....] - ETA: 55s - loss: 0.6897 - acc: 0.5330
8256/9333 [=========================>....] - ETA: 52s - loss: 0.6894 - acc: 0.5337
8320/9333 [=========================>....] - ETA: 49s - loss: 0.6893 - acc: 0.5343
8384/9333 [=========================>....] - ETA: 46s - loss: 0.6895 - acc: 0.5347
8448/9333 [==========================>...] - ETA: 43s - loss: 0.6894 - acc: 0.5352
8512/9333 [==========================>...] - ETA: 40s - loss: 0.6891 - acc: 0.5359
8576/9333 [==========================>...] - ETA: 37s - loss: 0.6893 - acc: 0.5354
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6895 - acc: 0.5353
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6897 - acc: 0.5346
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6900 - acc: 0.5342
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6898 - acc: 0.5349
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6897 - acc: 0.5350
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6897 - acc: 0.5346
9024/9333 [============================>.] - ETA: 15s - loss: 0.6895 - acc: 0.5352
9088/9333 [============================>.] - ETA: 12s - loss: 0.6896 - acc: 0.5352
9152/9333 [============================>.] - ETA: 8s - loss: 0.6897 - acc: 0.5346 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6895 - acc: 0.5350
9280/9333 [============================>.] - ETA: 2s - loss: 0.6895 - acc: 0.5350
9333/9333 [==============================] - 476s 51ms/step - loss: 0.6894 - acc: 0.5352 - val_loss: 0.6884 - val_acc: 0.5294

Epoch 00005: val_acc did not improve from 0.54484
Epoch 6/10

  64/9333 [..............................] - ETA: 7:36 - loss: 0.6676 - acc: 0.6250
 128/9333 [..............................] - ETA: 7:59 - loss: 0.6715 - acc: 0.5781
 192/9333 [..............................] - ETA: 7:47 - loss: 0.6784 - acc: 0.5781
 256/9333 [..............................] - ETA: 7:35 - loss: 0.6803 - acc: 0.5625
 320/9333 [>.............................] - ETA: 7:32 - loss: 0.6870 - acc: 0.5312
 384/9333 [>.............................] - ETA: 7:17 - loss: 0.6881 - acc: 0.5260
 448/9333 [>.............................] - ETA: 7:08 - loss: 0.6852 - acc: 0.5469
 512/9333 [>.............................] - ETA: 7:12 - loss: 0.6827 - acc: 0.5527
 576/9333 [>.............................] - ETA: 7:06 - loss: 0.6860 - acc: 0.5434
 640/9333 [=>............................] - ETA: 7:04 - loss: 0.6877 - acc: 0.5406
 704/9333 [=>............................] - ETA: 6:59 - loss: 0.6893 - acc: 0.5355
 768/9333 [=>............................] - ETA: 7:01 - loss: 0.6903 - acc: 0.5365
 832/9333 [=>............................] - ETA: 6:57 - loss: 0.6901 - acc: 0.5397
 896/9333 [=>............................] - ETA: 6:55 - loss: 0.6909 - acc: 0.5391
 960/9333 [==>...........................] - ETA: 6:50 - loss: 0.6900 - acc: 0.5469
1024/9333 [==>...........................] - ETA: 6:48 - loss: 0.6904 - acc: 0.5430
1088/9333 [==>...........................] - ETA: 6:43 - loss: 0.6894 - acc: 0.5450
1152/9333 [==>...........................] - ETA: 6:38 - loss: 0.6896 - acc: 0.5425
1216/9333 [==>...........................] - ETA: 6:36 - loss: 0.6892 - acc: 0.5436
1280/9333 [===>..........................] - ETA: 6:32 - loss: 0.6903 - acc: 0.5422
1344/9333 [===>..........................] - ETA: 6:31 - loss: 0.6896 - acc: 0.5499
1408/9333 [===>..........................] - ETA: 6:31 - loss: 0.6885 - acc: 0.5497
1472/9333 [===>..........................] - ETA: 6:28 - loss: 0.6891 - acc: 0.5469
1536/9333 [===>..........................] - ETA: 6:23 - loss: 0.6888 - acc: 0.5475
1600/9333 [====>.........................] - ETA: 6:21 - loss: 0.6878 - acc: 0.5494
1664/9333 [====>.........................] - ETA: 6:17 - loss: 0.6876 - acc: 0.5493
1728/9333 [====>.........................] - ETA: 6:15 - loss: 0.6873 - acc: 0.5515
1792/9333 [====>.........................] - ETA: 6:11 - loss: 0.6870 - acc: 0.5558
1856/9333 [====>.........................] - ETA: 6:08 - loss: 0.6868 - acc: 0.5566
1920/9333 [=====>........................] - ETA: 6:04 - loss: 0.6867 - acc: 0.5583
1984/9333 [=====>........................] - ETA: 6:02 - loss: 0.6866 - acc: 0.5590
2048/9333 [=====>........................] - ETA: 5:58 - loss: 0.6868 - acc: 0.5586
2112/9333 [=====>........................] - ETA: 5:55 - loss: 0.6867 - acc: 0.5587
2176/9333 [=====>........................] - ETA: 5:52 - loss: 0.6864 - acc: 0.5597
2240/9333 [======>.......................] - ETA: 5:49 - loss: 0.6866 - acc: 0.5580
2304/9333 [======>.......................] - ETA: 5:46 - loss: 0.6862 - acc: 0.5595
2368/9333 [======>.......................] - ETA: 5:43 - loss: 0.6865 - acc: 0.5591
2432/9333 [======>.......................] - ETA: 5:40 - loss: 0.6858 - acc: 0.5613
2496/9333 [=======>......................] - ETA: 5:36 - loss: 0.6857 - acc: 0.5613
2560/9333 [=======>......................] - ETA: 5:33 - loss: 0.6855 - acc: 0.5613
2624/9333 [=======>......................] - ETA: 5:30 - loss: 0.6861 - acc: 0.5591
2688/9333 [=======>......................] - ETA: 5:27 - loss: 0.6856 - acc: 0.5599
2752/9333 [=======>......................] - ETA: 5:23 - loss: 0.6861 - acc: 0.5585
2816/9333 [========>.....................] - ETA: 5:19 - loss: 0.6865 - acc: 0.5572
2880/9333 [========>.....................] - ETA: 5:17 - loss: 0.6866 - acc: 0.5566
2944/9333 [========>.....................] - ETA: 5:13 - loss: 0.6864 - acc: 0.5564
3008/9333 [========>.....................] - ETA: 5:10 - loss: 0.6866 - acc: 0.5555
3072/9333 [========>.....................] - ETA: 5:06 - loss: 0.6868 - acc: 0.5547
3136/9333 [=========>....................] - ETA: 5:03 - loss: 0.6868 - acc: 0.5542
3200/9333 [=========>....................] - ETA: 5:00 - loss: 0.6875 - acc: 0.5522
3264/9333 [=========>....................] - ETA: 4:57 - loss: 0.6877 - acc: 0.5515
3328/9333 [=========>....................] - ETA: 4:54 - loss: 0.6875 - acc: 0.5526
3392/9333 [=========>....................] - ETA: 4:51 - loss: 0.6882 - acc: 0.5507
3456/9333 [==========>...................] - ETA: 4:47 - loss: 0.6882 - acc: 0.5506
3520/9333 [==========>...................] - ETA: 4:44 - loss: 0.6882 - acc: 0.5509
3584/9333 [==========>...................] - ETA: 4:40 - loss: 0.6879 - acc: 0.5519
3648/9333 [==========>...................] - ETA: 4:37 - loss: 0.6879 - acc: 0.5529
3712/9333 [==========>...................] - ETA: 4:33 - loss: 0.6883 - acc: 0.5517
3776/9333 [===========>..................] - ETA: 4:31 - loss: 0.6881 - acc: 0.5538
3840/9333 [===========>..................] - ETA: 4:27 - loss: 0.6882 - acc: 0.5534
3904/9333 [===========>..................] - ETA: 4:24 - loss: 0.6884 - acc: 0.5528
3968/9333 [===========>..................] - ETA: 4:21 - loss: 0.6880 - acc: 0.5529
4032/9333 [===========>..................] - ETA: 4:17 - loss: 0.6878 - acc: 0.5531
4096/9333 [============>.................] - ETA: 4:13 - loss: 0.6875 - acc: 0.5540
4160/9333 [============>.................] - ETA: 4:10 - loss: 0.6877 - acc: 0.5524
4224/9333 [============>.................] - ETA: 4:07 - loss: 0.6875 - acc: 0.5528
4288/9333 [============>.................] - ETA: 4:04 - loss: 0.6875 - acc: 0.5520
4352/9333 [============>.................] - ETA: 4:01 - loss: 0.6875 - acc: 0.5524
4416/9333 [=============>................] - ETA: 3:58 - loss: 0.6871 - acc: 0.5537
4480/9333 [=============>................] - ETA: 3:55 - loss: 0.6871 - acc: 0.5525
4544/9333 [=============>................] - ETA: 3:52 - loss: 0.6874 - acc: 0.5515
4608/9333 [=============>................] - ETA: 3:49 - loss: 0.6872 - acc: 0.5521
4672/9333 [==============>...............] - ETA: 3:46 - loss: 0.6868 - acc: 0.5533
4736/9333 [==============>...............] - ETA: 3:42 - loss: 0.6869 - acc: 0.5536
4800/9333 [==============>...............] - ETA: 3:39 - loss: 0.6864 - acc: 0.5548
4864/9333 [==============>...............] - ETA: 3:36 - loss: 0.6863 - acc: 0.5551
4928/9333 [==============>...............] - ETA: 3:33 - loss: 0.6858 - acc: 0.5558
4992/9333 [===============>..............] - ETA: 3:30 - loss: 0.6857 - acc: 0.5563
5056/9333 [===============>..............] - ETA: 3:27 - loss: 0.6860 - acc: 0.5554
5120/9333 [===============>..............] - ETA: 3:23 - loss: 0.6858 - acc: 0.5555
5184/9333 [===============>..............] - ETA: 3:20 - loss: 0.6856 - acc: 0.5559
5248/9333 [===============>..............] - ETA: 3:17 - loss: 0.6855 - acc: 0.5564
5312/9333 [================>.............] - ETA: 3:14 - loss: 0.6855 - acc: 0.5565
5376/9333 [================>.............] - ETA: 3:11 - loss: 0.6851 - acc: 0.5582
5440/9333 [================>.............] - ETA: 3:07 - loss: 0.6849 - acc: 0.5581
5504/9333 [================>.............] - ETA: 3:04 - loss: 0.6849 - acc: 0.5580
5568/9333 [================>.............] - ETA: 3:01 - loss: 0.6848 - acc: 0.5580
5632/9333 [=================>............] - ETA: 2:58 - loss: 0.6845 - acc: 0.5584
5696/9333 [=================>............] - ETA: 2:55 - loss: 0.6850 - acc: 0.5572
5760/9333 [=================>............] - ETA: 2:52 - loss: 0.6852 - acc: 0.5569
5824/9333 [=================>............] - ETA: 2:49 - loss: 0.6854 - acc: 0.5561
5888/9333 [=================>............] - ETA: 2:45 - loss: 0.6855 - acc: 0.5555
5952/9333 [==================>...........] - ETA: 2:42 - loss: 0.6858 - acc: 0.5544
6016/9333 [==================>...........] - ETA: 2:39 - loss: 0.6859 - acc: 0.5544
6080/9333 [==================>...........] - ETA: 2:36 - loss: 0.6860 - acc: 0.5541
6144/9333 [==================>...........] - ETA: 2:33 - loss: 0.6860 - acc: 0.5542
6208/9333 [==================>...........] - ETA: 2:30 - loss: 0.6860 - acc: 0.5546
6272/9333 [===================>..........] - ETA: 2:27 - loss: 0.6862 - acc: 0.5539
6336/9333 [===================>..........] - ETA: 2:24 - loss: 0.6860 - acc: 0.5540
6400/9333 [===================>..........] - ETA: 2:21 - loss: 0.6861 - acc: 0.5541
6464/9333 [===================>..........] - ETA: 2:18 - loss: 0.6861 - acc: 0.5538
6528/9333 [===================>..........] - ETA: 2:15 - loss: 0.6861 - acc: 0.5538
6592/9333 [====================>.........] - ETA: 2:12 - loss: 0.6864 - acc: 0.5526
6656/9333 [====================>.........] - ETA: 2:08 - loss: 0.6867 - acc: 0.5515
6720/9333 [====================>.........] - ETA: 2:05 - loss: 0.6867 - acc: 0.5515
6784/9333 [====================>.........] - ETA: 2:02 - loss: 0.6869 - acc: 0.5510
6848/9333 [=====================>........] - ETA: 1:59 - loss: 0.6870 - acc: 0.5510
6912/9333 [=====================>........] - ETA: 1:56 - loss: 0.6868 - acc: 0.5514
6976/9333 [=====================>........] - ETA: 1:53 - loss: 0.6868 - acc: 0.5516
7040/9333 [=====================>........] - ETA: 1:50 - loss: 0.6868 - acc: 0.5521
7104/9333 [=====================>........] - ETA: 1:47 - loss: 0.6868 - acc: 0.5514
7168/9333 [======================>.......] - ETA: 1:44 - loss: 0.6867 - acc: 0.5520
7232/9333 [======================>.......] - ETA: 1:41 - loss: 0.6868 - acc: 0.5523
7296/9333 [======================>.......] - ETA: 1:38 - loss: 0.6870 - acc: 0.5514
7360/9333 [======================>.......] - ETA: 1:34 - loss: 0.6869 - acc: 0.5519
7424/9333 [======================>.......] - ETA: 1:31 - loss: 0.6869 - acc: 0.5515
7488/9333 [=======================>......] - ETA: 1:28 - loss: 0.6869 - acc: 0.5514
7552/9333 [=======================>......] - ETA: 1:25 - loss: 0.6869 - acc: 0.5510
7616/9333 [=======================>......] - ETA: 1:22 - loss: 0.6868 - acc: 0.5519
7680/9333 [=======================>......] - ETA: 1:19 - loss: 0.6864 - acc: 0.5525
7744/9333 [=======================>......] - ETA: 1:16 - loss: 0.6864 - acc: 0.5528
7808/9333 [========================>.....] - ETA: 1:13 - loss: 0.6866 - acc: 0.5524
7872/9333 [========================>.....] - ETA: 1:10 - loss: 0.6867 - acc: 0.5517
7936/9333 [========================>.....] - ETA: 1:07 - loss: 0.6869 - acc: 0.5517
8000/9333 [========================>.....] - ETA: 1:04 - loss: 0.6870 - acc: 0.5513
8064/9333 [========================>.....] - ETA: 1:01 - loss: 0.6870 - acc: 0.5507
8128/9333 [=========================>....] - ETA: 57s - loss: 0.6871 - acc: 0.5504 
8192/9333 [=========================>....] - ETA: 54s - loss: 0.6873 - acc: 0.5500
8256/9333 [=========================>....] - ETA: 51s - loss: 0.6873 - acc: 0.5497
8320/9333 [=========================>....] - ETA: 48s - loss: 0.6873 - acc: 0.5493
8384/9333 [=========================>....] - ETA: 45s - loss: 0.6873 - acc: 0.5491
8448/9333 [==========================>...] - ETA: 42s - loss: 0.6872 - acc: 0.5490
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6873 - acc: 0.5492
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6874 - acc: 0.5493
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6874 - acc: 0.5494
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6873 - acc: 0.5497
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6875 - acc: 0.5494
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6877 - acc: 0.5486
8896/9333 [===========================>..] - ETA: 20s - loss: 0.6880 - acc: 0.5481
8960/9333 [===========================>..] - ETA: 17s - loss: 0.6880 - acc: 0.5482
9024/9333 [============================>.] - ETA: 14s - loss: 0.6880 - acc: 0.5475
9088/9333 [============================>.] - ETA: 11s - loss: 0.6880 - acc: 0.5473
9152/9333 [============================>.] - ETA: 8s - loss: 0.6878 - acc: 0.5477 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6878 - acc: 0.5481
9280/9333 [============================>.] - ETA: 2s - loss: 0.6876 - acc: 0.5481
9333/9333 [==============================] - 469s 50ms/step - loss: 0.6878 - acc: 0.5477 - val_loss: 0.6917 - val_acc: 0.5323

Epoch 00006: val_acc did not improve from 0.54484
Epoch 7/10

  64/9333 [..............................] - ETA: 7:17 - loss: 0.6965 - acc: 0.5156
 128/9333 [..............................] - ETA: 7:22 - loss: 0.6828 - acc: 0.5703
 192/9333 [..............................] - ETA: 7:29 - loss: 0.6826 - acc: 0.5521
 256/9333 [..............................] - ETA: 7:36 - loss: 0.6835 - acc: 0.5391
 320/9333 [>.............................] - ETA: 7:32 - loss: 0.6826 - acc: 0.5469
 384/9333 [>.............................] - ETA: 7:29 - loss: 0.6829 - acc: 0.5469
 448/9333 [>.............................] - ETA: 7:25 - loss: 0.6873 - acc: 0.5290
 512/9333 [>.............................] - ETA: 7:22 - loss: 0.6844 - acc: 0.5449
 576/9333 [>.............................] - ETA: 7:15 - loss: 0.6852 - acc: 0.5503
 640/9333 [=>............................] - ETA: 7:12 - loss: 0.6866 - acc: 0.5391
 704/9333 [=>............................] - ETA: 7:07 - loss: 0.6853 - acc: 0.5455
 768/9333 [=>............................] - ETA: 6:59 - loss: 0.6857 - acc: 0.5521
 832/9333 [=>............................] - ETA: 6:57 - loss: 0.6854 - acc: 0.5481
 896/9333 [=>............................] - ETA: 6:51 - loss: 0.6848 - acc: 0.5469
 960/9333 [==>...........................] - ETA: 6:49 - loss: 0.6841 - acc: 0.5490
1024/9333 [==>...........................] - ETA: 6:46 - loss: 0.6850 - acc: 0.5488
1088/9333 [==>...........................] - ETA: 6:39 - loss: 0.6842 - acc: 0.5551
1152/9333 [==>...........................] - ETA: 6:36 - loss: 0.6841 - acc: 0.5582
1216/9333 [==>...........................] - ETA: 6:33 - loss: 0.6844 - acc: 0.5551
1280/9333 [===>..........................] - ETA: 6:29 - loss: 0.6846 - acc: 0.5555
1344/9333 [===>..........................] - ETA: 6:29 - loss: 0.6853 - acc: 0.5528
1408/9333 [===>..........................] - ETA: 6:26 - loss: 0.6855 - acc: 0.5511
1472/9333 [===>..........................] - ETA: 6:23 - loss: 0.6856 - acc: 0.5496
1536/9333 [===>..........................] - ETA: 6:20 - loss: 0.6855 - acc: 0.5488
1600/9333 [====>.........................] - ETA: 6:19 - loss: 0.6870 - acc: 0.5463
1664/9333 [====>.........................] - ETA: 6:16 - loss: 0.6881 - acc: 0.5421
1728/9333 [====>.........................] - ETA: 6:10 - loss: 0.6881 - acc: 0.5405
1792/9333 [====>.........................] - ETA: 6:07 - loss: 0.6871 - acc: 0.5430
1856/9333 [====>.........................] - ETA: 6:04 - loss: 0.6870 - acc: 0.5426
1920/9333 [=====>........................] - ETA: 6:00 - loss: 0.6876 - acc: 0.5411
1984/9333 [=====>........................] - ETA: 5:57 - loss: 0.6872 - acc: 0.5428
2048/9333 [=====>........................] - ETA: 5:54 - loss: 0.6877 - acc: 0.5410
2112/9333 [=====>........................] - ETA: 5:51 - loss: 0.6881 - acc: 0.5388
2176/9333 [=====>........................] - ETA: 5:48 - loss: 0.6883 - acc: 0.5395
2240/9333 [======>.......................] - ETA: 5:54 - loss: 0.6883 - acc: 0.5397
2304/9333 [======>.......................] - ETA: 5:51 - loss: 0.6891 - acc: 0.5373
2368/9333 [======>.......................] - ETA: 5:50 - loss: 0.6892 - acc: 0.5367
2432/9333 [======>.......................] - ETA: 5:47 - loss: 0.6891 - acc: 0.5378
2496/9333 [=======>......................] - ETA: 5:45 - loss: 0.6890 - acc: 0.5385
2560/9333 [=======>......................] - ETA: 5:41 - loss: 0.6881 - acc: 0.5418
2624/9333 [=======>......................] - ETA: 5:37 - loss: 0.6879 - acc: 0.5434
2688/9333 [=======>......................] - ETA: 5:34 - loss: 0.6880 - acc: 0.5446
2752/9333 [=======>......................] - ETA: 5:30 - loss: 0.6884 - acc: 0.5443
2816/9333 [========>.....................] - ETA: 5:27 - loss: 0.6882 - acc: 0.5430
2880/9333 [========>.....................] - ETA: 5:23 - loss: 0.6882 - acc: 0.5434
2944/9333 [========>.....................] - ETA: 5:19 - loss: 0.6884 - acc: 0.5408
3008/9333 [========>.....................] - ETA: 5:16 - loss: 0.6881 - acc: 0.5412
3072/9333 [========>.....................] - ETA: 5:12 - loss: 0.6888 - acc: 0.5404
3136/9333 [=========>....................] - ETA: 5:08 - loss: 0.6891 - acc: 0.5395
3200/9333 [=========>....................] - ETA: 5:04 - loss: 0.6888 - acc: 0.5416
3264/9333 [=========>....................] - ETA: 5:01 - loss: 0.6893 - acc: 0.5398
3328/9333 [=========>....................] - ETA: 4:57 - loss: 0.6886 - acc: 0.5418
3392/9333 [=========>....................] - ETA: 4:53 - loss: 0.6883 - acc: 0.5425
3456/9333 [==========>...................] - ETA: 4:51 - loss: 0.6883 - acc: 0.5422
3520/9333 [==========>...................] - ETA: 4:47 - loss: 0.6881 - acc: 0.5429
3584/9333 [==========>...................] - ETA: 4:43 - loss: 0.6879 - acc: 0.5441
3648/9333 [==========>...................] - ETA: 4:41 - loss: 0.6878 - acc: 0.5444
3712/9333 [==========>...................] - ETA: 4:37 - loss: 0.6874 - acc: 0.5455
3776/9333 [===========>..................] - ETA: 4:34 - loss: 0.6872 - acc: 0.5463
3840/9333 [===========>..................] - ETA: 4:31 - loss: 0.6873 - acc: 0.5464
3904/9333 [===========>..................] - ETA: 4:28 - loss: 0.6874 - acc: 0.5453
3968/9333 [===========>..................] - ETA: 4:24 - loss: 0.6876 - acc: 0.5454
4032/9333 [===========>..................] - ETA: 4:22 - loss: 0.6882 - acc: 0.5444
4096/9333 [============>.................] - ETA: 4:18 - loss: 0.6887 - acc: 0.5442
4160/9333 [============>.................] - ETA: 4:15 - loss: 0.6886 - acc: 0.5442
4224/9333 [============>.................] - ETA: 4:12 - loss: 0.6884 - acc: 0.5447
4288/9333 [============>.................] - ETA: 4:09 - loss: 0.6885 - acc: 0.5443
4352/9333 [============>.................] - ETA: 4:05 - loss: 0.6885 - acc: 0.5432
4416/9333 [=============>................] - ETA: 4:02 - loss: 0.6883 - acc: 0.5430
4480/9333 [=============>................] - ETA: 3:59 - loss: 0.6886 - acc: 0.5422
4544/9333 [=============>................] - ETA: 3:56 - loss: 0.6889 - acc: 0.5412
4608/9333 [=============>................] - ETA: 3:53 - loss: 0.6885 - acc: 0.5421
4672/9333 [==============>...............] - ETA: 3:50 - loss: 0.6885 - acc: 0.5420
4736/9333 [==============>...............] - ETA: 3:46 - loss: 0.6888 - acc: 0.5410
4800/9333 [==============>...............] - ETA: 3:43 - loss: 0.6888 - acc: 0.5408
4864/9333 [==============>...............] - ETA: 3:40 - loss: 0.6887 - acc: 0.5407
4928/9333 [==============>...............] - ETA: 3:37 - loss: 0.6886 - acc: 0.5406
4992/9333 [===============>..............] - ETA: 3:34 - loss: 0.6890 - acc: 0.5401
5056/9333 [===============>..............] - ETA: 3:30 - loss: 0.6890 - acc: 0.5405
5120/9333 [===============>..............] - ETA: 3:27 - loss: 0.6890 - acc: 0.5408
5184/9333 [===============>..............] - ETA: 3:24 - loss: 0.6892 - acc: 0.5401
5248/9333 [===============>..............] - ETA: 3:21 - loss: 0.6889 - acc: 0.5412
5312/9333 [================>.............] - ETA: 3:17 - loss: 0.6888 - acc: 0.5418
5376/9333 [================>.............] - ETA: 3:14 - loss: 0.6884 - acc: 0.5428
5440/9333 [================>.............] - ETA: 3:11 - loss: 0.6886 - acc: 0.5434
5504/9333 [================>.............] - ETA: 3:08 - loss: 0.6884 - acc: 0.5429
5568/9333 [================>.............] - ETA: 3:05 - loss: 0.6886 - acc: 0.5426
5632/9333 [=================>............] - ETA: 3:02 - loss: 0.6889 - acc: 0.5414
5696/9333 [=================>............] - ETA: 2:59 - loss: 0.6889 - acc: 0.5411
5760/9333 [=================>............] - ETA: 2:56 - loss: 0.6888 - acc: 0.5411
5824/9333 [=================>............] - ETA: 2:53 - loss: 0.6889 - acc: 0.5412
5888/9333 [=================>............] - ETA: 2:50 - loss: 0.6888 - acc: 0.5411
5952/9333 [==================>...........] - ETA: 2:46 - loss: 0.6892 - acc: 0.5410
6016/9333 [==================>...........] - ETA: 2:43 - loss: 0.6889 - acc: 0.5421
6080/9333 [==================>...........] - ETA: 2:40 - loss: 0.6887 - acc: 0.5426
6144/9333 [==================>...........] - ETA: 2:37 - loss: 0.6886 - acc: 0.5431
6208/9333 [==================>...........] - ETA: 2:33 - loss: 0.6884 - acc: 0.5433
6272/9333 [===================>..........] - ETA: 2:30 - loss: 0.6883 - acc: 0.5435
6336/9333 [===================>..........] - ETA: 2:27 - loss: 0.6882 - acc: 0.5439
6400/9333 [===================>..........] - ETA: 2:24 - loss: 0.6879 - acc: 0.5452
6464/9333 [===================>..........] - ETA: 2:20 - loss: 0.6878 - acc: 0.5453
6528/9333 [===================>..........] - ETA: 2:17 - loss: 0.6878 - acc: 0.5447
6592/9333 [====================>.........] - ETA: 2:14 - loss: 0.6877 - acc: 0.5457
6656/9333 [====================>.........] - ETA: 2:11 - loss: 0.6878 - acc: 0.5446
6720/9333 [====================>.........] - ETA: 2:07 - loss: 0.6878 - acc: 0.5449
6784/9333 [====================>.........] - ETA: 2:04 - loss: 0.6878 - acc: 0.5444
6848/9333 [=====================>........] - ETA: 2:01 - loss: 0.6874 - acc: 0.5448
6912/9333 [=====================>........] - ETA: 1:58 - loss: 0.6875 - acc: 0.5443
6976/9333 [=====================>........] - ETA: 1:54 - loss: 0.6873 - acc: 0.5450
7040/9333 [=====================>........] - ETA: 1:51 - loss: 0.6872 - acc: 0.5452
7104/9333 [=====================>........] - ETA: 1:48 - loss: 0.6875 - acc: 0.5445
7168/9333 [======================>.......] - ETA: 1:45 - loss: 0.6875 - acc: 0.5445
7232/9333 [======================>.......] - ETA: 1:42 - loss: 0.6876 - acc: 0.5441
7296/9333 [======================>.......] - ETA: 1:39 - loss: 0.6878 - acc: 0.5437
7360/9333 [======================>.......] - ETA: 1:35 - loss: 0.6877 - acc: 0.5435
7424/9333 [======================>.......] - ETA: 1:32 - loss: 0.6878 - acc: 0.5435
7488/9333 [=======================>......] - ETA: 1:29 - loss: 0.6876 - acc: 0.5441
7552/9333 [=======================>......] - ETA: 1:26 - loss: 0.6875 - acc: 0.5449
7616/9333 [=======================>......] - ETA: 1:23 - loss: 0.6874 - acc: 0.5458
7680/9333 [=======================>......] - ETA: 1:20 - loss: 0.6877 - acc: 0.5454
7744/9333 [=======================>......] - ETA: 1:17 - loss: 0.6877 - acc: 0.5456
7808/9333 [========================>.....] - ETA: 1:13 - loss: 0.6876 - acc: 0.5456
7872/9333 [========================>.....] - ETA: 1:10 - loss: 0.6877 - acc: 0.5454
7936/9333 [========================>.....] - ETA: 1:07 - loss: 0.6877 - acc: 0.5455
8000/9333 [========================>.....] - ETA: 1:04 - loss: 0.6877 - acc: 0.5453
8064/9333 [========================>.....] - ETA: 1:01 - loss: 0.6878 - acc: 0.5448
8128/9333 [=========================>....] - ETA: 58s - loss: 0.6878 - acc: 0.5445 
8192/9333 [=========================>....] - ETA: 55s - loss: 0.6879 - acc: 0.5444
8256/9333 [=========================>....] - ETA: 52s - loss: 0.6880 - acc: 0.5443
8320/9333 [=========================>....] - ETA: 49s - loss: 0.6877 - acc: 0.5453
8384/9333 [=========================>....] - ETA: 46s - loss: 0.6876 - acc: 0.5453
8448/9333 [==========================>...] - ETA: 42s - loss: 0.6876 - acc: 0.5458
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6877 - acc: 0.5456
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6877 - acc: 0.5449
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6875 - acc: 0.5456
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6874 - acc: 0.5454
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6875 - acc: 0.5451
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6875 - acc: 0.5447
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6876 - acc: 0.5444
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6874 - acc: 0.5450
9024/9333 [============================>.] - ETA: 15s - loss: 0.6873 - acc: 0.5451
9088/9333 [============================>.] - ETA: 11s - loss: 0.6873 - acc: 0.5447
9152/9333 [============================>.] - ETA: 8s - loss: 0.6873 - acc: 0.5447 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6874 - acc: 0.5445
9280/9333 [============================>.] - ETA: 2s - loss: 0.6876 - acc: 0.5439
9333/9333 [==============================] - 477s 51ms/step - loss: 0.6877 - acc: 0.5436 - val_loss: 0.6877 - val_acc: 0.5391

Epoch 00007: val_acc did not improve from 0.54484
Epoch 8/10

  64/9333 [..............................] - ETA: 7:39 - loss: 0.6877 - acc: 0.5000
 128/9333 [..............................] - ETA: 7:20 - loss: 0.6983 - acc: 0.4922
 192/9333 [..............................] - ETA: 7:01 - loss: 0.7034 - acc: 0.5208
 256/9333 [..............................] - ETA: 7:20 - loss: 0.6969 - acc: 0.5352
 320/9333 [>.............................] - ETA: 7:26 - loss: 0.6908 - acc: 0.5437
 384/9333 [>.............................] - ETA: 7:22 - loss: 0.6919 - acc: 0.5547
 448/9333 [>.............................] - ETA: 7:18 - loss: 0.6883 - acc: 0.5625
 512/9333 [>.............................] - ETA: 7:15 - loss: 0.6828 - acc: 0.5781
 576/9333 [>.............................] - ETA: 7:10 - loss: 0.6843 - acc: 0.5625
 640/9333 [=>............................] - ETA: 7:07 - loss: 0.6816 - acc: 0.5719
 704/9333 [=>............................] - ETA: 7:07 - loss: 0.6819 - acc: 0.5710
 768/9333 [=>............................] - ETA: 7:09 - loss: 0.6813 - acc: 0.5716
 832/9333 [=>............................] - ETA: 7:06 - loss: 0.6800 - acc: 0.5757
 896/9333 [=>............................] - ETA: 7:04 - loss: 0.6819 - acc: 0.5681
 960/9333 [==>...........................] - ETA: 6:59 - loss: 0.6819 - acc: 0.5687
1024/9333 [==>...........................] - ETA: 6:55 - loss: 0.6831 - acc: 0.5654
1088/9333 [==>...........................] - ETA: 6:52 - loss: 0.6832 - acc: 0.5662
1152/9333 [==>...........................] - ETA: 6:50 - loss: 0.6818 - acc: 0.5703
1216/9333 [==>...........................] - ETA: 6:45 - loss: 0.6815 - acc: 0.5699
1280/9333 [===>..........................] - ETA: 6:45 - loss: 0.6810 - acc: 0.5719
1344/9333 [===>..........................] - ETA: 6:42 - loss: 0.6806 - acc: 0.5692
1408/9333 [===>..........................] - ETA: 6:43 - loss: 0.6814 - acc: 0.5675
1472/9333 [===>..........................] - ETA: 6:40 - loss: 0.6793 - acc: 0.5707
1536/9333 [===>..........................] - ETA: 6:34 - loss: 0.6787 - acc: 0.5736
1600/9333 [====>.........................] - ETA: 6:30 - loss: 0.6790 - acc: 0.5706
1664/9333 [====>.........................] - ETA: 6:26 - loss: 0.6810 - acc: 0.5655
1728/9333 [====>.........................] - ETA: 6:22 - loss: 0.6803 - acc: 0.5700
1792/9333 [====>.........................] - ETA: 6:18 - loss: 0.6807 - acc: 0.5686
1856/9333 [====>.........................] - ETA: 6:15 - loss: 0.6816 - acc: 0.5668
1920/9333 [=====>........................] - ETA: 6:11 - loss: 0.6824 - acc: 0.5635
1984/9333 [=====>........................] - ETA: 6:08 - loss: 0.6813 - acc: 0.5645
2048/9333 [=====>........................] - ETA: 6:04 - loss: 0.6825 - acc: 0.5640
2112/9333 [=====>........................] - ETA: 6:05 - loss: 0.6823 - acc: 0.5625
2176/9333 [=====>........................] - ETA: 6:02 - loss: 0.6822 - acc: 0.5630
2240/9333 [======>.......................] - ETA: 6:00 - loss: 0.6824 - acc: 0.5634
2304/9333 [======>.......................] - ETA: 5:55 - loss: 0.6836 - acc: 0.5621
2368/9333 [======>.......................] - ETA: 5:52 - loss: 0.6842 - acc: 0.5608
2432/9333 [======>.......................] - ETA: 5:49 - loss: 0.6838 - acc: 0.5621
2496/9333 [=======>......................] - ETA: 5:46 - loss: 0.6828 - acc: 0.5637
2560/9333 [=======>......................] - ETA: 5:42 - loss: 0.6824 - acc: 0.5629
2624/9333 [=======>......................] - ETA: 5:38 - loss: 0.6831 - acc: 0.5610
2688/9333 [=======>......................] - ETA: 5:35 - loss: 0.6824 - acc: 0.5629
2752/9333 [=======>......................] - ETA: 5:31 - loss: 0.6828 - acc: 0.5625
2816/9333 [========>.....................] - ETA: 5:28 - loss: 0.6838 - acc: 0.5597
2880/9333 [========>.....................] - ETA: 5:24 - loss: 0.6845 - acc: 0.5580
2944/9333 [========>.....................] - ETA: 5:21 - loss: 0.6851 - acc: 0.5564
3008/9333 [========>.....................] - ETA: 5:18 - loss: 0.6850 - acc: 0.5572
3072/9333 [========>.....................] - ETA: 5:15 - loss: 0.6849 - acc: 0.5583
3136/9333 [=========>....................] - ETA: 5:13 - loss: 0.6840 - acc: 0.5609
3200/9333 [=========>....................] - ETA: 5:10 - loss: 0.6843 - acc: 0.5609
3264/9333 [=========>....................] - ETA: 5:07 - loss: 0.6838 - acc: 0.5619
3328/9333 [=========>....................] - ETA: 5:03 - loss: 0.6835 - acc: 0.5625
3392/9333 [=========>....................] - ETA: 4:59 - loss: 0.6834 - acc: 0.5622
3456/9333 [==========>...................] - ETA: 4:56 - loss: 0.6837 - acc: 0.5625
3520/9333 [==========>...................] - ETA: 4:52 - loss: 0.6839 - acc: 0.5619
3584/9333 [==========>...................] - ETA: 4:49 - loss: 0.6838 - acc: 0.5628
3648/9333 [==========>...................] - ETA: 4:46 - loss: 0.6845 - acc: 0.5609
3712/9333 [==========>...................] - ETA: 4:42 - loss: 0.6842 - acc: 0.5614
3776/9333 [===========>..................] - ETA: 4:39 - loss: 0.6841 - acc: 0.5622
3840/9333 [===========>..................] - ETA: 4:35 - loss: 0.6840 - acc: 0.5625
3904/9333 [===========>..................] - ETA: 4:32 - loss: 0.6838 - acc: 0.5635
3968/9333 [===========>..................] - ETA: 4:28 - loss: 0.6844 - acc: 0.5610
4032/9333 [===========>..................] - ETA: 4:25 - loss: 0.6843 - acc: 0.5610
4096/9333 [============>.................] - ETA: 4:22 - loss: 0.6852 - acc: 0.5586
4160/9333 [============>.................] - ETA: 4:19 - loss: 0.6859 - acc: 0.5570
4224/9333 [============>.................] - ETA: 4:17 - loss: 0.6855 - acc: 0.5587
4288/9333 [============>.................] - ETA: 4:13 - loss: 0.6855 - acc: 0.5590
4352/9333 [============>.................] - ETA: 4:10 - loss: 0.6856 - acc: 0.5591
4416/9333 [=============>................] - ETA: 4:07 - loss: 0.6856 - acc: 0.5593
4480/9333 [=============>................] - ETA: 4:04 - loss: 0.6856 - acc: 0.5594
4544/9333 [=============>................] - ETA: 4:00 - loss: 0.6854 - acc: 0.5594
4608/9333 [=============>................] - ETA: 3:57 - loss: 0.6853 - acc: 0.5588
4672/9333 [==============>...............] - ETA: 3:53 - loss: 0.6855 - acc: 0.5586
4736/9333 [==============>...............] - ETA: 3:50 - loss: 0.6855 - acc: 0.5579
4800/9333 [==============>...............] - ETA: 3:47 - loss: 0.6855 - acc: 0.5573
4864/9333 [==============>...............] - ETA: 3:44 - loss: 0.6852 - acc: 0.5578
4928/9333 [==============>...............] - ETA: 3:41 - loss: 0.6849 - acc: 0.5593
4992/9333 [===============>..............] - ETA: 3:38 - loss: 0.6848 - acc: 0.5591
5056/9333 [===============>..............] - ETA: 3:35 - loss: 0.6848 - acc: 0.5589
5120/9333 [===============>..............] - ETA: 3:31 - loss: 0.6848 - acc: 0.5586
5184/9333 [===============>..............] - ETA: 3:28 - loss: 0.6848 - acc: 0.5581
5248/9333 [===============>..............] - ETA: 3:25 - loss: 0.6849 - acc: 0.5579
5312/9333 [================>.............] - ETA: 3:22 - loss: 0.6849 - acc: 0.5584
5376/9333 [================>.............] - ETA: 3:19 - loss: 0.6850 - acc: 0.5578
5440/9333 [================>.............] - ETA: 3:15 - loss: 0.6849 - acc: 0.5579
5504/9333 [================>.............] - ETA: 3:12 - loss: 0.6846 - acc: 0.5585
5568/9333 [================>.............] - ETA: 3:09 - loss: 0.6845 - acc: 0.5585
5632/9333 [=================>............] - ETA: 3:06 - loss: 0.6846 - acc: 0.5577
5696/9333 [=================>............] - ETA: 3:02 - loss: 0.6844 - acc: 0.5579
5760/9333 [=================>............] - ETA: 2:59 - loss: 0.6848 - acc: 0.5575
5824/9333 [=================>............] - ETA: 2:56 - loss: 0.6849 - acc: 0.5570
5888/9333 [=================>............] - ETA: 2:53 - loss: 0.6848 - acc: 0.5569
5952/9333 [==================>...........] - ETA: 2:50 - loss: 0.6850 - acc: 0.5561
6016/9333 [==================>...........] - ETA: 2:46 - loss: 0.6849 - acc: 0.5560
6080/9333 [==================>...........] - ETA: 2:43 - loss: 0.6852 - acc: 0.5554
6144/9333 [==================>...........] - ETA: 2:40 - loss: 0.6855 - acc: 0.5553
6208/9333 [==================>...........] - ETA: 2:37 - loss: 0.6854 - acc: 0.5559
6272/9333 [===================>..........] - ETA: 2:33 - loss: 0.6852 - acc: 0.5563
6336/9333 [===================>..........] - ETA: 2:30 - loss: 0.6850 - acc: 0.5568
6400/9333 [===================>..........] - ETA: 2:27 - loss: 0.6850 - acc: 0.5569
6464/9333 [===================>..........] - ETA: 2:24 - loss: 0.6851 - acc: 0.5566
6528/9333 [===================>..........] - ETA: 2:20 - loss: 0.6853 - acc: 0.5558
6592/9333 [====================>.........] - ETA: 2:17 - loss: 0.6855 - acc: 0.5548
6656/9333 [====================>.........] - ETA: 2:14 - loss: 0.6858 - acc: 0.5535
6720/9333 [====================>.........] - ETA: 2:11 - loss: 0.6857 - acc: 0.5543
6784/9333 [====================>.........] - ETA: 2:07 - loss: 0.6858 - acc: 0.5535
6848/9333 [=====================>........] - ETA: 2:04 - loss: 0.6860 - acc: 0.5530
6912/9333 [=====================>........] - ETA: 2:01 - loss: 0.6860 - acc: 0.5531
6976/9333 [=====================>........] - ETA: 1:58 - loss: 0.6860 - acc: 0.5526
7040/9333 [=====================>........] - ETA: 1:54 - loss: 0.6859 - acc: 0.5531
7104/9333 [=====================>........] - ETA: 1:51 - loss: 0.6857 - acc: 0.5546
7168/9333 [======================>.......] - ETA: 1:48 - loss: 0.6858 - acc: 0.5547
7232/9333 [======================>.......] - ETA: 1:45 - loss: 0.6856 - acc: 0.5549
7296/9333 [======================>.......] - ETA: 1:42 - loss: 0.6858 - acc: 0.5539
7360/9333 [======================>.......] - ETA: 1:38 - loss: 0.6856 - acc: 0.5546
7424/9333 [======================>.......] - ETA: 1:35 - loss: 0.6855 - acc: 0.5554
7488/9333 [=======================>......] - ETA: 1:32 - loss: 0.6854 - acc: 0.5554
7552/9333 [=======================>......] - ETA: 1:29 - loss: 0.6854 - acc: 0.5556
7616/9333 [=======================>......] - ETA: 1:25 - loss: 0.6857 - acc: 0.5544
7680/9333 [=======================>......] - ETA: 1:22 - loss: 0.6856 - acc: 0.5546
7744/9333 [=======================>......] - ETA: 1:19 - loss: 0.6855 - acc: 0.5548
7808/9333 [========================>.....] - ETA: 1:16 - loss: 0.6854 - acc: 0.5557
7872/9333 [========================>.....] - ETA: 1:12 - loss: 0.6855 - acc: 0.5554
7936/9333 [========================>.....] - ETA: 1:09 - loss: 0.6856 - acc: 0.5557
8000/9333 [========================>.....] - ETA: 1:06 - loss: 0.6855 - acc: 0.5556
8064/9333 [========================>.....] - ETA: 1:03 - loss: 0.6858 - acc: 0.5549
8128/9333 [=========================>....] - ETA: 59s - loss: 0.6858 - acc: 0.5547 
8192/9333 [=========================>....] - ETA: 56s - loss: 0.6857 - acc: 0.5553
8256/9333 [=========================>....] - ETA: 53s - loss: 0.6855 - acc: 0.5558
8320/9333 [=========================>....] - ETA: 50s - loss: 0.6856 - acc: 0.5556
8384/9333 [=========================>....] - ETA: 47s - loss: 0.6858 - acc: 0.5553
8448/9333 [==========================>...] - ETA: 43s - loss: 0.6857 - acc: 0.5555
8512/9333 [==========================>...] - ETA: 40s - loss: 0.6858 - acc: 0.5555
8576/9333 [==========================>...] - ETA: 37s - loss: 0.6858 - acc: 0.5549
8640/9333 [==========================>...] - ETA: 34s - loss: 0.6859 - acc: 0.5545
8704/9333 [==========================>...] - ETA: 31s - loss: 0.6860 - acc: 0.5541
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6859 - acc: 0.5543
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6859 - acc: 0.5543
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6863 - acc: 0.5533
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6865 - acc: 0.5529
9024/9333 [============================>.] - ETA: 15s - loss: 0.6864 - acc: 0.5530
9088/9333 [============================>.] - ETA: 12s - loss: 0.6866 - acc: 0.5524
9152/9333 [============================>.] - ETA: 8s - loss: 0.6870 - acc: 0.5511 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6870 - acc: 0.5510
9280/9333 [============================>.] - ETA: 2s - loss: 0.6871 - acc: 0.5505
9333/9333 [==============================] - 476s 51ms/step - loss: 0.6871 - acc: 0.5508 - val_loss: 0.7027 - val_acc: 0.4986

Epoch 00008: val_acc did not improve from 0.54484
Epoch 9/10

  64/9333 [..............................] - ETA: 6:24 - loss: 0.6782 - acc: 0.5938
 128/9333 [..............................] - ETA: 6:52 - loss: 0.6918 - acc: 0.5547
 192/9333 [..............................] - ETA: 6:49 - loss: 0.6965 - acc: 0.5312
 256/9333 [..............................] - ETA: 6:53 - loss: 0.6936 - acc: 0.5352
 320/9333 [>.............................] - ETA: 6:46 - loss: 0.6926 - acc: 0.5250
 384/9333 [>.............................] - ETA: 6:48 - loss: 0.6948 - acc: 0.5182
 448/9333 [>.............................] - ETA: 6:44 - loss: 0.6950 - acc: 0.5268
 512/9333 [>.............................] - ETA: 6:43 - loss: 0.6945 - acc: 0.5254
 576/9333 [>.............................] - ETA: 6:44 - loss: 0.6941 - acc: 0.5278
 640/9333 [=>............................] - ETA: 6:36 - loss: 0.6938 - acc: 0.5250
 704/9333 [=>............................] - ETA: 6:36 - loss: 0.6950 - acc: 0.5114
 768/9333 [=>............................] - ETA: 6:32 - loss: 0.6946 - acc: 0.5117
 832/9333 [=>............................] - ETA: 6:28 - loss: 0.6949 - acc: 0.5120
 896/9333 [=>............................] - ETA: 6:22 - loss: 0.6940 - acc: 0.5179
 960/9333 [==>...........................] - ETA: 6:17 - loss: 0.6939 - acc: 0.5135
1024/9333 [==>...........................] - ETA: 6:15 - loss: 0.6959 - acc: 0.5029
1088/9333 [==>...........................] - ETA: 6:12 - loss: 0.6956 - acc: 0.5037
1152/9333 [==>...........................] - ETA: 6:08 - loss: 0.6946 - acc: 0.5087
1216/9333 [==>...........................] - ETA: 6:06 - loss: 0.6946 - acc: 0.5099
1280/9333 [===>..........................] - ETA: 6:05 - loss: 0.6943 - acc: 0.5109
1344/9333 [===>..........................] - ETA: 6:03 - loss: 0.6937 - acc: 0.5126
1408/9333 [===>..........................] - ETA: 5:59 - loss: 0.6929 - acc: 0.5156
1472/9333 [===>..........................] - ETA: 5:56 - loss: 0.6923 - acc: 0.5211
1536/9333 [===>..........................] - ETA: 5:54 - loss: 0.6920 - acc: 0.5234
1600/9333 [====>.........................] - ETA: 5:51 - loss: 0.6928 - acc: 0.5206
1664/9333 [====>.........................] - ETA: 5:48 - loss: 0.6915 - acc: 0.5252
1728/9333 [====>.........................] - ETA: 5:47 - loss: 0.6915 - acc: 0.5266
1792/9333 [====>.........................] - ETA: 5:45 - loss: 0.6921 - acc: 0.5229
1856/9333 [====>.........................] - ETA: 5:43 - loss: 0.6917 - acc: 0.5226
1920/9333 [=====>........................] - ETA: 5:40 - loss: 0.6915 - acc: 0.5250
1984/9333 [=====>........................] - ETA: 5:36 - loss: 0.6913 - acc: 0.5262
2048/9333 [=====>........................] - ETA: 5:32 - loss: 0.6922 - acc: 0.5229
2112/9333 [=====>........................] - ETA: 5:29 - loss: 0.6920 - acc: 0.5251
2176/9333 [=====>........................] - ETA: 5:27 - loss: 0.6917 - acc: 0.5280
2240/9333 [======>.......................] - ETA: 5:23 - loss: 0.6909 - acc: 0.5335
2304/9333 [======>.......................] - ETA: 5:20 - loss: 0.6912 - acc: 0.5304
2368/9333 [======>.......................] - ETA: 5:16 - loss: 0.6914 - acc: 0.5300
2432/9333 [======>.......................] - ETA: 5:13 - loss: 0.6918 - acc: 0.5271
2496/9333 [=======>......................] - ETA: 5:13 - loss: 0.6917 - acc: 0.5268
2560/9333 [=======>......................] - ETA: 5:12 - loss: 0.6918 - acc: 0.5258
2624/9333 [=======>......................] - ETA: 5:10 - loss: 0.6916 - acc: 0.5267
2688/9333 [=======>......................] - ETA: 5:07 - loss: 0.6913 - acc: 0.5279
2752/9333 [=======>......................] - ETA: 5:04 - loss: 0.6907 - acc: 0.5305
2816/9333 [========>.....................] - ETA: 5:02 - loss: 0.6909 - acc: 0.5298
2880/9333 [========>.....................] - ETA: 4:59 - loss: 0.6910 - acc: 0.5302
2944/9333 [========>.....................] - ETA: 4:57 - loss: 0.6907 - acc: 0.5316
3008/9333 [========>.....................] - ETA: 4:53 - loss: 0.6906 - acc: 0.5322
3072/9333 [========>.....................] - ETA: 4:50 - loss: 0.6904 - acc: 0.5335
3136/9333 [=========>....................] - ETA: 4:47 - loss: 0.6898 - acc: 0.5354
3200/9333 [=========>....................] - ETA: 4:45 - loss: 0.6892 - acc: 0.5369
3264/9333 [=========>....................] - ETA: 4:42 - loss: 0.6888 - acc: 0.5392
3328/9333 [=========>....................] - ETA: 4:39 - loss: 0.6887 - acc: 0.5400
3392/9333 [=========>....................] - ETA: 4:37 - loss: 0.6884 - acc: 0.5410
3456/9333 [==========>...................] - ETA: 4:34 - loss: 0.6886 - acc: 0.5408
3520/9333 [==========>...................] - ETA: 4:32 - loss: 0.6886 - acc: 0.5406
3584/9333 [==========>...................] - ETA: 4:28 - loss: 0.6881 - acc: 0.5424
3648/9333 [==========>...................] - ETA: 4:26 - loss: 0.6879 - acc: 0.5439
3712/9333 [==========>...................] - ETA: 4:23 - loss: 0.6881 - acc: 0.5428
3776/9333 [===========>..................] - ETA: 4:19 - loss: 0.6875 - acc: 0.5453
3840/9333 [===========>..................] - ETA: 4:16 - loss: 0.6872 - acc: 0.5466
3904/9333 [===========>..................] - ETA: 4:14 - loss: 0.6875 - acc: 0.5476
3968/9333 [===========>..................] - ETA: 4:11 - loss: 0.6880 - acc: 0.5464
4032/9333 [===========>..................] - ETA: 4:08 - loss: 0.6881 - acc: 0.5469
4096/9333 [============>.................] - ETA: 4:06 - loss: 0.6877 - acc: 0.5474
4160/9333 [============>.................] - ETA: 4:03 - loss: 0.6879 - acc: 0.5476
4224/9333 [============>.................] - ETA: 4:00 - loss: 0.6876 - acc: 0.5488
4288/9333 [============>.................] - ETA: 3:57 - loss: 0.6882 - acc: 0.5464
4352/9333 [============>.................] - ETA: 3:54 - loss: 0.6881 - acc: 0.5471
4416/9333 [=============>................] - ETA: 3:51 - loss: 0.6883 - acc: 0.5473
4480/9333 [=============>................] - ETA: 3:48 - loss: 0.6883 - acc: 0.5458
4544/9333 [=============>................] - ETA: 3:45 - loss: 0.6883 - acc: 0.5460
4608/9333 [=============>................] - ETA: 3:42 - loss: 0.6878 - acc: 0.5473
4672/9333 [==============>...............] - ETA: 3:40 - loss: 0.6874 - acc: 0.5482
4736/9333 [==============>...............] - ETA: 3:37 - loss: 0.6874 - acc: 0.5481
4800/9333 [==============>...............] - ETA: 3:34 - loss: 0.6873 - acc: 0.5477
4864/9333 [==============>...............] - ETA: 3:31 - loss: 0.6872 - acc: 0.5475
4928/9333 [==============>...............] - ETA: 3:28 - loss: 0.6874 - acc: 0.5469
4992/9333 [===============>..............] - ETA: 3:25 - loss: 0.6877 - acc: 0.5459
5056/9333 [===============>..............] - ETA: 3:22 - loss: 0.6877 - acc: 0.5457
5120/9333 [===============>..............] - ETA: 3:19 - loss: 0.6876 - acc: 0.5463
5184/9333 [===============>..............] - ETA: 3:16 - loss: 0.6877 - acc: 0.5453
5248/9333 [===============>..............] - ETA: 3:13 - loss: 0.6877 - acc: 0.5452
5312/9333 [================>.............] - ETA: 3:10 - loss: 0.6878 - acc: 0.5446
5376/9333 [================>.............] - ETA: 3:07 - loss: 0.6880 - acc: 0.5443
5440/9333 [================>.............] - ETA: 3:04 - loss: 0.6880 - acc: 0.5439
5504/9333 [================>.............] - ETA: 3:01 - loss: 0.6879 - acc: 0.5445
5568/9333 [================>.............] - ETA: 2:58 - loss: 0.6879 - acc: 0.5444
5632/9333 [=================>............] - ETA: 2:55 - loss: 0.6882 - acc: 0.5437
5696/9333 [=================>............] - ETA: 2:53 - loss: 0.6880 - acc: 0.5448
5760/9333 [=================>............] - ETA: 2:50 - loss: 0.6880 - acc: 0.5448
5824/9333 [=================>............] - ETA: 2:47 - loss: 0.6880 - acc: 0.5446
5888/9333 [=================>............] - ETA: 2:44 - loss: 0.6885 - acc: 0.5442
5952/9333 [==================>...........] - ETA: 2:41 - loss: 0.6885 - acc: 0.5442
6016/9333 [==================>...........] - ETA: 2:37 - loss: 0.6888 - acc: 0.5434
6080/9333 [==================>...........] - ETA: 2:35 - loss: 0.6884 - acc: 0.5441
6144/9333 [==================>...........] - ETA: 2:32 - loss: 0.6882 - acc: 0.5444
6208/9333 [==================>...........] - ETA: 2:29 - loss: 0.6879 - acc: 0.5448
6272/9333 [===================>..........] - ETA: 2:26 - loss: 0.6878 - acc: 0.5443
6336/9333 [===================>..........] - ETA: 2:23 - loss: 0.6878 - acc: 0.5447
6400/9333 [===================>..........] - ETA: 2:20 - loss: 0.6873 - acc: 0.5455
6464/9333 [===================>..........] - ETA: 2:17 - loss: 0.6876 - acc: 0.5449
6528/9333 [===================>..........] - ETA: 2:14 - loss: 0.6876 - acc: 0.5444
6592/9333 [====================>.........] - ETA: 2:11 - loss: 0.6877 - acc: 0.5448
6656/9333 [====================>.........] - ETA: 2:08 - loss: 0.6876 - acc: 0.5446
6720/9333 [====================>.........] - ETA: 2:05 - loss: 0.6875 - acc: 0.5454
6784/9333 [====================>.........] - ETA: 2:02 - loss: 0.6872 - acc: 0.5467
6848/9333 [=====================>........] - ETA: 1:59 - loss: 0.6871 - acc: 0.5476
6912/9333 [=====================>........] - ETA: 1:56 - loss: 0.6868 - acc: 0.5482
6976/9333 [=====================>........] - ETA: 1:53 - loss: 0.6863 - acc: 0.5495
7040/9333 [=====================>........] - ETA: 1:50 - loss: 0.6863 - acc: 0.5496
7104/9333 [=====================>........] - ETA: 1:47 - loss: 0.6865 - acc: 0.5497
7168/9333 [======================>.......] - ETA: 1:44 - loss: 0.6865 - acc: 0.5501
7232/9333 [======================>.......] - ETA: 1:41 - loss: 0.6866 - acc: 0.5498
7296/9333 [======================>.......] - ETA: 1:38 - loss: 0.6866 - acc: 0.5498
7360/9333 [======================>.......] - ETA: 1:35 - loss: 0.6867 - acc: 0.5499
7424/9333 [======================>.......] - ETA: 1:32 - loss: 0.6866 - acc: 0.5497
7488/9333 [=======================>......] - ETA: 1:29 - loss: 0.6866 - acc: 0.5495
7552/9333 [=======================>......] - ETA: 1:26 - loss: 0.6866 - acc: 0.5502
7616/9333 [=======================>......] - ETA: 1:22 - loss: 0.6865 - acc: 0.5506
7680/9333 [=======================>......] - ETA: 1:19 - loss: 0.6865 - acc: 0.5505
7744/9333 [=======================>......] - ETA: 1:16 - loss: 0.6865 - acc: 0.5504
7808/9333 [========================>.....] - ETA: 1:13 - loss: 0.6865 - acc: 0.5501
7872/9333 [========================>.....] - ETA: 1:10 - loss: 0.6864 - acc: 0.5507
7936/9333 [========================>.....] - ETA: 1:07 - loss: 0.6864 - acc: 0.5512
8000/9333 [========================>.....] - ETA: 1:04 - loss: 0.6864 - acc: 0.5509
8064/9333 [========================>.....] - ETA: 1:01 - loss: 0.6863 - acc: 0.5512
8128/9333 [=========================>....] - ETA: 58s - loss: 0.6860 - acc: 0.5527 
8192/9333 [=========================>....] - ETA: 55s - loss: 0.6859 - acc: 0.5531
8256/9333 [=========================>....] - ETA: 52s - loss: 0.6857 - acc: 0.5534
8320/9333 [=========================>....] - ETA: 49s - loss: 0.6858 - acc: 0.5532
8384/9333 [=========================>....] - ETA: 45s - loss: 0.6859 - acc: 0.5526
8448/9333 [==========================>...] - ETA: 42s - loss: 0.6859 - acc: 0.5523
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6859 - acc: 0.5520
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6861 - acc: 0.5514
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6864 - acc: 0.5507
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6863 - acc: 0.5507
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6862 - acc: 0.5510
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6865 - acc: 0.5500
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6867 - acc: 0.5495
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6866 - acc: 0.5499
9024/9333 [============================>.] - ETA: 14s - loss: 0.6866 - acc: 0.5494
9088/9333 [============================>.] - ETA: 11s - loss: 0.6867 - acc: 0.5494
9152/9333 [============================>.] - ETA: 8s - loss: 0.6866 - acc: 0.5497 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6867 - acc: 0.5492
9280/9333 [============================>.] - ETA: 2s - loss: 0.6867 - acc: 0.5494
9333/9333 [==============================] - 470s 50ms/step - loss: 0.6865 - acc: 0.5501 - val_loss: 0.6971 - val_acc: 0.5034

Epoch 00009: val_acc did not improve from 0.54484
Epoch 10/10

  64/9333 [..............................] - ETA: 7:07 - loss: 0.6917 - acc: 0.5781
 128/9333 [..............................] - ETA: 6:56 - loss: 0.6866 - acc: 0.5625
 192/9333 [..............................] - ETA: 6:55 - loss: 0.6914 - acc: 0.5260
 256/9333 [..............................] - ETA: 6:58 - loss: 0.6875 - acc: 0.5391
 320/9333 [>.............................] - ETA: 7:00 - loss: 0.6915 - acc: 0.5125
 384/9333 [>.............................] - ETA: 6:56 - loss: 0.6896 - acc: 0.5208
 448/9333 [>.............................] - ETA: 6:54 - loss: 0.6881 - acc: 0.5290
 512/9333 [>.............................] - ETA: 6:49 - loss: 0.6893 - acc: 0.5273
 576/9333 [>.............................] - ETA: 6:51 - loss: 0.6887 - acc: 0.5330
 640/9333 [=>............................] - ETA: 6:47 - loss: 0.6886 - acc: 0.5312
 704/9333 [=>............................] - ETA: 6:50 - loss: 0.6861 - acc: 0.5384
 768/9333 [=>............................] - ETA: 6:48 - loss: 0.6855 - acc: 0.5404
 832/9333 [=>............................] - ETA: 6:47 - loss: 0.6863 - acc: 0.5373
 896/9333 [=>............................] - ETA: 6:47 - loss: 0.6868 - acc: 0.5379
 960/9333 [==>...........................] - ETA: 6:48 - loss: 0.6864 - acc: 0.5365
1024/9333 [==>...........................] - ETA: 6:45 - loss: 0.6850 - acc: 0.5400
1088/9333 [==>...........................] - ETA: 6:46 - loss: 0.6864 - acc: 0.5368
1152/9333 [==>...........................] - ETA: 6:42 - loss: 0.6852 - acc: 0.5425
1216/9333 [==>...........................] - ETA: 6:38 - loss: 0.6855 - acc: 0.5395
1280/9333 [===>..........................] - ETA: 6:34 - loss: 0.6860 - acc: 0.5391
1344/9333 [===>..........................] - ETA: 6:32 - loss: 0.6860 - acc: 0.5372
1408/9333 [===>..........................] - ETA: 6:30 - loss: 0.6878 - acc: 0.5312
1472/9333 [===>..........................] - ETA: 6:26 - loss: 0.6885 - acc: 0.5285
1536/9333 [===>..........................] - ETA: 6:23 - loss: 0.6889 - acc: 0.5260
1600/9333 [====>.........................] - ETA: 6:20 - loss: 0.6891 - acc: 0.5238
1664/9333 [====>.........................] - ETA: 6:16 - loss: 0.6882 - acc: 0.5270
1728/9333 [====>.........................] - ETA: 6:11 - loss: 0.6875 - acc: 0.5295
1792/9333 [====>.........................] - ETA: 6:07 - loss: 0.6867 - acc: 0.5324
1856/9333 [====>.........................] - ETA: 6:03 - loss: 0.6883 - acc: 0.5264
1920/9333 [=====>........................] - ETA: 6:00 - loss: 0.6887 - acc: 0.5266
1984/9333 [=====>........................] - ETA: 5:57 - loss: 0.6887 - acc: 0.5257
2048/9333 [=====>........................] - ETA: 5:56 - loss: 0.6879 - acc: 0.5308
2112/9333 [=====>........................] - ETA: 5:53 - loss: 0.6881 - acc: 0.5294
2176/9333 [=====>........................] - ETA: 5:50 - loss: 0.6882 - acc: 0.5299
2240/9333 [======>.......................] - ETA: 5:46 - loss: 0.6879 - acc: 0.5299
2304/9333 [======>.......................] - ETA: 5:43 - loss: 0.6883 - acc: 0.5286
2368/9333 [======>.......................] - ETA: 5:39 - loss: 0.6877 - acc: 0.5312
2432/9333 [======>.......................] - ETA: 5:37 - loss: 0.6876 - acc: 0.5325
2496/9333 [=======>......................] - ETA: 5:36 - loss: 0.6882 - acc: 0.5308
2560/9333 [=======>......................] - ETA: 5:32 - loss: 0.6882 - acc: 0.5301
2624/9333 [=======>......................] - ETA: 5:28 - loss: 0.6884 - acc: 0.5282
2688/9333 [=======>......................] - ETA: 5:25 - loss: 0.6890 - acc: 0.5268
2752/9333 [=======>......................] - ETA: 5:21 - loss: 0.6892 - acc: 0.5254
2816/9333 [========>.....................] - ETA: 5:17 - loss: 0.6887 - acc: 0.5277
2880/9333 [========>.....................] - ETA: 5:14 - loss: 0.6890 - acc: 0.5260
2944/9333 [========>.....................] - ETA: 5:11 - loss: 0.6887 - acc: 0.5279
3008/9333 [========>.....................] - ETA: 5:08 - loss: 0.6881 - acc: 0.5312
3072/9333 [========>.....................] - ETA: 5:06 - loss: 0.6878 - acc: 0.5322
3136/9333 [=========>....................] - ETA: 5:03 - loss: 0.6878 - acc: 0.5306
3200/9333 [=========>....................] - ETA: 4:59 - loss: 0.6883 - acc: 0.5284
3264/9333 [=========>....................] - ETA: 4:57 - loss: 0.6880 - acc: 0.5288
3328/9333 [=========>....................] - ETA: 4:54 - loss: 0.6880 - acc: 0.5291
3392/9333 [=========>....................] - ETA: 4:51 - loss: 0.6883 - acc: 0.5289
3456/9333 [==========>...................] - ETA: 4:47 - loss: 0.6878 - acc: 0.5315
3520/9333 [==========>...................] - ETA: 4:44 - loss: 0.6878 - acc: 0.5307
3584/9333 [==========>...................] - ETA: 4:40 - loss: 0.6879 - acc: 0.5310
3648/9333 [==========>...................] - ETA: 4:37 - loss: 0.6878 - acc: 0.5302
3712/9333 [==========>...................] - ETA: 4:33 - loss: 0.6876 - acc: 0.5323
3776/9333 [===========>..................] - ETA: 4:30 - loss: 0.6875 - acc: 0.5320
3840/9333 [===========>..................] - ETA: 4:26 - loss: 0.6874 - acc: 0.5326
3904/9333 [===========>..................] - ETA: 4:24 - loss: 0.6872 - acc: 0.5325
3968/9333 [===========>..................] - ETA: 4:21 - loss: 0.6870 - acc: 0.5330
4032/9333 [===========>..................] - ETA: 4:18 - loss: 0.6869 - acc: 0.5347
4096/9333 [============>.................] - ETA: 4:14 - loss: 0.6868 - acc: 0.5356
4160/9333 [============>.................] - ETA: 4:11 - loss: 0.6869 - acc: 0.5358
4224/9333 [============>.................] - ETA: 4:08 - loss: 0.6868 - acc: 0.5362
4288/9333 [============>.................] - ETA: 4:05 - loss: 0.6873 - acc: 0.5359
4352/9333 [============>.................] - ETA: 4:02 - loss: 0.6875 - acc: 0.5352
4416/9333 [=============>................] - ETA: 3:59 - loss: 0.6871 - acc: 0.5356
4480/9333 [=============>................] - ETA: 3:56 - loss: 0.6875 - acc: 0.5353
4544/9333 [=============>................] - ETA: 3:52 - loss: 0.6876 - acc: 0.5350
4608/9333 [=============>................] - ETA: 3:49 - loss: 0.6876 - acc: 0.5349
4672/9333 [==============>...............] - ETA: 3:46 - loss: 0.6877 - acc: 0.5366
4736/9333 [==============>...............] - ETA: 3:43 - loss: 0.6872 - acc: 0.5393
4800/9333 [==============>...............] - ETA: 3:40 - loss: 0.6872 - acc: 0.5396
4864/9333 [==============>...............] - ETA: 3:36 - loss: 0.6867 - acc: 0.5413
4928/9333 [==============>...............] - ETA: 3:33 - loss: 0.6865 - acc: 0.5430
4992/9333 [===============>..............] - ETA: 3:30 - loss: 0.6860 - acc: 0.5447
5056/9333 [===============>..............] - ETA: 3:27 - loss: 0.6860 - acc: 0.5445
5120/9333 [===============>..............] - ETA: 3:24 - loss: 0.6862 - acc: 0.5445
5184/9333 [===============>..............] - ETA: 3:21 - loss: 0.6859 - acc: 0.5449
5248/9333 [===============>..............] - ETA: 3:18 - loss: 0.6855 - acc: 0.5461
5312/9333 [================>.............] - ETA: 3:15 - loss: 0.6858 - acc: 0.5450
5376/9333 [================>.............] - ETA: 3:11 - loss: 0.6855 - acc: 0.5452
5440/9333 [================>.............] - ETA: 3:08 - loss: 0.6855 - acc: 0.5456
5504/9333 [================>.............] - ETA: 3:05 - loss: 0.6856 - acc: 0.5461
5568/9333 [================>.............] - ETA: 3:02 - loss: 0.6858 - acc: 0.5465
5632/9333 [=================>............] - ETA: 2:59 - loss: 0.6857 - acc: 0.5476
5696/9333 [=================>............] - ETA: 2:56 - loss: 0.6859 - acc: 0.5474
5760/9333 [=================>............] - ETA: 2:52 - loss: 0.6862 - acc: 0.5465
5824/9333 [=================>............] - ETA: 2:49 - loss: 0.6860 - acc: 0.5470
5888/9333 [=================>............] - ETA: 2:46 - loss: 0.6859 - acc: 0.5474
5952/9333 [==================>...........] - ETA: 2:43 - loss: 0.6856 - acc: 0.5487
6016/9333 [==================>...........] - ETA: 2:39 - loss: 0.6855 - acc: 0.5492
6080/9333 [==================>...........] - ETA: 2:36 - loss: 0.6854 - acc: 0.5493
6144/9333 [==================>...........] - ETA: 2:34 - loss: 0.6855 - acc: 0.5492
6208/9333 [==================>...........] - ETA: 2:30 - loss: 0.6858 - acc: 0.5486
6272/9333 [===================>..........] - ETA: 2:27 - loss: 0.6861 - acc: 0.5475
6336/9333 [===================>..........] - ETA: 2:24 - loss: 0.6862 - acc: 0.5477
6400/9333 [===================>..........] - ETA: 2:21 - loss: 0.6858 - acc: 0.5487
6464/9333 [===================>..........] - ETA: 2:18 - loss: 0.6860 - acc: 0.5490
6528/9333 [===================>..........] - ETA: 2:15 - loss: 0.6856 - acc: 0.5504
6592/9333 [====================>.........] - ETA: 2:12 - loss: 0.6857 - acc: 0.5493
6656/9333 [====================>.........] - ETA: 2:09 - loss: 0.6855 - acc: 0.5497
6720/9333 [====================>.........] - ETA: 2:06 - loss: 0.6859 - acc: 0.5485
6784/9333 [====================>.........] - ETA: 2:02 - loss: 0.6861 - acc: 0.5479
6848/9333 [=====================>........] - ETA: 1:59 - loss: 0.6862 - acc: 0.5472
6912/9333 [=====================>........] - ETA: 1:56 - loss: 0.6863 - acc: 0.5469
6976/9333 [=====================>........] - ETA: 1:53 - loss: 0.6862 - acc: 0.5473
7040/9333 [=====================>........] - ETA: 1:50 - loss: 0.6863 - acc: 0.5474
7104/9333 [=====================>........] - ETA: 1:47 - loss: 0.6863 - acc: 0.5470
7168/9333 [======================>.......] - ETA: 1:44 - loss: 0.6867 - acc: 0.5459
7232/9333 [======================>.......] - ETA: 1:41 - loss: 0.6865 - acc: 0.5463
7296/9333 [======================>.......] - ETA: 1:38 - loss: 0.6868 - acc: 0.5454
7360/9333 [======================>.......] - ETA: 1:35 - loss: 0.6868 - acc: 0.5451
7424/9333 [======================>.......] - ETA: 1:32 - loss: 0.6868 - acc: 0.5455
7488/9333 [=======================>......] - ETA: 1:29 - loss: 0.6867 - acc: 0.5455
7552/9333 [=======================>......] - ETA: 1:26 - loss: 0.6866 - acc: 0.5459
7616/9333 [=======================>......] - ETA: 1:23 - loss: 0.6867 - acc: 0.5456
7680/9333 [=======================>......] - ETA: 1:20 - loss: 0.6869 - acc: 0.5451
7744/9333 [=======================>......] - ETA: 1:16 - loss: 0.6868 - acc: 0.5453
7808/9333 [========================>.....] - ETA: 1:13 - loss: 0.6870 - acc: 0.5443
7872/9333 [========================>.....] - ETA: 1:10 - loss: 0.6868 - acc: 0.5454
7936/9333 [========================>.....] - ETA: 1:07 - loss: 0.6869 - acc: 0.5449
8000/9333 [========================>.....] - ETA: 1:04 - loss: 0.6869 - acc: 0.5443
8064/9333 [========================>.....] - ETA: 1:01 - loss: 0.6868 - acc: 0.5445
8128/9333 [=========================>....] - ETA: 58s - loss: 0.6869 - acc: 0.5444 
8192/9333 [=========================>....] - ETA: 55s - loss: 0.6868 - acc: 0.5447
8256/9333 [=========================>....] - ETA: 52s - loss: 0.6869 - acc: 0.5447
8320/9333 [=========================>....] - ETA: 49s - loss: 0.6871 - acc: 0.5437
8384/9333 [=========================>....] - ETA: 46s - loss: 0.6870 - acc: 0.5446
8448/9333 [==========================>...] - ETA: 43s - loss: 0.6869 - acc: 0.5449
8512/9333 [==========================>...] - ETA: 39s - loss: 0.6869 - acc: 0.5445
8576/9333 [==========================>...] - ETA: 36s - loss: 0.6871 - acc: 0.5445
8640/9333 [==========================>...] - ETA: 33s - loss: 0.6870 - acc: 0.5446
8704/9333 [==========================>...] - ETA: 30s - loss: 0.6871 - acc: 0.5443
8768/9333 [===========================>..] - ETA: 27s - loss: 0.6872 - acc: 0.5437
8832/9333 [===========================>..] - ETA: 24s - loss: 0.6870 - acc: 0.5442
8896/9333 [===========================>..] - ETA: 21s - loss: 0.6869 - acc: 0.5447
8960/9333 [===========================>..] - ETA: 18s - loss: 0.6868 - acc: 0.5449
9024/9333 [============================>.] - ETA: 15s - loss: 0.6867 - acc: 0.5451
9088/9333 [============================>.] - ETA: 11s - loss: 0.6869 - acc: 0.5448
9152/9333 [============================>.] - ETA: 8s - loss: 0.6870 - acc: 0.5447 
9216/9333 [============================>.] - ETA: 5s - loss: 0.6868 - acc: 0.5455
9280/9333 [============================>.] - ETA: 2s - loss: 0.6868 - acc: 0.5452
9333/9333 [==============================] - 473s 51ms/step - loss: 0.6868 - acc: 0.5454 - val_loss: 0.6883 - val_acc: 0.5381

Epoch 00010: val_acc did not improve from 0.54484
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f402449f410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f402449f410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f40240dd110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f40240dd110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b6417c250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b6417c250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b6417c650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3b6417c650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39c42583d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39c42583d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f400441f090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f400441f090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b6417c490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3b6417c490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40043212d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40043212d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4004450590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4004450590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f40042cc410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f40042cc410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b24581350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3b24581350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40044500d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40044500d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ae4593290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ae4593290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4004064310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4004064310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fe472be90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fe472be90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe458d5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe458d5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40043ec590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f40043ec590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe472f710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe472f710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fe451e8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fe451e8d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fe4347c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fe4347c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe42ae890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe42ae890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fe451ef50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fe451ef50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe4391410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe4391410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fe41ab050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fe41ab050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fe44bfb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fe44bfb90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe47b5710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe47b5710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fe41ab190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fe41ab190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe451ea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fe451ea50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fe41b8bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fe41b8bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fc4517290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fc4517290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fc4435750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fc4435750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fe414f850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fe414f850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fc462c210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fc462c210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fc4364d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fc4364d10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fc41bd150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fc41bd150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fc436ced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fc436ced0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fc43c0d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fc43c0d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fc40ee450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fc40ee450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fa47a0950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3fa47a0950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fa45cb650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fa45cb650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fc43e0750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fc43e0750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fc4337a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fc4337a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fa47a0b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3fa47a0b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ec41f2650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ec41f2650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ea40b1210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ea40b1210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ec4203310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ec4203310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fc406f950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3fc406f950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ec4162810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ec4162810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e84674f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e84674f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e84766250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e84766250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e846629d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e846629d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e84674510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e84674510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e845f2110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e845f2110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ec422d4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ec422d4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e8455ef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e8455ef10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e84204790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e84204790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e843659d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e843659d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e845e5610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e845e5610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e8474fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e8474fa50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e84576250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e84576250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e84054610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e84054610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e8474f290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e8474f290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e68740590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e68740590>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 11:34
 128/2592 [>.............................] - ETA: 6:07 
 192/2592 [=>............................] - ETA: 4:15
 256/2592 [=>............................] - ETA: 3:20
 320/2592 [==>...........................] - ETA: 2:44
 384/2592 [===>..........................] - ETA: 2:21
 448/2592 [====>.........................] - ETA: 2:03
 512/2592 [====>.........................] - ETA: 1:49
 576/2592 [=====>........................] - ETA: 1:40
 640/2592 [======>.......................] - ETA: 1:31
 704/2592 [=======>......................] - ETA: 1:24
 768/2592 [=======>......................] - ETA: 1:18
 832/2592 [========>.....................] - ETA: 1:13
 896/2592 [=========>....................] - ETA: 1:08
 960/2592 [==========>...................] - ETA: 1:03
1024/2592 [==========>...................] - ETA: 59s 
1088/2592 [===========>..................] - ETA: 55s
1152/2592 [============>.................] - ETA: 51s
1216/2592 [=============>................] - ETA: 48s
1280/2592 [=============>................] - ETA: 45s
1344/2592 [==============>...............] - ETA: 42s
1408/2592 [===============>..............] - ETA: 39s
1472/2592 [================>.............] - ETA: 36s
1536/2592 [================>.............] - ETA: 34s
1600/2592 [=================>............] - ETA: 32s
1664/2592 [==================>...........] - ETA: 29s
1728/2592 [===================>..........] - ETA: 27s
1792/2592 [===================>..........] - ETA: 24s
1856/2592 [====================>.........] - ETA: 22s
1920/2592 [=====================>........] - ETA: 20s
1984/2592 [=====================>........] - ETA: 18s
2048/2592 [======================>.......] - ETA: 16s
2112/2592 [=======================>......] - ETA: 14s
2176/2592 [========================>.....] - ETA: 12s
2240/2592 [========================>.....] - ETA: 10s
2304/2592 [=========================>....] - ETA: 8s 
2368/2592 [==========================>...] - ETA: 6s
2432/2592 [===========================>..] - ETA: 4s
2496/2592 [===========================>..] - ETA: 2s
2560/2592 [============================>.] - ETA: 0s
2592/2592 [==============================] - 74s 28ms/step
loss: 0.6867432976946418
acc: 0.5478395061728395
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3964466810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3964466810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3964472850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3964472850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40241d8d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40241d8d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e241c1e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e241c1e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fc45a7250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3fc45a7250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e2457d5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e2457d5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e241c1910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e241c1910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f402445c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f402445c7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f400453a250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f400453a250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f40243bf310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f40243bf310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40243f1f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40243f1f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f400453a890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f400453a890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f402423fa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f402423fa50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4004568390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f4004568390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4004634050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f4004634050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40242e5b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40242e5b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4024256f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f4024256f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4024188a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f4024188a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f400453a2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f400453a2d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39640bc210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39640bc210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3944782e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3944782e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f38a46b2310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f38a46b2310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39640cce10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39640cce10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39446ac1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39446ac1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f394459ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f394459ba90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39641c5ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39641c5ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3964148810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3964148810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39446d1bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39446d1bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f394434d1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f394434d1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3944399b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3944399b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3944345ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3944345ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3944679f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3944679f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3944269210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3944269210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3944081250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3944081250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3924719450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3924719450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f392461ef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f392461ef10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39247a0ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39247a0ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f394431ccd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f394431ccd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3924528c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3924528c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39243ba410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39243ba410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39246c8750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39246c8750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39247a38d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39247a38d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f392442c650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f392442c650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39241df850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39241df850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39240d7290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39240d7290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39047b67d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39047b67d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39241dffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39241dffd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3924554090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3924554090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3904743cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3904743cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39045b2cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39045b2cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39240d13d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39240d13d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f390470fd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f390470fd90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39046348d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39046348d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39241c8510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39241c8510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3904254690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3904254690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f390432ec90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f390432ec90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f390444c910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f390444c910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39041fe6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39041fe6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3904050850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3904050850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f38e4735590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f38e4735590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f390408c710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f390408c710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39042ba910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39042ba910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38e473f8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38e473f8d0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 2:45:34 - loss: 0.7002 - acc: 0.5000
 128/9333 [..............................] - ETA: 1:32:29 - loss: 0.7235 - acc: 0.5234
 192/9333 [..............................] - ETA: 1:09:39 - loss: 0.7454 - acc: 0.5208
 256/9333 [..............................] - ETA: 56:44 - loss: 0.7582 - acc: 0.5000  
 320/9333 [>.............................] - ETA: 49:05 - loss: 0.7555 - acc: 0.5156
 384/9333 [>.............................] - ETA: 44:17 - loss: 0.7430 - acc: 0.5286
 448/9333 [>.............................] - ETA: 40:18 - loss: 0.7503 - acc: 0.5357
 512/9333 [>.............................] - ETA: 37:11 - loss: 0.7486 - acc: 0.5332
 576/9333 [>.............................] - ETA: 35:13 - loss: 0.7501 - acc: 0.5278
 640/9333 [=>............................] - ETA: 33:16 - loss: 0.7485 - acc: 0.5219
 704/9333 [=>............................] - ETA: 31:43 - loss: 0.7483 - acc: 0.5199
 768/9333 [=>............................] - ETA: 30:23 - loss: 0.7454 - acc: 0.5221
 832/9333 [=>............................] - ETA: 29:10 - loss: 0.7433 - acc: 0.5216
 896/9333 [=>............................] - ETA: 28:10 - loss: 0.7465 - acc: 0.5190
 960/9333 [==>...........................] - ETA: 27:18 - loss: 0.7448 - acc: 0.5167
1024/9333 [==>...........................] - ETA: 26:42 - loss: 0.7426 - acc: 0.5137
1088/9333 [==>...........................] - ETA: 25:54 - loss: 0.7407 - acc: 0.5138
1152/9333 [==>...........................] - ETA: 25:14 - loss: 0.7414 - acc: 0.5130
1216/9333 [==>...........................] - ETA: 24:35 - loss: 0.7370 - acc: 0.5173
1280/9333 [===>..........................] - ETA: 24:02 - loss: 0.7368 - acc: 0.5164
1344/9333 [===>..........................] - ETA: 23:35 - loss: 0.7364 - acc: 0.5156
1408/9333 [===>..........................] - ETA: 23:13 - loss: 0.7355 - acc: 0.5149
1472/9333 [===>..........................] - ETA: 22:42 - loss: 0.7359 - acc: 0.5122
1536/9333 [===>..........................] - ETA: 22:12 - loss: 0.7339 - acc: 0.5156
1600/9333 [====>.........................] - ETA: 21:45 - loss: 0.7340 - acc: 0.5162
1664/9333 [====>.........................] - ETA: 21:24 - loss: 0.7330 - acc: 0.5168
1728/9333 [====>.........................] - ETA: 21:04 - loss: 0.7316 - acc: 0.5179
1792/9333 [====>.........................] - ETA: 20:47 - loss: 0.7326 - acc: 0.5145
1856/9333 [====>.........................] - ETA: 20:28 - loss: 0.7313 - acc: 0.5162
1920/9333 [=====>........................] - ETA: 20:09 - loss: 0.7302 - acc: 0.5172
1984/9333 [=====>........................] - ETA: 19:54 - loss: 0.7284 - acc: 0.5197
2048/9333 [=====>........................] - ETA: 19:39 - loss: 0.7290 - acc: 0.5166
2112/9333 [=====>........................] - ETA: 19:25 - loss: 0.7276 - acc: 0.5189
2176/9333 [=====>........................] - ETA: 19:09 - loss: 0.7261 - acc: 0.5225
2240/9333 [======>.......................] - ETA: 18:56 - loss: 0.7242 - acc: 0.5246
2304/9333 [======>.......................] - ETA: 18:44 - loss: 0.7250 - acc: 0.5217
2368/9333 [======>.......................] - ETA: 18:30 - loss: 0.7247 - acc: 0.5220
2432/9333 [======>.......................] - ETA: 18:17 - loss: 0.7234 - acc: 0.5230
2496/9333 [=======>......................] - ETA: 18:06 - loss: 0.7227 - acc: 0.5220
2560/9333 [=======>......................] - ETA: 17:51 - loss: 0.7223 - acc: 0.5223
2624/9333 [=======>......................] - ETA: 17:35 - loss: 0.7210 - acc: 0.5225
2688/9333 [=======>......................] - ETA: 17:22 - loss: 0.7207 - acc: 0.5234
2752/9333 [=======>......................] - ETA: 17:09 - loss: 0.7207 - acc: 0.5214
2816/9333 [========>.....................] - ETA: 16:55 - loss: 0.7194 - acc: 0.5249
2880/9333 [========>.....................] - ETA: 16:44 - loss: 0.7189 - acc: 0.5257
2944/9333 [========>.....................] - ETA: 16:34 - loss: 0.7186 - acc: 0.5272
3008/9333 [========>.....................] - ETA: 16:23 - loss: 0.7172 - acc: 0.5289
3072/9333 [========>.....................] - ETA: 16:12 - loss: 0.7177 - acc: 0.5293
3136/9333 [=========>....................] - ETA: 16:00 - loss: 0.7171 - acc: 0.5297
3200/9333 [=========>....................] - ETA: 15:49 - loss: 0.7172 - acc: 0.5291
3264/9333 [=========>....................] - ETA: 15:38 - loss: 0.7186 - acc: 0.5267
3328/9333 [=========>....................] - ETA: 15:27 - loss: 0.7194 - acc: 0.5246
3392/9333 [=========>....................] - ETA: 15:15 - loss: 0.7194 - acc: 0.5248
3456/9333 [==========>...................] - ETA: 15:03 - loss: 0.7190 - acc: 0.5243
3520/9333 [==========>...................] - ETA: 14:50 - loss: 0.7197 - acc: 0.5233
3584/9333 [==========>...................] - ETA: 14:37 - loss: 0.7196 - acc: 0.5234
3648/9333 [==========>...................] - ETA: 14:24 - loss: 0.7191 - acc: 0.5249
3712/9333 [==========>...................] - ETA: 14:13 - loss: 0.7186 - acc: 0.5248
3776/9333 [===========>..................] - ETA: 14:00 - loss: 0.7181 - acc: 0.5267
3840/9333 [===========>..................] - ETA: 13:48 - loss: 0.7184 - acc: 0.5247
3904/9333 [===========>..................] - ETA: 13:36 - loss: 0.7181 - acc: 0.5236
3968/9333 [===========>..................] - ETA: 13:23 - loss: 0.7174 - acc: 0.5252
4032/9333 [===========>..................] - ETA: 13:12 - loss: 0.7181 - acc: 0.5228
4096/9333 [============>.................] - ETA: 13:00 - loss: 0.7175 - acc: 0.5229
4160/9333 [============>.................] - ETA: 12:49 - loss: 0.7176 - acc: 0.5219
4224/9333 [============>.................] - ETA: 12:37 - loss: 0.7175 - acc: 0.5230
4288/9333 [============>.................] - ETA: 12:26 - loss: 0.7173 - acc: 0.5229
4352/9333 [============>.................] - ETA: 12:15 - loss: 0.7175 - acc: 0.5221
4416/9333 [=============>................] - ETA: 12:04 - loss: 0.7173 - acc: 0.5217
4480/9333 [=============>................] - ETA: 11:53 - loss: 0.7165 - acc: 0.5230
4544/9333 [=============>................] - ETA: 11:41 - loss: 0.7159 - acc: 0.5235
4608/9333 [=============>................] - ETA: 11:30 - loss: 0.7150 - acc: 0.5252
4672/9333 [==============>...............] - ETA: 11:20 - loss: 0.7146 - acc: 0.5250
4736/9333 [==============>...............] - ETA: 11:09 - loss: 0.7143 - acc: 0.5253
4800/9333 [==============>...............] - ETA: 10:58 - loss: 0.7146 - acc: 0.5246
4864/9333 [==============>...............] - ETA: 10:47 - loss: 0.7141 - acc: 0.5255
4928/9333 [==============>...............] - ETA: 10:37 - loss: 0.7142 - acc: 0.5254
4992/9333 [===============>..............] - ETA: 10:27 - loss: 0.7144 - acc: 0.5240
5056/9333 [===============>..............] - ETA: 10:17 - loss: 0.7139 - acc: 0.5241
5120/9333 [===============>..............] - ETA: 10:06 - loss: 0.7133 - acc: 0.5250
5184/9333 [===============>..............] - ETA: 9:56 - loss: 0.7128 - acc: 0.5260 
5248/9333 [===============>..............] - ETA: 9:46 - loss: 0.7120 - acc: 0.5271
5312/9333 [================>.............] - ETA: 9:35 - loss: 0.7128 - acc: 0.5258
5376/9333 [================>.............] - ETA: 9:25 - loss: 0.7128 - acc: 0.5257
5440/9333 [================>.............] - ETA: 9:15 - loss: 0.7124 - acc: 0.5261
5504/9333 [================>.............] - ETA: 9:05 - loss: 0.7121 - acc: 0.5267
5568/9333 [================>.............] - ETA: 8:56 - loss: 0.7123 - acc: 0.5260
5632/9333 [=================>............] - ETA: 8:47 - loss: 0.7123 - acc: 0.5252
5696/9333 [=================>............] - ETA: 8:37 - loss: 0.7119 - acc: 0.5260
5760/9333 [=================>............] - ETA: 8:28 - loss: 0.7123 - acc: 0.5248
5824/9333 [=================>............] - ETA: 8:18 - loss: 0.7123 - acc: 0.5247
5888/9333 [=================>............] - ETA: 8:09 - loss: 0.7126 - acc: 0.5243
5952/9333 [==================>...........] - ETA: 7:59 - loss: 0.7126 - acc: 0.5240
6016/9333 [==================>...........] - ETA: 7:50 - loss: 0.7123 - acc: 0.5246
6080/9333 [==================>...........] - ETA: 7:40 - loss: 0.7115 - acc: 0.5260
6144/9333 [==================>...........] - ETA: 7:31 - loss: 0.7113 - acc: 0.5262
6208/9333 [==================>...........] - ETA: 7:21 - loss: 0.7111 - acc: 0.5264
6272/9333 [===================>..........] - ETA: 7:12 - loss: 0.7114 - acc: 0.5254
6336/9333 [===================>..........] - ETA: 7:03 - loss: 0.7111 - acc: 0.5253
6400/9333 [===================>..........] - ETA: 6:54 - loss: 0.7113 - acc: 0.5241
6464/9333 [===================>..........] - ETA: 6:44 - loss: 0.7111 - acc: 0.5243
6528/9333 [===================>..........] - ETA: 6:35 - loss: 0.7110 - acc: 0.5242
6592/9333 [====================>.........] - ETA: 6:26 - loss: 0.7109 - acc: 0.5247
6656/9333 [====================>.........] - ETA: 6:16 - loss: 0.7107 - acc: 0.5251
6720/9333 [====================>.........] - ETA: 6:08 - loss: 0.7108 - acc: 0.5238
6784/9333 [====================>.........] - ETA: 5:59 - loss: 0.7105 - acc: 0.5240
6848/9333 [=====================>........] - ETA: 5:50 - loss: 0.7104 - acc: 0.5244
6912/9333 [=====================>........] - ETA: 5:40 - loss: 0.7100 - acc: 0.5246
6976/9333 [=====================>........] - ETA: 5:31 - loss: 0.7098 - acc: 0.5244
7040/9333 [=====================>........] - ETA: 5:22 - loss: 0.7094 - acc: 0.5249
7104/9333 [=====================>........] - ETA: 5:13 - loss: 0.7094 - acc: 0.5253
7168/9333 [======================>.......] - ETA: 5:04 - loss: 0.7094 - acc: 0.5250
7232/9333 [======================>.......] - ETA: 4:55 - loss: 0.7094 - acc: 0.5248
7296/9333 [======================>.......] - ETA: 4:45 - loss: 0.7094 - acc: 0.5252
7360/9333 [======================>.......] - ETA: 4:36 - loss: 0.7091 - acc: 0.5253
7424/9333 [======================>.......] - ETA: 4:27 - loss: 0.7086 - acc: 0.5263
7488/9333 [=======================>......] - ETA: 4:18 - loss: 0.7084 - acc: 0.5262
7552/9333 [=======================>......] - ETA: 4:09 - loss: 0.7082 - acc: 0.5266
7616/9333 [=======================>......] - ETA: 4:00 - loss: 0.7082 - acc: 0.5270
7680/9333 [=======================>......] - ETA: 3:51 - loss: 0.7082 - acc: 0.5277
7744/9333 [=======================>......] - ETA: 3:42 - loss: 0.7079 - acc: 0.5278
7808/9333 [========================>.....] - ETA: 3:32 - loss: 0.7078 - acc: 0.5277
7872/9333 [========================>.....] - ETA: 3:23 - loss: 0.7078 - acc: 0.5279
7936/9333 [========================>.....] - ETA: 3:14 - loss: 0.7073 - acc: 0.5286
8000/9333 [========================>.....] - ETA: 3:05 - loss: 0.7072 - acc: 0.5284
8064/9333 [========================>.....] - ETA: 2:56 - loss: 0.7072 - acc: 0.5281
8128/9333 [=========================>....] - ETA: 2:47 - loss: 0.7068 - acc: 0.5290
8192/9333 [=========================>....] - ETA: 2:38 - loss: 0.7068 - acc: 0.5288
8256/9333 [=========================>....] - ETA: 2:29 - loss: 0.7071 - acc: 0.5283
8320/9333 [=========================>....] - ETA: 2:20 - loss: 0.7071 - acc: 0.5285
8384/9333 [=========================>....] - ETA: 2:11 - loss: 0.7070 - acc: 0.5286
8448/9333 [==========================>...] - ETA: 2:02 - loss: 0.7070 - acc: 0.5284
8512/9333 [==========================>...] - ETA: 1:53 - loss: 0.7071 - acc: 0.5280
8576/9333 [==========================>...] - ETA: 1:44 - loss: 0.7072 - acc: 0.5274
8640/9333 [==========================>...] - ETA: 1:36 - loss: 0.7071 - acc: 0.5274
8704/9333 [==========================>...] - ETA: 1:27 - loss: 0.7069 - acc: 0.5279
8768/9333 [===========================>..] - ETA: 1:18 - loss: 0.7069 - acc: 0.5276
8832/9333 [===========================>..] - ETA: 1:09 - loss: 0.7069 - acc: 0.5274
8896/9333 [===========================>..] - ETA: 1:00 - loss: 0.7066 - acc: 0.5279
8960/9333 [===========================>..] - ETA: 51s - loss: 0.7065 - acc: 0.5282 
9024/9333 [============================>.] - ETA: 42s - loss: 0.7067 - acc: 0.5277
9088/9333 [============================>.] - ETA: 33s - loss: 0.7066 - acc: 0.5278
9152/9333 [============================>.] - ETA: 25s - loss: 0.7064 - acc: 0.5283
9216/9333 [============================>.] - ETA: 16s - loss: 0.7063 - acc: 0.5284
9280/9333 [============================>.] - ETA: 7s - loss: 0.7059 - acc: 0.5295 
9333/9333 [==============================] - 1347s 144ms/step - loss: 0.7063 - acc: 0.5292 - val_loss: 0.6909 - val_acc: 0.5130

Epoch 00001: val_acc improved from -inf to 0.51302, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window10/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 21:50 - loss: 0.7016 - acc: 0.5781
 128/9333 [..............................] - ETA: 21:35 - loss: 0.7075 - acc: 0.5547
 192/9333 [..............................] - ETA: 20:36 - loss: 0.7024 - acc: 0.5573
 256/9333 [..............................] - ETA: 20:22 - loss: 0.6979 - acc: 0.5664
 320/9333 [>.............................] - ETA: 19:58 - loss: 0.7018 - acc: 0.5500
 384/9333 [>.............................] - ETA: 19:30 - loss: 0.7001 - acc: 0.5443
 448/9333 [>.............................] - ETA: 19:19 - loss: 0.6982 - acc: 0.5469
 512/9333 [>.............................] - ETA: 19:45 - loss: 0.6976 - acc: 0.5430
 576/9333 [>.............................] - ETA: 19:31 - loss: 0.6944 - acc: 0.5486
 640/9333 [=>............................] - ETA: 19:24 - loss: 0.6936 - acc: 0.5500
 704/9333 [=>............................] - ETA: 19:36 - loss: 0.6915 - acc: 0.5526
 768/9333 [=>............................] - ETA: 19:22 - loss: 0.6882 - acc: 0.5599
 832/9333 [=>............................] - ETA: 19:17 - loss: 0.6905 - acc: 0.5601
 896/9333 [=>............................] - ETA: 19:08 - loss: 0.6904 - acc: 0.5558
 960/9333 [==>...........................] - ETA: 19:00 - loss: 0.6920 - acc: 0.5521
1024/9333 [==>...........................] - ETA: 18:52 - loss: 0.6937 - acc: 0.5479
1088/9333 [==>...........................] - ETA: 18:46 - loss: 0.6957 - acc: 0.5432
1152/9333 [==>...........................] - ETA: 18:36 - loss: 0.6964 - acc: 0.5399
1216/9333 [==>...........................] - ETA: 18:22 - loss: 0.6974 - acc: 0.5387
1280/9333 [===>..........................] - ETA: 18:06 - loss: 0.6969 - acc: 0.5375
1344/9333 [===>..........................] - ETA: 17:51 - loss: 0.6978 - acc: 0.5387
1408/9333 [===>..........................] - ETA: 17:41 - loss: 0.7006 - acc: 0.5291
1472/9333 [===>..........................] - ETA: 17:27 - loss: 0.7006 - acc: 0.5272
1536/9333 [===>..........................] - ETA: 17:11 - loss: 0.6992 - acc: 0.5286
1600/9333 [====>.........................] - ETA: 16:58 - loss: 0.7003 - acc: 0.5262
1664/9333 [====>.........................] - ETA: 16:44 - loss: 0.6997 - acc: 0.5300
1728/9333 [====>.........................] - ETA: 16:30 - loss: 0.7006 - acc: 0.5260
1792/9333 [====>.........................] - ETA: 16:16 - loss: 0.7002 - acc: 0.5262
1856/9333 [====>.........................] - ETA: 16:07 - loss: 0.7000 - acc: 0.5269
1920/9333 [=====>........................] - ETA: 15:55 - loss: 0.6998 - acc: 0.5276
1984/9333 [=====>........................] - ETA: 15:42 - loss: 0.6992 - acc: 0.5292
2048/9333 [=====>........................] - ETA: 15:32 - loss: 0.6990 - acc: 0.5298
2112/9333 [=====>........................] - ETA: 15:23 - loss: 0.6981 - acc: 0.5322
2176/9333 [=====>........................] - ETA: 15:10 - loss: 0.6970 - acc: 0.5340
2240/9333 [======>.......................] - ETA: 14:58 - loss: 0.6967 - acc: 0.5371
2304/9333 [======>.......................] - ETA: 14:49 - loss: 0.6954 - acc: 0.5395
2368/9333 [======>.......................] - ETA: 14:38 - loss: 0.6954 - acc: 0.5405
2432/9333 [======>.......................] - ETA: 14:28 - loss: 0.6950 - acc: 0.5407
2496/9333 [=======>......................] - ETA: 14:18 - loss: 0.6959 - acc: 0.5389
2560/9333 [=======>......................] - ETA: 14:08 - loss: 0.6953 - acc: 0.5395
2624/9333 [=======>......................] - ETA: 13:57 - loss: 0.6952 - acc: 0.5389
2688/9333 [=======>......................] - ETA: 13:49 - loss: 0.6949 - acc: 0.5391
2752/9333 [=======>......................] - ETA: 13:41 - loss: 0.6950 - acc: 0.5392
2816/9333 [========>.....................] - ETA: 13:32 - loss: 0.6953 - acc: 0.5394
2880/9333 [========>.....................] - ETA: 13:22 - loss: 0.6951 - acc: 0.5403
2944/9333 [========>.....................] - ETA: 13:14 - loss: 0.6954 - acc: 0.5377
3008/9333 [========>.....................] - ETA: 13:06 - loss: 0.6952 - acc: 0.5376
3072/9333 [========>.....................] - ETA: 12:57 - loss: 0.6957 - acc: 0.5361
3136/9333 [=========>....................] - ETA: 12:48 - loss: 0.6954 - acc: 0.5379
3200/9333 [=========>....................] - ETA: 12:39 - loss: 0.6962 - acc: 0.5347
3264/9333 [=========>....................] - ETA: 12:33 - loss: 0.6959 - acc: 0.5349
3328/9333 [=========>....................] - ETA: 12:24 - loss: 0.6952 - acc: 0.5364
3392/9333 [=========>....................] - ETA: 12:17 - loss: 0.6958 - acc: 0.5351
3456/9333 [==========>...................] - ETA: 12:09 - loss: 0.6953 - acc: 0.5365
3520/9333 [==========>...................] - ETA: 12:02 - loss: 0.6957 - acc: 0.5344
3584/9333 [==========>...................] - ETA: 11:54 - loss: 0.6955 - acc: 0.5340
3648/9333 [==========>...................] - ETA: 11:46 - loss: 0.6957 - acc: 0.5318
3712/9333 [==========>...................] - ETA: 11:37 - loss: 0.6952 - acc: 0.5342
3776/9333 [===========>..................] - ETA: 11:29 - loss: 0.6949 - acc: 0.5352
3840/9333 [===========>..................] - ETA: 11:20 - loss: 0.6949 - acc: 0.5357
3904/9333 [===========>..................] - ETA: 11:11 - loss: 0.6952 - acc: 0.5341
3968/9333 [===========>..................] - ETA: 11:02 - loss: 0.6948 - acc: 0.5358
4032/9333 [===========>..................] - ETA: 10:53 - loss: 0.6951 - acc: 0.5350
4096/9333 [============>.................] - ETA: 10:44 - loss: 0.6956 - acc: 0.5334
4160/9333 [============>.................] - ETA: 10:34 - loss: 0.6957 - acc: 0.5322
4224/9333 [============>.................] - ETA: 10:25 - loss: 0.6954 - acc: 0.5324
4288/9333 [============>.................] - ETA: 10:15 - loss: 0.6955 - acc: 0.5326
4352/9333 [============>.................] - ETA: 10:07 - loss: 0.6957 - acc: 0.5324
4416/9333 [=============>................] - ETA: 9:58 - loss: 0.6958 - acc: 0.5315 
4480/9333 [=============>................] - ETA: 9:49 - loss: 0.6948 - acc: 0.5337
4544/9333 [=============>................] - ETA: 9:41 - loss: 0.6947 - acc: 0.5330
4608/9333 [=============>................] - ETA: 9:32 - loss: 0.6947 - acc: 0.5339
4672/9333 [==============>...............] - ETA: 9:23 - loss: 0.6950 - acc: 0.5330
4736/9333 [==============>...............] - ETA: 9:14 - loss: 0.6943 - acc: 0.5351
4800/9333 [==============>...............] - ETA: 9:06 - loss: 0.6947 - acc: 0.5354
4864/9333 [==============>...............] - ETA: 8:58 - loss: 0.6943 - acc: 0.5366
4928/9333 [==============>...............] - ETA: 8:49 - loss: 0.6948 - acc: 0.5357
4992/9333 [===============>..............] - ETA: 8:41 - loss: 0.6949 - acc: 0.5353
5056/9333 [===============>..............] - ETA: 8:32 - loss: 0.6945 - acc: 0.5364
5120/9333 [===============>..............] - ETA: 8:24 - loss: 0.6943 - acc: 0.5361
5184/9333 [===============>..............] - ETA: 8:16 - loss: 0.6947 - acc: 0.5355
5248/9333 [===============>..............] - ETA: 8:08 - loss: 0.6949 - acc: 0.5351
5312/9333 [================>.............] - ETA: 7:59 - loss: 0.6947 - acc: 0.5358
5376/9333 [================>.............] - ETA: 7:51 - loss: 0.6947 - acc: 0.5352
5440/9333 [================>.............] - ETA: 7:43 - loss: 0.6948 - acc: 0.5351
5504/9333 [================>.............] - ETA: 7:35 - loss: 0.6947 - acc: 0.5352
5568/9333 [================>.............] - ETA: 7:26 - loss: 0.6946 - acc: 0.5350
5632/9333 [=================>............] - ETA: 7:18 - loss: 0.6948 - acc: 0.5344
5696/9333 [=================>............] - ETA: 7:10 - loss: 0.6946 - acc: 0.5344
5760/9333 [=================>............] - ETA: 7:02 - loss: 0.6945 - acc: 0.5347
5824/9333 [=================>............] - ETA: 6:54 - loss: 0.6945 - acc: 0.5350
5888/9333 [=================>............] - ETA: 6:46 - loss: 0.6949 - acc: 0.5345
5952/9333 [==================>...........] - ETA: 6:38 - loss: 0.6950 - acc: 0.5343
6016/9333 [==================>...........] - ETA: 6:30 - loss: 0.6949 - acc: 0.5349
6080/9333 [==================>...........] - ETA: 6:22 - loss: 0.6954 - acc: 0.5337
6144/9333 [==================>...........] - ETA: 6:15 - loss: 0.6952 - acc: 0.5342
6208/9333 [==================>...........] - ETA: 6:08 - loss: 0.6952 - acc: 0.5333
6272/9333 [===================>..........] - ETA: 6:00 - loss: 0.6955 - acc: 0.5325
6336/9333 [===================>..........] - ETA: 5:53 - loss: 0.6954 - acc: 0.5336
6400/9333 [===================>..........] - ETA: 5:45 - loss: 0.6954 - acc: 0.5333
6464/9333 [===================>..........] - ETA: 5:37 - loss: 0.6952 - acc: 0.5339
6528/9333 [===================>..........] - ETA: 5:30 - loss: 0.6953 - acc: 0.5334
6592/9333 [====================>.........] - ETA: 5:23 - loss: 0.6951 - acc: 0.5340
6656/9333 [====================>.........] - ETA: 5:15 - loss: 0.6957 - acc: 0.5322
6720/9333 [====================>.........] - ETA: 5:08 - loss: 0.6952 - acc: 0.5339
6784/9333 [====================>.........] - ETA: 5:00 - loss: 0.6949 - acc: 0.5348
6848/9333 [=====================>........] - ETA: 4:53 - loss: 0.6949 - acc: 0.5349
6912/9333 [=====================>........] - ETA: 4:45 - loss: 0.6947 - acc: 0.5349
6976/9333 [=====================>........] - ETA: 4:38 - loss: 0.6945 - acc: 0.5353
7040/9333 [=====================>........] - ETA: 4:30 - loss: 0.6944 - acc: 0.5355
7104/9333 [=====================>........] - ETA: 4:22 - loss: 0.6944 - acc: 0.5355
7168/9333 [======================>.......] - ETA: 4:15 - loss: 0.6942 - acc: 0.5357
7232/9333 [======================>.......] - ETA: 4:07 - loss: 0.6942 - acc: 0.5360
7296/9333 [======================>.......] - ETA: 4:00 - loss: 0.6943 - acc: 0.5352
7360/9333 [======================>.......] - ETA: 3:52 - loss: 0.6950 - acc: 0.5342
7424/9333 [======================>.......] - ETA: 3:45 - loss: 0.6950 - acc: 0.5341
7488/9333 [=======================>......] - ETA: 3:37 - loss: 0.6952 - acc: 0.5337
7552/9333 [=======================>......] - ETA: 3:29 - loss: 0.6954 - acc: 0.5328
7616/9333 [=======================>......] - ETA: 3:22 - loss: 0.6952 - acc: 0.5339
7680/9333 [=======================>......] - ETA: 3:14 - loss: 0.6952 - acc: 0.5336
7744/9333 [=======================>......] - ETA: 3:07 - loss: 0.6952 - acc: 0.5332
7808/9333 [========================>.....] - ETA: 2:59 - loss: 0.6951 - acc: 0.5336
7872/9333 [========================>.....] - ETA: 2:52 - loss: 0.6952 - acc: 0.5330
7936/9333 [========================>.....] - ETA: 2:44 - loss: 0.6951 - acc: 0.5329
8000/9333 [========================>.....] - ETA: 2:37 - loss: 0.6952 - acc: 0.5331
8064/9333 [========================>.....] - ETA: 2:29 - loss: 0.6950 - acc: 0.5334
8128/9333 [=========================>....] - ETA: 2:21 - loss: 0.6950 - acc: 0.5337
8192/9333 [=========================>....] - ETA: 2:14 - loss: 0.6948 - acc: 0.5342
8256/9333 [=========================>....] - ETA: 2:06 - loss: 0.6948 - acc: 0.5340
8320/9333 [=========================>....] - ETA: 1:59 - loss: 0.6949 - acc: 0.5338
8384/9333 [=========================>....] - ETA: 1:52 - loss: 0.6948 - acc: 0.5338
8448/9333 [==========================>...] - ETA: 1:44 - loss: 0.6949 - acc: 0.5339
8512/9333 [==========================>...] - ETA: 1:36 - loss: 0.6950 - acc: 0.5332
8576/9333 [==========================>...] - ETA: 1:29 - loss: 0.6951 - acc: 0.5331
8640/9333 [==========================>...] - ETA: 1:21 - loss: 0.6948 - acc: 0.5339
8704/9333 [==========================>...] - ETA: 1:14 - loss: 0.6946 - acc: 0.5345
8768/9333 [===========================>..] - ETA: 1:06 - loss: 0.6944 - acc: 0.5350
8832/9333 [===========================>..] - ETA: 59s - loss: 0.6947 - acc: 0.5342 
8896/9333 [===========================>..] - ETA: 51s - loss: 0.6947 - acc: 0.5344
8960/9333 [===========================>..] - ETA: 44s - loss: 0.6948 - acc: 0.5342
9024/9333 [============================>.] - ETA: 36s - loss: 0.6950 - acc: 0.5337
9088/9333 [============================>.] - ETA: 28s - loss: 0.6948 - acc: 0.5343
9152/9333 [============================>.] - ETA: 21s - loss: 0.6947 - acc: 0.5349
9216/9333 [============================>.] - ETA: 13s - loss: 0.6948 - acc: 0.5347
9280/9333 [============================>.] - ETA: 6s - loss: 0.6948 - acc: 0.5347 
9333/9333 [==============================] - 1144s 123ms/step - loss: 0.6949 - acc: 0.5347 - val_loss: 0.6901 - val_acc: 0.5284

Epoch 00002: val_acc improved from 0.51302 to 0.52845, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window10/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 3/10

  64/9333 [..............................] - ETA: 21:56 - loss: 0.6836 - acc: 0.5781
 128/9333 [..............................] - ETA: 19:51 - loss: 0.6778 - acc: 0.5859
 192/9333 [..............................] - ETA: 18:42 - loss: 0.6865 - acc: 0.5469
 256/9333 [..............................] - ETA: 18:19 - loss: 0.6871 - acc: 0.5352
 320/9333 [>.............................] - ETA: 18:00 - loss: 0.6831 - acc: 0.5500
 384/9333 [>.............................] - ETA: 17:40 - loss: 0.6867 - acc: 0.5495
 448/9333 [>.............................] - ETA: 17:36 - loss: 0.6927 - acc: 0.5335
 512/9333 [>.............................] - ETA: 17:41 - loss: 0.6887 - acc: 0.5410
 576/9333 [>.............................] - ETA: 17:31 - loss: 0.6914 - acc: 0.5295
 640/9333 [=>............................] - ETA: 17:24 - loss: 0.6919 - acc: 0.5312
 704/9333 [=>............................] - ETA: 17:18 - loss: 0.6909 - acc: 0.5398
 768/9333 [=>............................] - ETA: 17:11 - loss: 0.6899 - acc: 0.5404
 832/9333 [=>............................] - ETA: 16:57 - loss: 0.6907 - acc: 0.5361
 896/9333 [=>............................] - ETA: 16:44 - loss: 0.6908 - acc: 0.5402
 960/9333 [==>...........................] - ETA: 16:30 - loss: 0.6880 - acc: 0.5479
1024/9333 [==>...........................] - ETA: 16:29 - loss: 0.6881 - acc: 0.5479
1088/9333 [==>...........................] - ETA: 16:15 - loss: 0.6873 - acc: 0.5496
1152/9333 [==>...........................] - ETA: 16:06 - loss: 0.6869 - acc: 0.5521
1216/9333 [==>...........................] - ETA: 16:05 - loss: 0.6877 - acc: 0.5485
1280/9333 [===>..........................] - ETA: 15:59 - loss: 0.6881 - acc: 0.5500
1344/9333 [===>..........................] - ETA: 15:53 - loss: 0.6880 - acc: 0.5476
1408/9333 [===>..........................] - ETA: 15:48 - loss: 0.6865 - acc: 0.5483
1472/9333 [===>..........................] - ETA: 15:42 - loss: 0.6868 - acc: 0.5482
1536/9333 [===>..........................] - ETA: 15:30 - loss: 0.6849 - acc: 0.5540
1600/9333 [====>.........................] - ETA: 15:19 - loss: 0.6870 - acc: 0.5494
1664/9333 [====>.........................] - ETA: 15:13 - loss: 0.6872 - acc: 0.5469
1728/9333 [====>.........................] - ETA: 15:01 - loss: 0.6870 - acc: 0.5480
1792/9333 [====>.........................] - ETA: 14:50 - loss: 0.6875 - acc: 0.5469
1856/9333 [====>.........................] - ETA: 14:41 - loss: 0.6884 - acc: 0.5458
1920/9333 [=====>........................] - ETA: 14:39 - loss: 0.6885 - acc: 0.5443
1984/9333 [=====>........................] - ETA: 14:33 - loss: 0.6885 - acc: 0.5449
2048/9333 [=====>........................] - ETA: 14:25 - loss: 0.6880 - acc: 0.5464
2112/9333 [=====>........................] - ETA: 14:18 - loss: 0.6876 - acc: 0.5464
2176/9333 [=====>........................] - ETA: 14:09 - loss: 0.6872 - acc: 0.5464
2240/9333 [======>.......................] - ETA: 14:02 - loss: 0.6878 - acc: 0.5451
2304/9333 [======>.......................] - ETA: 13:56 - loss: 0.6876 - acc: 0.5460
2368/9333 [======>.......................] - ETA: 13:53 - loss: 0.6877 - acc: 0.5460
2432/9333 [======>.......................] - ETA: 13:47 - loss: 0.6883 - acc: 0.5444
2496/9333 [=======>......................] - ETA: 13:41 - loss: 0.6880 - acc: 0.5449
2560/9333 [=======>......................] - ETA: 13:35 - loss: 0.6874 - acc: 0.5453
2624/9333 [=======>......................] - ETA: 13:30 - loss: 0.6862 - acc: 0.5488
2688/9333 [=======>......................] - ETA: 13:23 - loss: 0.6867 - acc: 0.5480
2752/9333 [=======>......................] - ETA: 13:16 - loss: 0.6866 - acc: 0.5491
2816/9333 [========>.....................] - ETA: 13:09 - loss: 0.6870 - acc: 0.5490
2880/9333 [========>.....................] - ETA: 13:01 - loss: 0.6867 - acc: 0.5486
2944/9333 [========>.....................] - ETA: 12:53 - loss: 0.6872 - acc: 0.5472
3008/9333 [========>.....................] - ETA: 12:45 - loss: 0.6866 - acc: 0.5485
3072/9333 [========>.....................] - ETA: 12:39 - loss: 0.6866 - acc: 0.5479
3136/9333 [=========>....................] - ETA: 12:32 - loss: 0.6862 - acc: 0.5497
3200/9333 [=========>....................] - ETA: 12:24 - loss: 0.6863 - acc: 0.5500
3264/9333 [=========>....................] - ETA: 12:15 - loss: 0.6868 - acc: 0.5484
3328/9333 [=========>....................] - ETA: 12:07 - loss: 0.6868 - acc: 0.5496
3392/9333 [=========>....................] - ETA: 11:59 - loss: 0.6865 - acc: 0.5516
3456/9333 [==========>...................] - ETA: 11:52 - loss: 0.6860 - acc: 0.5530
3520/9333 [==========>...................] - ETA: 11:44 - loss: 0.6853 - acc: 0.5551
3584/9333 [==========>...................] - ETA: 11:36 - loss: 0.6854 - acc: 0.5547
3648/9333 [==========>...................] - ETA: 11:27 - loss: 0.6853 - acc: 0.5540
3712/9333 [==========>...................] - ETA: 11:19 - loss: 0.6852 - acc: 0.5536
3776/9333 [===========>..................] - ETA: 11:10 - loss: 0.6856 - acc: 0.5532
3840/9333 [===========>..................] - ETA: 11:01 - loss: 0.6852 - acc: 0.5534
3904/9333 [===========>..................] - ETA: 10:52 - loss: 0.6854 - acc: 0.5520
3968/9333 [===========>..................] - ETA: 10:43 - loss: 0.6854 - acc: 0.5522
4032/9333 [===========>..................] - ETA: 10:36 - loss: 0.6856 - acc: 0.5516
4096/9333 [============>.................] - ETA: 10:27 - loss: 0.6859 - acc: 0.5510
4160/9333 [============>.................] - ETA: 10:20 - loss: 0.6860 - acc: 0.5507
4224/9333 [============>.................] - ETA: 10:12 - loss: 0.6861 - acc: 0.5504
4288/9333 [============>.................] - ETA: 10:05 - loss: 0.6860 - acc: 0.5499
4352/9333 [============>.................] - ETA: 9:57 - loss: 0.6861 - acc: 0.5499 
4416/9333 [=============>................] - ETA: 9:49 - loss: 0.6864 - acc: 0.5489
4480/9333 [=============>................] - ETA: 9:40 - loss: 0.6863 - acc: 0.5498
4544/9333 [=============>................] - ETA: 9:32 - loss: 0.6862 - acc: 0.5500
4608/9333 [=============>................] - ETA: 9:24 - loss: 0.6867 - acc: 0.5486
4672/9333 [==============>...............] - ETA: 9:16 - loss: 0.6867 - acc: 0.5486
4736/9333 [==============>...............] - ETA: 9:08 - loss: 0.6863 - acc: 0.5496
4800/9333 [==============>...............] - ETA: 9:02 - loss: 0.6860 - acc: 0.5515
4864/9333 [==============>...............] - ETA: 8:54 - loss: 0.6860 - acc: 0.5518
4928/9333 [==============>...............] - ETA: 8:46 - loss: 0.6860 - acc: 0.5524
4992/9333 [===============>..............] - ETA: 8:39 - loss: 0.6860 - acc: 0.5525
5056/9333 [===============>..............] - ETA: 8:31 - loss: 0.6862 - acc: 0.5522
5120/9333 [===============>..............] - ETA: 8:22 - loss: 0.6860 - acc: 0.5531
5184/9333 [===============>..............] - ETA: 8:14 - loss: 0.6858 - acc: 0.5529
5248/9333 [===============>..............] - ETA: 8:06 - loss: 0.6855 - acc: 0.5537
5312/9333 [================>.............] - ETA: 7:58 - loss: 0.6865 - acc: 0.5514
5376/9333 [================>.............] - ETA: 7:51 - loss: 0.6864 - acc: 0.5521
5440/9333 [================>.............] - ETA: 7:43 - loss: 0.6866 - acc: 0.5517
5504/9333 [================>.............] - ETA: 7:36 - loss: 0.6863 - acc: 0.5529
5568/9333 [================>.............] - ETA: 7:29 - loss: 0.6861 - acc: 0.5535
5632/9333 [=================>............] - ETA: 7:21 - loss: 0.6859 - acc: 0.5538
5696/9333 [=================>............] - ETA: 7:13 - loss: 0.6859 - acc: 0.5537
5760/9333 [=================>............] - ETA: 7:06 - loss: 0.6856 - acc: 0.5552
5824/9333 [=================>............] - ETA: 6:59 - loss: 0.6856 - acc: 0.5551
5888/9333 [=================>............] - ETA: 6:51 - loss: 0.6859 - acc: 0.5550
5952/9333 [==================>...........] - ETA: 6:44 - loss: 0.6858 - acc: 0.5551
6016/9333 [==================>...........] - ETA: 6:36 - loss: 0.6857 - acc: 0.5555
6080/9333 [==================>...........] - ETA: 6:29 - loss: 0.6852 - acc: 0.5561
6144/9333 [==================>...........] - ETA: 6:21 - loss: 0.6858 - acc: 0.5547
6208/9333 [==================>...........] - ETA: 6:14 - loss: 0.6860 - acc: 0.5538
6272/9333 [===================>..........] - ETA: 6:06 - loss: 0.6864 - acc: 0.5533
6336/9333 [===================>..........] - ETA: 5:58 - loss: 0.6862 - acc: 0.5532
6400/9333 [===================>..........] - ETA: 5:51 - loss: 0.6864 - acc: 0.5528
6464/9333 [===================>..........] - ETA: 5:43 - loss: 0.6863 - acc: 0.5528
6528/9333 [===================>..........] - ETA: 5:35 - loss: 0.6864 - acc: 0.5521
6592/9333 [====================>.........] - ETA: 5:28 - loss: 0.6866 - acc: 0.5513
6656/9333 [====================>.........] - ETA: 5:20 - loss: 0.6868 - acc: 0.5502
6720/9333 [====================>.........] - ETA: 5:12 - loss: 0.6873 - acc: 0.5497
6784/9333 [====================>.........] - ETA: 5:05 - loss: 0.6875 - acc: 0.5495
6848/9333 [=====================>........] - ETA: 4:57 - loss: 0.6876 - acc: 0.5491
6912/9333 [=====================>........] - ETA: 4:50 - loss: 0.6875 - acc: 0.5493
6976/9333 [=====================>........] - ETA: 4:42 - loss: 0.6875 - acc: 0.5496
7040/9333 [=====================>........] - ETA: 4:34 - loss: 0.6877 - acc: 0.5489
7104/9333 [=====================>........] - ETA: 4:27 - loss: 0.6874 - acc: 0.5491
7168/9333 [======================>.......] - ETA: 4:19 - loss: 0.6877 - acc: 0.5484
7232/9333 [======================>.......] - ETA: 4:12 - loss: 0.6875 - acc: 0.5484
7296/9333 [======================>.......] - ETA: 4:04 - loss: 0.6875 - acc: 0.5482
7360/9333 [======================>.......] - ETA: 3:56 - loss: 0.6877 - acc: 0.5480
7424/9333 [======================>.......] - ETA: 3:49 - loss: 0.6878 - acc: 0.5471
7488/9333 [=======================>......] - ETA: 3:41 - loss: 0.6879 - acc: 0.5463
7552/9333 [=======================>......] - ETA: 3:33 - loss: 0.6878 - acc: 0.5467
7616/9333 [=======================>......] - ETA: 3:26 - loss: 0.6879 - acc: 0.5457
7680/9333 [=======================>......] - ETA: 3:18 - loss: 0.6880 - acc: 0.5458
7744/9333 [=======================>......] - ETA: 3:10 - loss: 0.6877 - acc: 0.5462
7808/9333 [========================>.....] - ETA: 3:02 - loss: 0.6877 - acc: 0.5462
7872/9333 [========================>.....] - ETA: 2:55 - loss: 0.6878 - acc: 0.5465
7936/9333 [========================>.....] - ETA: 2:47 - loss: 0.6879 - acc: 0.5461
8000/9333 [========================>.....] - ETA: 2:39 - loss: 0.6881 - acc: 0.5454
8064/9333 [========================>.....] - ETA: 2:32 - loss: 0.6884 - acc: 0.5454
8128/9333 [=========================>....] - ETA: 2:24 - loss: 0.6884 - acc: 0.5459
8192/9333 [=========================>....] - ETA: 2:17 - loss: 0.6883 - acc: 0.5457
8256/9333 [=========================>....] - ETA: 2:09 - loss: 0.6885 - acc: 0.5454
8320/9333 [=========================>....] - ETA: 2:01 - loss: 0.6884 - acc: 0.5457
8384/9333 [=========================>....] - ETA: 1:54 - loss: 0.6884 - acc: 0.5457
8448/9333 [==========================>...] - ETA: 1:46 - loss: 0.6881 - acc: 0.5469
8512/9333 [==========================>...] - ETA: 1:38 - loss: 0.6883 - acc: 0.5464
8576/9333 [==========================>...] - ETA: 1:30 - loss: 0.6880 - acc: 0.5470
8640/9333 [==========================>...] - ETA: 1:23 - loss: 0.6879 - acc: 0.5470
8704/9333 [==========================>...] - ETA: 1:15 - loss: 0.6878 - acc: 0.5470
8768/9333 [===========================>..] - ETA: 1:07 - loss: 0.6881 - acc: 0.5465
8832/9333 [===========================>..] - ETA: 1:00 - loss: 0.6880 - acc: 0.5465
8896/9333 [===========================>..] - ETA: 52s - loss: 0.6882 - acc: 0.5460 
8960/9333 [===========================>..] - ETA: 44s - loss: 0.6880 - acc: 0.5467
9024/9333 [============================>.] - ETA: 37s - loss: 0.6877 - acc: 0.5473
9088/9333 [============================>.] - ETA: 29s - loss: 0.6875 - acc: 0.5479
9152/9333 [============================>.] - ETA: 21s - loss: 0.6876 - acc: 0.5483
9216/9333 [============================>.] - ETA: 14s - loss: 0.6875 - acc: 0.5486
9280/9333 [============================>.] - ETA: 6s - loss: 0.6873 - acc: 0.5490 
9333/9333 [==============================] - 1163s 125ms/step - loss: 0.6873 - acc: 0.5491 - val_loss: 0.6890 - val_acc: 0.5381

Epoch 00003: val_acc improved from 0.52845 to 0.53809, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window10/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 4/10

  64/9333 [..............................] - ETA: 18:20 - loss: 0.7208 - acc: 0.4375
 128/9333 [..............................] - ETA: 19:00 - loss: 0.7016 - acc: 0.4688
 192/9333 [..............................] - ETA: 18:47 - loss: 0.6980 - acc: 0.4896
 256/9333 [..............................] - ETA: 18:02 - loss: 0.6974 - acc: 0.5117
 320/9333 [>.............................] - ETA: 17:28 - loss: 0.6857 - acc: 0.5375
 384/9333 [>.............................] - ETA: 17:03 - loss: 0.6800 - acc: 0.5469
 448/9333 [>.............................] - ETA: 16:56 - loss: 0.6825 - acc: 0.5469
 512/9333 [>.............................] - ETA: 16:40 - loss: 0.6791 - acc: 0.5488
 576/9333 [>.............................] - ETA: 16:27 - loss: 0.6816 - acc: 0.5469
 640/9333 [=>............................] - ETA: 16:19 - loss: 0.6840 - acc: 0.5437
 704/9333 [=>............................] - ETA: 16:06 - loss: 0.6844 - acc: 0.5412
 768/9333 [=>............................] - ETA: 15:52 - loss: 0.6864 - acc: 0.5443
 832/9333 [=>............................] - ETA: 15:50 - loss: 0.6860 - acc: 0.5433
 896/9333 [=>............................] - ETA: 15:40 - loss: 0.6843 - acc: 0.5491
 960/9333 [==>...........................] - ETA: 15:28 - loss: 0.6827 - acc: 0.5521
1024/9333 [==>...........................] - ETA: 15:18 - loss: 0.6819 - acc: 0.5557
1088/9333 [==>...........................] - ETA: 15:13 - loss: 0.6811 - acc: 0.5524
1152/9333 [==>...........................] - ETA: 15:03 - loss: 0.6834 - acc: 0.5486
1216/9333 [==>...........................] - ETA: 14:53 - loss: 0.6842 - acc: 0.5493
1280/9333 [===>..........................] - ETA: 14:44 - loss: 0.6845 - acc: 0.5484
1344/9333 [===>..........................] - ETA: 14:37 - loss: 0.6841 - acc: 0.5491
1408/9333 [===>..........................] - ETA: 14:27 - loss: 0.6823 - acc: 0.5540
1472/9333 [===>..........................] - ETA: 14:20 - loss: 0.6827 - acc: 0.5537
1536/9333 [===>..........................] - ETA: 14:11 - loss: 0.6826 - acc: 0.5521
1600/9333 [====>.........................] - ETA: 14:03 - loss: 0.6827 - acc: 0.5494
1664/9333 [====>.........................] - ETA: 14:02 - loss: 0.6830 - acc: 0.5493
1728/9333 [====>.........................] - ETA: 13:53 - loss: 0.6854 - acc: 0.5440
1792/9333 [====>.........................] - ETA: 13:44 - loss: 0.6863 - acc: 0.5435
1856/9333 [====>.........................] - ETA: 13:37 - loss: 0.6858 - acc: 0.5469
1920/9333 [=====>........................] - ETA: 13:29 - loss: 0.6855 - acc: 0.5479
1984/9333 [=====>........................] - ETA: 13:20 - loss: 0.6862 - acc: 0.5459
2048/9333 [=====>........................] - ETA: 13:12 - loss: 0.6852 - acc: 0.5479
2112/9333 [=====>........................] - ETA: 13:04 - loss: 0.6860 - acc: 0.5483
2176/9333 [=====>........................] - ETA: 12:55 - loss: 0.6858 - acc: 0.5496
2240/9333 [======>.......................] - ETA: 12:46 - loss: 0.6857 - acc: 0.5496
2304/9333 [======>.......................] - ETA: 12:41 - loss: 0.6858 - acc: 0.5499
2368/9333 [======>.......................] - ETA: 12:33 - loss: 0.6857 - acc: 0.5503
2432/9333 [======>.......................] - ETA: 12:25 - loss: 0.6849 - acc: 0.5522
2496/9333 [=======>......................] - ETA: 12:19 - loss: 0.6847 - acc: 0.5545
2560/9333 [=======>......................] - ETA: 12:11 - loss: 0.6847 - acc: 0.5539
2624/9333 [=======>......................] - ETA: 12:04 - loss: 0.6845 - acc: 0.5541
2688/9333 [=======>......................] - ETA: 11:57 - loss: 0.6849 - acc: 0.5532
2752/9333 [=======>......................] - ETA: 11:52 - loss: 0.6853 - acc: 0.5516
2816/9333 [========>.....................] - ETA: 11:44 - loss: 0.6852 - acc: 0.5501
2880/9333 [========>.....................] - ETA: 11:36 - loss: 0.6855 - acc: 0.5479
2944/9333 [========>.....................] - ETA: 11:29 - loss: 0.6855 - acc: 0.5486
3008/9333 [========>.....................] - ETA: 11:21 - loss: 0.6856 - acc: 0.5485
3072/9333 [========>.....................] - ETA: 11:14 - loss: 0.6859 - acc: 0.5482
3136/9333 [=========>....................] - ETA: 11:08 - loss: 0.6860 - acc: 0.5485
3200/9333 [=========>....................] - ETA: 11:01 - loss: 0.6866 - acc: 0.5475
3264/9333 [=========>....................] - ETA: 10:54 - loss: 0.6872 - acc: 0.5463
3328/9333 [=========>....................] - ETA: 10:46 - loss: 0.6867 - acc: 0.5484
3392/9333 [=========>....................] - ETA: 10:39 - loss: 0.6869 - acc: 0.5478
3456/9333 [==========>...................] - ETA: 10:32 - loss: 0.6869 - acc: 0.5477
3520/9333 [==========>...................] - ETA: 10:24 - loss: 0.6866 - acc: 0.5477
3584/9333 [==========>...................] - ETA: 10:17 - loss: 0.6866 - acc: 0.5477
3648/9333 [==========>...................] - ETA: 10:11 - loss: 0.6864 - acc: 0.5493
3712/9333 [==========>...................] - ETA: 10:03 - loss: 0.6869 - acc: 0.5480
3776/9333 [===========>..................] - ETA: 9:56 - loss: 0.6857 - acc: 0.5527 
3840/9333 [===========>..................] - ETA: 9:49 - loss: 0.6855 - acc: 0.5544
3904/9333 [===========>..................] - ETA: 9:43 - loss: 0.6856 - acc: 0.5535
3968/9333 [===========>..................] - ETA: 9:36 - loss: 0.6854 - acc: 0.5539
4032/9333 [===========>..................] - ETA: 9:29 - loss: 0.6852 - acc: 0.5541
4096/9333 [============>.................] - ETA: 9:23 - loss: 0.6853 - acc: 0.5547
4160/9333 [============>.................] - ETA: 9:16 - loss: 0.6849 - acc: 0.5570
4224/9333 [============>.................] - ETA: 9:09 - loss: 0.6851 - acc: 0.5561
4288/9333 [============>.................] - ETA: 9:02 - loss: 0.6849 - acc: 0.5569
4352/9333 [============>.................] - ETA: 8:55 - loss: 0.6846 - acc: 0.5572
4416/9333 [=============>................] - ETA: 8:48 - loss: 0.6852 - acc: 0.5553
4480/9333 [=============>................] - ETA: 8:41 - loss: 0.6850 - acc: 0.5554
4544/9333 [=============>................] - ETA: 8:34 - loss: 0.6847 - acc: 0.5570
4608/9333 [=============>................] - ETA: 8:27 - loss: 0.6847 - acc: 0.5575
4672/9333 [==============>...............] - ETA: 8:20 - loss: 0.6847 - acc: 0.5569
4736/9333 [==============>...............] - ETA: 8:12 - loss: 0.6844 - acc: 0.5570
4800/9333 [==============>...............] - ETA: 8:05 - loss: 0.6846 - acc: 0.5560
4864/9333 [==============>...............] - ETA: 7:59 - loss: 0.6848 - acc: 0.5555
4928/9333 [==============>...............] - ETA: 7:53 - loss: 0.6851 - acc: 0.5554
4992/9333 [===============>..............] - ETA: 7:46 - loss: 0.6852 - acc: 0.5549
5056/9333 [===============>..............] - ETA: 7:39 - loss: 0.6849 - acc: 0.5558
5120/9333 [===============>..............] - ETA: 7:32 - loss: 0.6850 - acc: 0.5557
5184/9333 [===============>..............] - ETA: 7:25 - loss: 0.6849 - acc: 0.5563
5248/9333 [===============>..............] - ETA: 7:18 - loss: 0.6847 - acc: 0.5570
5312/9333 [================>.............] - ETA: 7:12 - loss: 0.6849 - acc: 0.5570
5376/9333 [================>.............] - ETA: 7:05 - loss: 0.6851 - acc: 0.5560
5440/9333 [================>.............] - ETA: 6:58 - loss: 0.6846 - acc: 0.5568
5504/9333 [================>.............] - ETA: 6:51 - loss: 0.6844 - acc: 0.5563
5568/9333 [================>.............] - ETA: 6:44 - loss: 0.6844 - acc: 0.5560
5632/9333 [=================>............] - ETA: 6:37 - loss: 0.6847 - acc: 0.5558
5696/9333 [=================>............] - ETA: 6:31 - loss: 0.6848 - acc: 0.5551
5760/9333 [=================>............] - ETA: 6:24 - loss: 0.6846 - acc: 0.5554
5824/9333 [=================>............] - ETA: 6:17 - loss: 0.6838 - acc: 0.5575
5888/9333 [=================>............] - ETA: 6:10 - loss: 0.6837 - acc: 0.5576
5952/9333 [==================>...........] - ETA: 6:03 - loss: 0.6842 - acc: 0.5561
6016/9333 [==================>...........] - ETA: 5:57 - loss: 0.6842 - acc: 0.5567
6080/9333 [==================>...........] - ETA: 5:50 - loss: 0.6840 - acc: 0.5566
6144/9333 [==================>...........] - ETA: 5:43 - loss: 0.6840 - acc: 0.5570
6208/9333 [==================>...........] - ETA: 5:36 - loss: 0.6843 - acc: 0.5562
6272/9333 [===================>..........] - ETA: 5:29 - loss: 0.6843 - acc: 0.5558
6336/9333 [===================>..........] - ETA: 5:23 - loss: 0.6841 - acc: 0.5568
6400/9333 [===================>..........] - ETA: 5:17 - loss: 0.6842 - acc: 0.5566
6464/9333 [===================>..........] - ETA: 5:10 - loss: 0.6843 - acc: 0.5557
6528/9333 [===================>..........] - ETA: 5:03 - loss: 0.6846 - acc: 0.5550
6592/9333 [====================>.........] - ETA: 4:56 - loss: 0.6844 - acc: 0.5551
6656/9333 [====================>.........] - ETA: 4:49 - loss: 0.6843 - acc: 0.5550
6720/9333 [====================>.........] - ETA: 4:42 - loss: 0.6845 - acc: 0.5545
6784/9333 [====================>.........] - ETA: 4:35 - loss: 0.6846 - acc: 0.5542
6848/9333 [=====================>........] - ETA: 4:29 - loss: 0.6841 - acc: 0.5552
6912/9333 [=====================>........] - ETA: 4:22 - loss: 0.6839 - acc: 0.5560
6976/9333 [=====================>........] - ETA: 4:15 - loss: 0.6838 - acc: 0.5562
7040/9333 [=====================>........] - ETA: 4:08 - loss: 0.6838 - acc: 0.5563
7104/9333 [=====================>........] - ETA: 4:01 - loss: 0.6838 - acc: 0.5562
7168/9333 [======================>.......] - ETA: 3:54 - loss: 0.6840 - acc: 0.5562
7232/9333 [======================>.......] - ETA: 3:47 - loss: 0.6842 - acc: 0.5559
7296/9333 [======================>.......] - ETA: 3:40 - loss: 0.6840 - acc: 0.5566
7360/9333 [======================>.......] - ETA: 3:33 - loss: 0.6841 - acc: 0.5564
7424/9333 [======================>.......] - ETA: 3:27 - loss: 0.6845 - acc: 0.5558
7488/9333 [=======================>......] - ETA: 3:20 - loss: 0.6844 - acc: 0.5557
7552/9333 [=======================>......] - ETA: 3:13 - loss: 0.6845 - acc: 0.5553
7616/9333 [=======================>......] - ETA: 3:06 - loss: 0.6844 - acc: 0.5558
7680/9333 [=======================>......] - ETA: 2:59 - loss: 0.6840 - acc: 0.5568
7744/9333 [=======================>......] - ETA: 2:52 - loss: 0.6838 - acc: 0.5571
7808/9333 [========================>.....] - ETA: 2:45 - loss: 0.6838 - acc: 0.5570
7872/9333 [========================>.....] - ETA: 2:38 - loss: 0.6835 - acc: 0.5578
7936/9333 [========================>.....] - ETA: 2:32 - loss: 0.6832 - acc: 0.5581
8000/9333 [========================>.....] - ETA: 2:25 - loss: 0.6834 - acc: 0.5576
8064/9333 [========================>.....] - ETA: 2:18 - loss: 0.6835 - acc: 0.5578
8128/9333 [=========================>....] - ETA: 2:11 - loss: 0.6833 - acc: 0.5584
8192/9333 [=========================>....] - ETA: 2:04 - loss: 0.6833 - acc: 0.5586
8256/9333 [=========================>....] - ETA: 1:57 - loss: 0.6834 - acc: 0.5580
8320/9333 [=========================>....] - ETA: 1:50 - loss: 0.6836 - acc: 0.5579
8384/9333 [=========================>....] - ETA: 1:43 - loss: 0.6835 - acc: 0.5580
8448/9333 [==========================>...] - ETA: 1:36 - loss: 0.6834 - acc: 0.5584
8512/9333 [==========================>...] - ETA: 1:29 - loss: 0.6836 - acc: 0.5583
8576/9333 [==========================>...] - ETA: 1:22 - loss: 0.6835 - acc: 0.5584
8640/9333 [==========================>...] - ETA: 1:15 - loss: 0.6834 - acc: 0.5584
8704/9333 [==========================>...] - ETA: 1:08 - loss: 0.6832 - acc: 0.5589
8768/9333 [===========================>..] - ETA: 1:01 - loss: 0.6832 - acc: 0.5589
8832/9333 [===========================>..] - ETA: 54s - loss: 0.6833 - acc: 0.5590 
8896/9333 [===========================>..] - ETA: 47s - loss: 0.6834 - acc: 0.5586
8960/9333 [===========================>..] - ETA: 40s - loss: 0.6831 - acc: 0.5590
9024/9333 [============================>.] - ETA: 33s - loss: 0.6830 - acc: 0.5592
9088/9333 [============================>.] - ETA: 26s - loss: 0.6831 - acc: 0.5593
9152/9333 [============================>.] - ETA: 19s - loss: 0.6835 - acc: 0.5586
9216/9333 [============================>.] - ETA: 12s - loss: 0.6833 - acc: 0.5589
9280/9333 [============================>.] - ETA: 5s - loss: 0.6833 - acc: 0.5591 
9333/9333 [==============================] - 1065s 114ms/step - loss: 0.6835 - acc: 0.5584 - val_loss: 0.6903 - val_acc: 0.5554

Epoch 00004: val_acc improved from 0.53809 to 0.55545, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window10/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 5/10

  64/9333 [..............................] - ETA: 22:13 - loss: 0.6907 - acc: 0.5312
 128/9333 [..............................] - ETA: 19:37 - loss: 0.6915 - acc: 0.5312
 192/9333 [..............................] - ETA: 19:07 - loss: 0.6744 - acc: 0.5625
 256/9333 [..............................] - ETA: 19:06 - loss: 0.6877 - acc: 0.5508
 320/9333 [>.............................] - ETA: 18:46 - loss: 0.6800 - acc: 0.5719
 384/9333 [>.............................] - ETA: 18:18 - loss: 0.6760 - acc: 0.5807
 448/9333 [>.............................] - ETA: 18:02 - loss: 0.6821 - acc: 0.5692
 512/9333 [>.............................] - ETA: 17:53 - loss: 0.6817 - acc: 0.5684
 576/9333 [>.............................] - ETA: 17:39 - loss: 0.6834 - acc: 0.5573
 640/9333 [=>............................] - ETA: 17:29 - loss: 0.6813 - acc: 0.5656
 704/9333 [=>............................] - ETA: 17:22 - loss: 0.6824 - acc: 0.5611
 768/9333 [=>............................] - ETA: 17:14 - loss: 0.6821 - acc: 0.5625
 832/9333 [=>............................] - ETA: 17:06 - loss: 0.6819 - acc: 0.5685
 896/9333 [=>............................] - ETA: 17:00 - loss: 0.6804 - acc: 0.5714
 960/9333 [==>...........................] - ETA: 16:44 - loss: 0.6822 - acc: 0.5687
1024/9333 [==>...........................] - ETA: 16:29 - loss: 0.6828 - acc: 0.5674
1088/9333 [==>...........................] - ETA: 16:12 - loss: 0.6842 - acc: 0.5643
1152/9333 [==>...........................] - ETA: 15:58 - loss: 0.6845 - acc: 0.5634
1216/9333 [==>...........................] - ETA: 15:45 - loss: 0.6829 - acc: 0.5650
1280/9333 [===>..........................] - ETA: 15:33 - loss: 0.6840 - acc: 0.5609
1344/9333 [===>..........................] - ETA: 15:26 - loss: 0.6824 - acc: 0.5647
1408/9333 [===>..........................] - ETA: 15:20 - loss: 0.6828 - acc: 0.5625
1472/9333 [===>..........................] - ETA: 15:10 - loss: 0.6812 - acc: 0.5666
1536/9333 [===>..........................] - ETA: 15:02 - loss: 0.6830 - acc: 0.5625
1600/9333 [====>.........................] - ETA: 14:52 - loss: 0.6836 - acc: 0.5594
1664/9333 [====>.........................] - ETA: 14:41 - loss: 0.6832 - acc: 0.5565
1728/9333 [====>.........................] - ETA: 14:32 - loss: 0.6825 - acc: 0.5608
1792/9333 [====>.........................] - ETA: 14:23 - loss: 0.6828 - acc: 0.5603
1856/9333 [====>.........................] - ETA: 14:15 - loss: 0.6831 - acc: 0.5598
1920/9333 [=====>........................] - ETA: 14:10 - loss: 0.6832 - acc: 0.5589
1984/9333 [=====>........................] - ETA: 14:06 - loss: 0.6835 - acc: 0.5585
2048/9333 [=====>........................] - ETA: 14:00 - loss: 0.6837 - acc: 0.5586
2112/9333 [=====>........................] - ETA: 13:54 - loss: 0.6849 - acc: 0.5554
2176/9333 [=====>........................] - ETA: 13:47 - loss: 0.6845 - acc: 0.5574
2240/9333 [======>.......................] - ETA: 13:40 - loss: 0.6850 - acc: 0.5580
2304/9333 [======>.......................] - ETA: 13:34 - loss: 0.6851 - acc: 0.5577
2368/9333 [======>.......................] - ETA: 13:27 - loss: 0.6850 - acc: 0.5579
2432/9333 [======>.......................] - ETA: 13:20 - loss: 0.6841 - acc: 0.5604
2496/9333 [=======>......................] - ETA: 13:19 - loss: 0.6831 - acc: 0.5633
2560/9333 [=======>......................] - ETA: 13:14 - loss: 0.6835 - acc: 0.5621
2624/9333 [=======>......................] - ETA: 13:08 - loss: 0.6838 - acc: 0.5617
2688/9333 [=======>......................] - ETA: 13:03 - loss: 0.6837 - acc: 0.5632
2752/9333 [=======>......................] - ETA: 12:57 - loss: 0.6842 - acc: 0.5618
2816/9333 [========>.....................] - ETA: 12:49 - loss: 0.6830 - acc: 0.5646
2880/9333 [========>.....................] - ETA: 12:44 - loss: 0.6833 - acc: 0.5639
2944/9333 [========>.....................] - ETA: 12:37 - loss: 0.6836 - acc: 0.5639
3008/9333 [========>.....................] - ETA: 12:29 - loss: 0.6836 - acc: 0.5642
3072/9333 [========>.....................] - ETA: 12:21 - loss: 0.6834 - acc: 0.5641
3136/9333 [=========>....................] - ETA: 12:13 - loss: 0.6840 - acc: 0.5641
3200/9333 [=========>....................] - ETA: 12:07 - loss: 0.6845 - acc: 0.5634
3264/9333 [=========>....................] - ETA: 12:00 - loss: 0.6842 - acc: 0.5640
3328/9333 [=========>....................] - ETA: 11:52 - loss: 0.6845 - acc: 0.5625
3392/9333 [=========>....................] - ETA: 11:44 - loss: 0.6849 - acc: 0.5616
3456/9333 [==========>...................] - ETA: 11:38 - loss: 0.6852 - acc: 0.5611
3520/9333 [==========>...................] - ETA: 11:29 - loss: 0.6850 - acc: 0.5602
3584/9333 [==========>...................] - ETA: 11:21 - loss: 0.6850 - acc: 0.5603
3648/9333 [==========>...................] - ETA: 11:13 - loss: 0.6849 - acc: 0.5598
3712/9333 [==========>...................] - ETA: 11:06 - loss: 0.6849 - acc: 0.5598
3776/9333 [===========>..................] - ETA: 10:58 - loss: 0.6849 - acc: 0.5604
3840/9333 [===========>..................] - ETA: 10:51 - loss: 0.6847 - acc: 0.5599
3904/9333 [===========>..................] - ETA: 10:42 - loss: 0.6846 - acc: 0.5610
3968/9333 [===========>..................] - ETA: 10:36 - loss: 0.6851 - acc: 0.5602
4032/9333 [===========>..................] - ETA: 10:28 - loss: 0.6858 - acc: 0.5583
4096/9333 [============>.................] - ETA: 10:20 - loss: 0.6858 - acc: 0.5583
4160/9333 [============>.................] - ETA: 10:15 - loss: 0.6860 - acc: 0.5579
4224/9333 [============>.................] - ETA: 10:08 - loss: 0.6864 - acc: 0.5580
4288/9333 [============>.................] - ETA: 10:00 - loss: 0.6870 - acc: 0.5564
4352/9333 [============>.................] - ETA: 9:54 - loss: 0.6872 - acc: 0.5556 
4416/9333 [=============>................] - ETA: 9:47 - loss: 0.6870 - acc: 0.5555
4480/9333 [=============>................] - ETA: 9:40 - loss: 0.6871 - acc: 0.5551
4544/9333 [=============>................] - ETA: 9:33 - loss: 0.6871 - acc: 0.5552
4608/9333 [=============>................] - ETA: 9:25 - loss: 0.6872 - acc: 0.5545
4672/9333 [==============>...............] - ETA: 9:18 - loss: 0.6873 - acc: 0.5537
4736/9333 [==============>...............] - ETA: 9:09 - loss: 0.6875 - acc: 0.5530
4800/9333 [==============>...............] - ETA: 9:03 - loss: 0.6874 - acc: 0.5519
4864/9333 [==============>...............] - ETA: 8:55 - loss: 0.6873 - acc: 0.5528
4928/9333 [==============>...............] - ETA: 8:47 - loss: 0.6872 - acc: 0.5534
4992/9333 [===============>..............] - ETA: 8:39 - loss: 0.6872 - acc: 0.5527
5056/9333 [===============>..............] - ETA: 8:32 - loss: 0.6870 - acc: 0.5538
5120/9333 [===============>..............] - ETA: 8:24 - loss: 0.6872 - acc: 0.5525
5184/9333 [===============>..............] - ETA: 8:16 - loss: 0.6875 - acc: 0.5511
5248/9333 [===============>..............] - ETA: 8:08 - loss: 0.6875 - acc: 0.5514
5312/9333 [================>.............] - ETA: 7:59 - loss: 0.6871 - acc: 0.5531
5376/9333 [================>.............] - ETA: 7:51 - loss: 0.6870 - acc: 0.5530
5440/9333 [================>.............] - ETA: 7:43 - loss: 0.6869 - acc: 0.5529
5504/9333 [================>.............] - ETA: 7:35 - loss: 0.6868 - acc: 0.5534
5568/9333 [================>.............] - ETA: 7:26 - loss: 0.6870 - acc: 0.5524
5632/9333 [=================>............] - ETA: 7:19 - loss: 0.6868 - acc: 0.5527
5696/9333 [=================>............] - ETA: 7:11 - loss: 0.6866 - acc: 0.5537
5760/9333 [=================>............] - ETA: 7:03 - loss: 0.6861 - acc: 0.5549
5824/9333 [=================>............] - ETA: 6:55 - loss: 0.6860 - acc: 0.5556
5888/9333 [=================>............] - ETA: 6:47 - loss: 0.6861 - acc: 0.5550
5952/9333 [==================>...........] - ETA: 6:39 - loss: 0.6863 - acc: 0.5549
6016/9333 [==================>...........] - ETA: 6:31 - loss: 0.6861 - acc: 0.5555
6080/9333 [==================>...........] - ETA: 6:23 - loss: 0.6860 - acc: 0.5554
6144/9333 [==================>...........] - ETA: 6:15 - loss: 0.6856 - acc: 0.5562
6208/9333 [==================>...........] - ETA: 6:07 - loss: 0.6853 - acc: 0.5570
6272/9333 [===================>..........] - ETA: 5:59 - loss: 0.6851 - acc: 0.5574
6336/9333 [===================>..........] - ETA: 5:51 - loss: 0.6849 - acc: 0.5574
6400/9333 [===================>..........] - ETA: 5:44 - loss: 0.6849 - acc: 0.5577
6464/9333 [===================>..........] - ETA: 5:36 - loss: 0.6843 - acc: 0.5591
6528/9333 [===================>..........] - ETA: 5:28 - loss: 0.6847 - acc: 0.5582
6592/9333 [====================>.........] - ETA: 5:21 - loss: 0.6846 - acc: 0.5581
6656/9333 [====================>.........] - ETA: 5:13 - loss: 0.6845 - acc: 0.5578
6720/9333 [====================>.........] - ETA: 5:05 - loss: 0.6846 - acc: 0.5577
6784/9333 [====================>.........] - ETA: 4:57 - loss: 0.6844 - acc: 0.5585
6848/9333 [=====================>........] - ETA: 4:50 - loss: 0.6845 - acc: 0.5583
6912/9333 [=====================>........] - ETA: 4:42 - loss: 0.6844 - acc: 0.5584
6976/9333 [=====================>........] - ETA: 4:34 - loss: 0.6847 - acc: 0.5583
7040/9333 [=====================>........] - ETA: 4:27 - loss: 0.6846 - acc: 0.5585
7104/9333 [=====================>........] - ETA: 4:19 - loss: 0.6846 - acc: 0.5587
7168/9333 [======================>.......] - ETA: 4:12 - loss: 0.6847 - acc: 0.5580
7232/9333 [======================>.......] - ETA: 4:04 - loss: 0.6849 - acc: 0.5577
7296/9333 [======================>.......] - ETA: 3:56 - loss: 0.6851 - acc: 0.5569
7360/9333 [======================>.......] - ETA: 3:49 - loss: 0.6852 - acc: 0.5572
7424/9333 [======================>.......] - ETA: 3:41 - loss: 0.6847 - acc: 0.5578
7488/9333 [=======================>......] - ETA: 3:34 - loss: 0.6847 - acc: 0.5584
7552/9333 [=======================>......] - ETA: 3:26 - loss: 0.6845 - acc: 0.5589
7616/9333 [=======================>......] - ETA: 3:18 - loss: 0.6843 - acc: 0.5591
7680/9333 [=======================>......] - ETA: 3:11 - loss: 0.6843 - acc: 0.5590
7744/9333 [=======================>......] - ETA: 3:03 - loss: 0.6841 - acc: 0.5590
7808/9333 [========================>.....] - ETA: 2:56 - loss: 0.6839 - acc: 0.5598
7872/9333 [========================>.....] - ETA: 2:48 - loss: 0.6840 - acc: 0.5600
7936/9333 [========================>.....] - ETA: 2:41 - loss: 0.6842 - acc: 0.5597
8000/9333 [========================>.....] - ETA: 2:33 - loss: 0.6843 - acc: 0.5596
8064/9333 [========================>.....] - ETA: 2:26 - loss: 0.6846 - acc: 0.5592
8128/9333 [=========================>....] - ETA: 2:18 - loss: 0.6845 - acc: 0.5594
8192/9333 [=========================>....] - ETA: 2:11 - loss: 0.6844 - acc: 0.5592
8256/9333 [=========================>....] - ETA: 2:03 - loss: 0.6845 - acc: 0.5591
8320/9333 [=========================>....] - ETA: 1:56 - loss: 0.6844 - acc: 0.5588
8384/9333 [=========================>....] - ETA: 1:48 - loss: 0.6842 - acc: 0.5588
8448/9333 [==========================>...] - ETA: 1:41 - loss: 0.6845 - acc: 0.5578
8512/9333 [==========================>...] - ETA: 1:34 - loss: 0.6842 - acc: 0.5591
8576/9333 [==========================>...] - ETA: 1:26 - loss: 0.6842 - acc: 0.5595
8640/9333 [==========================>...] - ETA: 1:19 - loss: 0.6842 - acc: 0.5590
8704/9333 [==========================>...] - ETA: 1:12 - loss: 0.6843 - acc: 0.5588
8768/9333 [===========================>..] - ETA: 1:04 - loss: 0.6844 - acc: 0.5584
8832/9333 [===========================>..] - ETA: 57s - loss: 0.6843 - acc: 0.5588 
8896/9333 [===========================>..] - ETA: 50s - loss: 0.6845 - acc: 0.5581
8960/9333 [===========================>..] - ETA: 42s - loss: 0.6844 - acc: 0.5584
9024/9333 [============================>.] - ETA: 35s - loss: 0.6845 - acc: 0.5577
9088/9333 [============================>.] - ETA: 28s - loss: 0.6846 - acc: 0.5572
9152/9333 [============================>.] - ETA: 20s - loss: 0.6846 - acc: 0.5575
9216/9333 [============================>.] - ETA: 13s - loss: 0.6848 - acc: 0.5570
9280/9333 [============================>.] - ETA: 6s - loss: 0.6848 - acc: 0.5570 
9333/9333 [==============================] - 1109s 119ms/step - loss: 0.6847 - acc: 0.5577 - val_loss: 0.6895 - val_acc: 0.5419

Epoch 00005: val_acc did not improve from 0.55545
Epoch 6/10

  64/9333 [..............................] - ETA: 16:52 - loss: 0.6591 - acc: 0.6094
 128/9333 [..............................] - ETA: 17:17 - loss: 0.6830 - acc: 0.5703
 192/9333 [..............................] - ETA: 17:47 - loss: 0.6808 - acc: 0.5833
 256/9333 [..............................] - ETA: 18:03 - loss: 0.6832 - acc: 0.5742
 320/9333 [>.............................] - ETA: 17:30 - loss: 0.6819 - acc: 0.5625
 384/9333 [>.............................] - ETA: 17:02 - loss: 0.6860 - acc: 0.5495
 448/9333 [>.............................] - ETA: 17:04 - loss: 0.6909 - acc: 0.5491
 512/9333 [>.............................] - ETA: 16:58 - loss: 0.6905 - acc: 0.5547
 576/9333 [>.............................] - ETA: 16:52 - loss: 0.6930 - acc: 0.5521
 640/9333 [=>............................] - ETA: 16:44 - loss: 0.6903 - acc: 0.5625
 704/9333 [=>............................] - ETA: 16:40 - loss: 0.6881 - acc: 0.5625
 768/9333 [=>............................] - ETA: 16:33 - loss: 0.6876 - acc: 0.5612
 832/9333 [=>............................] - ETA: 16:25 - loss: 0.6866 - acc: 0.5589
 896/9333 [=>............................] - ETA: 16:25 - loss: 0.6877 - acc: 0.5558
 960/9333 [==>...........................] - ETA: 16:24 - loss: 0.6877 - acc: 0.5552
1024/9333 [==>...........................] - ETA: 16:15 - loss: 0.6874 - acc: 0.5518
1088/9333 [==>...........................] - ETA: 16:12 - loss: 0.6878 - acc: 0.5487
1152/9333 [==>...........................] - ETA: 16:01 - loss: 0.6862 - acc: 0.5573
1216/9333 [==>...........................] - ETA: 15:52 - loss: 0.6856 - acc: 0.5617
1280/9333 [===>..........................] - ETA: 15:48 - loss: 0.6875 - acc: 0.5570
1344/9333 [===>..........................] - ETA: 15:50 - loss: 0.6855 - acc: 0.5618
1408/9333 [===>..........................] - ETA: 15:45 - loss: 0.6866 - acc: 0.5611
1472/9333 [===>..........................] - ETA: 15:38 - loss: 0.6857 - acc: 0.5645
1536/9333 [===>..........................] - ETA: 15:29 - loss: 0.6857 - acc: 0.5638
1600/9333 [====>.........................] - ETA: 15:26 - loss: 0.6843 - acc: 0.5650
1664/9333 [====>.........................] - ETA: 15:15 - loss: 0.6835 - acc: 0.5649
1728/9333 [====>.........................] - ETA: 15:03 - loss: 0.6830 - acc: 0.5654
1792/9333 [====>.........................] - ETA: 14:57 - loss: 0.6829 - acc: 0.5653
1856/9333 [====>.........................] - ETA: 14:46 - loss: 0.6828 - acc: 0.5652
1920/9333 [=====>........................] - ETA: 14:35 - loss: 0.6828 - acc: 0.5661
1984/9333 [=====>........................] - ETA: 14:26 - loss: 0.6829 - acc: 0.5660
2048/9333 [=====>........................] - ETA: 14:16 - loss: 0.6824 - acc: 0.5684
2112/9333 [=====>........................] - ETA: 14:06 - loss: 0.6811 - acc: 0.5705
2176/9333 [=====>........................] - ETA: 13:56 - loss: 0.6809 - acc: 0.5685
2240/9333 [======>.......................] - ETA: 13:46 - loss: 0.6812 - acc: 0.5661
2304/9333 [======>.......................] - ETA: 13:39 - loss: 0.6809 - acc: 0.5673
2368/9333 [======>.......................] - ETA: 13:29 - loss: 0.6805 - acc: 0.5688
2432/9333 [======>.......................] - ETA: 13:20 - loss: 0.6799 - acc: 0.5699
2496/9333 [=======>......................] - ETA: 13:11 - loss: 0.6802 - acc: 0.5689
2560/9333 [=======>......................] - ETA: 13:03 - loss: 0.6792 - acc: 0.5711
2624/9333 [=======>......................] - ETA: 12:55 - loss: 0.6786 - acc: 0.5724
2688/9333 [=======>......................] - ETA: 12:46 - loss: 0.6796 - acc: 0.5711
2752/9333 [=======>......................] - ETA: 12:40 - loss: 0.6802 - acc: 0.5694
2816/9333 [========>.....................] - ETA: 12:31 - loss: 0.6808 - acc: 0.5682
2880/9333 [========>.....................] - ETA: 12:22 - loss: 0.6809 - acc: 0.5687
2944/9333 [========>.....................] - ETA: 12:14 - loss: 0.6807 - acc: 0.5679
3008/9333 [========>.....................] - ETA: 12:06 - loss: 0.6811 - acc: 0.5662
3072/9333 [========>.....................] - ETA: 11:58 - loss: 0.6811 - acc: 0.5664
3136/9333 [=========>....................] - ETA: 11:49 - loss: 0.6812 - acc: 0.5657
3200/9333 [=========>....................] - ETA: 11:40 - loss: 0.6807 - acc: 0.5672
3264/9333 [=========>....................] - ETA: 11:32 - loss: 0.6810 - acc: 0.5659
3328/9333 [=========>....................] - ETA: 11:23 - loss: 0.6815 - acc: 0.5643
3392/9333 [=========>....................] - ETA: 11:15 - loss: 0.6814 - acc: 0.5652
3456/9333 [==========>...................] - ETA: 11:07 - loss: 0.6823 - acc: 0.5628
3520/9333 [==========>...................] - ETA: 10:58 - loss: 0.6820 - acc: 0.5645
3584/9333 [==========>...................] - ETA: 10:50 - loss: 0.6822 - acc: 0.5650
3648/9333 [==========>...................] - ETA: 10:42 - loss: 0.6818 - acc: 0.5658
3712/9333 [==========>...................] - ETA: 10:35 - loss: 0.6816 - acc: 0.5663
3776/9333 [===========>..................] - ETA: 10:28 - loss: 0.6808 - acc: 0.5697
3840/9333 [===========>..................] - ETA: 10:21 - loss: 0.6814 - acc: 0.5674
3904/9333 [===========>..................] - ETA: 10:15 - loss: 0.6820 - acc: 0.5656
3968/9333 [===========>..................] - ETA: 10:07 - loss: 0.6818 - acc: 0.5665
4032/9333 [===========>..................] - ETA: 10:00 - loss: 0.6821 - acc: 0.5657
4096/9333 [============>.................] - ETA: 9:52 - loss: 0.6821 - acc: 0.5654 
4160/9333 [============>.................] - ETA: 9:45 - loss: 0.6822 - acc: 0.5644
4224/9333 [============>.................] - ETA: 9:37 - loss: 0.6821 - acc: 0.5649
4288/9333 [============>.................] - ETA: 9:29 - loss: 0.6821 - acc: 0.5653
4352/9333 [============>.................] - ETA: 9:25 - loss: 0.6823 - acc: 0.5643
4416/9333 [=============>................] - ETA: 9:17 - loss: 0.6828 - acc: 0.5630
4480/9333 [=============>................] - ETA: 9:09 - loss: 0.6827 - acc: 0.5627
4544/9333 [=============>................] - ETA: 9:02 - loss: 0.6825 - acc: 0.5618
4608/9333 [=============>................] - ETA: 8:56 - loss: 0.6825 - acc: 0.5623
4672/9333 [==============>...............] - ETA: 8:48 - loss: 0.6828 - acc: 0.5612
4736/9333 [==============>...............] - ETA: 8:40 - loss: 0.6827 - acc: 0.5612
4800/9333 [==============>...............] - ETA: 8:34 - loss: 0.6826 - acc: 0.5610
4864/9333 [==============>...............] - ETA: 8:27 - loss: 0.6827 - acc: 0.5611
4928/9333 [==============>...............] - ETA: 8:20 - loss: 0.6826 - acc: 0.5613
4992/9333 [===============>..............] - ETA: 8:13 - loss: 0.6827 - acc: 0.5613
5056/9333 [===============>..............] - ETA: 8:06 - loss: 0.6827 - acc: 0.5611
5120/9333 [===============>..............] - ETA: 7:59 - loss: 0.6824 - acc: 0.5621
5184/9333 [===============>..............] - ETA: 7:52 - loss: 0.6822 - acc: 0.5625
5248/9333 [===============>..............] - ETA: 7:45 - loss: 0.6823 - acc: 0.5627
5312/9333 [================>.............] - ETA: 7:37 - loss: 0.6825 - acc: 0.5619
5376/9333 [================>.............] - ETA: 7:30 - loss: 0.6824 - acc: 0.5625
5440/9333 [================>.............] - ETA: 7:22 - loss: 0.6826 - acc: 0.5618
5504/9333 [================>.............] - ETA: 7:14 - loss: 0.6823 - acc: 0.5623
5568/9333 [================>.............] - ETA: 7:07 - loss: 0.6824 - acc: 0.5627
5632/9333 [=================>............] - ETA: 7:00 - loss: 0.6828 - acc: 0.5621
5696/9333 [=================>............] - ETA: 6:53 - loss: 0.6826 - acc: 0.5630
5760/9333 [=================>............] - ETA: 6:45 - loss: 0.6825 - acc: 0.5622
5824/9333 [=================>............] - ETA: 6:38 - loss: 0.6828 - acc: 0.5616
5888/9333 [=================>............] - ETA: 6:30 - loss: 0.6824 - acc: 0.5628
5952/9333 [==================>...........] - ETA: 6:23 - loss: 0.6823 - acc: 0.5625
6016/9333 [==================>...........] - ETA: 6:16 - loss: 0.6823 - acc: 0.5618
6080/9333 [==================>...........] - ETA: 6:09 - loss: 0.6824 - acc: 0.5618
6144/9333 [==================>...........] - ETA: 6:01 - loss: 0.6823 - acc: 0.5612
6208/9333 [==================>...........] - ETA: 5:54 - loss: 0.6826 - acc: 0.5602
6272/9333 [===================>..........] - ETA: 5:47 - loss: 0.6825 - acc: 0.5604
6336/9333 [===================>..........] - ETA: 5:39 - loss: 0.6826 - acc: 0.5598
6400/9333 [===================>..........] - ETA: 5:32 - loss: 0.6826 - acc: 0.5594
6464/9333 [===================>..........] - ETA: 5:26 - loss: 0.6824 - acc: 0.5596
6528/9333 [===================>..........] - ETA: 5:19 - loss: 0.6825 - acc: 0.5588
6592/9333 [====================>.........] - ETA: 5:11 - loss: 0.6825 - acc: 0.5583
6656/9333 [====================>.........] - ETA: 5:04 - loss: 0.6824 - acc: 0.5581
6720/9333 [====================>.........] - ETA: 4:57 - loss: 0.6820 - acc: 0.5592
6784/9333 [====================>.........] - ETA: 4:49 - loss: 0.6820 - acc: 0.5593
6848/9333 [=====================>........] - ETA: 4:41 - loss: 0.6821 - acc: 0.5587
6912/9333 [=====================>........] - ETA: 4:34 - loss: 0.6823 - acc: 0.5586
6976/9333 [=====================>........] - ETA: 4:27 - loss: 0.6823 - acc: 0.5585
7040/9333 [=====================>........] - ETA: 4:20 - loss: 0.6823 - acc: 0.5585
7104/9333 [=====================>........] - ETA: 4:13 - loss: 0.6823 - acc: 0.5591
7168/9333 [======================>.......] - ETA: 4:06 - loss: 0.6824 - acc: 0.5585
7232/9333 [======================>.......] - ETA: 3:59 - loss: 0.6821 - acc: 0.5592
7296/9333 [======================>.......] - ETA: 3:52 - loss: 0.6823 - acc: 0.5588
7360/9333 [======================>.......] - ETA: 3:44 - loss: 0.6824 - acc: 0.5590
7424/9333 [======================>.......] - ETA: 3:37 - loss: 0.6825 - acc: 0.5589
7488/9333 [=======================>......] - ETA: 3:29 - loss: 0.6824 - acc: 0.5590
7552/9333 [=======================>......] - ETA: 3:22 - loss: 0.6826 - acc: 0.5583
7616/9333 [=======================>......] - ETA: 3:14 - loss: 0.6825 - acc: 0.5588
7680/9333 [=======================>......] - ETA: 3:07 - loss: 0.6828 - acc: 0.5582
7744/9333 [=======================>......] - ETA: 3:01 - loss: 0.6827 - acc: 0.5588
7808/9333 [========================>.....] - ETA: 2:54 - loss: 0.6828 - acc: 0.5589
7872/9333 [========================>.....] - ETA: 2:46 - loss: 0.6827 - acc: 0.5593
7936/9333 [========================>.....] - ETA: 2:39 - loss: 0.6829 - acc: 0.5586
8000/9333 [========================>.....] - ETA: 2:32 - loss: 0.6830 - acc: 0.5579
8064/9333 [========================>.....] - ETA: 2:24 - loss: 0.6830 - acc: 0.5577
8128/9333 [=========================>....] - ETA: 2:17 - loss: 0.6832 - acc: 0.5577
8192/9333 [=========================>....] - ETA: 2:10 - loss: 0.6830 - acc: 0.5582
8256/9333 [=========================>....] - ETA: 2:02 - loss: 0.6831 - acc: 0.5575
8320/9333 [=========================>....] - ETA: 1:55 - loss: 0.6832 - acc: 0.5576
8384/9333 [=========================>....] - ETA: 1:48 - loss: 0.6832 - acc: 0.5575
8448/9333 [==========================>...] - ETA: 1:41 - loss: 0.6831 - acc: 0.5580
8512/9333 [==========================>...] - ETA: 1:33 - loss: 0.6829 - acc: 0.5587
8576/9333 [==========================>...] - ETA: 1:26 - loss: 0.6828 - acc: 0.5594
8640/9333 [==========================>...] - ETA: 1:19 - loss: 0.6827 - acc: 0.5594
8704/9333 [==========================>...] - ETA: 1:11 - loss: 0.6826 - acc: 0.5595
8768/9333 [===========================>..] - ETA: 1:04 - loss: 0.6828 - acc: 0.5592
8832/9333 [===========================>..] - ETA: 57s - loss: 0.6828 - acc: 0.5591 
8896/9333 [===========================>..] - ETA: 49s - loss: 0.6827 - acc: 0.5596
8960/9333 [===========================>..] - ETA: 42s - loss: 0.6824 - acc: 0.5602
9024/9333 [============================>.] - ETA: 35s - loss: 0.6821 - acc: 0.5609
9088/9333 [============================>.] - ETA: 28s - loss: 0.6818 - acc: 0.5616
9152/9333 [============================>.] - ETA: 20s - loss: 0.6816 - acc: 0.5622
9216/9333 [============================>.] - ETA: 13s - loss: 0.6817 - acc: 0.5621
9280/9333 [============================>.] - ETA: 6s - loss: 0.6821 - acc: 0.5610 
9333/9333 [==============================] - 1114s 119ms/step - loss: 0.6823 - acc: 0.5601 - val_loss: 0.6894 - val_acc: 0.5400

Epoch 00006: val_acc did not improve from 0.55545
Epoch 7/10

  64/9333 [..............................] - ETA: 20:43 - loss: 0.6413 - acc: 0.6094
 128/9333 [..............................] - ETA: 19:42 - loss: 0.6585 - acc: 0.6250
 192/9333 [..............................] - ETA: 18:52 - loss: 0.6628 - acc: 0.6198
 256/9333 [..............................] - ETA: 18:15 - loss: 0.6689 - acc: 0.6055
 320/9333 [>.............................] - ETA: 17:53 - loss: 0.6806 - acc: 0.5813
 384/9333 [>.............................] - ETA: 17:37 - loss: 0.6860 - acc: 0.5677
 448/9333 [>.............................] - ETA: 17:30 - loss: 0.6821 - acc: 0.5692
 512/9333 [>.............................] - ETA: 17:19 - loss: 0.6829 - acc: 0.5645
 576/9333 [>.............................] - ETA: 16:59 - loss: 0.6811 - acc: 0.5694
 640/9333 [=>............................] - ETA: 16:48 - loss: 0.6841 - acc: 0.5734
 704/9333 [=>............................] - ETA: 16:38 - loss: 0.6809 - acc: 0.5810
 768/9333 [=>............................] - ETA: 16:42 - loss: 0.6806 - acc: 0.5820
 832/9333 [=>............................] - ETA: 16:33 - loss: 0.6814 - acc: 0.5745
 896/9333 [=>............................] - ETA: 16:24 - loss: 0.6822 - acc: 0.5681
 960/9333 [==>...........................] - ETA: 16:16 - loss: 0.6819 - acc: 0.5656
1024/9333 [==>...........................] - ETA: 16:07 - loss: 0.6813 - acc: 0.5674
1088/9333 [==>...........................] - ETA: 15:58 - loss: 0.6803 - acc: 0.5699
1152/9333 [==>...........................] - ETA: 15:47 - loss: 0.6818 - acc: 0.5634
1216/9333 [==>...........................] - ETA: 15:42 - loss: 0.6799 - acc: 0.5674
1280/9333 [===>..........................] - ETA: 15:34 - loss: 0.6788 - acc: 0.5742
1344/9333 [===>..........................] - ETA: 15:29 - loss: 0.6779 - acc: 0.5774
1408/9333 [===>..........................] - ETA: 15:21 - loss: 0.6783 - acc: 0.5788
1472/9333 [===>..........................] - ETA: 15:16 - loss: 0.6787 - acc: 0.5774
1536/9333 [===>..........................] - ETA: 15:10 - loss: 0.6792 - acc: 0.5736
1600/9333 [====>.........................] - ETA: 15:03 - loss: 0.6791 - acc: 0.5750
1664/9333 [====>.........................] - ETA: 14:54 - loss: 0.6800 - acc: 0.5733
1728/9333 [====>.........................] - ETA: 14:45 - loss: 0.6812 - acc: 0.5723
1792/9333 [====>.........................] - ETA: 14:40 - loss: 0.6821 - acc: 0.5714
1856/9333 [====>.........................] - ETA: 14:32 - loss: 0.6815 - acc: 0.5733
1920/9333 [=====>........................] - ETA: 14:19 - loss: 0.6815 - acc: 0.5740
1984/9333 [=====>........................] - ETA: 14:12 - loss: 0.6816 - acc: 0.5741
2048/9333 [=====>........................] - ETA: 14:06 - loss: 0.6813 - acc: 0.5757
2112/9333 [=====>........................] - ETA: 13:56 - loss: 0.6801 - acc: 0.5800
2176/9333 [=====>........................] - ETA: 13:47 - loss: 0.6794 - acc: 0.5790
2240/9333 [======>.......................] - ETA: 13:37 - loss: 0.6810 - acc: 0.5746
2304/9333 [======>.......................] - ETA: 13:33 - loss: 0.6810 - acc: 0.5734
2368/9333 [======>.......................] - ETA: 13:28 - loss: 0.6813 - acc: 0.5718
2432/9333 [======>.......................] - ETA: 13:21 - loss: 0.6813 - acc: 0.5711
2496/9333 [=======>......................] - ETA: 13:17 - loss: 0.6804 - acc: 0.5713
2560/9333 [=======>......................] - ETA: 13:10 - loss: 0.6810 - acc: 0.5711
2624/9333 [=======>......................] - ETA: 13:03 - loss: 0.6812 - acc: 0.5705
2688/9333 [=======>......................] - ETA: 12:57 - loss: 0.6801 - acc: 0.5714
2752/9333 [=======>......................] - ETA: 12:48 - loss: 0.6794 - acc: 0.5734
2816/9333 [========>.....................] - ETA: 12:40 - loss: 0.6799 - acc: 0.5707
2880/9333 [========>.....................] - ETA: 12:32 - loss: 0.6799 - acc: 0.5715
2944/9333 [========>.....................] - ETA: 12:28 - loss: 0.6796 - acc: 0.5717
3008/9333 [========>.....................] - ETA: 12:21 - loss: 0.6800 - acc: 0.5708
3072/9333 [========>.....................] - ETA: 12:13 - loss: 0.6800 - acc: 0.5710
3136/9333 [=========>....................] - ETA: 12:05 - loss: 0.6799 - acc: 0.5708
3200/9333 [=========>....................] - ETA: 12:00 - loss: 0.6797 - acc: 0.5716
3264/9333 [=========>....................] - ETA: 11:51 - loss: 0.6800 - acc: 0.5717
3328/9333 [=========>....................] - ETA: 11:44 - loss: 0.6801 - acc: 0.5718
3392/9333 [=========>....................] - ETA: 11:36 - loss: 0.6802 - acc: 0.5708
3456/9333 [==========>...................] - ETA: 11:29 - loss: 0.6803 - acc: 0.5703
3520/9333 [==========>...................] - ETA: 11:20 - loss: 0.6809 - acc: 0.5690
3584/9333 [==========>...................] - ETA: 11:11 - loss: 0.6816 - acc: 0.5675
3648/9333 [==========>...................] - ETA: 11:03 - loss: 0.6814 - acc: 0.5677
3712/9333 [==========>...................] - ETA: 10:55 - loss: 0.6813 - acc: 0.5682
3776/9333 [===========>..................] - ETA: 10:49 - loss: 0.6810 - acc: 0.5694
3840/9333 [===========>..................] - ETA: 10:41 - loss: 0.6809 - acc: 0.5695
3904/9333 [===========>..................] - ETA: 10:33 - loss: 0.6809 - acc: 0.5676
3968/9333 [===========>..................] - ETA: 10:25 - loss: 0.6809 - acc: 0.5673
4032/9333 [===========>..................] - ETA: 10:16 - loss: 0.6805 - acc: 0.5682
4096/9333 [============>.................] - ETA: 10:08 - loss: 0.6805 - acc: 0.5686
4160/9333 [============>.................] - ETA: 10:00 - loss: 0.6798 - acc: 0.5704
4224/9333 [============>.................] - ETA: 9:53 - loss: 0.6798 - acc: 0.5701 
4288/9333 [============>.................] - ETA: 9:45 - loss: 0.6799 - acc: 0.5695
4352/9333 [============>.................] - ETA: 9:36 - loss: 0.6801 - acc: 0.5687
4416/9333 [=============>................] - ETA: 9:28 - loss: 0.6800 - acc: 0.5686
4480/9333 [=============>................] - ETA: 9:21 - loss: 0.6794 - acc: 0.5701
4544/9333 [=============>................] - ETA: 9:13 - loss: 0.6797 - acc: 0.5700
4608/9333 [=============>................] - ETA: 9:05 - loss: 0.6798 - acc: 0.5699
4672/9333 [==============>...............] - ETA: 8:58 - loss: 0.6802 - acc: 0.5700
4736/9333 [==============>...............] - ETA: 8:49 - loss: 0.6805 - acc: 0.5690
4800/9333 [==============>...............] - ETA: 8:41 - loss: 0.6803 - acc: 0.5690
4864/9333 [==============>...............] - ETA: 8:33 - loss: 0.6803 - acc: 0.5689
4928/9333 [==============>...............] - ETA: 8:25 - loss: 0.6803 - acc: 0.5692
4992/9333 [===============>..............] - ETA: 8:17 - loss: 0.6804 - acc: 0.5689
5056/9333 [===============>..............] - ETA: 8:10 - loss: 0.6799 - acc: 0.5694
5120/9333 [===============>..............] - ETA: 8:02 - loss: 0.6797 - acc: 0.5701
5184/9333 [===============>..............] - ETA: 7:54 - loss: 0.6795 - acc: 0.5704
5248/9333 [===============>..............] - ETA: 7:46 - loss: 0.6790 - acc: 0.5716
5312/9333 [================>.............] - ETA: 7:38 - loss: 0.6789 - acc: 0.5715
5376/9333 [================>.............] - ETA: 7:31 - loss: 0.6785 - acc: 0.5725
5440/9333 [================>.............] - ETA: 7:23 - loss: 0.6785 - acc: 0.5730
5504/9333 [================>.............] - ETA: 7:15 - loss: 0.6788 - acc: 0.5729
5568/9333 [================>.............] - ETA: 7:08 - loss: 0.6790 - acc: 0.5722
5632/9333 [=================>............] - ETA: 7:00 - loss: 0.6790 - acc: 0.5721
5696/9333 [=================>............] - ETA: 6:52 - loss: 0.6791 - acc: 0.5722
5760/9333 [=================>............] - ETA: 6:45 - loss: 0.6788 - acc: 0.5726
5824/9333 [=================>............] - ETA: 6:37 - loss: 0.6787 - acc: 0.5718
5888/9333 [=================>............] - ETA: 6:30 - loss: 0.6785 - acc: 0.5720
5952/9333 [==================>...........] - ETA: 6:22 - loss: 0.6789 - acc: 0.5714
6016/9333 [==================>...........] - ETA: 6:14 - loss: 0.6790 - acc: 0.5715
6080/9333 [==================>...........] - ETA: 6:07 - loss: 0.6795 - acc: 0.5704
6144/9333 [==================>...........] - ETA: 5:59 - loss: 0.6794 - acc: 0.5706
6208/9333 [==================>...........] - ETA: 5:52 - loss: 0.6797 - acc: 0.5709
6272/9333 [===================>..........] - ETA: 5:44 - loss: 0.6801 - acc: 0.5703
6336/9333 [===================>..........] - ETA: 5:37 - loss: 0.6801 - acc: 0.5705
6400/9333 [===================>..........] - ETA: 5:29 - loss: 0.6805 - acc: 0.5702
6464/9333 [===================>..........] - ETA: 5:22 - loss: 0.6806 - acc: 0.5698
6528/9333 [===================>..........] - ETA: 5:14 - loss: 0.6809 - acc: 0.5689
6592/9333 [====================>.........] - ETA: 5:07 - loss: 0.6811 - acc: 0.5680
6656/9333 [====================>.........] - ETA: 4:59 - loss: 0.6807 - acc: 0.5688
6720/9333 [====================>.........] - ETA: 4:52 - loss: 0.6805 - acc: 0.5696
6784/9333 [====================>.........] - ETA: 4:44 - loss: 0.6804 - acc: 0.5697
6848/9333 [=====================>........] - ETA: 4:37 - loss: 0.6803 - acc: 0.5698
6912/9333 [=====================>........] - ETA: 4:30 - loss: 0.6804 - acc: 0.5694
6976/9333 [=====================>........] - ETA: 4:23 - loss: 0.6803 - acc: 0.5692
7040/9333 [=====================>........] - ETA: 4:15 - loss: 0.6802 - acc: 0.5692
7104/9333 [=====================>........] - ETA: 4:08 - loss: 0.6795 - acc: 0.5704
7168/9333 [======================>.......] - ETA: 4:01 - loss: 0.6795 - acc: 0.5702
7232/9333 [======================>.......] - ETA: 3:53 - loss: 0.6794 - acc: 0.5698
7296/9333 [======================>.......] - ETA: 3:46 - loss: 0.6798 - acc: 0.5695
7360/9333 [======================>.......] - ETA: 3:39 - loss: 0.6795 - acc: 0.5697
7424/9333 [======================>.......] - ETA: 3:32 - loss: 0.6797 - acc: 0.5695
7488/9333 [=======================>......] - ETA: 3:24 - loss: 0.6798 - acc: 0.5690
7552/9333 [=======================>......] - ETA: 3:17 - loss: 0.6797 - acc: 0.5693
7616/9333 [=======================>......] - ETA: 3:10 - loss: 0.6798 - acc: 0.5689
7680/9333 [=======================>......] - ETA: 3:03 - loss: 0.6798 - acc: 0.5687
7744/9333 [=======================>......] - ETA: 2:55 - loss: 0.6797 - acc: 0.5692
7808/9333 [========================>.....] - ETA: 2:48 - loss: 0.6796 - acc: 0.5693
7872/9333 [========================>.....] - ETA: 2:42 - loss: 0.6796 - acc: 0.5694
7936/9333 [========================>.....] - ETA: 2:35 - loss: 0.6800 - acc: 0.5684
8000/9333 [========================>.....] - ETA: 2:28 - loss: 0.6800 - acc: 0.5683
8064/9333 [========================>.....] - ETA: 2:20 - loss: 0.6800 - acc: 0.5681
8128/9333 [=========================>....] - ETA: 2:13 - loss: 0.6796 - acc: 0.5685
8192/9333 [=========================>....] - ETA: 2:06 - loss: 0.6795 - acc: 0.5692
8256/9333 [=========================>....] - ETA: 1:59 - loss: 0.6797 - acc: 0.5689
8320/9333 [=========================>....] - ETA: 1:52 - loss: 0.6797 - acc: 0.5692
8384/9333 [=========================>....] - ETA: 1:45 - loss: 0.6798 - acc: 0.5688
8448/9333 [==========================>...] - ETA: 1:38 - loss: 0.6799 - acc: 0.5689
8512/9333 [==========================>...] - ETA: 1:31 - loss: 0.6800 - acc: 0.5690
8576/9333 [==========================>...] - ETA: 1:24 - loss: 0.6798 - acc: 0.5693
8640/9333 [==========================>...] - ETA: 1:16 - loss: 0.6794 - acc: 0.5704
8704/9333 [==========================>...] - ETA: 1:09 - loss: 0.6793 - acc: 0.5707
8768/9333 [===========================>..] - ETA: 1:02 - loss: 0.6794 - acc: 0.5707
8832/9333 [===========================>..] - ETA: 55s - loss: 0.6792 - acc: 0.5711 
8896/9333 [===========================>..] - ETA: 48s - loss: 0.6791 - acc: 0.5714
8960/9333 [===========================>..] - ETA: 41s - loss: 0.6791 - acc: 0.5711
9024/9333 [============================>.] - ETA: 34s - loss: 0.6789 - acc: 0.5713
9088/9333 [============================>.] - ETA: 27s - loss: 0.6790 - acc: 0.5713
9152/9333 [============================>.] - ETA: 20s - loss: 0.6791 - acc: 0.5711
9216/9333 [============================>.] - ETA: 12s - loss: 0.6790 - acc: 0.5713
9280/9333 [============================>.] - ETA: 5s - loss: 0.6788 - acc: 0.5719 
9333/9333 [==============================] - 1074s 115ms/step - loss: 0.6790 - acc: 0.5716 - val_loss: 0.6862 - val_acc: 0.5410

Epoch 00007: val_acc did not improve from 0.55545
Epoch 8/10

  64/9333 [..............................] - ETA: 16:19 - loss: 0.6678 - acc: 0.5781
 128/9333 [..............................] - ETA: 17:03 - loss: 0.6772 - acc: 0.5469
 192/9333 [..............................] - ETA: 17:22 - loss: 0.6675 - acc: 0.5990
 256/9333 [..............................] - ETA: 17:45 - loss: 0.6713 - acc: 0.5898
 320/9333 [>.............................] - ETA: 17:33 - loss: 0.6764 - acc: 0.5750
 384/9333 [>.............................] - ETA: 17:35 - loss: 0.6751 - acc: 0.5703
 448/9333 [>.............................] - ETA: 17:34 - loss: 0.6702 - acc: 0.5826
 512/9333 [>.............................] - ETA: 17:07 - loss: 0.6683 - acc: 0.5938
 576/9333 [>.............................] - ETA: 16:55 - loss: 0.6716 - acc: 0.5885
 640/9333 [=>............................] - ETA: 16:49 - loss: 0.6664 - acc: 0.6047
 704/9333 [=>............................] - ETA: 16:30 - loss: 0.6680 - acc: 0.5966
 768/9333 [=>............................] - ETA: 16:17 - loss: 0.6680 - acc: 0.5951
 832/9333 [=>............................] - ETA: 16:20 - loss: 0.6699 - acc: 0.5925
 896/9333 [=>............................] - ETA: 16:13 - loss: 0.6697 - acc: 0.5904
 960/9333 [==>...........................] - ETA: 16:06 - loss: 0.6713 - acc: 0.5885
1024/9333 [==>...........................] - ETA: 16:03 - loss: 0.6721 - acc: 0.5869
1088/9333 [==>...........................] - ETA: 15:56 - loss: 0.6742 - acc: 0.5827
1152/9333 [==>...........................] - ETA: 15:45 - loss: 0.6754 - acc: 0.5816
1216/9333 [==>...........................] - ETA: 15:34 - loss: 0.6731 - acc: 0.5855
1280/9333 [===>..........................] - ETA: 15:26 - loss: 0.6718 - acc: 0.5875
1344/9333 [===>..........................] - ETA: 15:14 - loss: 0.6713 - acc: 0.5878
1408/9333 [===>..........................] - ETA: 15:03 - loss: 0.6724 - acc: 0.5881
1472/9333 [===>..........................] - ETA: 14:54 - loss: 0.6745 - acc: 0.5842
1536/9333 [===>..........................] - ETA: 14:54 - loss: 0.6746 - acc: 0.5833
1600/9333 [====>.........................] - ETA: 14:47 - loss: 0.6757 - acc: 0.5813
1664/9333 [====>.........................] - ETA: 14:41 - loss: 0.6743 - acc: 0.5841
1728/9333 [====>.........................] - ETA: 14:41 - loss: 0.6748 - acc: 0.5839
1792/9333 [====>.........................] - ETA: 14:33 - loss: 0.6758 - acc: 0.5826
1856/9333 [====>.........................] - ETA: 14:23 - loss: 0.6755 - acc: 0.5819
1920/9333 [=====>........................] - ETA: 14:15 - loss: 0.6741 - acc: 0.5854
1984/9333 [=====>........................] - ETA: 14:05 - loss: 0.6735 - acc: 0.5857
2048/9333 [=====>........................] - ETA: 13:55 - loss: 0.6736 - acc: 0.5850
2112/9333 [=====>........................] - ETA: 13:46 - loss: 0.6726 - acc: 0.5876
2176/9333 [=====>........................] - ETA: 13:44 - loss: 0.6711 - acc: 0.5905
2240/9333 [======>.......................] - ETA: 13:37 - loss: 0.6709 - acc: 0.5906
2304/9333 [======>.......................] - ETA: 13:29 - loss: 0.6708 - acc: 0.5903
2368/9333 [======>.......................] - ETA: 13:21 - loss: 0.6718 - acc: 0.5891
2432/9333 [======>.......................] - ETA: 13:16 - loss: 0.6731 - acc: 0.5863
2496/9333 [=======>......................] - ETA: 13:08 - loss: 0.6723 - acc: 0.5877
2560/9333 [=======>......................] - ETA: 12:59 - loss: 0.6734 - acc: 0.5863
2624/9333 [=======>......................] - ETA: 12:52 - loss: 0.6740 - acc: 0.5857
2688/9333 [=======>......................] - ETA: 12:43 - loss: 0.6753 - acc: 0.5837
2752/9333 [=======>......................] - ETA: 12:34 - loss: 0.6747 - acc: 0.5858
2816/9333 [========>.....................] - ETA: 12:25 - loss: 0.6747 - acc: 0.5870
2880/9333 [========>.....................] - ETA: 12:24 - loss: 0.6755 - acc: 0.5854
2944/9333 [========>.....................] - ETA: 12:17 - loss: 0.6762 - acc: 0.5842
3008/9333 [========>.....................] - ETA: 12:10 - loss: 0.6763 - acc: 0.5824
3072/9333 [========>.....................] - ETA: 12:03 - loss: 0.6760 - acc: 0.5824
3136/9333 [=========>....................] - ETA: 11:56 - loss: 0.6765 - acc: 0.5800
3200/9333 [=========>....................] - ETA: 11:48 - loss: 0.6769 - acc: 0.5794
3264/9333 [=========>....................] - ETA: 11:40 - loss: 0.6764 - acc: 0.5806
3328/9333 [=========>....................] - ETA: 11:31 - loss: 0.6766 - acc: 0.5799
3392/9333 [=========>....................] - ETA: 11:22 - loss: 0.6765 - acc: 0.5799
3456/9333 [==========>...................] - ETA: 11:15 - loss: 0.6767 - acc: 0.5790
3520/9333 [==========>...................] - ETA: 11:08 - loss: 0.6767 - acc: 0.5784
3584/9333 [==========>...................] - ETA: 11:01 - loss: 0.6771 - acc: 0.5767
3648/9333 [==========>...................] - ETA: 10:54 - loss: 0.6763 - acc: 0.5781
3712/9333 [==========>...................] - ETA: 10:47 - loss: 0.6764 - acc: 0.5776
3776/9333 [===========>..................] - ETA: 10:39 - loss: 0.6769 - acc: 0.5776
3840/9333 [===========>..................] - ETA: 10:33 - loss: 0.6771 - acc: 0.5753
3904/9333 [===========>..................] - ETA: 10:25 - loss: 0.6770 - acc: 0.5763
3968/9333 [===========>..................] - ETA: 10:18 - loss: 0.6770 - acc: 0.5756
4032/9333 [===========>..................] - ETA: 10:10 - loss: 0.6769 - acc: 0.5759
4096/9333 [============>.................] - ETA: 10:03 - loss: 0.6775 - acc: 0.5735
4160/9333 [============>.................] - ETA: 9:56 - loss: 0.6775 - acc: 0.5738 
4224/9333 [============>.................] - ETA: 9:48 - loss: 0.6780 - acc: 0.5727
4288/9333 [============>.................] - ETA: 9:41 - loss: 0.6778 - acc: 0.5732
4352/9333 [============>.................] - ETA: 9:35 - loss: 0.6778 - acc: 0.5728
4416/9333 [=============>................] - ETA: 9:28 - loss: 0.6777 - acc: 0.5731
4480/9333 [=============>................] - ETA: 9:20 - loss: 0.6781 - acc: 0.5723
4544/9333 [=============>................] - ETA: 9:13 - loss: 0.6779 - acc: 0.5735
4608/9333 [=============>................] - ETA: 9:06 - loss: 0.6780 - acc: 0.5736
4672/9333 [==============>...............] - ETA: 8:59 - loss: 0.6782 - acc: 0.5732
4736/9333 [==============>...............] - ETA: 8:51 - loss: 0.6780 - acc: 0.5743
4800/9333 [==============>...............] - ETA: 8:43 - loss: 0.6779 - acc: 0.5744
4864/9333 [==============>...............] - ETA: 8:35 - loss: 0.6782 - acc: 0.5742
4928/9333 [==============>...............] - ETA: 8:28 - loss: 0.6780 - acc: 0.5747
4992/9333 [===============>..............] - ETA: 8:21 - loss: 0.6782 - acc: 0.5749
5056/9333 [===============>..............] - ETA: 8:13 - loss: 0.6780 - acc: 0.5754
5120/9333 [===============>..............] - ETA: 8:04 - loss: 0.6782 - acc: 0.5750
5184/9333 [===============>..............] - ETA: 7:56 - loss: 0.6784 - acc: 0.5748
5248/9333 [===============>..............] - ETA: 7:48 - loss: 0.6787 - acc: 0.5741
5312/9333 [================>.............] - ETA: 7:41 - loss: 0.6787 - acc: 0.5736
5376/9333 [================>.............] - ETA: 7:33 - loss: 0.6787 - acc: 0.5737
5440/9333 [================>.............] - ETA: 7:25 - loss: 0.6787 - acc: 0.5743
5504/9333 [================>.............] - ETA: 7:18 - loss: 0.6786 - acc: 0.5738
5568/9333 [================>.............] - ETA: 7:10 - loss: 0.6786 - acc: 0.5735
5632/9333 [=================>............] - ETA: 7:02 - loss: 0.6784 - acc: 0.5744
5696/9333 [=================>............] - ETA: 6:54 - loss: 0.6782 - acc: 0.5741
5760/9333 [=================>............] - ETA: 6:47 - loss: 0.6779 - acc: 0.5752
5824/9333 [=================>............] - ETA: 6:39 - loss: 0.6776 - acc: 0.5761
5888/9333 [=================>............] - ETA: 6:32 - loss: 0.6776 - acc: 0.5761
5952/9333 [==================>...........] - ETA: 6:25 - loss: 0.6772 - acc: 0.5766
6016/9333 [==================>...........] - ETA: 6:18 - loss: 0.6774 - acc: 0.5756
6080/9333 [==================>...........] - ETA: 6:10 - loss: 0.6772 - acc: 0.5758
6144/9333 [==================>...........] - ETA: 6:03 - loss: 0.6769 - acc: 0.5760
6208/9333 [==================>...........] - ETA: 5:56 - loss: 0.6774 - acc: 0.5755
6272/9333 [===================>..........] - ETA: 5:48 - loss: 0.6771 - acc: 0.5765
6336/9333 [===================>..........] - ETA: 5:40 - loss: 0.6772 - acc: 0.5758
6400/9333 [===================>..........] - ETA: 5:33 - loss: 0.6772 - acc: 0.5756
6464/9333 [===================>..........] - ETA: 5:26 - loss: 0.6773 - acc: 0.5756
6528/9333 [===================>..........] - ETA: 5:19 - loss: 0.6773 - acc: 0.5761
6592/9333 [====================>.........] - ETA: 5:11 - loss: 0.6772 - acc: 0.5769
6656/9333 [====================>.........] - ETA: 5:04 - loss: 0.6773 - acc: 0.5771
6720/9333 [====================>.........] - ETA: 4:56 - loss: 0.6777 - acc: 0.5759
6784/9333 [====================>.........] - ETA: 4:48 - loss: 0.6778 - acc: 0.5759
6848/9333 [=====================>........] - ETA: 4:41 - loss: 0.6782 - acc: 0.5754
6912/9333 [=====================>........] - ETA: 4:33 - loss: 0.6785 - acc: 0.5748
6976/9333 [=====================>........] - ETA: 4:26 - loss: 0.6788 - acc: 0.5745
7040/9333 [=====================>........] - ETA: 4:19 - loss: 0.6792 - acc: 0.5740
7104/9333 [=====================>........] - ETA: 4:12 - loss: 0.6791 - acc: 0.5738
7168/9333 [======================>.......] - ETA: 4:04 - loss: 0.6789 - acc: 0.5744
7232/9333 [======================>.......] - ETA: 3:57 - loss: 0.6789 - acc: 0.5741
7296/9333 [======================>.......] - ETA: 3:50 - loss: 0.6791 - acc: 0.5739
7360/9333 [======================>.......] - ETA: 3:42 - loss: 0.6792 - acc: 0.5736
7424/9333 [======================>.......] - ETA: 3:35 - loss: 0.6791 - acc: 0.5739
7488/9333 [=======================>......] - ETA: 3:28 - loss: 0.6790 - acc: 0.5740
7552/9333 [=======================>......] - ETA: 3:20 - loss: 0.6791 - acc: 0.5738
7616/9333 [=======================>......] - ETA: 3:13 - loss: 0.6792 - acc: 0.5734
7680/9333 [=======================>......] - ETA: 3:06 - loss: 0.6792 - acc: 0.5737
7744/9333 [=======================>......] - ETA: 2:58 - loss: 0.6791 - acc: 0.5741
7808/9333 [========================>.....] - ETA: 2:51 - loss: 0.6791 - acc: 0.5743
7872/9333 [========================>.....] - ETA: 2:44 - loss: 0.6792 - acc: 0.5736
7936/9333 [========================>.....] - ETA: 2:37 - loss: 0.6794 - acc: 0.5733
8000/9333 [========================>.....] - ETA: 2:29 - loss: 0.6793 - acc: 0.5733
8064/9333 [========================>.....] - ETA: 2:22 - loss: 0.6795 - acc: 0.5725
8128/9333 [=========================>....] - ETA: 2:15 - loss: 0.6795 - acc: 0.5723
8192/9333 [=========================>....] - ETA: 2:08 - loss: 0.6793 - acc: 0.5729
8256/9333 [=========================>....] - ETA: 2:00 - loss: 0.6793 - acc: 0.5728
8320/9333 [=========================>....] - ETA: 1:53 - loss: 0.6792 - acc: 0.5732
8384/9333 [=========================>....] - ETA: 1:46 - loss: 0.6794 - acc: 0.5729
8448/9333 [==========================>...] - ETA: 1:39 - loss: 0.6794 - acc: 0.5729
8512/9333 [==========================>...] - ETA: 1:31 - loss: 0.6793 - acc: 0.5726
8576/9333 [==========================>...] - ETA: 1:24 - loss: 0.6793 - acc: 0.5725
8640/9333 [==========================>...] - ETA: 1:17 - loss: 0.6791 - acc: 0.5729
8704/9333 [==========================>...] - ETA: 1:10 - loss: 0.6790 - acc: 0.5738
8768/9333 [===========================>..] - ETA: 1:03 - loss: 0.6789 - acc: 0.5741
8832/9333 [===========================>..] - ETA: 55s - loss: 0.6789 - acc: 0.5743 
8896/9333 [===========================>..] - ETA: 48s - loss: 0.6791 - acc: 0.5740
8960/9333 [===========================>..] - ETA: 41s - loss: 0.6793 - acc: 0.5737
9024/9333 [============================>.] - ETA: 34s - loss: 0.6792 - acc: 0.5742
9088/9333 [============================>.] - ETA: 27s - loss: 0.6792 - acc: 0.5739
9152/9333 [============================>.] - ETA: 20s - loss: 0.6792 - acc: 0.5741
9216/9333 [============================>.] - ETA: 12s - loss: 0.6792 - acc: 0.5742
9280/9333 [============================>.] - ETA: 5s - loss: 0.6795 - acc: 0.5736 
9333/9333 [==============================] - 1065s 114ms/step - loss: 0.6796 - acc: 0.5733 - val_loss: 0.6878 - val_acc: 0.5419

Epoch 00008: val_acc did not improve from 0.55545
Epoch 9/10

  64/9333 [..............................] - ETA: 14:25 - loss: 0.6759 - acc: 0.5938
 128/9333 [..............................] - ETA: 14:16 - loss: 0.7043 - acc: 0.5156
 192/9333 [..............................] - ETA: 14:00 - loss: 0.6838 - acc: 0.5417
 256/9333 [..............................] - ETA: 14:14 - loss: 0.6793 - acc: 0.5703
 320/9333 [>.............................] - ETA: 14:07 - loss: 0.6727 - acc: 0.5875
 384/9333 [>.............................] - ETA: 13:58 - loss: 0.6757 - acc: 0.5885
 448/9333 [>.............................] - ETA: 13:48 - loss: 0.6747 - acc: 0.5938
 512/9333 [>.............................] - ETA: 13:52 - loss: 0.6771 - acc: 0.5801
 576/9333 [>.............................] - ETA: 13:46 - loss: 0.6782 - acc: 0.5764
 640/9333 [=>............................] - ETA: 13:36 - loss: 0.6746 - acc: 0.5875
 704/9333 [=>............................] - ETA: 13:29 - loss: 0.6722 - acc: 0.5895
 768/9333 [=>............................] - ETA: 13:31 - loss: 0.6754 - acc: 0.5846
 832/9333 [=>............................] - ETA: 13:23 - loss: 0.6769 - acc: 0.5829
 896/9333 [=>............................] - ETA: 13:16 - loss: 0.6796 - acc: 0.5759
 960/9333 [==>...........................] - ETA: 13:11 - loss: 0.6806 - acc: 0.5771
1024/9333 [==>...........................] - ETA: 13:08 - loss: 0.6820 - acc: 0.5742
1088/9333 [==>...........................] - ETA: 13:03 - loss: 0.6817 - acc: 0.5763
1152/9333 [==>...........................] - ETA: 12:56 - loss: 0.6808 - acc: 0.5781
1216/9333 [==>...........................] - ETA: 12:48 - loss: 0.6807 - acc: 0.5765
1280/9333 [===>..........................] - ETA: 12:47 - loss: 0.6806 - acc: 0.5727
1344/9333 [===>..........................] - ETA: 12:42 - loss: 0.6791 - acc: 0.5759
1408/9333 [===>..........................] - ETA: 12:36 - loss: 0.6789 - acc: 0.5781
1472/9333 [===>..........................] - ETA: 12:28 - loss: 0.6801 - acc: 0.5747
1536/9333 [===>..........................] - ETA: 12:21 - loss: 0.6815 - acc: 0.5703
1600/9333 [====>.........................] - ETA: 12:17 - loss: 0.6821 - acc: 0.5694
1664/9333 [====>.........................] - ETA: 12:11 - loss: 0.6820 - acc: 0.5685
1728/9333 [====>.........................] - ETA: 12:04 - loss: 0.6825 - acc: 0.5689
1792/9333 [====>.........................] - ETA: 11:56 - loss: 0.6811 - acc: 0.5709
1856/9333 [====>.........................] - ETA: 11:51 - loss: 0.6814 - acc: 0.5695
1920/9333 [=====>........................] - ETA: 11:44 - loss: 0.6810 - acc: 0.5698
1984/9333 [=====>........................] - ETA: 11:39 - loss: 0.6815 - acc: 0.5701
2048/9333 [=====>........................] - ETA: 11:32 - loss: 0.6811 - acc: 0.5718
2112/9333 [=====>........................] - ETA: 11:28 - loss: 0.6803 - acc: 0.5720
2176/9333 [=====>........................] - ETA: 11:20 - loss: 0.6805 - acc: 0.5726
2240/9333 [======>.......................] - ETA: 11:15 - loss: 0.6788 - acc: 0.5759
2304/9333 [======>.......................] - ETA: 11:09 - loss: 0.6788 - acc: 0.5773
2368/9333 [======>.......................] - ETA: 11:03 - loss: 0.6797 - acc: 0.5773
2432/9333 [======>.......................] - ETA: 10:56 - loss: 0.6790 - acc: 0.5777
2496/9333 [=======>......................] - ETA: 10:49 - loss: 0.6785 - acc: 0.5785
2560/9333 [=======>......................] - ETA: 10:42 - loss: 0.6791 - acc: 0.5781
2624/9333 [=======>......................] - ETA: 10:37 - loss: 0.6780 - acc: 0.5816
2688/9333 [=======>......................] - ETA: 10:31 - loss: 0.6774 - acc: 0.5822
2752/9333 [=======>......................] - ETA: 10:24 - loss: 0.6781 - acc: 0.5810
2816/9333 [========>.....................] - ETA: 10:17 - loss: 0.6783 - acc: 0.5792
2880/9333 [========>.....................] - ETA: 10:11 - loss: 0.6778 - acc: 0.5795
2944/9333 [========>.....................] - ETA: 10:05 - loss: 0.6776 - acc: 0.5808
3008/9333 [========>.....................] - ETA: 10:00 - loss: 0.6777 - acc: 0.5814
3072/9333 [========>.....................] - ETA: 9:53 - loss: 0.6783 - acc: 0.5798 
3136/9333 [=========>....................] - ETA: 9:46 - loss: 0.6792 - acc: 0.5778
3200/9333 [=========>....................] - ETA: 9:42 - loss: 0.6789 - acc: 0.5784
3264/9333 [=========>....................] - ETA: 9:36 - loss: 0.6788 - acc: 0.5778
3328/9333 [=========>....................] - ETA: 9:30 - loss: 0.6784 - acc: 0.5793
3392/9333 [=========>....................] - ETA: 9:27 - loss: 0.6785 - acc: 0.5796
3456/9333 [==========>...................] - ETA: 9:22 - loss: 0.6774 - acc: 0.5828
3520/9333 [==========>...................] - ETA: 9:18 - loss: 0.6773 - acc: 0.5824
3584/9333 [==========>...................] - ETA: 9:12 - loss: 0.6774 - acc: 0.5818
3648/9333 [==========>...................] - ETA: 9:07 - loss: 0.6769 - acc: 0.5828
3712/9333 [==========>...................] - ETA: 9:01 - loss: 0.6768 - acc: 0.5835
3776/9333 [===========>..................] - ETA: 8:56 - loss: 0.6770 - acc: 0.5832
3840/9333 [===========>..................] - ETA: 8:50 - loss: 0.6776 - acc: 0.5815
3904/9333 [===========>..................] - ETA: 8:44 - loss: 0.6773 - acc: 0.5812
3968/9333 [===========>..................] - ETA: 8:39 - loss: 0.6769 - acc: 0.5829
4032/9333 [===========>..................] - ETA: 8:34 - loss: 0.6777 - acc: 0.5804
4096/9333 [============>.................] - ETA: 8:29 - loss: 0.6781 - acc: 0.5793
4160/9333 [============>.................] - ETA: 8:22 - loss: 0.6782 - acc: 0.5793
4224/9333 [============>.................] - ETA: 8:16 - loss: 0.6783 - acc: 0.5793
4288/9333 [============>.................] - ETA: 8:11 - loss: 0.6790 - acc: 0.5770
4352/9333 [============>.................] - ETA: 8:05 - loss: 0.6787 - acc: 0.5777
4416/9333 [=============>................] - ETA: 8:00 - loss: 0.6791 - acc: 0.5772
4480/9333 [=============>................] - ETA: 7:54 - loss: 0.6796 - acc: 0.5754
4544/9333 [=============>................] - ETA: 7:48 - loss: 0.6793 - acc: 0.5759
4608/9333 [=============>................] - ETA: 7:43 - loss: 0.6790 - acc: 0.5766
4672/9333 [==============>...............] - ETA: 7:38 - loss: 0.6789 - acc: 0.5775
4736/9333 [==============>...............] - ETA: 7:32 - loss: 0.6788 - acc: 0.5779
4800/9333 [==============>...............] - ETA: 7:26 - loss: 0.6789 - acc: 0.5775
4864/9333 [==============>...............] - ETA: 7:20 - loss: 0.6791 - acc: 0.5769
4928/9333 [==============>...............] - ETA: 7:14 - loss: 0.6791 - acc: 0.5771
4992/9333 [===============>..............] - ETA: 7:08 - loss: 0.6787 - acc: 0.5783
5056/9333 [===============>..............] - ETA: 7:02 - loss: 0.6787 - acc: 0.5775
5120/9333 [===============>..............] - ETA: 6:56 - loss: 0.6787 - acc: 0.5779
5184/9333 [===============>..............] - ETA: 6:50 - loss: 0.6790 - acc: 0.5774
5248/9333 [===============>..............] - ETA: 6:44 - loss: 0.6788 - acc: 0.5783
5312/9333 [================>.............] - ETA: 6:38 - loss: 0.6783 - acc: 0.5789
5376/9333 [================>.............] - ETA: 6:32 - loss: 0.6780 - acc: 0.5798
5440/9333 [================>.............] - ETA: 6:25 - loss: 0.6781 - acc: 0.5787
5504/9333 [================>.............] - ETA: 6:20 - loss: 0.6782 - acc: 0.5785
5568/9333 [================>.............] - ETA: 6:14 - loss: 0.6781 - acc: 0.5785
5632/9333 [=================>............] - ETA: 6:08 - loss: 0.6782 - acc: 0.5783
5696/9333 [=================>............] - ETA: 6:02 - loss: 0.6787 - acc: 0.5771
5760/9333 [=================>............] - ETA: 5:56 - loss: 0.6793 - acc: 0.5757
5824/9333 [=================>............] - ETA: 5:50 - loss: 0.6796 - acc: 0.5750
5888/9333 [=================>............] - ETA: 5:43 - loss: 0.6794 - acc: 0.5756
5952/9333 [==================>...........] - ETA: 5:37 - loss: 0.6792 - acc: 0.5759
6016/9333 [==================>...........] - ETA: 5:31 - loss: 0.6792 - acc: 0.5756
6080/9333 [==================>...........] - ETA: 5:24 - loss: 0.6791 - acc: 0.5757
6144/9333 [==================>...........] - ETA: 5:19 - loss: 0.6789 - acc: 0.5758
6208/9333 [==================>...........] - ETA: 5:12 - loss: 0.6787 - acc: 0.5767
6272/9333 [===================>..........] - ETA: 5:07 - loss: 0.6790 - acc: 0.5761
6336/9333 [===================>..........] - ETA: 5:01 - loss: 0.6793 - acc: 0.5747
6400/9333 [===================>..........] - ETA: 4:54 - loss: 0.6794 - acc: 0.5750
6464/9333 [===================>..........] - ETA: 4:48 - loss: 0.6797 - acc: 0.5738
6528/9333 [===================>..........] - ETA: 4:42 - loss: 0.6797 - acc: 0.5738
6592/9333 [====================>.........] - ETA: 4:35 - loss: 0.6798 - acc: 0.5739
6656/9333 [====================>.........] - ETA: 4:29 - loss: 0.6798 - acc: 0.5744
6720/9333 [====================>.........] - ETA: 4:23 - loss: 0.6798 - acc: 0.5744
6784/9333 [====================>.........] - ETA: 4:17 - loss: 0.6799 - acc: 0.5740
6848/9333 [=====================>........] - ETA: 4:10 - loss: 0.6796 - acc: 0.5743
6912/9333 [=====================>........] - ETA: 4:04 - loss: 0.6797 - acc: 0.5741
6976/9333 [=====================>........] - ETA: 3:57 - loss: 0.6796 - acc: 0.5738
7040/9333 [=====================>........] - ETA: 3:51 - loss: 0.6794 - acc: 0.5746
7104/9333 [=====================>........] - ETA: 3:45 - loss: 0.6793 - acc: 0.5753
7168/9333 [======================>.......] - ETA: 3:38 - loss: 0.6791 - acc: 0.5756
7232/9333 [======================>.......] - ETA: 3:32 - loss: 0.6792 - acc: 0.5748
7296/9333 [======================>.......] - ETA: 3:25 - loss: 0.6792 - acc: 0.5748
7360/9333 [======================>.......] - ETA: 3:19 - loss: 0.6789 - acc: 0.5755
7424/9333 [======================>.......] - ETA: 3:12 - loss: 0.6789 - acc: 0.5749
7488/9333 [=======================>......] - ETA: 3:06 - loss: 0.6788 - acc: 0.5745
7552/9333 [=======================>......] - ETA: 3:00 - loss: 0.6785 - acc: 0.5749
7616/9333 [=======================>......] - ETA: 2:53 - loss: 0.6787 - acc: 0.5748
7680/9333 [=======================>......] - ETA: 2:47 - loss: 0.6783 - acc: 0.5755
7744/9333 [=======================>......] - ETA: 2:40 - loss: 0.6783 - acc: 0.5757
7808/9333 [========================>.....] - ETA: 2:34 - loss: 0.6786 - acc: 0.5751
7872/9333 [========================>.....] - ETA: 2:27 - loss: 0.6787 - acc: 0.5746
7936/9333 [========================>.....] - ETA: 2:21 - loss: 0.6786 - acc: 0.5747
8000/9333 [========================>.....] - ETA: 2:14 - loss: 0.6785 - acc: 0.5750
8064/9333 [========================>.....] - ETA: 2:08 - loss: 0.6785 - acc: 0.5749
8128/9333 [=========================>....] - ETA: 2:01 - loss: 0.6785 - acc: 0.5742
8192/9333 [=========================>....] - ETA: 1:55 - loss: 0.6788 - acc: 0.5737
8256/9333 [=========================>....] - ETA: 1:48 - loss: 0.6789 - acc: 0.5735
8320/9333 [=========================>....] - ETA: 1:42 - loss: 0.6792 - acc: 0.5726
8384/9333 [=========================>....] - ETA: 1:36 - loss: 0.6792 - acc: 0.5724
8448/9333 [==========================>...] - ETA: 1:29 - loss: 0.6791 - acc: 0.5715
8512/9333 [==========================>...] - ETA: 1:23 - loss: 0.6790 - acc: 0.5719
8576/9333 [==========================>...] - ETA: 1:16 - loss: 0.6791 - acc: 0.5716
8640/9333 [==========================>...] - ETA: 1:10 - loss: 0.6789 - acc: 0.5718
8704/9333 [==========================>...] - ETA: 1:03 - loss: 0.6792 - acc: 0.5710
8768/9333 [===========================>..] - ETA: 57s - loss: 0.6794 - acc: 0.5703 
8832/9333 [===========================>..] - ETA: 51s - loss: 0.6795 - acc: 0.5703
8896/9333 [===========================>..] - ETA: 44s - loss: 0.6795 - acc: 0.5699
8960/9333 [===========================>..] - ETA: 38s - loss: 0.6795 - acc: 0.5701
9024/9333 [============================>.] - ETA: 31s - loss: 0.6792 - acc: 0.5708
9088/9333 [============================>.] - ETA: 24s - loss: 0.6793 - acc: 0.5702
9152/9333 [============================>.] - ETA: 18s - loss: 0.6794 - acc: 0.5697
9216/9333 [============================>.] - ETA: 11s - loss: 0.6793 - acc: 0.5701
9280/9333 [============================>.] - ETA: 5s - loss: 0.6794 - acc: 0.5703 
9333/9333 [==============================] - 993s 106ms/step - loss: 0.6796 - acc: 0.5697 - val_loss: 0.7056 - val_acc: 0.5294

Epoch 00009: val_acc did not improve from 0.55545
Epoch 10/10

  64/9333 [..............................] - ETA: 16:02 - loss: 0.6675 - acc: 0.6094
 128/9333 [..............................] - ETA: 15:33 - loss: 0.6710 - acc: 0.6172
 192/9333 [..............................] - ETA: 15:38 - loss: 0.6763 - acc: 0.5885
 256/9333 [..............................] - ETA: 15:37 - loss: 0.6696 - acc: 0.5977
 320/9333 [>.............................] - ETA: 15:31 - loss: 0.6730 - acc: 0.5906
 384/9333 [>.............................] - ETA: 15:34 - loss: 0.6818 - acc: 0.5677
 448/9333 [>.............................] - ETA: 15:29 - loss: 0.6756 - acc: 0.5848
 512/9333 [>.............................] - ETA: 15:24 - loss: 0.6773 - acc: 0.5762
 576/9333 [>.............................] - ETA: 15:20 - loss: 0.6789 - acc: 0.5764
 640/9333 [=>............................] - ETA: 15:20 - loss: 0.6803 - acc: 0.5750
 704/9333 [=>............................] - ETA: 15:17 - loss: 0.6781 - acc: 0.5739
 768/9333 [=>............................] - ETA: 15:19 - loss: 0.6793 - acc: 0.5729
 832/9333 [=>............................] - ETA: 15:15 - loss: 0.6805 - acc: 0.5697
 896/9333 [=>............................] - ETA: 15:09 - loss: 0.6786 - acc: 0.5692
 960/9333 [==>...........................] - ETA: 15:01 - loss: 0.6790 - acc: 0.5667
1024/9333 [==>...........................] - ETA: 14:54 - loss: 0.6773 - acc: 0.5723
1088/9333 [==>...........................] - ETA: 14:48 - loss: 0.6766 - acc: 0.5772
1152/9333 [==>...........................] - ETA: 14:40 - loss: 0.6754 - acc: 0.5807
1216/9333 [==>...........................] - ETA: 14:31 - loss: 0.6755 - acc: 0.5822
1280/9333 [===>..........................] - ETA: 14:23 - loss: 0.6751 - acc: 0.5813
1344/9333 [===>..........................] - ETA: 14:15 - loss: 0.6756 - acc: 0.5804
1408/9333 [===>..........................] - ETA: 14:15 - loss: 0.6757 - acc: 0.5817
1472/9333 [===>..........................] - ETA: 14:09 - loss: 0.6758 - acc: 0.5808
1536/9333 [===>..........................] - ETA: 13:59 - loss: 0.6762 - acc: 0.5794
1600/9333 [====>.........................] - ETA: 13:50 - loss: 0.6782 - acc: 0.5737
1664/9333 [====>.........................] - ETA: 13:42 - loss: 0.6780 - acc: 0.5733
1728/9333 [====>.........................] - ETA: 13:32 - loss: 0.6775 - acc: 0.5741
1792/9333 [====>.........................] - ETA: 13:23 - loss: 0.6778 - acc: 0.5725
1856/9333 [====>.........................] - ETA: 13:13 - loss: 0.6774 - acc: 0.5727
1920/9333 [=====>........................] - ETA: 13:06 - loss: 0.6765 - acc: 0.5734
1984/9333 [=====>........................] - ETA: 12:57 - loss: 0.6748 - acc: 0.5736
2048/9333 [=====>........................] - ETA: 12:47 - loss: 0.6743 - acc: 0.5742
2112/9333 [=====>........................] - ETA: 12:38 - loss: 0.6757 - acc: 0.5705
2176/9333 [=====>........................] - ETA: 12:31 - loss: 0.6764 - acc: 0.5708
2240/9333 [======>.......................] - ETA: 12:23 - loss: 0.6777 - acc: 0.5692
2304/9333 [======>.......................] - ETA: 12:14 - loss: 0.6768 - acc: 0.5707
2368/9333 [======>.......................] - ETA: 12:06 - loss: 0.6770 - acc: 0.5697
2432/9333 [======>.......................] - ETA: 11:59 - loss: 0.6766 - acc: 0.5703
2496/9333 [=======>......................] - ETA: 11:50 - loss: 0.6775 - acc: 0.5689
2560/9333 [=======>......................] - ETA: 11:42 - loss: 0.6778 - acc: 0.5664
2624/9333 [=======>......................] - ETA: 11:33 - loss: 0.6770 - acc: 0.5682
2688/9333 [=======>......................] - ETA: 11:26 - loss: 0.6775 - acc: 0.5673
2752/9333 [=======>......................] - ETA: 11:19 - loss: 0.6774 - acc: 0.5665
2816/9333 [========>.....................] - ETA: 11:10 - loss: 0.6781 - acc: 0.5636
2880/9333 [========>.....................] - ETA: 11:03 - loss: 0.6785 - acc: 0.5618
2944/9333 [========>.....................] - ETA: 10:56 - loss: 0.6794 - acc: 0.5598
3008/9333 [========>.....................] - ETA: 10:48 - loss: 0.6799 - acc: 0.5585
3072/9333 [========>.....................] - ETA: 10:39 - loss: 0.6802 - acc: 0.5586
3136/9333 [=========>....................] - ETA: 10:32 - loss: 0.6800 - acc: 0.5596
3200/9333 [=========>....................] - ETA: 10:25 - loss: 0.6792 - acc: 0.5631
3264/9333 [=========>....................] - ETA: 10:17 - loss: 0.6796 - acc: 0.5610
3328/9333 [=========>....................] - ETA: 10:09 - loss: 0.6798 - acc: 0.5610
3392/9333 [=========>....................] - ETA: 10:04 - loss: 0.6799 - acc: 0.5610
3456/9333 [==========>...................] - ETA: 9:56 - loss: 0.6797 - acc: 0.5608 
3520/9333 [==========>...................] - ETA: 9:49 - loss: 0.6797 - acc: 0.5611
3584/9333 [==========>...................] - ETA: 9:41 - loss: 0.6796 - acc: 0.5614
3648/9333 [==========>...................] - ETA: 9:34 - loss: 0.6802 - acc: 0.5598
3712/9333 [==========>...................] - ETA: 9:27 - loss: 0.6802 - acc: 0.5598
3776/9333 [===========>..................] - ETA: 9:20 - loss: 0.6802 - acc: 0.5599
3840/9333 [===========>..................] - ETA: 9:13 - loss: 0.6799 - acc: 0.5602
3904/9333 [===========>..................] - ETA: 9:06 - loss: 0.6799 - acc: 0.5610
3968/9333 [===========>..................] - ETA: 8:58 - loss: 0.6797 - acc: 0.5620
4032/9333 [===========>..................] - ETA: 8:51 - loss: 0.6802 - acc: 0.5595
4096/9333 [============>.................] - ETA: 8:44 - loss: 0.6803 - acc: 0.5598
4160/9333 [============>.................] - ETA: 8:37 - loss: 0.6803 - acc: 0.5603
4224/9333 [============>.................] - ETA: 8:30 - loss: 0.6797 - acc: 0.5620
4288/9333 [============>.................] - ETA: 8:23 - loss: 0.6800 - acc: 0.5620
4352/9333 [============>.................] - ETA: 8:17 - loss: 0.6796 - acc: 0.5620
4416/9333 [=============>................] - ETA: 8:10 - loss: 0.6799 - acc: 0.5614
4480/9333 [=============>................] - ETA: 8:03 - loss: 0.6795 - acc: 0.5629
4544/9333 [=============>................] - ETA: 7:56 - loss: 0.6799 - acc: 0.5632
4608/9333 [=============>................] - ETA: 7:50 - loss: 0.6793 - acc: 0.5638
4672/9333 [==============>...............] - ETA: 7:43 - loss: 0.6795 - acc: 0.5623
4736/9333 [==============>...............] - ETA: 7:37 - loss: 0.6792 - acc: 0.5631
4800/9333 [==============>...............] - ETA: 7:32 - loss: 0.6798 - acc: 0.5617
4864/9333 [==============>...............] - ETA: 7:26 - loss: 0.6797 - acc: 0.5621
4928/9333 [==============>...............] - ETA: 7:20 - loss: 0.6796 - acc: 0.5621
4992/9333 [===============>..............] - ETA: 7:14 - loss: 0.6796 - acc: 0.5621
5056/9333 [===============>..............] - ETA: 7:07 - loss: 0.6794 - acc: 0.5625
5120/9333 [===============>..............] - ETA: 7:02 - loss: 0.6796 - acc: 0.5625
5184/9333 [===============>..............] - ETA: 6:56 - loss: 0.6799 - acc: 0.5625
5248/9333 [===============>..............] - ETA: 6:50 - loss: 0.6796 - acc: 0.5631
5312/9333 [================>.............] - ETA: 6:45 - loss: 0.6797 - acc: 0.5625
5376/9333 [================>.............] - ETA: 6:38 - loss: 0.6792 - acc: 0.5642
5440/9333 [================>.............] - ETA: 6:31 - loss: 0.6791 - acc: 0.5643
5504/9333 [================>.............] - ETA: 6:26 - loss: 0.6790 - acc: 0.5645
5568/9333 [================>.............] - ETA: 6:20 - loss: 0.6788 - acc: 0.5645
5632/9333 [=================>............] - ETA: 6:13 - loss: 0.6791 - acc: 0.5648
5696/9333 [=================>............] - ETA: 6:07 - loss: 0.6792 - acc: 0.5643
5760/9333 [=================>............] - ETA: 6:01 - loss: 0.6794 - acc: 0.5641
5824/9333 [=================>............] - ETA: 5:55 - loss: 0.6794 - acc: 0.5649
5888/9333 [=================>............] - ETA: 5:48 - loss: 0.6794 - acc: 0.5640
5952/9333 [==================>...........] - ETA: 5:42 - loss: 0.6793 - acc: 0.5649
6016/9333 [==================>...........] - ETA: 5:36 - loss: 0.6794 - acc: 0.5647
6080/9333 [==================>...........] - ETA: 5:30 - loss: 0.6794 - acc: 0.5645
6144/9333 [==================>...........] - ETA: 5:24 - loss: 0.6792 - acc: 0.5653
6208/9333 [==================>...........] - ETA: 5:18 - loss: 0.6788 - acc: 0.5660
6272/9333 [===================>..........] - ETA: 5:11 - loss: 0.6790 - acc: 0.5662
6336/9333 [===================>..........] - ETA: 5:04 - loss: 0.6787 - acc: 0.5664
6400/9333 [===================>..........] - ETA: 4:58 - loss: 0.6790 - acc: 0.5659
6464/9333 [===================>..........] - ETA: 4:52 - loss: 0.6789 - acc: 0.5662
6528/9333 [===================>..........] - ETA: 4:45 - loss: 0.6789 - acc: 0.5666
6592/9333 [====================>.........] - ETA: 4:39 - loss: 0.6789 - acc: 0.5672
6656/9333 [====================>.........] - ETA: 4:33 - loss: 0.6790 - acc: 0.5666
6720/9333 [====================>.........] - ETA: 4:26 - loss: 0.6785 - acc: 0.5674
6784/9333 [====================>.........] - ETA: 4:19 - loss: 0.6782 - acc: 0.5681
6848/9333 [=====================>........] - ETA: 4:12 - loss: 0.6782 - acc: 0.5683
6912/9333 [=====================>........] - ETA: 4:06 - loss: 0.6782 - acc: 0.5689
6976/9333 [=====================>........] - ETA: 4:00 - loss: 0.6780 - acc: 0.5690
7040/9333 [=====================>........] - ETA: 3:54 - loss: 0.6776 - acc: 0.5693
7104/9333 [=====================>........] - ETA: 3:48 - loss: 0.6773 - acc: 0.5697
7168/9333 [======================>.......] - ETA: 3:41 - loss: 0.6774 - acc: 0.5698
7232/9333 [======================>.......] - ETA: 3:34 - loss: 0.6776 - acc: 0.5696
7296/9333 [======================>.......] - ETA: 3:28 - loss: 0.6774 - acc: 0.5702
7360/9333 [======================>.......] - ETA: 3:21 - loss: 0.6775 - acc: 0.5705
7424/9333 [======================>.......] - ETA: 3:15 - loss: 0.6777 - acc: 0.5707
7488/9333 [=======================>......] - ETA: 3:09 - loss: 0.6778 - acc: 0.5708
7552/9333 [=======================>......] - ETA: 3:03 - loss: 0.6782 - acc: 0.5699
7616/9333 [=======================>......] - ETA: 2:56 - loss: 0.6783 - acc: 0.5702
7680/9333 [=======================>......] - ETA: 2:49 - loss: 0.6781 - acc: 0.5711
7744/9333 [=======================>......] - ETA: 2:43 - loss: 0.6781 - acc: 0.5714
7808/9333 [========================>.....] - ETA: 2:36 - loss: 0.6784 - acc: 0.5707
7872/9333 [========================>.....] - ETA: 2:29 - loss: 0.6783 - acc: 0.5708
7936/9333 [========================>.....] - ETA: 2:23 - loss: 0.6782 - acc: 0.5708
8000/9333 [========================>.....] - ETA: 2:16 - loss: 0.6783 - acc: 0.5705
8064/9333 [========================>.....] - ETA: 2:10 - loss: 0.6784 - acc: 0.5704
8128/9333 [=========================>....] - ETA: 2:04 - loss: 0.6785 - acc: 0.5698
8192/9333 [=========================>....] - ETA: 1:57 - loss: 0.6783 - acc: 0.5702
8256/9333 [=========================>....] - ETA: 1:51 - loss: 0.6784 - acc: 0.5706
8320/9333 [=========================>....] - ETA: 1:44 - loss: 0.6786 - acc: 0.5704
8384/9333 [=========================>....] - ETA: 1:38 - loss: 0.6787 - acc: 0.5703
8448/9333 [==========================>...] - ETA: 1:31 - loss: 0.6785 - acc: 0.5702
8512/9333 [==========================>...] - ETA: 1:25 - loss: 0.6784 - acc: 0.5708
8576/9333 [==========================>...] - ETA: 1:18 - loss: 0.6783 - acc: 0.5712
8640/9333 [==========================>...] - ETA: 1:12 - loss: 0.6786 - acc: 0.5709
8704/9333 [==========================>...] - ETA: 1:05 - loss: 0.6786 - acc: 0.5710
8768/9333 [===========================>..] - ETA: 59s - loss: 0.6789 - acc: 0.5705 
8832/9333 [===========================>..] - ETA: 52s - loss: 0.6786 - acc: 0.5712
8896/9333 [===========================>..] - ETA: 45s - loss: 0.6785 - acc: 0.5715
8960/9333 [===========================>..] - ETA: 39s - loss: 0.6783 - acc: 0.5719
9024/9333 [============================>.] - ETA: 32s - loss: 0.6784 - acc: 0.5715
9088/9333 [============================>.] - ETA: 25s - loss: 0.6782 - acc: 0.5717
9152/9333 [============================>.] - ETA: 19s - loss: 0.6781 - acc: 0.5719
9216/9333 [============================>.] - ETA: 12s - loss: 0.6780 - acc: 0.5719
9280/9333 [============================>.] - ETA: 5s - loss: 0.6783 - acc: 0.5714 
9333/9333 [==============================] - 1020s 109ms/step - loss: 0.6784 - acc: 0.5709 - val_loss: 0.6996 - val_acc: 0.5169

Epoch 00010: val_acc did not improve from 0.55545
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3e24675310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3e24675310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3e2456c050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3e2456c050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e04680050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e04680050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e04680bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e04680bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e04610350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e04610350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e045bc4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e045bc4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e04680310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e04680310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e045b9810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e045b9810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e04560c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e04560c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e0454b590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e0454b590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e042e4210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e042e4210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e04261150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e04261150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38e472d750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38e472d750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f37c4488850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f37c4488850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e04444750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e04444750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37c4479f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37c4479f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e041a3fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e041a3fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e04444410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e04444410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e04058c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e04058c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3de4501890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3de4501890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3de441e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3de441e310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e04058fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e04058fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3de4387d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3de4387d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3de42bfa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3de42bfa50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3de4232f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3de4232f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3de431d0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3de431d0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3de42bfa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3de42bfa90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3de4366550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3de4366550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3dc47c6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3dc47c6910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3dc46976d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3dc46976d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3dc47efe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3dc47efe50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3dc47922d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3dc47922d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3dc4541b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3dc4541b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3dc4492310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3dc4492310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3dc476cd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3dc476cd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3964419590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3964419590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3dc47c0950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3dc47c0950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39644906d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39644906d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3dc43c7290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3dc43c7290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3dc40d2dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3dc40d2dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f406448e7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f406448e7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3dc41c58d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3dc41c58d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3dc415d890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3dc415d890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3cc43dc090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3cc43dc090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3cc42b3c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3cc42b3c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3cc4342950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3cc4342950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3cc43e8f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3cc43e8f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3dc40b9fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3dc40b9fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ca40633d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3ca40633d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ca40ae750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3ca40ae750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ca405ef10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3ca405ef10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3dc40cf8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3dc40cf8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3cc433f990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3cc433f990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c84560650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c84560650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c844c0990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c844c0990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c842d5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c842d5090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c84564710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c84564710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3de43218d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3de43218d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c84446fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c84446fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c840e32d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c840e32d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c84238850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c84238850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c84626950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c84626950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c8408f110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c8408f110>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 15:01
 128/2592 [>.............................] - ETA: 7:46 
 192/2592 [=>............................] - ETA: 5:20
 256/2592 [=>............................] - ETA: 4:10
 320/2592 [==>...........................] - ETA: 3:25
 384/2592 [===>..........................] - ETA: 2:54
 448/2592 [====>.........................] - ETA: 2:32
 512/2592 [====>.........................] - ETA: 2:15
 576/2592 [=====>........................] - ETA: 2:01
 640/2592 [======>.......................] - ETA: 1:50
 704/2592 [=======>......................] - ETA: 1:41
 768/2592 [=======>......................] - ETA: 1:33
 832/2592 [========>.....................] - ETA: 1:26
 896/2592 [=========>....................] - ETA: 1:21
 960/2592 [==========>...................] - ETA: 1:15
1024/2592 [==========>...................] - ETA: 1:10
1088/2592 [===========>..................] - ETA: 1:05
1152/2592 [============>.................] - ETA: 1:01
1216/2592 [=============>................] - ETA: 57s 
1280/2592 [=============>................] - ETA: 53s
1344/2592 [==============>...............] - ETA: 49s
1408/2592 [===============>..............] - ETA: 46s
1472/2592 [================>.............] - ETA: 42s
1536/2592 [================>.............] - ETA: 39s
1600/2592 [=================>............] - ETA: 36s
1664/2592 [==================>...........] - ETA: 34s
1728/2592 [===================>..........] - ETA: 31s
1792/2592 [===================>..........] - ETA: 28s
1856/2592 [====================>.........] - ETA: 26s
1920/2592 [=====================>........] - ETA: 23s
1984/2592 [=====================>........] - ETA: 21s
2048/2592 [======================>.......] - ETA: 18s
2112/2592 [=======================>......] - ETA: 16s
2176/2592 [========================>.....] - ETA: 14s
2240/2592 [========================>.....] - ETA: 11s
2304/2592 [=========================>....] - ETA: 9s 
2368/2592 [==========================>...] - ETA: 7s
2432/2592 [===========================>..] - ETA: 5s
2496/2592 [===========================>..] - ETA: 3s
2560/2592 [============================>.] - ETA: 1s
2592/2592 [==============================] - 85s 33ms/step
loss: 0.6853876327290948
acc: 0.5497685185185185
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f377c593490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f377c593490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3964418bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3964418bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36e09d4fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36e09d4fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c243bba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c243bba50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f36e09f5c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f36e09f5c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c240403d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c240403d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c246b3790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c246b3790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36e09f5550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36e09f5550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e24569190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e24569190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e24167650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3e24167650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e24531e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e24531e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e245693d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e245693d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e24292a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e24292a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e24205ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3e24205ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f377c47ac50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f377c47ac50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e240bf7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e240bf7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e241bf210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3e241bf210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e245dd0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e245dd0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f377c48b450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f377c48b450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f377c2b3890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f377c2b3890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e047bb190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e047bb190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f377c2bc210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f377c2bc210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f377c331490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f377c331490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f377c15ca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f377c15ca90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3748713450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3748713450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37485c0fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37485c0fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f377c1553d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f377c1553d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3748796450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3748796450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f37484bf790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f37484bf790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f37485c0b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f37485c0b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37482cd0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37482cd0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3748432750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3748432750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f374851c3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f374851c3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f37481f9410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f37481f9410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f37480d15d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f37480d15d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f374815ebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f374815ebd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f374872ff50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f374872ff50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37480c32d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37480c32d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f372863a650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f372863a650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f37481efcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f37481efcd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3728446c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3728446c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f372863ad10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f372863ad10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3728633b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3728633b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f372855e110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f372855e110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3728365490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3728365490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37285aa050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37285aa050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f37285c3190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f37285c3190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f372824e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f372824e550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f37283a6090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f37283a6090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f371472b1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f371472b1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37145dcb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37145dcb90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3728365510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3728365510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37147b8b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37147b8b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3714503fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3714503fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f37143c17d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f37143c17d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37142e8290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37142e8290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3714503690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3714503690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3714279a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3714279a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f37143c8b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f37143c8b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f37140e9d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f37140e9d10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f372805c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f372805c7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f37144d1950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f37144d1950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37144fbf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37144fbf90>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 2:52:36 - loss: 0.7261 - acc: 0.5781
 128/9333 [..............................] - ETA: 1:33:48 - loss: 0.7936 - acc: 0.5469
 192/9333 [..............................] - ETA: 1:07:51 - loss: 0.7675 - acc: 0.5573
 256/9333 [..............................] - ETA: 54:31 - loss: 0.7577 - acc: 0.5664  
 320/9333 [>.............................] - ETA: 46:33 - loss: 0.7704 - acc: 0.5312
 384/9333 [>.............................] - ETA: 41:01 - loss: 0.7496 - acc: 0.5312
 448/9333 [>.............................] - ETA: 37:10 - loss: 0.7583 - acc: 0.5089
 512/9333 [>.............................] - ETA: 34:09 - loss: 0.7514 - acc: 0.5176
 576/9333 [>.............................] - ETA: 31:52 - loss: 0.7508 - acc: 0.5226
 640/9333 [=>............................] - ETA: 30:09 - loss: 0.7454 - acc: 0.5312
 704/9333 [=>............................] - ETA: 28:37 - loss: 0.7390 - acc: 0.5369
 768/9333 [=>............................] - ETA: 27:23 - loss: 0.7333 - acc: 0.5443
 832/9333 [=>............................] - ETA: 26:16 - loss: 0.7329 - acc: 0.5409
 896/9333 [=>............................] - ETA: 25:22 - loss: 0.7325 - acc: 0.5424
 960/9333 [==>...........................] - ETA: 24:26 - loss: 0.7328 - acc: 0.5417
1024/9333 [==>...........................] - ETA: 23:35 - loss: 0.7309 - acc: 0.5430
1088/9333 [==>...........................] - ETA: 22:54 - loss: 0.7297 - acc: 0.5432
1152/9333 [==>...........................] - ETA: 22:14 - loss: 0.7292 - acc: 0.5425
1216/9333 [==>...........................] - ETA: 21:38 - loss: 0.7326 - acc: 0.5411
1280/9333 [===>..........................] - ETA: 21:06 - loss: 0.7313 - acc: 0.5375
1344/9333 [===>..........................] - ETA: 20:31 - loss: 0.7280 - acc: 0.5394
1408/9333 [===>..........................] - ETA: 20:00 - loss: 0.7291 - acc: 0.5348
1472/9333 [===>..........................] - ETA: 19:29 - loss: 0.7308 - acc: 0.5306
1536/9333 [===>..........................] - ETA: 19:04 - loss: 0.7302 - acc: 0.5286
1600/9333 [====>.........................] - ETA: 18:42 - loss: 0.7300 - acc: 0.5275
1664/9333 [====>.........................] - ETA: 18:25 - loss: 0.7269 - acc: 0.5312
1728/9333 [====>.........................] - ETA: 18:07 - loss: 0.7260 - acc: 0.5318
1792/9333 [====>.........................] - ETA: 17:48 - loss: 0.7263 - acc: 0.5318
1856/9333 [====>.........................] - ETA: 17:31 - loss: 0.7265 - acc: 0.5312
1920/9333 [=====>........................] - ETA: 17:16 - loss: 0.7258 - acc: 0.5297
1984/9333 [=====>........................] - ETA: 17:00 - loss: 0.7250 - acc: 0.5292
2048/9333 [=====>........................] - ETA: 16:45 - loss: 0.7230 - acc: 0.5327
2112/9333 [=====>........................] - ETA: 16:28 - loss: 0.7227 - acc: 0.5322
2176/9333 [=====>........................] - ETA: 16:15 - loss: 0.7210 - acc: 0.5326
2240/9333 [======>.......................] - ETA: 16:00 - loss: 0.7223 - acc: 0.5308
2304/9333 [======>.......................] - ETA: 15:45 - loss: 0.7223 - acc: 0.5312
2368/9333 [======>.......................] - ETA: 15:30 - loss: 0.7199 - acc: 0.5359
2432/9333 [======>.......................] - ETA: 15:16 - loss: 0.7216 - acc: 0.5337
2496/9333 [=======>......................] - ETA: 15:02 - loss: 0.7232 - acc: 0.5325
2560/9333 [=======>......................] - ETA: 14:50 - loss: 0.7229 - acc: 0.5312
2624/9333 [=======>......................] - ETA: 14:35 - loss: 0.7213 - acc: 0.5347
2688/9333 [=======>......................] - ETA: 14:22 - loss: 0.7210 - acc: 0.5353
2752/9333 [=======>......................] - ETA: 14:10 - loss: 0.7230 - acc: 0.5334
2816/9333 [========>.....................] - ETA: 13:57 - loss: 0.7224 - acc: 0.5348
2880/9333 [========>.....................] - ETA: 13:45 - loss: 0.7222 - acc: 0.5354
2944/9333 [========>.....................] - ETA: 13:34 - loss: 0.7223 - acc: 0.5346
3008/9333 [========>.....................] - ETA: 13:21 - loss: 0.7219 - acc: 0.5356
3072/9333 [========>.....................] - ETA: 13:10 - loss: 0.7233 - acc: 0.5332
3136/9333 [=========>....................] - ETA: 12:59 - loss: 0.7238 - acc: 0.5325
3200/9333 [=========>....................] - ETA: 12:49 - loss: 0.7230 - acc: 0.5334
3264/9333 [=========>....................] - ETA: 12:38 - loss: 0.7211 - acc: 0.5358
3328/9333 [=========>....................] - ETA: 12:29 - loss: 0.7205 - acc: 0.5364
3392/9333 [=========>....................] - ETA: 12:18 - loss: 0.7205 - acc: 0.5371
3456/9333 [==========>...................] - ETA: 12:10 - loss: 0.7199 - acc: 0.5391
3520/9333 [==========>...................] - ETA: 12:00 - loss: 0.7193 - acc: 0.5395
3584/9333 [==========>...................] - ETA: 11:49 - loss: 0.7177 - acc: 0.5410
3648/9333 [==========>...................] - ETA: 11:40 - loss: 0.7179 - acc: 0.5400
3712/9333 [==========>...................] - ETA: 11:30 - loss: 0.7176 - acc: 0.5407
3776/9333 [===========>..................] - ETA: 11:20 - loss: 0.7177 - acc: 0.5392
3840/9333 [===========>..................] - ETA: 11:10 - loss: 0.7178 - acc: 0.5388
3904/9333 [===========>..................] - ETA: 11:00 - loss: 0.7173 - acc: 0.5387
3968/9333 [===========>..................] - ETA: 10:51 - loss: 0.7172 - acc: 0.5383
4032/9333 [===========>..................] - ETA: 10:41 - loss: 0.7164 - acc: 0.5394
4096/9333 [============>.................] - ETA: 10:31 - loss: 0.7151 - acc: 0.5413
4160/9333 [============>.................] - ETA: 10:22 - loss: 0.7145 - acc: 0.5416
4224/9333 [============>.................] - ETA: 10:12 - loss: 0.7139 - acc: 0.5426
4288/9333 [============>.................] - ETA: 10:03 - loss: 0.7144 - acc: 0.5417
4352/9333 [============>.................] - ETA: 9:54 - loss: 0.7141 - acc: 0.5420 
4416/9333 [=============>................] - ETA: 9:45 - loss: 0.7147 - acc: 0.5421
4480/9333 [=============>................] - ETA: 9:36 - loss: 0.7148 - acc: 0.5411
4544/9333 [=============>................] - ETA: 9:26 - loss: 0.7146 - acc: 0.5409
4608/9333 [=============>................] - ETA: 9:17 - loss: 0.7148 - acc: 0.5399
4672/9333 [==============>...............] - ETA: 9:08 - loss: 0.7144 - acc: 0.5411
4736/9333 [==============>...............] - ETA: 8:58 - loss: 0.7130 - acc: 0.5433
4800/9333 [==============>...............] - ETA: 8:50 - loss: 0.7128 - acc: 0.5437
4864/9333 [==============>...............] - ETA: 8:40 - loss: 0.7133 - acc: 0.5436
4928/9333 [==============>...............] - ETA: 8:31 - loss: 0.7127 - acc: 0.5434
4992/9333 [===============>..............] - ETA: 8:23 - loss: 0.7129 - acc: 0.5431
5056/9333 [===============>..............] - ETA: 8:14 - loss: 0.7127 - acc: 0.5425
5120/9333 [===============>..............] - ETA: 8:06 - loss: 0.7121 - acc: 0.5430
5184/9333 [===============>..............] - ETA: 7:57 - loss: 0.7121 - acc: 0.5430
5248/9333 [===============>..............] - ETA: 7:49 - loss: 0.7132 - acc: 0.5408
5312/9333 [================>.............] - ETA: 7:40 - loss: 0.7135 - acc: 0.5397
5376/9333 [================>.............] - ETA: 7:31 - loss: 0.7125 - acc: 0.5413
5440/9333 [================>.............] - ETA: 7:23 - loss: 0.7128 - acc: 0.5406
5504/9333 [================>.............] - ETA: 7:15 - loss: 0.7126 - acc: 0.5407
5568/9333 [================>.............] - ETA: 7:06 - loss: 0.7123 - acc: 0.5406
5632/9333 [=================>............] - ETA: 6:58 - loss: 0.7123 - acc: 0.5401
5696/9333 [=================>............] - ETA: 6:50 - loss: 0.7116 - acc: 0.5420
5760/9333 [=================>............] - ETA: 6:41 - loss: 0.7116 - acc: 0.5413
5824/9333 [=================>............] - ETA: 6:33 - loss: 0.7117 - acc: 0.5414
5888/9333 [=================>............] - ETA: 6:25 - loss: 0.7121 - acc: 0.5408
5952/9333 [==================>...........] - ETA: 6:18 - loss: 0.7120 - acc: 0.5412
6016/9333 [==================>...........] - ETA: 6:10 - loss: 0.7113 - acc: 0.5419
6080/9333 [==================>...........] - ETA: 6:02 - loss: 0.7115 - acc: 0.5414
6144/9333 [==================>...........] - ETA: 5:55 - loss: 0.7116 - acc: 0.5413
6208/9333 [==================>...........] - ETA: 5:47 - loss: 0.7112 - acc: 0.5419
6272/9333 [===================>..........] - ETA: 5:39 - loss: 0.7110 - acc: 0.5423
6336/9333 [===================>..........] - ETA: 5:31 - loss: 0.7111 - acc: 0.5421
6400/9333 [===================>..........] - ETA: 5:24 - loss: 0.7111 - acc: 0.5417
6464/9333 [===================>..........] - ETA: 5:17 - loss: 0.7106 - acc: 0.5419
6528/9333 [===================>..........] - ETA: 5:09 - loss: 0.7103 - acc: 0.5427
6592/9333 [====================>.........] - ETA: 5:01 - loss: 0.7103 - acc: 0.5423
6656/9333 [====================>.........] - ETA: 4:54 - loss: 0.7101 - acc: 0.5424
6720/9333 [====================>.........] - ETA: 4:46 - loss: 0.7102 - acc: 0.5421
6784/9333 [====================>.........] - ETA: 4:39 - loss: 0.7104 - acc: 0.5411
6848/9333 [=====================>........] - ETA: 4:32 - loss: 0.7104 - acc: 0.5409
6912/9333 [=====================>........] - ETA: 4:24 - loss: 0.7102 - acc: 0.5411
6976/9333 [=====================>........] - ETA: 4:17 - loss: 0.7104 - acc: 0.5400
7040/9333 [=====================>........] - ETA: 4:10 - loss: 0.7101 - acc: 0.5406
7104/9333 [=====================>........] - ETA: 4:03 - loss: 0.7100 - acc: 0.5405
7168/9333 [======================>.......] - ETA: 3:55 - loss: 0.7101 - acc: 0.5402
7232/9333 [======================>.......] - ETA: 3:48 - loss: 0.7097 - acc: 0.5408
7296/9333 [======================>.......] - ETA: 3:41 - loss: 0.7095 - acc: 0.5404
7360/9333 [======================>.......] - ETA: 3:34 - loss: 0.7091 - acc: 0.5410
7424/9333 [======================>.......] - ETA: 3:27 - loss: 0.7092 - acc: 0.5407
7488/9333 [=======================>......] - ETA: 3:20 - loss: 0.7091 - acc: 0.5415
7552/9333 [=======================>......] - ETA: 3:12 - loss: 0.7094 - acc: 0.5405
7616/9333 [=======================>......] - ETA: 3:05 - loss: 0.7090 - acc: 0.5414
7680/9333 [=======================>......] - ETA: 2:58 - loss: 0.7085 - acc: 0.5421
7744/9333 [=======================>......] - ETA: 2:51 - loss: 0.7082 - acc: 0.5421
7808/9333 [========================>.....] - ETA: 2:44 - loss: 0.7084 - acc: 0.5414
7872/9333 [========================>.....] - ETA: 2:37 - loss: 0.7081 - acc: 0.5418
7936/9333 [========================>.....] - ETA: 2:30 - loss: 0.7078 - acc: 0.5422
8000/9333 [========================>.....] - ETA: 2:23 - loss: 0.7075 - acc: 0.5424
8064/9333 [========================>.....] - ETA: 2:16 - loss: 0.7076 - acc: 0.5420
8128/9333 [=========================>....] - ETA: 2:09 - loss: 0.7073 - acc: 0.5422
8192/9333 [=========================>....] - ETA: 2:02 - loss: 0.7071 - acc: 0.5425
8256/9333 [=========================>....] - ETA: 1:55 - loss: 0.7069 - acc: 0.5428
8320/9333 [=========================>....] - ETA: 1:48 - loss: 0.7070 - acc: 0.5425
8384/9333 [=========================>....] - ETA: 1:41 - loss: 0.7069 - acc: 0.5423
8448/9333 [==========================>...] - ETA: 1:35 - loss: 0.7067 - acc: 0.5425
8512/9333 [==========================>...] - ETA: 1:28 - loss: 0.7068 - acc: 0.5426
8576/9333 [==========================>...] - ETA: 1:21 - loss: 0.7065 - acc: 0.5429
8640/9333 [==========================>...] - ETA: 1:14 - loss: 0.7065 - acc: 0.5427
8704/9333 [==========================>...] - ETA: 1:07 - loss: 0.7059 - acc: 0.5439
8768/9333 [===========================>..] - ETA: 1:00 - loss: 0.7055 - acc: 0.5443
8832/9333 [===========================>..] - ETA: 53s - loss: 0.7055 - acc: 0.5439 
8896/9333 [===========================>..] - ETA: 46s - loss: 0.7052 - acc: 0.5442
8960/9333 [===========================>..] - ETA: 39s - loss: 0.7052 - acc: 0.5443
9024/9333 [============================>.] - ETA: 32s - loss: 0.7047 - acc: 0.5453
9088/9333 [============================>.] - ETA: 26s - loss: 0.7049 - acc: 0.5452
9152/9333 [============================>.] - ETA: 19s - loss: 0.7053 - acc: 0.5446
9216/9333 [============================>.] - ETA: 12s - loss: 0.7050 - acc: 0.5452
9280/9333 [============================>.] - ETA: 5s - loss: 0.7051 - acc: 0.5452 
9333/9333 [==============================] - 1040s 111ms/step - loss: 0.7056 - acc: 0.5443 - val_loss: 0.6820 - val_acc: 0.5448

Epoch 00001: val_acc improved from -inf to 0.54484, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window11/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 15:06 - loss: 0.6697 - acc: 0.5938
 128/9333 [..............................] - ETA: 14:39 - loss: 0.6643 - acc: 0.6016
 192/9333 [..............................] - ETA: 14:18 - loss: 0.6538 - acc: 0.6146
 256/9333 [..............................] - ETA: 14:30 - loss: 0.6708 - acc: 0.5781
 320/9333 [>.............................] - ETA: 14:43 - loss: 0.6814 - acc: 0.5594
 384/9333 [>.............................] - ETA: 14:49 - loss: 0.6856 - acc: 0.5625
 448/9333 [>.............................] - ETA: 14:43 - loss: 0.6794 - acc: 0.5781
 512/9333 [>.............................] - ETA: 14:46 - loss: 0.6709 - acc: 0.5898
 576/9333 [>.............................] - ETA: 14:33 - loss: 0.6764 - acc: 0.5781
 640/9333 [=>............................] - ETA: 14:30 - loss: 0.6719 - acc: 0.5859
 704/9333 [=>............................] - ETA: 14:23 - loss: 0.6746 - acc: 0.5824
 768/9333 [=>............................] - ETA: 14:15 - loss: 0.6799 - acc: 0.5755
 832/9333 [=>............................] - ETA: 14:06 - loss: 0.6812 - acc: 0.5757
 896/9333 [=>............................] - ETA: 13:53 - loss: 0.6824 - acc: 0.5759
 960/9333 [==>...........................] - ETA: 13:40 - loss: 0.6819 - acc: 0.5750
1024/9333 [==>...........................] - ETA: 13:32 - loss: 0.6806 - acc: 0.5742
1088/9333 [==>...........................] - ETA: 13:26 - loss: 0.6820 - acc: 0.5699
1152/9333 [==>...........................] - ETA: 13:20 - loss: 0.6829 - acc: 0.5651
1216/9333 [==>...........................] - ETA: 13:13 - loss: 0.6825 - acc: 0.5699
1280/9333 [===>..........................] - ETA: 13:10 - loss: 0.6807 - acc: 0.5711
1344/9333 [===>..........................] - ETA: 13:07 - loss: 0.6796 - acc: 0.5714
1408/9333 [===>..........................] - ETA: 13:06 - loss: 0.6809 - acc: 0.5710
1472/9333 [===>..........................] - ETA: 13:01 - loss: 0.6806 - acc: 0.5720
1536/9333 [===>..........................] - ETA: 12:55 - loss: 0.6783 - acc: 0.5775
1600/9333 [====>.........................] - ETA: 12:50 - loss: 0.6807 - acc: 0.5719
1664/9333 [====>.........................] - ETA: 12:45 - loss: 0.6817 - acc: 0.5709
1728/9333 [====>.........................] - ETA: 12:40 - loss: 0.6814 - acc: 0.5712
1792/9333 [====>.........................] - ETA: 12:35 - loss: 0.6825 - acc: 0.5698
1856/9333 [====>.........................] - ETA: 12:29 - loss: 0.6822 - acc: 0.5700
1920/9333 [=====>........................] - ETA: 12:23 - loss: 0.6826 - acc: 0.5682
1984/9333 [=====>........................] - ETA: 12:18 - loss: 0.6829 - acc: 0.5691
2048/9333 [=====>........................] - ETA: 12:10 - loss: 0.6831 - acc: 0.5688
2112/9333 [=====>........................] - ETA: 12:01 - loss: 0.6838 - acc: 0.5687
2176/9333 [=====>........................] - ETA: 11:52 - loss: 0.6836 - acc: 0.5699
2240/9333 [======>.......................] - ETA: 11:42 - loss: 0.6828 - acc: 0.5714
2304/9333 [======>.......................] - ETA: 11:33 - loss: 0.6832 - acc: 0.5720
2368/9333 [======>.......................] - ETA: 11:26 - loss: 0.6823 - acc: 0.5726
2432/9333 [======>.......................] - ETA: 11:19 - loss: 0.6821 - acc: 0.5728
2496/9333 [=======>......................] - ETA: 11:10 - loss: 0.6810 - acc: 0.5745
2560/9333 [=======>......................] - ETA: 11:03 - loss: 0.6814 - acc: 0.5742
2624/9333 [=======>......................] - ETA: 10:56 - loss: 0.6811 - acc: 0.5755
2688/9333 [=======>......................] - ETA: 10:48 - loss: 0.6808 - acc: 0.5744
2752/9333 [=======>......................] - ETA: 10:41 - loss: 0.6793 - acc: 0.5763
2816/9333 [========>.....................] - ETA: 10:35 - loss: 0.6798 - acc: 0.5753
2880/9333 [========>.....................] - ETA: 10:27 - loss: 0.6792 - acc: 0.5757
2944/9333 [========>.....................] - ETA: 10:19 - loss: 0.6793 - acc: 0.5768
3008/9333 [========>.....................] - ETA: 10:11 - loss: 0.6786 - acc: 0.5788
3072/9333 [========>.....................] - ETA: 10:03 - loss: 0.6774 - acc: 0.5801
3136/9333 [=========>....................] - ETA: 9:57 - loss: 0.6781 - acc: 0.5784 
3200/9333 [=========>....................] - ETA: 9:50 - loss: 0.6791 - acc: 0.5763
3264/9333 [=========>....................] - ETA: 9:42 - loss: 0.6791 - acc: 0.5766
3328/9333 [=========>....................] - ETA: 9:36 - loss: 0.6788 - acc: 0.5775
3392/9333 [=========>....................] - ETA: 9:29 - loss: 0.6792 - acc: 0.5758
3456/9333 [==========>...................] - ETA: 9:22 - loss: 0.6790 - acc: 0.5770
3520/9333 [==========>...................] - ETA: 9:14 - loss: 0.6778 - acc: 0.5787
3584/9333 [==========>...................] - ETA: 9:08 - loss: 0.6781 - acc: 0.5784
3648/9333 [==========>...................] - ETA: 9:02 - loss: 0.6784 - acc: 0.5779
3712/9333 [==========>...................] - ETA: 8:56 - loss: 0.6788 - acc: 0.5770
3776/9333 [===========>..................] - ETA: 8:49 - loss: 0.6781 - acc: 0.5781
3840/9333 [===========>..................] - ETA: 8:43 - loss: 0.6773 - acc: 0.5797
3904/9333 [===========>..................] - ETA: 8:36 - loss: 0.6774 - acc: 0.5809
3968/9333 [===========>..................] - ETA: 8:29 - loss: 0.6783 - acc: 0.5789
4032/9333 [===========>..................] - ETA: 8:22 - loss: 0.6787 - acc: 0.5791
4096/9333 [============>.................] - ETA: 8:14 - loss: 0.6790 - acc: 0.5791
4160/9333 [============>.................] - ETA: 8:07 - loss: 0.6802 - acc: 0.5762
4224/9333 [============>.................] - ETA: 8:00 - loss: 0.6794 - acc: 0.5767
4288/9333 [============>.................] - ETA: 7:52 - loss: 0.6796 - acc: 0.5753
4352/9333 [============>.................] - ETA: 7:44 - loss: 0.6795 - acc: 0.5749
4416/9333 [=============>................] - ETA: 7:36 - loss: 0.6800 - acc: 0.5738
4480/9333 [=============>................] - ETA: 7:29 - loss: 0.6805 - acc: 0.5721
4544/9333 [=============>................] - ETA: 7:21 - loss: 0.6812 - acc: 0.5713
4608/9333 [=============>................] - ETA: 7:14 - loss: 0.6809 - acc: 0.5723
4672/9333 [==============>...............] - ETA: 7:08 - loss: 0.6815 - acc: 0.5708
4736/9333 [==============>...............] - ETA: 7:02 - loss: 0.6810 - acc: 0.5716
4800/9333 [==============>...............] - ETA: 6:55 - loss: 0.6810 - acc: 0.5713
4864/9333 [==============>...............] - ETA: 6:48 - loss: 0.6813 - acc: 0.5709
4928/9333 [==============>...............] - ETA: 6:41 - loss: 0.6814 - acc: 0.5712
4992/9333 [===============>..............] - ETA: 6:34 - loss: 0.6815 - acc: 0.5715
5056/9333 [===============>..............] - ETA: 6:27 - loss: 0.6809 - acc: 0.5716
5120/9333 [===============>..............] - ETA: 6:21 - loss: 0.6806 - acc: 0.5719
5184/9333 [===============>..............] - ETA: 6:14 - loss: 0.6804 - acc: 0.5727
5248/9333 [===============>..............] - ETA: 6:07 - loss: 0.6808 - acc: 0.5718
5312/9333 [================>.............] - ETA: 6:01 - loss: 0.6804 - acc: 0.5723
5376/9333 [================>.............] - ETA: 5:55 - loss: 0.6806 - acc: 0.5722
5440/9333 [================>.............] - ETA: 5:48 - loss: 0.6802 - acc: 0.5722
5504/9333 [================>.............] - ETA: 5:42 - loss: 0.6803 - acc: 0.5718
5568/9333 [================>.............] - ETA: 5:35 - loss: 0.6802 - acc: 0.5717
5632/9333 [=================>............] - ETA: 5:29 - loss: 0.6801 - acc: 0.5710
5696/9333 [=================>............] - ETA: 5:23 - loss: 0.6792 - acc: 0.5727
5760/9333 [=================>............] - ETA: 5:16 - loss: 0.6789 - acc: 0.5726
5824/9333 [=================>............] - ETA: 5:10 - loss: 0.6792 - acc: 0.5723
5888/9333 [=================>............] - ETA: 5:04 - loss: 0.6787 - acc: 0.5734
5952/9333 [==================>...........] - ETA: 4:58 - loss: 0.6787 - acc: 0.5726
6016/9333 [==================>...........] - ETA: 4:52 - loss: 0.6784 - acc: 0.5731
6080/9333 [==================>...........] - ETA: 4:46 - loss: 0.6779 - acc: 0.5740
6144/9333 [==================>...........] - ETA: 4:40 - loss: 0.6786 - acc: 0.5732
6208/9333 [==================>...........] - ETA: 4:33 - loss: 0.6783 - acc: 0.5743
6272/9333 [===================>..........] - ETA: 4:27 - loss: 0.6785 - acc: 0.5735
6336/9333 [===================>..........] - ETA: 4:21 - loss: 0.6782 - acc: 0.5740
6400/9333 [===================>..........] - ETA: 4:15 - loss: 0.6781 - acc: 0.5737
6464/9333 [===================>..........] - ETA: 4:10 - loss: 0.6784 - acc: 0.5735
6528/9333 [===================>..........] - ETA: 4:04 - loss: 0.6779 - acc: 0.5754
6592/9333 [====================>.........] - ETA: 3:58 - loss: 0.6783 - acc: 0.5745
6656/9333 [====================>.........] - ETA: 3:52 - loss: 0.6783 - acc: 0.5745
6720/9333 [====================>.........] - ETA: 3:46 - loss: 0.6786 - acc: 0.5743
6784/9333 [====================>.........] - ETA: 3:40 - loss: 0.6783 - acc: 0.5746
6848/9333 [=====================>........] - ETA: 3:35 - loss: 0.6783 - acc: 0.5751
6912/9333 [=====================>........] - ETA: 3:29 - loss: 0.6784 - acc: 0.5748
6976/9333 [=====================>........] - ETA: 3:23 - loss: 0.6785 - acc: 0.5750
7040/9333 [=====================>........] - ETA: 3:17 - loss: 0.6785 - acc: 0.5746
7104/9333 [=====================>........] - ETA: 3:12 - loss: 0.6787 - acc: 0.5739
7168/9333 [======================>.......] - ETA: 3:06 - loss: 0.6789 - acc: 0.5741
7232/9333 [======================>.......] - ETA: 3:00 - loss: 0.6789 - acc: 0.5743
7296/9333 [======================>.......] - ETA: 2:54 - loss: 0.6785 - acc: 0.5744
7360/9333 [======================>.......] - ETA: 2:49 - loss: 0.6782 - acc: 0.5750
7424/9333 [======================>.......] - ETA: 2:43 - loss: 0.6783 - acc: 0.5749
7488/9333 [=======================>......] - ETA: 2:37 - loss: 0.6779 - acc: 0.5755
7552/9333 [=======================>......] - ETA: 2:32 - loss: 0.6778 - acc: 0.5755
7616/9333 [=======================>......] - ETA: 2:26 - loss: 0.6778 - acc: 0.5758
7680/9333 [=======================>......] - ETA: 2:21 - loss: 0.6773 - acc: 0.5768
7744/9333 [=======================>......] - ETA: 2:15 - loss: 0.6772 - acc: 0.5770
7808/9333 [========================>.....] - ETA: 2:09 - loss: 0.6770 - acc: 0.5770
7872/9333 [========================>.....] - ETA: 2:04 - loss: 0.6768 - acc: 0.5775
7936/9333 [========================>.....] - ETA: 1:58 - loss: 0.6767 - acc: 0.5776
8000/9333 [========================>.....] - ETA: 1:53 - loss: 0.6767 - acc: 0.5775
8064/9333 [========================>.....] - ETA: 1:47 - loss: 0.6769 - acc: 0.5773
8128/9333 [=========================>....] - ETA: 1:42 - loss: 0.6771 - acc: 0.5775
8192/9333 [=========================>....] - ETA: 1:36 - loss: 0.6774 - acc: 0.5770
8256/9333 [=========================>....] - ETA: 1:31 - loss: 0.6775 - acc: 0.5775
8320/9333 [=========================>....] - ETA: 1:25 - loss: 0.6774 - acc: 0.5778
8384/9333 [=========================>....] - ETA: 1:20 - loss: 0.6773 - acc: 0.5780
8448/9333 [==========================>...] - ETA: 1:14 - loss: 0.6779 - acc: 0.5775
8512/9333 [==========================>...] - ETA: 1:09 - loss: 0.6779 - acc: 0.5773
8576/9333 [==========================>...] - ETA: 1:03 - loss: 0.6781 - acc: 0.5767
8640/9333 [==========================>...] - ETA: 58s - loss: 0.6781 - acc: 0.5769 
8704/9333 [==========================>...] - ETA: 52s - loss: 0.6782 - acc: 0.5765
8768/9333 [===========================>..] - ETA: 47s - loss: 0.6780 - acc: 0.5769
8832/9333 [===========================>..] - ETA: 42s - loss: 0.6783 - acc: 0.5757
8896/9333 [===========================>..] - ETA: 36s - loss: 0.6780 - acc: 0.5760
8960/9333 [===========================>..] - ETA: 31s - loss: 0.6781 - acc: 0.5759
9024/9333 [============================>.] - ETA: 25s - loss: 0.6777 - acc: 0.5764
9088/9333 [============================>.] - ETA: 20s - loss: 0.6776 - acc: 0.5759
9152/9333 [============================>.] - ETA: 15s - loss: 0.6773 - acc: 0.5764
9216/9333 [============================>.] - ETA: 9s - loss: 0.6775 - acc: 0.5767 
9280/9333 [============================>.] - ETA: 4s - loss: 0.6774 - acc: 0.5766
9333/9333 [==============================] - 806s 86ms/step - loss: 0.6774 - acc: 0.5763 - val_loss: 0.6702 - val_acc: 0.5661

Epoch 00002: val_acc improved from 0.54484 to 0.56606, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window11/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 3/10

  64/9333 [..............................] - ETA: 12:13 - loss: 0.6551 - acc: 0.5625
 128/9333 [..............................] - ETA: 11:53 - loss: 0.7014 - acc: 0.4766
 192/9333 [..............................] - ETA: 11:41 - loss: 0.6906 - acc: 0.4896
 256/9333 [..............................] - ETA: 11:24 - loss: 0.6863 - acc: 0.5156
 320/9333 [>.............................] - ETA: 11:16 - loss: 0.6845 - acc: 0.5281
 384/9333 [>.............................] - ETA: 11:13 - loss: 0.6871 - acc: 0.5260
 448/9333 [>.............................] - ETA: 11:09 - loss: 0.6772 - acc: 0.5424
 512/9333 [>.............................] - ETA: 11:15 - loss: 0.6763 - acc: 0.5547
 576/9333 [>.............................] - ETA: 11:24 - loss: 0.6690 - acc: 0.5712
 640/9333 [=>............................] - ETA: 11:34 - loss: 0.6751 - acc: 0.5594
 704/9333 [=>............................] - ETA: 11:43 - loss: 0.6723 - acc: 0.5668
 768/9333 [=>............................] - ETA: 11:37 - loss: 0.6700 - acc: 0.5664
 832/9333 [=>............................] - ETA: 11:32 - loss: 0.6743 - acc: 0.5589
 896/9333 [=>............................] - ETA: 11:36 - loss: 0.6726 - acc: 0.5603
 960/9333 [==>...........................] - ETA: 11:26 - loss: 0.6738 - acc: 0.5646
1024/9333 [==>...........................] - ETA: 11:32 - loss: 0.6740 - acc: 0.5615
1088/9333 [==>...........................] - ETA: 11:26 - loss: 0.6739 - acc: 0.5616
1152/9333 [==>...........................] - ETA: 11:22 - loss: 0.6741 - acc: 0.5668
1216/9333 [==>...........................] - ETA: 11:16 - loss: 0.6741 - acc: 0.5691
1280/9333 [===>..........................] - ETA: 11:08 - loss: 0.6730 - acc: 0.5742
1344/9333 [===>..........................] - ETA: 11:00 - loss: 0.6722 - acc: 0.5789
1408/9333 [===>..........................] - ETA: 11:03 - loss: 0.6715 - acc: 0.5824
1472/9333 [===>..........................] - ETA: 10:58 - loss: 0.6724 - acc: 0.5822
1536/9333 [===>..........................] - ETA: 10:51 - loss: 0.6725 - acc: 0.5827
1600/9333 [====>.........................] - ETA: 10:44 - loss: 0.6719 - acc: 0.5844
1664/9333 [====>.........................] - ETA: 10:40 - loss: 0.6734 - acc: 0.5811
1728/9333 [====>.........................] - ETA: 10:36 - loss: 0.6748 - acc: 0.5770
1792/9333 [====>.........................] - ETA: 10:29 - loss: 0.6746 - acc: 0.5759
1856/9333 [====>.........................] - ETA: 10:21 - loss: 0.6757 - acc: 0.5727
1920/9333 [=====>........................] - ETA: 10:13 - loss: 0.6743 - acc: 0.5766
1984/9333 [=====>........................] - ETA: 10:08 - loss: 0.6744 - acc: 0.5751
2048/9333 [=====>........................] - ETA: 10:08 - loss: 0.6734 - acc: 0.5786
2112/9333 [=====>........................] - ETA: 10:02 - loss: 0.6733 - acc: 0.5786
2176/9333 [=====>........................] - ETA: 9:58 - loss: 0.6730 - acc: 0.5790 
2240/9333 [======>.......................] - ETA: 9:51 - loss: 0.6736 - acc: 0.5786
2304/9333 [======>.......................] - ETA: 9:44 - loss: 0.6735 - acc: 0.5786
2368/9333 [======>.......................] - ETA: 9:37 - loss: 0.6729 - acc: 0.5798
2432/9333 [======>.......................] - ETA: 9:30 - loss: 0.6724 - acc: 0.5794
2496/9333 [=======>......................] - ETA: 9:28 - loss: 0.6729 - acc: 0.5789
2560/9333 [=======>......................] - ETA: 9:26 - loss: 0.6738 - acc: 0.5777
2624/9333 [=======>......................] - ETA: 9:21 - loss: 0.6725 - acc: 0.5804
2688/9333 [=======>......................] - ETA: 9:16 - loss: 0.6741 - acc: 0.5785
2752/9333 [=======>......................] - ETA: 9:10 - loss: 0.6740 - acc: 0.5792
2816/9333 [========>.....................] - ETA: 9:03 - loss: 0.6735 - acc: 0.5799
2880/9333 [========>.....................] - ETA: 8:56 - loss: 0.6728 - acc: 0.5813
2944/9333 [========>.....................] - ETA: 8:49 - loss: 0.6738 - acc: 0.5781
3008/9333 [========>.....................] - ETA: 8:43 - loss: 0.6738 - acc: 0.5775
3072/9333 [========>.....................] - ETA: 8:38 - loss: 0.6731 - acc: 0.5785
3136/9333 [=========>....................] - ETA: 8:35 - loss: 0.6731 - acc: 0.5788
3200/9333 [=========>....................] - ETA: 8:29 - loss: 0.6735 - acc: 0.5775
3264/9333 [=========>....................] - ETA: 8:24 - loss: 0.6728 - acc: 0.5766
3328/9333 [=========>....................] - ETA: 8:19 - loss: 0.6726 - acc: 0.5772
3392/9333 [=========>....................] - ETA: 8:13 - loss: 0.6736 - acc: 0.5764
3456/9333 [==========>...................] - ETA: 8:06 - loss: 0.6729 - acc: 0.5784
3520/9333 [==========>...................] - ETA: 8:00 - loss: 0.6736 - acc: 0.5784
3584/9333 [==========>...................] - ETA: 7:54 - loss: 0.6736 - acc: 0.5787
3648/9333 [==========>...................] - ETA: 7:48 - loss: 0.6736 - acc: 0.5792
3712/9333 [==========>...................] - ETA: 7:44 - loss: 0.6724 - acc: 0.5822
3776/9333 [===========>..................] - ETA: 7:40 - loss: 0.6720 - acc: 0.5840
3840/9333 [===========>..................] - ETA: 7:35 - loss: 0.6717 - acc: 0.5841
3904/9333 [===========>..................] - ETA: 7:31 - loss: 0.6720 - acc: 0.5845
3968/9333 [===========>..................] - ETA: 7:25 - loss: 0.6713 - acc: 0.5859
4032/9333 [===========>..................] - ETA: 7:19 - loss: 0.6717 - acc: 0.5848
4096/9333 [============>.................] - ETA: 7:13 - loss: 0.6709 - acc: 0.5864
4160/9333 [============>.................] - ETA: 7:07 - loss: 0.6712 - acc: 0.5858
4224/9333 [============>.................] - ETA: 7:01 - loss: 0.6711 - acc: 0.5859
4288/9333 [============>.................] - ETA: 6:55 - loss: 0.6707 - acc: 0.5870
4352/9333 [============>.................] - ETA: 6:49 - loss: 0.6709 - acc: 0.5866
4416/9333 [=============>................] - ETA: 6:43 - loss: 0.6716 - acc: 0.5863
4480/9333 [=============>................] - ETA: 6:38 - loss: 0.6710 - acc: 0.5873
4544/9333 [=============>................] - ETA: 6:34 - loss: 0.6710 - acc: 0.5863
4608/9333 [=============>................] - ETA: 6:29 - loss: 0.6704 - acc: 0.5872
4672/9333 [==============>...............] - ETA: 6:24 - loss: 0.6700 - acc: 0.5875
4736/9333 [==============>...............] - ETA: 6:19 - loss: 0.6690 - acc: 0.5885
4800/9333 [==============>...............] - ETA: 6:14 - loss: 0.6691 - acc: 0.5881
4864/9333 [==============>...............] - ETA: 6:08 - loss: 0.6679 - acc: 0.5896
4928/9333 [==============>...............] - ETA: 6:02 - loss: 0.6690 - acc: 0.5885
4992/9333 [===============>..............] - ETA: 5:57 - loss: 0.6699 - acc: 0.5869
5056/9333 [===============>..............] - ETA: 5:51 - loss: 0.6702 - acc: 0.5868
5120/9333 [===============>..............] - ETA: 5:45 - loss: 0.6710 - acc: 0.5852
5184/9333 [===============>..............] - ETA: 5:39 - loss: 0.6709 - acc: 0.5851
5248/9333 [===============>..............] - ETA: 5:33 - loss: 0.6711 - acc: 0.5850
5312/9333 [================>.............] - ETA: 5:28 - loss: 0.6711 - acc: 0.5853
5376/9333 [================>.............] - ETA: 5:23 - loss: 0.6712 - acc: 0.5852
5440/9333 [================>.............] - ETA: 5:19 - loss: 0.6712 - acc: 0.5849
5504/9333 [================>.............] - ETA: 5:14 - loss: 0.6710 - acc: 0.5861
5568/9333 [================>.............] - ETA: 5:09 - loss: 0.6710 - acc: 0.5864
5632/9333 [=================>............] - ETA: 5:04 - loss: 0.6708 - acc: 0.5866
5696/9333 [=================>............] - ETA: 4:59 - loss: 0.6708 - acc: 0.5871
5760/9333 [=================>............] - ETA: 4:53 - loss: 0.6714 - acc: 0.5863
5824/9333 [=================>............] - ETA: 4:48 - loss: 0.6711 - acc: 0.5869
5888/9333 [=================>............] - ETA: 4:42 - loss: 0.6716 - acc: 0.5856
5952/9333 [==================>...........] - ETA: 4:37 - loss: 0.6716 - acc: 0.5852
6016/9333 [==================>...........] - ETA: 4:31 - loss: 0.6713 - acc: 0.5858
6080/9333 [==================>...........] - ETA: 4:26 - loss: 0.6715 - acc: 0.5849
6144/9333 [==================>...........] - ETA: 4:20 - loss: 0.6715 - acc: 0.5853
6208/9333 [==================>...........] - ETA: 4:15 - loss: 0.6713 - acc: 0.5860
6272/9333 [===================>..........] - ETA: 4:10 - loss: 0.6711 - acc: 0.5861
6336/9333 [===================>..........] - ETA: 4:05 - loss: 0.6717 - acc: 0.5852
6400/9333 [===================>..........] - ETA: 4:00 - loss: 0.6720 - acc: 0.5850
6464/9333 [===================>..........] - ETA: 3:55 - loss: 0.6716 - acc: 0.5852
6528/9333 [===================>..........] - ETA: 3:50 - loss: 0.6717 - acc: 0.5847
6592/9333 [====================>.........] - ETA: 3:45 - loss: 0.6714 - acc: 0.5846
6656/9333 [====================>.........] - ETA: 3:40 - loss: 0.6714 - acc: 0.5843
6720/9333 [====================>.........] - ETA: 3:35 - loss: 0.6715 - acc: 0.5841
6784/9333 [====================>.........] - ETA: 3:30 - loss: 0.6716 - acc: 0.5839
6848/9333 [=====================>........] - ETA: 3:25 - loss: 0.6711 - acc: 0.5859
6912/9333 [=====================>........] - ETA: 3:20 - loss: 0.6716 - acc: 0.5852
6976/9333 [=====================>........] - ETA: 3:15 - loss: 0.6718 - acc: 0.5853
7040/9333 [=====================>........] - ETA: 3:10 - loss: 0.6721 - acc: 0.5847
7104/9333 [=====================>........] - ETA: 3:05 - loss: 0.6721 - acc: 0.5850
7168/9333 [======================>.......] - ETA: 3:00 - loss: 0.6720 - acc: 0.5852
7232/9333 [======================>.......] - ETA: 2:55 - loss: 0.6721 - acc: 0.5857
7296/9333 [======================>.......] - ETA: 2:50 - loss: 0.6725 - acc: 0.5851
7360/9333 [======================>.......] - ETA: 2:45 - loss: 0.6723 - acc: 0.5849
7424/9333 [======================>.......] - ETA: 2:40 - loss: 0.6724 - acc: 0.5847
7488/9333 [=======================>......] - ETA: 2:34 - loss: 0.6720 - acc: 0.5856
7552/9333 [=======================>......] - ETA: 2:29 - loss: 0.6722 - acc: 0.5857
7616/9333 [=======================>......] - ETA: 2:24 - loss: 0.6722 - acc: 0.5860
7680/9333 [=======================>......] - ETA: 2:19 - loss: 0.6717 - acc: 0.5870
7744/9333 [=======================>......] - ETA: 2:14 - loss: 0.6716 - acc: 0.5866
7808/9333 [========================>.....] - ETA: 2:08 - loss: 0.6715 - acc: 0.5867
7872/9333 [========================>.....] - ETA: 2:03 - loss: 0.6719 - acc: 0.5859
7936/9333 [========================>.....] - ETA: 1:58 - loss: 0.6725 - acc: 0.5852
8000/9333 [========================>.....] - ETA: 1:52 - loss: 0.6727 - acc: 0.5853
8064/9333 [========================>.....] - ETA: 1:47 - loss: 0.6727 - acc: 0.5853
8128/9333 [=========================>....] - ETA: 1:41 - loss: 0.6721 - acc: 0.5865
8192/9333 [=========================>....] - ETA: 1:36 - loss: 0.6718 - acc: 0.5870
8256/9333 [=========================>....] - ETA: 1:30 - loss: 0.6713 - acc: 0.5875
8320/9333 [=========================>....] - ETA: 1:25 - loss: 0.6710 - acc: 0.5881
8384/9333 [=========================>....] - ETA: 1:19 - loss: 0.6713 - acc: 0.5873
8448/9333 [==========================>...] - ETA: 1:14 - loss: 0.6721 - acc: 0.5862
8512/9333 [==========================>...] - ETA: 1:09 - loss: 0.6722 - acc: 0.5863
8576/9333 [==========================>...] - ETA: 1:03 - loss: 0.6722 - acc: 0.5862
8640/9333 [==========================>...] - ETA: 58s - loss: 0.6723 - acc: 0.5860 
8704/9333 [==========================>...] - ETA: 53s - loss: 0.6723 - acc: 0.5858
8768/9333 [===========================>..] - ETA: 47s - loss: 0.6719 - acc: 0.5868
8832/9333 [===========================>..] - ETA: 42s - loss: 0.6718 - acc: 0.5871
8896/9333 [===========================>..] - ETA: 36s - loss: 0.6719 - acc: 0.5867
8960/9333 [===========================>..] - ETA: 31s - loss: 0.6719 - acc: 0.5867
9024/9333 [============================>.] - ETA: 25s - loss: 0.6721 - acc: 0.5864
9088/9333 [============================>.] - ETA: 20s - loss: 0.6719 - acc: 0.5864
9152/9333 [============================>.] - ETA: 15s - loss: 0.6716 - acc: 0.5872
9216/9333 [============================>.] - ETA: 9s - loss: 0.6717 - acc: 0.5870 
9280/9333 [============================>.] - ETA: 4s - loss: 0.6717 - acc: 0.5872
9333/9333 [==============================] - 815s 87ms/step - loss: 0.6717 - acc: 0.5871 - val_loss: 0.6704 - val_acc: 0.5689

Epoch 00003: val_acc improved from 0.56606 to 0.56895, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window11/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 4/10

  64/9333 [..............................] - ETA: 10:22 - loss: 0.6726 - acc: 0.5469
 128/9333 [..............................] - ETA: 11:10 - loss: 0.6594 - acc: 0.5703
 192/9333 [..............................] - ETA: 10:57 - loss: 0.6653 - acc: 0.5833
 256/9333 [..............................] - ETA: 11:01 - loss: 0.6576 - acc: 0.5938
 320/9333 [>.............................] - ETA: 11:58 - loss: 0.6581 - acc: 0.5938
 384/9333 [>.............................] - ETA: 12:28 - loss: 0.6605 - acc: 0.5964
 448/9333 [>.............................] - ETA: 12:34 - loss: 0.6590 - acc: 0.5871
 512/9333 [>.............................] - ETA: 12:37 - loss: 0.6586 - acc: 0.5918
 576/9333 [>.............................] - ETA: 12:35 - loss: 0.6573 - acc: 0.5955
 640/9333 [=>............................] - ETA: 12:24 - loss: 0.6605 - acc: 0.5969
 704/9333 [=>............................] - ETA: 12:11 - loss: 0.6611 - acc: 0.5966
 768/9333 [=>............................] - ETA: 11:56 - loss: 0.6595 - acc: 0.5990
 832/9333 [=>............................] - ETA: 11:46 - loss: 0.6637 - acc: 0.5901
 896/9333 [=>............................] - ETA: 11:37 - loss: 0.6633 - acc: 0.5882
 960/9333 [==>...........................] - ETA: 11:26 - loss: 0.6639 - acc: 0.5896
1024/9333 [==>...........................] - ETA: 11:17 - loss: 0.6625 - acc: 0.5908
1088/9333 [==>...........................] - ETA: 11:14 - loss: 0.6627 - acc: 0.5956
1152/9333 [==>...........................] - ETA: 11:19 - loss: 0.6605 - acc: 0.5990
1216/9333 [==>...........................] - ETA: 11:18 - loss: 0.6589 - acc: 0.6003
1280/9333 [===>..........................] - ETA: 11:18 - loss: 0.6569 - acc: 0.6047
1344/9333 [===>..........................] - ETA: 11:14 - loss: 0.6574 - acc: 0.6049
1408/9333 [===>..........................] - ETA: 11:16 - loss: 0.6578 - acc: 0.6051
1472/9333 [===>..........................] - ETA: 11:09 - loss: 0.6598 - acc: 0.6033
1536/9333 [===>..........................] - ETA: 11:00 - loss: 0.6602 - acc: 0.6016
1600/9333 [====>.........................] - ETA: 10:53 - loss: 0.6619 - acc: 0.6006
1664/9333 [====>.........................] - ETA: 10:45 - loss: 0.6632 - acc: 0.6010
1728/9333 [====>.........................] - ETA: 10:39 - loss: 0.6633 - acc: 0.6019
1792/9333 [====>.........................] - ETA: 10:31 - loss: 0.6623 - acc: 0.6044
1856/9333 [====>.........................] - ETA: 10:27 - loss: 0.6604 - acc: 0.6078
1920/9333 [=====>........................] - ETA: 10:27 - loss: 0.6602 - acc: 0.6052
1984/9333 [=====>........................] - ETA: 10:23 - loss: 0.6618 - acc: 0.6033
2048/9333 [=====>........................] - ETA: 10:18 - loss: 0.6616 - acc: 0.6040
2112/9333 [=====>........................] - ETA: 10:11 - loss: 0.6612 - acc: 0.6027
2176/9333 [=====>........................] - ETA: 10:08 - loss: 0.6604 - acc: 0.6048
2240/9333 [======>.......................] - ETA: 10:00 - loss: 0.6606 - acc: 0.6045
2304/9333 [======>.......................] - ETA: 9:51 - loss: 0.6603 - acc: 0.6055 
2368/9333 [======>.......................] - ETA: 9:43 - loss: 0.6612 - acc: 0.6043
2432/9333 [======>.......................] - ETA: 9:37 - loss: 0.6598 - acc: 0.6077
2496/9333 [=======>......................] - ETA: 9:28 - loss: 0.6591 - acc: 0.6090
2560/9333 [=======>......................] - ETA: 9:20 - loss: 0.6588 - acc: 0.6090
2624/9333 [=======>......................] - ETA: 9:14 - loss: 0.6593 - acc: 0.6075
2688/9333 [=======>......................] - ETA: 9:13 - loss: 0.6610 - acc: 0.6053
2752/9333 [=======>......................] - ETA: 9:09 - loss: 0.6606 - acc: 0.6061
2816/9333 [========>.....................] - ETA: 9:03 - loss: 0.6601 - acc: 0.6051
2880/9333 [========>.....................] - ETA: 8:59 - loss: 0.6603 - acc: 0.6028
2944/9333 [========>.....................] - ETA: 8:54 - loss: 0.6611 - acc: 0.5992
3008/9333 [========>.....................] - ETA: 8:47 - loss: 0.6614 - acc: 0.5991
3072/9333 [========>.....................] - ETA: 8:40 - loss: 0.6610 - acc: 0.5996
3136/9333 [=========>....................] - ETA: 8:33 - loss: 0.6615 - acc: 0.6004
3200/9333 [=========>....................] - ETA: 8:26 - loss: 0.6626 - acc: 0.5984
3264/9333 [=========>....................] - ETA: 8:19 - loss: 0.6631 - acc: 0.5974
3328/9333 [=========>....................] - ETA: 8:12 - loss: 0.6639 - acc: 0.5953
3392/9333 [=========>....................] - ETA: 8:04 - loss: 0.6646 - acc: 0.5952
3456/9333 [==========>...................] - ETA: 7:59 - loss: 0.6651 - acc: 0.5946
3520/9333 [==========>...................] - ETA: 7:54 - loss: 0.6652 - acc: 0.5955
3584/9333 [==========>...................] - ETA: 7:50 - loss: 0.6649 - acc: 0.5957
3648/9333 [==========>...................] - ETA: 7:45 - loss: 0.6656 - acc: 0.5957
3712/9333 [==========>...................] - ETA: 7:39 - loss: 0.6661 - acc: 0.5954
3776/9333 [===========>..................] - ETA: 7:34 - loss: 0.6659 - acc: 0.5961
3840/9333 [===========>..................] - ETA: 7:29 - loss: 0.6658 - acc: 0.5956
3904/9333 [===========>..................] - ETA: 7:24 - loss: 0.6654 - acc: 0.5966
3968/9333 [===========>..................] - ETA: 7:19 - loss: 0.6650 - acc: 0.5968
4032/9333 [===========>..................] - ETA: 7:14 - loss: 0.6650 - acc: 0.5965
4096/9333 [============>.................] - ETA: 7:09 - loss: 0.6654 - acc: 0.5957
4160/9333 [============>.................] - ETA: 7:05 - loss: 0.6650 - acc: 0.5959
4224/9333 [============>.................] - ETA: 7:00 - loss: 0.6653 - acc: 0.5956
4288/9333 [============>.................] - ETA: 6:55 - loss: 0.6653 - acc: 0.5942
4352/9333 [============>.................] - ETA: 6:50 - loss: 0.6654 - acc: 0.5935
4416/9333 [=============>................] - ETA: 6:46 - loss: 0.6658 - acc: 0.5922
4480/9333 [=============>................] - ETA: 6:42 - loss: 0.6657 - acc: 0.5920
4544/9333 [=============>................] - ETA: 6:37 - loss: 0.6655 - acc: 0.5918
4608/9333 [=============>................] - ETA: 6:33 - loss: 0.6652 - acc: 0.5927
4672/9333 [==============>...............] - ETA: 6:29 - loss: 0.6649 - acc: 0.5938
4736/9333 [==============>...............] - ETA: 6:24 - loss: 0.6643 - acc: 0.5948
4800/9333 [==============>...............] - ETA: 6:20 - loss: 0.6634 - acc: 0.5962
4864/9333 [==============>...............] - ETA: 6:16 - loss: 0.6633 - acc: 0.5960
4928/9333 [==============>...............] - ETA: 6:12 - loss: 0.6630 - acc: 0.5958
4992/9333 [===============>..............] - ETA: 6:08 - loss: 0.6633 - acc: 0.5954
5056/9333 [===============>..............] - ETA: 6:03 - loss: 0.6634 - acc: 0.5945
5120/9333 [===============>..............] - ETA: 5:59 - loss: 0.6637 - acc: 0.5938
5184/9333 [===============>..............] - ETA: 5:54 - loss: 0.6633 - acc: 0.5939
5248/9333 [===============>..............] - ETA: 5:49 - loss: 0.6636 - acc: 0.5936
5312/9333 [================>.............] - ETA: 5:44 - loss: 0.6630 - acc: 0.5945
5376/9333 [================>.............] - ETA: 5:39 - loss: 0.6634 - acc: 0.5943
5440/9333 [================>.............] - ETA: 5:33 - loss: 0.6631 - acc: 0.5949
5504/9333 [================>.............] - ETA: 5:28 - loss: 0.6635 - acc: 0.5939
5568/9333 [================>.............] - ETA: 5:23 - loss: 0.6635 - acc: 0.5943
5632/9333 [=================>............] - ETA: 5:18 - loss: 0.6638 - acc: 0.5938
5696/9333 [=================>............] - ETA: 5:13 - loss: 0.6641 - acc: 0.5934
5760/9333 [=================>............] - ETA: 5:08 - loss: 0.6647 - acc: 0.5936
5824/9333 [=================>............] - ETA: 5:03 - loss: 0.6646 - acc: 0.5938
5888/9333 [=================>............] - ETA: 4:58 - loss: 0.6647 - acc: 0.5939
5952/9333 [==================>...........] - ETA: 4:53 - loss: 0.6649 - acc: 0.5934
6016/9333 [==================>...........] - ETA: 4:47 - loss: 0.6645 - acc: 0.5941
6080/9333 [==================>...........] - ETA: 4:42 - loss: 0.6645 - acc: 0.5941
6144/9333 [==================>...........] - ETA: 4:37 - loss: 0.6645 - acc: 0.5942
6208/9333 [==================>...........] - ETA: 4:32 - loss: 0.6643 - acc: 0.5941
6272/9333 [===================>..........] - ETA: 4:26 - loss: 0.6644 - acc: 0.5939
6336/9333 [===================>..........] - ETA: 4:21 - loss: 0.6649 - acc: 0.5931
6400/9333 [===================>..........] - ETA: 4:15 - loss: 0.6656 - acc: 0.5920
6464/9333 [===================>..........] - ETA: 4:10 - loss: 0.6659 - acc: 0.5910
6528/9333 [===================>..........] - ETA: 4:04 - loss: 0.6657 - acc: 0.5915
6592/9333 [====================>.........] - ETA: 3:58 - loss: 0.6655 - acc: 0.5924
6656/9333 [====================>.........] - ETA: 3:52 - loss: 0.6652 - acc: 0.5927
6720/9333 [====================>.........] - ETA: 3:47 - loss: 0.6653 - acc: 0.5926
6784/9333 [====================>.........] - ETA: 3:41 - loss: 0.6650 - acc: 0.5933
6848/9333 [=====================>........] - ETA: 3:35 - loss: 0.6651 - acc: 0.5929
6912/9333 [=====================>........] - ETA: 3:29 - loss: 0.6647 - acc: 0.5930
6976/9333 [=====================>........] - ETA: 3:23 - loss: 0.6646 - acc: 0.5930
7040/9333 [=====================>........] - ETA: 3:17 - loss: 0.6643 - acc: 0.5926
7104/9333 [=====================>........] - ETA: 3:12 - loss: 0.6648 - acc: 0.5912
7168/9333 [======================>.......] - ETA: 3:06 - loss: 0.6649 - acc: 0.5917
7232/9333 [======================>.......] - ETA: 3:00 - loss: 0.6651 - acc: 0.5908
7296/9333 [======================>.......] - ETA: 2:55 - loss: 0.6647 - acc: 0.5922
7360/9333 [======================>.......] - ETA: 2:49 - loss: 0.6650 - acc: 0.5921
7424/9333 [======================>.......] - ETA: 2:43 - loss: 0.6647 - acc: 0.5931
7488/9333 [=======================>......] - ETA: 2:38 - loss: 0.6644 - acc: 0.5932
7552/9333 [=======================>......] - ETA: 2:32 - loss: 0.6637 - acc: 0.5938
7616/9333 [=======================>......] - ETA: 2:26 - loss: 0.6639 - acc: 0.5935
7680/9333 [=======================>......] - ETA: 2:21 - loss: 0.6647 - acc: 0.5926
7744/9333 [=======================>......] - ETA: 2:16 - loss: 0.6645 - acc: 0.5930
7808/9333 [========================>.....] - ETA: 2:10 - loss: 0.6645 - acc: 0.5932
7872/9333 [========================>.....] - ETA: 2:05 - loss: 0.6645 - acc: 0.5935
7936/9333 [========================>.....] - ETA: 1:59 - loss: 0.6649 - acc: 0.5934
8000/9333 [========================>.....] - ETA: 1:54 - loss: 0.6645 - acc: 0.5940
8064/9333 [========================>.....] - ETA: 1:48 - loss: 0.6643 - acc: 0.5946
8128/9333 [=========================>....] - ETA: 1:43 - loss: 0.6637 - acc: 0.5955
8192/9333 [=========================>....] - ETA: 1:37 - loss: 0.6638 - acc: 0.5951
8256/9333 [=========================>....] - ETA: 1:32 - loss: 0.6640 - acc: 0.5948
8320/9333 [=========================>....] - ETA: 1:26 - loss: 0.6641 - acc: 0.5948
8384/9333 [=========================>....] - ETA: 1:21 - loss: 0.6644 - acc: 0.5942
8448/9333 [==========================>...] - ETA: 1:15 - loss: 0.6645 - acc: 0.5939
8512/9333 [==========================>...] - ETA: 1:10 - loss: 0.6639 - acc: 0.5948
8576/9333 [==========================>...] - ETA: 1:04 - loss: 0.6636 - acc: 0.5956
8640/9333 [==========================>...] - ETA: 59s - loss: 0.6636 - acc: 0.5959 
8704/9333 [==========================>...] - ETA: 53s - loss: 0.6637 - acc: 0.5962
8768/9333 [===========================>..] - ETA: 48s - loss: 0.6638 - acc: 0.5966
8832/9333 [===========================>..] - ETA: 42s - loss: 0.6638 - acc: 0.5965
8896/9333 [===========================>..] - ETA: 37s - loss: 0.6638 - acc: 0.5963
8960/9333 [===========================>..] - ETA: 31s - loss: 0.6638 - acc: 0.5962
9024/9333 [============================>.] - ETA: 26s - loss: 0.6634 - acc: 0.5965
9088/9333 [============================>.] - ETA: 20s - loss: 0.6637 - acc: 0.5961
9152/9333 [============================>.] - ETA: 15s - loss: 0.6640 - acc: 0.5954
9216/9333 [============================>.] - ETA: 10s - loss: 0.6645 - acc: 0.5947
9280/9333 [============================>.] - ETA: 4s - loss: 0.6643 - acc: 0.5946 
9333/9333 [==============================] - 829s 89ms/step - loss: 0.6641 - acc: 0.5948 - val_loss: 0.6695 - val_acc: 0.5931

Epoch 00004: val_acc improved from 0.56895 to 0.59306, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window11/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 5/10

  64/9333 [..............................] - ETA: 11:38 - loss: 0.6232 - acc: 0.6719
 128/9333 [..............................] - ETA: 11:54 - loss: 0.6651 - acc: 0.5781
 192/9333 [..............................] - ETA: 11:58 - loss: 0.6605 - acc: 0.6042
 256/9333 [..............................] - ETA: 12:23 - loss: 0.6561 - acc: 0.6133
 320/9333 [>.............................] - ETA: 12:46 - loss: 0.6550 - acc: 0.6156
 384/9333 [>.............................] - ETA: 13:01 - loss: 0.6569 - acc: 0.6172
 448/9333 [>.............................] - ETA: 13:00 - loss: 0.6541 - acc: 0.6228
 512/9333 [>.............................] - ETA: 12:49 - loss: 0.6550 - acc: 0.6172
 576/9333 [>.............................] - ETA: 12:47 - loss: 0.6585 - acc: 0.6128
 640/9333 [=>............................] - ETA: 12:32 - loss: 0.6576 - acc: 0.6172
 704/9333 [=>............................] - ETA: 12:25 - loss: 0.6585 - acc: 0.6165
 768/9333 [=>............................] - ETA: 12:15 - loss: 0.6573 - acc: 0.6146
 832/9333 [=>............................] - ETA: 12:00 - loss: 0.6573 - acc: 0.6166
 896/9333 [=>............................] - ETA: 11:48 - loss: 0.6594 - acc: 0.6116
 960/9333 [==>...........................] - ETA: 11:37 - loss: 0.6624 - acc: 0.6052
1024/9333 [==>...........................] - ETA: 11:46 - loss: 0.6636 - acc: 0.6025
1088/9333 [==>...........................] - ETA: 11:50 - loss: 0.6633 - acc: 0.6048
1152/9333 [==>...........................] - ETA: 11:43 - loss: 0.6646 - acc: 0.6042
1216/9333 [==>...........................] - ETA: 11:40 - loss: 0.6657 - acc: 0.6036
1280/9333 [===>..........................] - ETA: 11:35 - loss: 0.6640 - acc: 0.6086
1344/9333 [===>..........................] - ETA: 11:27 - loss: 0.6615 - acc: 0.6109
1408/9333 [===>..........................] - ETA: 11:18 - loss: 0.6626 - acc: 0.6101
1472/9333 [===>..........................] - ETA: 11:10 - loss: 0.6611 - acc: 0.6080
1536/9333 [===>..........................] - ETA: 11:01 - loss: 0.6601 - acc: 0.6087
1600/9333 [====>.........................] - ETA: 10:53 - loss: 0.6608 - acc: 0.6088
1664/9333 [====>.........................] - ETA: 10:43 - loss: 0.6599 - acc: 0.6082
1728/9333 [====>.........................] - ETA: 10:34 - loss: 0.6585 - acc: 0.6100
1792/9333 [====>.........................] - ETA: 10:31 - loss: 0.6598 - acc: 0.6094
1856/9333 [====>.........................] - ETA: 10:33 - loss: 0.6598 - acc: 0.6072
1920/9333 [=====>........................] - ETA: 10:28 - loss: 0.6586 - acc: 0.6109
1984/9333 [=====>........................] - ETA: 10:22 - loss: 0.6593 - acc: 0.6099
2048/9333 [=====>........................] - ETA: 10:21 - loss: 0.6597 - acc: 0.6099
2112/9333 [=====>........................] - ETA: 10:16 - loss: 0.6596 - acc: 0.6084
2176/9333 [=====>........................] - ETA: 10:09 - loss: 0.6592 - acc: 0.6094
2240/9333 [======>.......................] - ETA: 10:02 - loss: 0.6590 - acc: 0.6080
2304/9333 [======>.......................] - ETA: 9:55 - loss: 0.6598 - acc: 0.6072 
2368/9333 [======>.......................] - ETA: 9:49 - loss: 0.6606 - acc: 0.6052
2432/9333 [======>.......................] - ETA: 9:41 - loss: 0.6613 - acc: 0.6044
2496/9333 [=======>......................] - ETA: 9:36 - loss: 0.6627 - acc: 0.6018
2560/9333 [=======>......................] - ETA: 9:33 - loss: 0.6626 - acc: 0.6020
2624/9333 [=======>......................] - ETA: 9:31 - loss: 0.6612 - acc: 0.6040
2688/9333 [=======>......................] - ETA: 9:27 - loss: 0.6611 - acc: 0.6045
2752/9333 [=======>......................] - ETA: 9:24 - loss: 0.6619 - acc: 0.6032
2816/9333 [========>.....................] - ETA: 9:19 - loss: 0.6616 - acc: 0.6023
2880/9333 [========>.....................] - ETA: 9:14 - loss: 0.6622 - acc: 0.6003
2944/9333 [========>.....................] - ETA: 9:09 - loss: 0.6622 - acc: 0.6009
3008/9333 [========>.....................] - ETA: 9:05 - loss: 0.6632 - acc: 0.5994
3072/9333 [========>.....................] - ETA: 9:00 - loss: 0.6632 - acc: 0.5986
3136/9333 [=========>....................] - ETA: 8:56 - loss: 0.6638 - acc: 0.5976
3200/9333 [=========>....................] - ETA: 8:51 - loss: 0.6639 - acc: 0.5966
3264/9333 [=========>....................] - ETA: 8:46 - loss: 0.6641 - acc: 0.5971
3328/9333 [=========>....................] - ETA: 8:40 - loss: 0.6646 - acc: 0.5956
3392/9333 [=========>....................] - ETA: 8:36 - loss: 0.6645 - acc: 0.5952
3456/9333 [==========>...................] - ETA: 8:30 - loss: 0.6644 - acc: 0.5949
3520/9333 [==========>...................] - ETA: 8:26 - loss: 0.6648 - acc: 0.5946
3584/9333 [==========>...................] - ETA: 8:21 - loss: 0.6645 - acc: 0.5943
3648/9333 [==========>...................] - ETA: 8:16 - loss: 0.6644 - acc: 0.5946
3712/9333 [==========>...................] - ETA: 8:11 - loss: 0.6642 - acc: 0.5954
3776/9333 [===========>..................] - ETA: 8:08 - loss: 0.6636 - acc: 0.5967
3840/9333 [===========>..................] - ETA: 8:04 - loss: 0.6643 - acc: 0.5945
3904/9333 [===========>..................] - ETA: 7:59 - loss: 0.6650 - acc: 0.5930
3968/9333 [===========>..................] - ETA: 7:54 - loss: 0.6642 - acc: 0.5953
4032/9333 [===========>..................] - ETA: 7:49 - loss: 0.6638 - acc: 0.5957
4096/9333 [============>.................] - ETA: 7:43 - loss: 0.6648 - acc: 0.5952
4160/9333 [============>.................] - ETA: 7:38 - loss: 0.6652 - acc: 0.5942
4224/9333 [============>.................] - ETA: 7:34 - loss: 0.6646 - acc: 0.5954
4288/9333 [============>.................] - ETA: 7:28 - loss: 0.6644 - acc: 0.5954
4352/9333 [============>.................] - ETA: 7:22 - loss: 0.6640 - acc: 0.5954
4416/9333 [=============>................] - ETA: 7:16 - loss: 0.6651 - acc: 0.5938
4480/9333 [=============>................] - ETA: 7:11 - loss: 0.6649 - acc: 0.5933
4544/9333 [=============>................] - ETA: 7:05 - loss: 0.6648 - acc: 0.5949
4608/9333 [=============>................] - ETA: 7:00 - loss: 0.6653 - acc: 0.5942
4672/9333 [==============>...............] - ETA: 6:55 - loss: 0.6648 - acc: 0.5952
4736/9333 [==============>...............] - ETA: 6:49 - loss: 0.6646 - acc: 0.5954
4800/9333 [==============>...............] - ETA: 6:43 - loss: 0.6640 - acc: 0.5965
4864/9333 [==============>...............] - ETA: 6:38 - loss: 0.6641 - acc: 0.5960
4928/9333 [==============>...............] - ETA: 6:33 - loss: 0.6642 - acc: 0.5956
4992/9333 [===============>..............] - ETA: 6:27 - loss: 0.6638 - acc: 0.5962
5056/9333 [===============>..............] - ETA: 6:22 - loss: 0.6632 - acc: 0.5971
5120/9333 [===============>..............] - ETA: 6:16 - loss: 0.6629 - acc: 0.5975
5184/9333 [===============>..............] - ETA: 6:11 - loss: 0.6631 - acc: 0.5965
5248/9333 [===============>..............] - ETA: 6:05 - loss: 0.6629 - acc: 0.5970
5312/9333 [================>.............] - ETA: 6:00 - loss: 0.6627 - acc: 0.5971
5376/9333 [================>.............] - ETA: 5:54 - loss: 0.6627 - acc: 0.5975
5440/9333 [================>.............] - ETA: 5:48 - loss: 0.6627 - acc: 0.5976
5504/9333 [================>.............] - ETA: 5:43 - loss: 0.6619 - acc: 0.5985
5568/9333 [================>.............] - ETA: 5:37 - loss: 0.6616 - acc: 0.5986
5632/9333 [=================>............] - ETA: 5:31 - loss: 0.6613 - acc: 0.5991
5696/9333 [=================>............] - ETA: 5:25 - loss: 0.6618 - acc: 0.5981
5760/9333 [=================>............] - ETA: 5:20 - loss: 0.6614 - acc: 0.5983
5824/9333 [=================>............] - ETA: 5:14 - loss: 0.6611 - acc: 0.5998
5888/9333 [=================>............] - ETA: 5:08 - loss: 0.6609 - acc: 0.6000
5952/9333 [==================>...........] - ETA: 5:03 - loss: 0.6611 - acc: 0.6001
6016/9333 [==================>...........] - ETA: 4:57 - loss: 0.6610 - acc: 0.6009
6080/9333 [==================>...........] - ETA: 4:51 - loss: 0.6606 - acc: 0.6013
6144/9333 [==================>...........] - ETA: 4:45 - loss: 0.6602 - acc: 0.6019
6208/9333 [==================>...........] - ETA: 4:40 - loss: 0.6602 - acc: 0.6020
6272/9333 [===================>..........] - ETA: 4:34 - loss: 0.6607 - acc: 0.6011
6336/9333 [===================>..........] - ETA: 4:29 - loss: 0.6610 - acc: 0.6007
6400/9333 [===================>..........] - ETA: 4:23 - loss: 0.6611 - acc: 0.6006
6464/9333 [===================>..........] - ETA: 4:17 - loss: 0.6613 - acc: 0.6009
6528/9333 [===================>..........] - ETA: 4:11 - loss: 0.6613 - acc: 0.6006
6592/9333 [====================>.........] - ETA: 4:06 - loss: 0.6617 - acc: 0.6000
6656/9333 [====================>.........] - ETA: 4:00 - loss: 0.6616 - acc: 0.5999
6720/9333 [====================>.........] - ETA: 3:54 - loss: 0.6617 - acc: 0.6000
6784/9333 [====================>.........] - ETA: 3:48 - loss: 0.6620 - acc: 0.6001
6848/9333 [=====================>........] - ETA: 3:42 - loss: 0.6620 - acc: 0.6000
6912/9333 [=====================>........] - ETA: 3:37 - loss: 0.6623 - acc: 0.5994
6976/9333 [=====================>........] - ETA: 3:31 - loss: 0.6621 - acc: 0.5996
7040/9333 [=====================>........] - ETA: 3:25 - loss: 0.6619 - acc: 0.5996
7104/9333 [=====================>........] - ETA: 3:19 - loss: 0.6624 - acc: 0.5984
7168/9333 [======================>.......] - ETA: 3:13 - loss: 0.6628 - acc: 0.5977
7232/9333 [======================>.......] - ETA: 3:07 - loss: 0.6629 - acc: 0.5971
7296/9333 [======================>.......] - ETA: 3:02 - loss: 0.6629 - acc: 0.5968
7360/9333 [======================>.......] - ETA: 2:56 - loss: 0.6639 - acc: 0.5954
7424/9333 [======================>.......] - ETA: 2:50 - loss: 0.6640 - acc: 0.5951
7488/9333 [=======================>......] - ETA: 2:44 - loss: 0.6640 - acc: 0.5951
7552/9333 [=======================>......] - ETA: 2:38 - loss: 0.6643 - acc: 0.5948
7616/9333 [=======================>......] - ETA: 2:32 - loss: 0.6645 - acc: 0.5944
7680/9333 [=======================>......] - ETA: 2:26 - loss: 0.6646 - acc: 0.5941
7744/9333 [=======================>......] - ETA: 2:20 - loss: 0.6646 - acc: 0.5941
7808/9333 [========================>.....] - ETA: 2:14 - loss: 0.6649 - acc: 0.5940
7872/9333 [========================>.....] - ETA: 2:09 - loss: 0.6650 - acc: 0.5938
7936/9333 [========================>.....] - ETA: 2:03 - loss: 0.6651 - acc: 0.5934
8000/9333 [========================>.....] - ETA: 1:57 - loss: 0.6650 - acc: 0.5936
8064/9333 [========================>.....] - ETA: 1:52 - loss: 0.6650 - acc: 0.5936
8128/9333 [=========================>....] - ETA: 1:46 - loss: 0.6648 - acc: 0.5940
8192/9333 [=========================>....] - ETA: 1:40 - loss: 0.6649 - acc: 0.5942
8256/9333 [=========================>....] - ETA: 1:34 - loss: 0.6651 - acc: 0.5941
8320/9333 [=========================>....] - ETA: 1:29 - loss: 0.6651 - acc: 0.5939
8384/9333 [=========================>....] - ETA: 1:23 - loss: 0.6651 - acc: 0.5939
8448/9333 [==========================>...] - ETA: 1:17 - loss: 0.6650 - acc: 0.5943
8512/9333 [==========================>...] - ETA: 1:11 - loss: 0.6652 - acc: 0.5939
8576/9333 [==========================>...] - ETA: 1:06 - loss: 0.6650 - acc: 0.5940
8640/9333 [==========================>...] - ETA: 1:00 - loss: 0.6648 - acc: 0.5943
8704/9333 [==========================>...] - ETA: 55s - loss: 0.6650 - acc: 0.5939 
8768/9333 [===========================>..] - ETA: 49s - loss: 0.6645 - acc: 0.5951
8832/9333 [===========================>..] - ETA: 44s - loss: 0.6642 - acc: 0.5954
8896/9333 [===========================>..] - ETA: 38s - loss: 0.6640 - acc: 0.5959
8960/9333 [===========================>..] - ETA: 32s - loss: 0.6638 - acc: 0.5962
9024/9333 [============================>.] - ETA: 27s - loss: 0.6633 - acc: 0.5966
9088/9333 [============================>.] - ETA: 21s - loss: 0.6636 - acc: 0.5958
9152/9333 [============================>.] - ETA: 15s - loss: 0.6636 - acc: 0.5954
9216/9333 [============================>.] - ETA: 10s - loss: 0.6639 - acc: 0.5952
9280/9333 [============================>.] - ETA: 4s - loss: 0.6642 - acc: 0.5948 
9333/9333 [==============================] - 845s 91ms/step - loss: 0.6643 - acc: 0.5946 - val_loss: 0.6806 - val_acc: 0.5738

Epoch 00005: val_acc did not improve from 0.59306
Epoch 6/10

  64/9333 [..............................] - ETA: 10:49 - loss: 0.7202 - acc: 0.4844
 128/9333 [..............................] - ETA: 10:51 - loss: 0.6767 - acc: 0.5547
 192/9333 [..............................] - ETA: 10:31 - loss: 0.6592 - acc: 0.5781
 256/9333 [..............................] - ETA: 10:32 - loss: 0.6660 - acc: 0.5547
 320/9333 [>.............................] - ETA: 10:36 - loss: 0.6701 - acc: 0.5687
 384/9333 [>.............................] - ETA: 11:14 - loss: 0.6699 - acc: 0.5729
 448/9333 [>.............................] - ETA: 12:02 - loss: 0.6642 - acc: 0.5804
 512/9333 [>.............................] - ETA: 12:04 - loss: 0.6668 - acc: 0.5781
 576/9333 [>.............................] - ETA: 12:04 - loss: 0.6633 - acc: 0.5851
 640/9333 [=>............................] - ETA: 12:06 - loss: 0.6598 - acc: 0.5875
 704/9333 [=>............................] - ETA: 11:49 - loss: 0.6549 - acc: 0.5966
 768/9333 [=>............................] - ETA: 11:38 - loss: 0.6521 - acc: 0.6042
 832/9333 [=>............................] - ETA: 11:23 - loss: 0.6551 - acc: 0.6010
 896/9333 [=>............................] - ETA: 11:11 - loss: 0.6540 - acc: 0.6038
 960/9333 [==>...........................] - ETA: 10:56 - loss: 0.6573 - acc: 0.6021
1024/9333 [==>...........................] - ETA: 10:48 - loss: 0.6610 - acc: 0.5967
1088/9333 [==>...........................] - ETA: 10:38 - loss: 0.6602 - acc: 0.5928
1152/9333 [==>...........................] - ETA: 10:41 - loss: 0.6594 - acc: 0.5946
1216/9333 [==>...........................] - ETA: 10:40 - loss: 0.6605 - acc: 0.5929
1280/9333 [===>..........................] - ETA: 10:40 - loss: 0.6583 - acc: 0.5961
1344/9333 [===>..........................] - ETA: 10:38 - loss: 0.6602 - acc: 0.5975
1408/9333 [===>..........................] - ETA: 10:36 - loss: 0.6594 - acc: 0.5952
1472/9333 [===>..........................] - ETA: 10:34 - loss: 0.6606 - acc: 0.5917
1536/9333 [===>..........................] - ETA: 10:26 - loss: 0.6628 - acc: 0.5898
1600/9333 [====>.........................] - ETA: 10:23 - loss: 0.6635 - acc: 0.5863
1664/9333 [====>.........................] - ETA: 10:19 - loss: 0.6607 - acc: 0.5925
1728/9333 [====>.........................] - ETA: 10:17 - loss: 0.6595 - acc: 0.5961
1792/9333 [====>.........................] - ETA: 10:13 - loss: 0.6608 - acc: 0.5932
1856/9333 [====>.........................] - ETA: 10:13 - loss: 0.6598 - acc: 0.5938
1920/9333 [=====>........................] - ETA: 10:15 - loss: 0.6603 - acc: 0.5943
1984/9333 [=====>........................] - ETA: 10:15 - loss: 0.6611 - acc: 0.5948
2048/9333 [=====>........................] - ETA: 10:11 - loss: 0.6632 - acc: 0.5933
2112/9333 [=====>........................] - ETA: 10:10 - loss: 0.6641 - acc: 0.5928
2176/9333 [=====>........................] - ETA: 10:06 - loss: 0.6635 - acc: 0.5933
2240/9333 [======>.......................] - ETA: 10:01 - loss: 0.6628 - acc: 0.5929
2304/9333 [======>.......................] - ETA: 9:55 - loss: 0.6639 - acc: 0.5920 
2368/9333 [======>.......................] - ETA: 9:50 - loss: 0.6643 - acc: 0.5921
2432/9333 [======>.......................] - ETA: 9:44 - loss: 0.6642 - acc: 0.5921
2496/9333 [=======>......................] - ETA: 9:40 - loss: 0.6640 - acc: 0.5917
2560/9333 [=======>......................] - ETA: 9:35 - loss: 0.6645 - acc: 0.5922
2624/9333 [=======>......................] - ETA: 9:34 - loss: 0.6634 - acc: 0.5949
2688/9333 [=======>......................] - ETA: 9:32 - loss: 0.6629 - acc: 0.5949
2752/9333 [=======>......................] - ETA: 9:29 - loss: 0.6639 - acc: 0.5938
2816/9333 [========>.....................] - ETA: 9:26 - loss: 0.6637 - acc: 0.5941
2880/9333 [========>.....................] - ETA: 9:22 - loss: 0.6639 - acc: 0.5938
2944/9333 [========>.....................] - ETA: 9:15 - loss: 0.6631 - acc: 0.5948
3008/9333 [========>.....................] - ETA: 9:10 - loss: 0.6631 - acc: 0.5961
3072/9333 [========>.....................] - ETA: 9:05 - loss: 0.6628 - acc: 0.5957
3136/9333 [=========>....................] - ETA: 8:59 - loss: 0.6628 - acc: 0.5957
3200/9333 [=========>....................] - ETA: 8:53 - loss: 0.6621 - acc: 0.5962
3264/9333 [=========>....................] - ETA: 8:51 - loss: 0.6625 - acc: 0.5962
3328/9333 [=========>....................] - ETA: 8:49 - loss: 0.6624 - acc: 0.5971
3392/9333 [=========>....................] - ETA: 8:46 - loss: 0.6625 - acc: 0.5967
3456/9333 [==========>...................] - ETA: 8:41 - loss: 0.6622 - acc: 0.5975
3520/9333 [==========>...................] - ETA: 8:36 - loss: 0.6627 - acc: 0.5957
3584/9333 [==========>...................] - ETA: 8:31 - loss: 0.6633 - acc: 0.5949
3648/9333 [==========>...................] - ETA: 8:27 - loss: 0.6622 - acc: 0.5968
3712/9333 [==========>...................] - ETA: 8:23 - loss: 0.6610 - acc: 0.5983
3776/9333 [===========>..................] - ETA: 8:18 - loss: 0.6616 - acc: 0.5975
3840/9333 [===========>..................] - ETA: 8:13 - loss: 0.6619 - acc: 0.5969
3904/9333 [===========>..................] - ETA: 8:09 - loss: 0.6621 - acc: 0.5973
3968/9333 [===========>..................] - ETA: 8:04 - loss: 0.6624 - acc: 0.5968
4032/9333 [===========>..................] - ETA: 7:59 - loss: 0.6619 - acc: 0.5980
4096/9333 [============>.................] - ETA: 7:54 - loss: 0.6619 - acc: 0.5972
4160/9333 [============>.................] - ETA: 7:50 - loss: 0.6616 - acc: 0.5976
4224/9333 [============>.................] - ETA: 7:45 - loss: 0.6612 - acc: 0.5980
4288/9333 [============>.................] - ETA: 7:41 - loss: 0.6608 - acc: 0.5996
4352/9333 [============>.................] - ETA: 7:37 - loss: 0.6610 - acc: 0.6002
4416/9333 [=============>................] - ETA: 7:32 - loss: 0.6605 - acc: 0.6003
4480/9333 [=============>................] - ETA: 7:27 - loss: 0.6605 - acc: 0.5998
4544/9333 [=============>................] - ETA: 7:22 - loss: 0.6599 - acc: 0.6008
4608/9333 [=============>................] - ETA: 7:17 - loss: 0.6596 - acc: 0.6007
4672/9333 [==============>...............] - ETA: 7:13 - loss: 0.6598 - acc: 0.6002
4736/9333 [==============>...............] - ETA: 7:07 - loss: 0.6599 - acc: 0.6009
4800/9333 [==============>...............] - ETA: 7:02 - loss: 0.6597 - acc: 0.6010
4864/9333 [==============>...............] - ETA: 6:57 - loss: 0.6608 - acc: 0.5995
4928/9333 [==============>...............] - ETA: 6:51 - loss: 0.6610 - acc: 0.6002
4992/9333 [===============>..............] - ETA: 6:46 - loss: 0.6616 - acc: 0.5990
5056/9333 [===============>..............] - ETA: 6:40 - loss: 0.6621 - acc: 0.5987
5120/9333 [===============>..............] - ETA: 6:35 - loss: 0.6622 - acc: 0.5992
5184/9333 [===============>..............] - ETA: 6:29 - loss: 0.6618 - acc: 0.5997
5248/9333 [===============>..............] - ETA: 6:24 - loss: 0.6615 - acc: 0.5998
5312/9333 [================>.............] - ETA: 6:19 - loss: 0.6617 - acc: 0.5994
5376/9333 [================>.............] - ETA: 6:14 - loss: 0.6618 - acc: 0.5991
5440/9333 [================>.............] - ETA: 6:09 - loss: 0.6620 - acc: 0.5987
5504/9333 [================>.............] - ETA: 6:03 - loss: 0.6621 - acc: 0.5979
5568/9333 [================>.............] - ETA: 5:58 - loss: 0.6619 - acc: 0.5988
5632/9333 [=================>............] - ETA: 5:51 - loss: 0.6614 - acc: 0.5996
5696/9333 [=================>............] - ETA: 5:46 - loss: 0.6615 - acc: 0.5995
5760/9333 [=================>............] - ETA: 5:40 - loss: 0.6617 - acc: 0.5990
5824/9333 [=================>............] - ETA: 5:35 - loss: 0.6616 - acc: 0.5992
5888/9333 [=================>............] - ETA: 5:29 - loss: 0.6620 - acc: 0.5983
5952/9333 [==================>...........] - ETA: 5:23 - loss: 0.6619 - acc: 0.5990
6016/9333 [==================>...........] - ETA: 5:17 - loss: 0.6622 - acc: 0.5981
6080/9333 [==================>...........] - ETA: 5:12 - loss: 0.6622 - acc: 0.5985
6144/9333 [==================>...........] - ETA: 5:06 - loss: 0.6618 - acc: 0.5986
6208/9333 [==================>...........] - ETA: 5:00 - loss: 0.6614 - acc: 0.5997
6272/9333 [===================>..........] - ETA: 4:54 - loss: 0.6622 - acc: 0.5987
6336/9333 [===================>..........] - ETA: 4:48 - loss: 0.6623 - acc: 0.5988
6400/9333 [===================>..........] - ETA: 4:42 - loss: 0.6625 - acc: 0.5984
6464/9333 [===================>..........] - ETA: 4:36 - loss: 0.6624 - acc: 0.5987
6528/9333 [===================>..........] - ETA: 4:30 - loss: 0.6624 - acc: 0.5985
6592/9333 [====================>.........] - ETA: 4:24 - loss: 0.6624 - acc: 0.5981
6656/9333 [====================>.........] - ETA: 4:18 - loss: 0.6621 - acc: 0.5989
6720/9333 [====================>.........] - ETA: 4:12 - loss: 0.6618 - acc: 0.5991
6784/9333 [====================>.........] - ETA: 4:06 - loss: 0.6619 - acc: 0.5994
6848/9333 [=====================>........] - ETA: 4:00 - loss: 0.6620 - acc: 0.5993
6912/9333 [=====================>........] - ETA: 3:54 - loss: 0.6620 - acc: 0.5985
6976/9333 [=====================>........] - ETA: 3:47 - loss: 0.6622 - acc: 0.5982
7040/9333 [=====================>........] - ETA: 3:41 - loss: 0.6625 - acc: 0.5976
7104/9333 [=====================>........] - ETA: 3:35 - loss: 0.6619 - acc: 0.5987
7168/9333 [======================>.......] - ETA: 3:29 - loss: 0.6622 - acc: 0.5979
7232/9333 [======================>.......] - ETA: 3:22 - loss: 0.6621 - acc: 0.5983
7296/9333 [======================>.......] - ETA: 3:16 - loss: 0.6621 - acc: 0.5980
7360/9333 [======================>.......] - ETA: 3:10 - loss: 0.6625 - acc: 0.5976
7424/9333 [======================>.......] - ETA: 3:04 - loss: 0.6621 - acc: 0.5982
7488/9333 [=======================>......] - ETA: 2:58 - loss: 0.6622 - acc: 0.5978
7552/9333 [=======================>......] - ETA: 2:52 - loss: 0.6620 - acc: 0.5976
7616/9333 [=======================>......] - ETA: 2:45 - loss: 0.6618 - acc: 0.5977
7680/9333 [=======================>......] - ETA: 2:39 - loss: 0.6621 - acc: 0.5975
7744/9333 [=======================>......] - ETA: 2:33 - loss: 0.6621 - acc: 0.5976
7808/9333 [========================>.....] - ETA: 2:27 - loss: 0.6622 - acc: 0.5977
7872/9333 [========================>.....] - ETA: 2:21 - loss: 0.6626 - acc: 0.5976
7936/9333 [========================>.....] - ETA: 2:14 - loss: 0.6625 - acc: 0.5980
8000/9333 [========================>.....] - ETA: 2:08 - loss: 0.6628 - acc: 0.5975
8064/9333 [========================>.....] - ETA: 2:02 - loss: 0.6624 - acc: 0.5976
8128/9333 [=========================>....] - ETA: 1:56 - loss: 0.6623 - acc: 0.5974
8192/9333 [=========================>....] - ETA: 1:50 - loss: 0.6619 - acc: 0.5980
8256/9333 [=========================>....] - ETA: 1:44 - loss: 0.6618 - acc: 0.5981
8320/9333 [=========================>....] - ETA: 1:38 - loss: 0.6622 - acc: 0.5978
8384/9333 [=========================>....] - ETA: 1:31 - loss: 0.6622 - acc: 0.5978
8448/9333 [==========================>...] - ETA: 1:25 - loss: 0.6621 - acc: 0.5980
8512/9333 [==========================>...] - ETA: 1:19 - loss: 0.6621 - acc: 0.5981
8576/9333 [==========================>...] - ETA: 1:13 - loss: 0.6623 - acc: 0.5972
8640/9333 [==========================>...] - ETA: 1:07 - loss: 0.6618 - acc: 0.5973
8704/9333 [==========================>...] - ETA: 1:00 - loss: 0.6618 - acc: 0.5971
8768/9333 [===========================>..] - ETA: 54s - loss: 0.6618 - acc: 0.5971 
8832/9333 [===========================>..] - ETA: 48s - loss: 0.6616 - acc: 0.5973
8896/9333 [===========================>..] - ETA: 42s - loss: 0.6616 - acc: 0.5972
8960/9333 [===========================>..] - ETA: 36s - loss: 0.6621 - acc: 0.5965
9024/9333 [============================>.] - ETA: 29s - loss: 0.6621 - acc: 0.5962
9088/9333 [============================>.] - ETA: 23s - loss: 0.6618 - acc: 0.5971
9152/9333 [============================>.] - ETA: 17s - loss: 0.6613 - acc: 0.5978
9216/9333 [============================>.] - ETA: 11s - loss: 0.6613 - acc: 0.5978
9280/9333 [============================>.] - ETA: 5s - loss: 0.6614 - acc: 0.5986 
9333/9333 [==============================] - 934s 100ms/step - loss: 0.6612 - acc: 0.5992 - val_loss: 0.6666 - val_acc: 0.5622

Epoch 00006: val_acc did not improve from 0.59306
Epoch 7/10

  64/9333 [..............................] - ETA: 12:43 - loss: 0.6989 - acc: 0.5781
 128/9333 [..............................] - ETA: 13:33 - loss: 0.6550 - acc: 0.6094
 192/9333 [..............................] - ETA: 13:23 - loss: 0.6520 - acc: 0.6302
 256/9333 [..............................] - ETA: 13:12 - loss: 0.6397 - acc: 0.6367
 320/9333 [>.............................] - ETA: 12:57 - loss: 0.6472 - acc: 0.6156
 384/9333 [>.............................] - ETA: 12:59 - loss: 0.6474 - acc: 0.6172
 448/9333 [>.............................] - ETA: 13:20 - loss: 0.6402 - acc: 0.6250
 512/9333 [>.............................] - ETA: 13:31 - loss: 0.6359 - acc: 0.6309
 576/9333 [>.............................] - ETA: 13:34 - loss: 0.6362 - acc: 0.6354
 640/9333 [=>............................] - ETA: 13:37 - loss: 0.6383 - acc: 0.6359
 704/9333 [=>............................] - ETA: 13:30 - loss: 0.6348 - acc: 0.6392
 768/9333 [=>............................] - ETA: 13:21 - loss: 0.6416 - acc: 0.6341
 832/9333 [=>............................] - ETA: 13:15 - loss: 0.6415 - acc: 0.6334
 896/9333 [=>............................] - ETA: 13:17 - loss: 0.6459 - acc: 0.6250
 960/9333 [==>...........................] - ETA: 13:11 - loss: 0.6466 - acc: 0.6240
1024/9333 [==>...........................] - ETA: 13:06 - loss: 0.6447 - acc: 0.6289
1088/9333 [==>...........................] - ETA: 13:05 - loss: 0.6475 - acc: 0.6250
1152/9333 [==>...........................] - ETA: 13:03 - loss: 0.6459 - acc: 0.6267
1216/9333 [==>...........................] - ETA: 13:02 - loss: 0.6458 - acc: 0.6291
1280/9333 [===>..........................] - ETA: 12:56 - loss: 0.6476 - acc: 0.6289
1344/9333 [===>..........................] - ETA: 12:53 - loss: 0.6447 - acc: 0.6302
1408/9333 [===>..........................] - ETA: 12:49 - loss: 0.6445 - acc: 0.6300
1472/9333 [===>..........................] - ETA: 12:43 - loss: 0.6443 - acc: 0.6311
1536/9333 [===>..........................] - ETA: 12:39 - loss: 0.6453 - acc: 0.6289
1600/9333 [====>.........................] - ETA: 12:35 - loss: 0.6464 - acc: 0.6294
1664/9333 [====>.........................] - ETA: 12:30 - loss: 0.6472 - acc: 0.6298
1728/9333 [====>.........................] - ETA: 12:26 - loss: 0.6495 - acc: 0.6285
1792/9333 [====>.........................] - ETA: 12:21 - loss: 0.6490 - acc: 0.6289
1856/9333 [====>.........................] - ETA: 12:18 - loss: 0.6501 - acc: 0.6272
1920/9333 [=====>........................] - ETA: 12:13 - loss: 0.6513 - acc: 0.6276
1984/9333 [=====>........................] - ETA: 12:09 - loss: 0.6537 - acc: 0.6255
2048/9333 [=====>........................] - ETA: 12:05 - loss: 0.6542 - acc: 0.6250
2112/9333 [=====>........................] - ETA: 11:59 - loss: 0.6555 - acc: 0.6245
2176/9333 [=====>........................] - ETA: 11:53 - loss: 0.6541 - acc: 0.6245
2240/9333 [======>.......................] - ETA: 11:47 - loss: 0.6529 - acc: 0.6246
2304/9333 [======>.......................] - ETA: 11:42 - loss: 0.6529 - acc: 0.6237
2368/9333 [======>.......................] - ETA: 11:37 - loss: 0.6525 - acc: 0.6233
2432/9333 [======>.......................] - ETA: 11:31 - loss: 0.6530 - acc: 0.6225
2496/9333 [=======>......................] - ETA: 11:25 - loss: 0.6523 - acc: 0.6246
2560/9333 [=======>......................] - ETA: 11:19 - loss: 0.6538 - acc: 0.6230
2624/9333 [=======>......................] - ETA: 11:13 - loss: 0.6540 - acc: 0.6231
2688/9333 [=======>......................] - ETA: 11:06 - loss: 0.6530 - acc: 0.6239
2752/9333 [=======>......................] - ETA: 11:00 - loss: 0.6541 - acc: 0.6232
2816/9333 [========>.....................] - ETA: 10:54 - loss: 0.6551 - acc: 0.6207
2880/9333 [========>.....................] - ETA: 10:48 - loss: 0.6546 - acc: 0.6215
2944/9333 [========>.....................] - ETA: 10:41 - loss: 0.6541 - acc: 0.6226
3008/9333 [========>.....................] - ETA: 10:34 - loss: 0.6541 - acc: 0.6233
3072/9333 [========>.....................] - ETA: 10:28 - loss: 0.6533 - acc: 0.6247
3136/9333 [=========>....................] - ETA: 10:21 - loss: 0.6527 - acc: 0.6253
3200/9333 [=========>....................] - ETA: 10:16 - loss: 0.6523 - acc: 0.6259
3264/9333 [=========>....................] - ETA: 10:10 - loss: 0.6524 - acc: 0.6262
3328/9333 [=========>....................] - ETA: 10:05 - loss: 0.6527 - acc: 0.6265
3392/9333 [=========>....................] - ETA: 9:58 - loss: 0.6516 - acc: 0.6279 
3456/9333 [==========>...................] - ETA: 9:52 - loss: 0.6521 - acc: 0.6267
3520/9333 [==========>...................] - ETA: 9:46 - loss: 0.6519 - acc: 0.6267
3584/9333 [==========>...................] - ETA: 9:39 - loss: 0.6526 - acc: 0.6250
3648/9333 [==========>...................] - ETA: 9:33 - loss: 0.6524 - acc: 0.6255
3712/9333 [==========>...................] - ETA: 9:27 - loss: 0.6520 - acc: 0.6255
3776/9333 [===========>..................] - ETA: 9:21 - loss: 0.6519 - acc: 0.6258
3840/9333 [===========>..................] - ETA: 9:14 - loss: 0.6522 - acc: 0.6247
3904/9333 [===========>..................] - ETA: 9:07 - loss: 0.6516 - acc: 0.6258
3968/9333 [===========>..................] - ETA: 9:00 - loss: 0.6521 - acc: 0.6250
4032/9333 [===========>..................] - ETA: 8:53 - loss: 0.6515 - acc: 0.6260
4096/9333 [============>.................] - ETA: 8:46 - loss: 0.6513 - acc: 0.6250
4160/9333 [============>.................] - ETA: 8:38 - loss: 0.6522 - acc: 0.6238
4224/9333 [============>.................] - ETA: 8:32 - loss: 0.6535 - acc: 0.6222
4288/9333 [============>.................] - ETA: 8:25 - loss: 0.6539 - acc: 0.6220
4352/9333 [============>.................] - ETA: 8:17 - loss: 0.6543 - acc: 0.6211
4416/9333 [=============>................] - ETA: 8:11 - loss: 0.6546 - acc: 0.6202
4480/9333 [=============>................] - ETA: 8:05 - loss: 0.6543 - acc: 0.6210
4544/9333 [=============>................] - ETA: 7:59 - loss: 0.6540 - acc: 0.6213
4608/9333 [=============>................] - ETA: 7:53 - loss: 0.6534 - acc: 0.6222
4672/9333 [==============>...............] - ETA: 7:47 - loss: 0.6537 - acc: 0.6218
4736/9333 [==============>...............] - ETA: 7:40 - loss: 0.6536 - acc: 0.6214
4800/9333 [==============>...............] - ETA: 7:34 - loss: 0.6539 - acc: 0.6206
4864/9333 [==============>...............] - ETA: 7:28 - loss: 0.6538 - acc: 0.6197
4928/9333 [==============>...............] - ETA: 7:22 - loss: 0.6541 - acc: 0.6185
4992/9333 [===============>..............] - ETA: 7:16 - loss: 0.6535 - acc: 0.6192
5056/9333 [===============>..............] - ETA: 7:09 - loss: 0.6538 - acc: 0.6183
5120/9333 [===============>..............] - ETA: 7:03 - loss: 0.6536 - acc: 0.6191
5184/9333 [===============>..............] - ETA: 6:57 - loss: 0.6539 - acc: 0.6186
5248/9333 [===============>..............] - ETA: 6:50 - loss: 0.6545 - acc: 0.6174
5312/9333 [================>.............] - ETA: 6:44 - loss: 0.6545 - acc: 0.6177
5376/9333 [================>.............] - ETA: 6:38 - loss: 0.6552 - acc: 0.6163
5440/9333 [================>.............] - ETA: 6:32 - loss: 0.6551 - acc: 0.6173
5504/9333 [================>.............] - ETA: 6:26 - loss: 0.6550 - acc: 0.6165
5568/9333 [================>.............] - ETA: 6:19 - loss: 0.6545 - acc: 0.6167
5632/9333 [=================>............] - ETA: 6:13 - loss: 0.6543 - acc: 0.6172
5696/9333 [=================>............] - ETA: 6:07 - loss: 0.6543 - acc: 0.6175
5760/9333 [=================>............] - ETA: 6:01 - loss: 0.6550 - acc: 0.6158
5824/9333 [=================>............] - ETA: 5:55 - loss: 0.6549 - acc: 0.6159
5888/9333 [=================>............] - ETA: 5:48 - loss: 0.6548 - acc: 0.6153
5952/9333 [==================>...........] - ETA: 5:42 - loss: 0.6549 - acc: 0.6148
6016/9333 [==================>...........] - ETA: 5:36 - loss: 0.6552 - acc: 0.6147
6080/9333 [==================>...........] - ETA: 5:30 - loss: 0.6552 - acc: 0.6146
6144/9333 [==================>...........] - ETA: 5:23 - loss: 0.6553 - acc: 0.6154
6208/9333 [==================>...........] - ETA: 5:17 - loss: 0.6551 - acc: 0.6157
6272/9333 [===================>..........] - ETA: 5:11 - loss: 0.6551 - acc: 0.6158
6336/9333 [===================>..........] - ETA: 5:05 - loss: 0.6550 - acc: 0.6160
6400/9333 [===================>..........] - ETA: 4:58 - loss: 0.6556 - acc: 0.6152
6464/9333 [===================>..........] - ETA: 4:51 - loss: 0.6552 - acc: 0.6159
6528/9333 [===================>..........] - ETA: 4:45 - loss: 0.6553 - acc: 0.6157
6592/9333 [====================>.........] - ETA: 4:39 - loss: 0.6551 - acc: 0.6156
6656/9333 [====================>.........] - ETA: 4:32 - loss: 0.6551 - acc: 0.6163
6720/9333 [====================>.........] - ETA: 4:26 - loss: 0.6554 - acc: 0.6161
6784/9333 [====================>.........] - ETA: 4:19 - loss: 0.6557 - acc: 0.6160
6848/9333 [=====================>........] - ETA: 4:13 - loss: 0.6558 - acc: 0.6154
6912/9333 [=====================>........] - ETA: 4:06 - loss: 0.6557 - acc: 0.6157
6976/9333 [=====================>........] - ETA: 4:00 - loss: 0.6557 - acc: 0.6157
7040/9333 [=====================>........] - ETA: 3:53 - loss: 0.6552 - acc: 0.6165
7104/9333 [=====================>........] - ETA: 3:46 - loss: 0.6550 - acc: 0.6171
7168/9333 [======================>.......] - ETA: 3:40 - loss: 0.6550 - acc: 0.6170
7232/9333 [======================>.......] - ETA: 3:33 - loss: 0.6551 - acc: 0.6164
7296/9333 [======================>.......] - ETA: 3:27 - loss: 0.6549 - acc: 0.6165
7360/9333 [======================>.......] - ETA: 3:20 - loss: 0.6548 - acc: 0.6166
7424/9333 [======================>.......] - ETA: 3:13 - loss: 0.6544 - acc: 0.6168
7488/9333 [=======================>......] - ETA: 3:07 - loss: 0.6543 - acc: 0.6169
7552/9333 [=======================>......] - ETA: 3:00 - loss: 0.6545 - acc: 0.6164
7616/9333 [=======================>......] - ETA: 2:54 - loss: 0.6546 - acc: 0.6161
7680/9333 [=======================>......] - ETA: 2:48 - loss: 0.6548 - acc: 0.6160
7744/9333 [=======================>......] - ETA: 2:41 - loss: 0.6550 - acc: 0.6154
7808/9333 [========================>.....] - ETA: 2:35 - loss: 0.6556 - acc: 0.6149
7872/9333 [========================>.....] - ETA: 2:29 - loss: 0.6557 - acc: 0.6148
7936/9333 [========================>.....] - ETA: 2:22 - loss: 0.6557 - acc: 0.6143
8000/9333 [========================>.....] - ETA: 2:16 - loss: 0.6560 - acc: 0.6140
8064/9333 [========================>.....] - ETA: 2:10 - loss: 0.6559 - acc: 0.6138
8128/9333 [=========================>....] - ETA: 2:03 - loss: 0.6560 - acc: 0.6138
8192/9333 [=========================>....] - ETA: 1:57 - loss: 0.6559 - acc: 0.6144
8256/9333 [=========================>....] - ETA: 1:50 - loss: 0.6560 - acc: 0.6143
8320/9333 [=========================>....] - ETA: 1:44 - loss: 0.6557 - acc: 0.6144
8384/9333 [=========================>....] - ETA: 1:37 - loss: 0.6556 - acc: 0.6145
8448/9333 [==========================>...] - ETA: 1:31 - loss: 0.6558 - acc: 0.6143
8512/9333 [==========================>...] - ETA: 1:24 - loss: 0.6557 - acc: 0.6143
8576/9333 [==========================>...] - ETA: 1:18 - loss: 0.6558 - acc: 0.6142
8640/9333 [==========================>...] - ETA: 1:11 - loss: 0.6556 - acc: 0.6146
8704/9333 [==========================>...] - ETA: 1:05 - loss: 0.6560 - acc: 0.6139
8768/9333 [===========================>..] - ETA: 58s - loss: 0.6560 - acc: 0.6139 
8832/9333 [===========================>..] - ETA: 51s - loss: 0.6561 - acc: 0.6132
8896/9333 [===========================>..] - ETA: 45s - loss: 0.6564 - acc: 0.6131
8960/9333 [===========================>..] - ETA: 38s - loss: 0.6564 - acc: 0.6132
9024/9333 [============================>.] - ETA: 32s - loss: 0.6566 - acc: 0.6129
9088/9333 [============================>.] - ETA: 25s - loss: 0.6569 - acc: 0.6128
9152/9333 [============================>.] - ETA: 18s - loss: 0.6574 - acc: 0.6117
9216/9333 [============================>.] - ETA: 12s - loss: 0.6575 - acc: 0.6113
9280/9333 [============================>.] - ETA: 5s - loss: 0.6575 - acc: 0.6115 
9333/9333 [==============================] - 1012s 108ms/step - loss: 0.6575 - acc: 0.6112 - val_loss: 0.6686 - val_acc: 0.5661

Epoch 00007: val_acc did not improve from 0.59306
Epoch 8/10

  64/9333 [..............................] - ETA: 18:02 - loss: 0.6991 - acc: 0.5625
 128/9333 [..............................] - ETA: 17:26 - loss: 0.7064 - acc: 0.5391
 192/9333 [..............................] - ETA: 17:37 - loss: 0.6766 - acc: 0.6094
 256/9333 [..............................] - ETA: 17:38 - loss: 0.6756 - acc: 0.6133
 320/9333 [>.............................] - ETA: 17:35 - loss: 0.6745 - acc: 0.5938
 384/9333 [>.............................] - ETA: 17:23 - loss: 0.6739 - acc: 0.5911
 448/9333 [>.............................] - ETA: 17:18 - loss: 0.6732 - acc: 0.5826
 512/9333 [>.............................] - ETA: 17:04 - loss: 0.6701 - acc: 0.5938
 576/9333 [>.............................] - ETA: 16:59 - loss: 0.6699 - acc: 0.5972
 640/9333 [=>............................] - ETA: 16:49 - loss: 0.6722 - acc: 0.5953
 704/9333 [=>............................] - ETA: 16:39 - loss: 0.6690 - acc: 0.6023
 768/9333 [=>............................] - ETA: 16:31 - loss: 0.6695 - acc: 0.5977
 832/9333 [=>............................] - ETA: 16:23 - loss: 0.6694 - acc: 0.5986
 896/9333 [=>............................] - ETA: 16:15 - loss: 0.6709 - acc: 0.5960
 960/9333 [==>...........................] - ETA: 16:08 - loss: 0.6674 - acc: 0.6062
1024/9333 [==>...........................] - ETA: 15:57 - loss: 0.6690 - acc: 0.6016
1088/9333 [==>...........................] - ETA: 15:49 - loss: 0.6683 - acc: 0.6048
1152/9333 [==>...........................] - ETA: 15:37 - loss: 0.6707 - acc: 0.5990
1216/9333 [==>...........................] - ETA: 15:28 - loss: 0.6686 - acc: 0.6012
1280/9333 [===>..........................] - ETA: 15:18 - loss: 0.6681 - acc: 0.6070
1344/9333 [===>..........................] - ETA: 15:12 - loss: 0.6672 - acc: 0.6094
1408/9333 [===>..........................] - ETA: 15:03 - loss: 0.6674 - acc: 0.6058
1472/9333 [===>..........................] - ETA: 14:51 - loss: 0.6672 - acc: 0.6033
1536/9333 [===>..........................] - ETA: 14:39 - loss: 0.6665 - acc: 0.6035
1600/9333 [====>.........................] - ETA: 14:32 - loss: 0.6668 - acc: 0.6019
1664/9333 [====>.........................] - ETA: 14:22 - loss: 0.6636 - acc: 0.6058
1728/9333 [====>.........................] - ETA: 14:15 - loss: 0.6639 - acc: 0.6059
1792/9333 [====>.........................] - ETA: 14:07 - loss: 0.6617 - acc: 0.6077
1856/9333 [====>.........................] - ETA: 14:00 - loss: 0.6623 - acc: 0.6061
1920/9333 [=====>........................] - ETA: 13:52 - loss: 0.6605 - acc: 0.6073
1984/9333 [=====>........................] - ETA: 13:46 - loss: 0.6601 - acc: 0.6069
2048/9333 [=====>........................] - ETA: 13:37 - loss: 0.6586 - acc: 0.6108
2112/9333 [=====>........................] - ETA: 13:29 - loss: 0.6601 - acc: 0.6108
2176/9333 [=====>........................] - ETA: 13:22 - loss: 0.6603 - acc: 0.6098
2240/9333 [======>.......................] - ETA: 13:14 - loss: 0.6611 - acc: 0.6085
2304/9333 [======>.......................] - ETA: 13:09 - loss: 0.6610 - acc: 0.6089
2368/9333 [======>.......................] - ETA: 13:02 - loss: 0.6600 - acc: 0.6098
2432/9333 [======>.......................] - ETA: 12:57 - loss: 0.6600 - acc: 0.6102
2496/9333 [=======>......................] - ETA: 12:50 - loss: 0.6612 - acc: 0.6090
2560/9333 [=======>......................] - ETA: 12:43 - loss: 0.6620 - acc: 0.6078
2624/9333 [=======>......................] - ETA: 12:36 - loss: 0.6618 - acc: 0.6071
2688/9333 [=======>......................] - ETA: 12:29 - loss: 0.6615 - acc: 0.6068
2752/9333 [=======>......................] - ETA: 12:23 - loss: 0.6594 - acc: 0.6090
2816/9333 [========>.....................] - ETA: 12:16 - loss: 0.6602 - acc: 0.6080
2880/9333 [========>.....................] - ETA: 12:08 - loss: 0.6602 - acc: 0.6073
2944/9333 [========>.....................] - ETA: 12:01 - loss: 0.6621 - acc: 0.6060
3008/9333 [========>.....................] - ETA: 11:53 - loss: 0.6634 - acc: 0.6047
3072/9333 [========>.....................] - ETA: 11:46 - loss: 0.6645 - acc: 0.6035
3136/9333 [=========>....................] - ETA: 11:40 - loss: 0.6638 - acc: 0.6040
3200/9333 [=========>....................] - ETA: 11:33 - loss: 0.6639 - acc: 0.6034
3264/9333 [=========>....................] - ETA: 11:26 - loss: 0.6640 - acc: 0.6032
3328/9333 [=========>....................] - ETA: 11:17 - loss: 0.6634 - acc: 0.6040
3392/9333 [=========>....................] - ETA: 11:09 - loss: 0.6618 - acc: 0.6070
3456/9333 [==========>...................] - ETA: 11:02 - loss: 0.6622 - acc: 0.6062
3520/9333 [==========>...................] - ETA: 10:53 - loss: 0.6608 - acc: 0.6088
3584/9333 [==========>...................] - ETA: 10:45 - loss: 0.6616 - acc: 0.6071
3648/9333 [==========>...................] - ETA: 10:37 - loss: 0.6618 - acc: 0.6066
3712/9333 [==========>...................] - ETA: 10:30 - loss: 0.6619 - acc: 0.6075
3776/9333 [===========>..................] - ETA: 10:22 - loss: 0.6619 - acc: 0.6075
3840/9333 [===========>..................] - ETA: 10:14 - loss: 0.6618 - acc: 0.6070
3904/9333 [===========>..................] - ETA: 10:06 - loss: 0.6619 - acc: 0.6066
3968/9333 [===========>..................] - ETA: 9:59 - loss: 0.6622 - acc: 0.6051 
4032/9333 [===========>..................] - ETA: 9:51 - loss: 0.6626 - acc: 0.6042
4096/9333 [============>.................] - ETA: 9:43 - loss: 0.6626 - acc: 0.6030
4160/9333 [============>.................] - ETA: 9:35 - loss: 0.6626 - acc: 0.6031
4224/9333 [============>.................] - ETA: 9:27 - loss: 0.6626 - acc: 0.6032
4288/9333 [============>.................] - ETA: 9:19 - loss: 0.6622 - acc: 0.6031
4352/9333 [============>.................] - ETA: 9:12 - loss: 0.6621 - acc: 0.6029
4416/9333 [=============>................] - ETA: 9:04 - loss: 0.6620 - acc: 0.6039
4480/9333 [=============>................] - ETA: 8:56 - loss: 0.6621 - acc: 0.6036
4544/9333 [=============>................] - ETA: 8:48 - loss: 0.6616 - acc: 0.6048
4608/9333 [=============>................] - ETA: 8:40 - loss: 0.6615 - acc: 0.6057
4672/9333 [==============>...............] - ETA: 8:33 - loss: 0.6616 - acc: 0.6062
4736/9333 [==============>...............] - ETA: 8:25 - loss: 0.6618 - acc: 0.6049
4800/9333 [==============>...............] - ETA: 8:18 - loss: 0.6614 - acc: 0.6058
4864/9333 [==============>...............] - ETA: 8:11 - loss: 0.6615 - acc: 0.6057
4928/9333 [==============>...............] - ETA: 8:03 - loss: 0.6617 - acc: 0.6057
4992/9333 [===============>..............] - ETA: 7:56 - loss: 0.6621 - acc: 0.6044
5056/9333 [===============>..............] - ETA: 7:47 - loss: 0.6623 - acc: 0.6042
5120/9333 [===============>..............] - ETA: 7:40 - loss: 0.6629 - acc: 0.6029
5184/9333 [===============>..............] - ETA: 7:33 - loss: 0.6633 - acc: 0.6022
5248/9333 [===============>..............] - ETA: 7:26 - loss: 0.6630 - acc: 0.6025
5312/9333 [================>.............] - ETA: 7:19 - loss: 0.6625 - acc: 0.6035
5376/9333 [================>.............] - ETA: 7:11 - loss: 0.6618 - acc: 0.6042
5440/9333 [================>.............] - ETA: 7:04 - loss: 0.6615 - acc: 0.6042
5504/9333 [================>.............] - ETA: 6:57 - loss: 0.6616 - acc: 0.6034
5568/9333 [================>.............] - ETA: 6:49 - loss: 0.6613 - acc: 0.6036
5632/9333 [=================>............] - ETA: 6:42 - loss: 0.6619 - acc: 0.6032
5696/9333 [=================>............] - ETA: 6:35 - loss: 0.6615 - acc: 0.6039
5760/9333 [=================>............] - ETA: 6:27 - loss: 0.6612 - acc: 0.6045
5824/9333 [=================>............] - ETA: 6:20 - loss: 0.6609 - acc: 0.6049
5888/9333 [=================>............] - ETA: 6:13 - loss: 0.6606 - acc: 0.6056
5952/9333 [==================>...........] - ETA: 6:06 - loss: 0.6609 - acc: 0.6050
6016/9333 [==================>...........] - ETA: 5:58 - loss: 0.6613 - acc: 0.6046
6080/9333 [==================>...........] - ETA: 5:51 - loss: 0.6608 - acc: 0.6053
6144/9333 [==================>...........] - ETA: 5:44 - loss: 0.6612 - acc: 0.6047
6208/9333 [==================>...........] - ETA: 5:37 - loss: 0.6609 - acc: 0.6049
6272/9333 [===================>..........] - ETA: 5:30 - loss: 0.6610 - acc: 0.6046
6336/9333 [===================>..........] - ETA: 5:22 - loss: 0.6614 - acc: 0.6032
6400/9333 [===================>..........] - ETA: 5:15 - loss: 0.6613 - acc: 0.6036
6464/9333 [===================>..........] - ETA: 5:08 - loss: 0.6610 - acc: 0.6046
6528/9333 [===================>..........] - ETA: 5:01 - loss: 0.6610 - acc: 0.6042
6592/9333 [====================>.........] - ETA: 4:54 - loss: 0.6605 - acc: 0.6048
6656/9333 [====================>.........] - ETA: 4:47 - loss: 0.6600 - acc: 0.6056
6720/9333 [====================>.........] - ETA: 4:40 - loss: 0.6597 - acc: 0.6065
6784/9333 [====================>.........] - ETA: 4:33 - loss: 0.6596 - acc: 0.6058
6848/9333 [=====================>........] - ETA: 4:26 - loss: 0.6595 - acc: 0.6057
6912/9333 [=====================>........] - ETA: 4:19 - loss: 0.6593 - acc: 0.6056
6976/9333 [=====================>........] - ETA: 4:12 - loss: 0.6596 - acc: 0.6049
7040/9333 [=====================>........] - ETA: 4:05 - loss: 0.6596 - acc: 0.6050
7104/9333 [=====================>........] - ETA: 3:58 - loss: 0.6597 - acc: 0.6046
7168/9333 [======================>.......] - ETA: 3:51 - loss: 0.6595 - acc: 0.6048
7232/9333 [======================>.......] - ETA: 3:44 - loss: 0.6592 - acc: 0.6048
7296/9333 [======================>.......] - ETA: 3:37 - loss: 0.6595 - acc: 0.6044
7360/9333 [======================>.......] - ETA: 3:30 - loss: 0.6595 - acc: 0.6042
7424/9333 [======================>.......] - ETA: 3:23 - loss: 0.6593 - acc: 0.6043
7488/9333 [=======================>......] - ETA: 3:16 - loss: 0.6591 - acc: 0.6044
7552/9333 [=======================>......] - ETA: 3:09 - loss: 0.6589 - acc: 0.6042
7616/9333 [=======================>......] - ETA: 3:02 - loss: 0.6595 - acc: 0.6037
7680/9333 [=======================>......] - ETA: 2:55 - loss: 0.6594 - acc: 0.6035
7744/9333 [=======================>......] - ETA: 2:48 - loss: 0.6593 - acc: 0.6034
7808/9333 [========================>.....] - ETA: 2:42 - loss: 0.6593 - acc: 0.6032
7872/9333 [========================>.....] - ETA: 2:35 - loss: 0.6598 - acc: 0.6032
7936/9333 [========================>.....] - ETA: 2:28 - loss: 0.6606 - acc: 0.6021
8000/9333 [========================>.....] - ETA: 2:21 - loss: 0.6601 - acc: 0.6029
8064/9333 [========================>.....] - ETA: 2:14 - loss: 0.6598 - acc: 0.6033
8128/9333 [=========================>....] - ETA: 2:07 - loss: 0.6597 - acc: 0.6037
8192/9333 [=========================>....] - ETA: 2:00 - loss: 0.6595 - acc: 0.6042
8256/9333 [=========================>....] - ETA: 1:53 - loss: 0.6594 - acc: 0.6045
8320/9333 [=========================>....] - ETA: 1:47 - loss: 0.6590 - acc: 0.6059
8384/9333 [=========================>....] - ETA: 1:40 - loss: 0.6589 - acc: 0.6065
8448/9333 [==========================>...] - ETA: 1:33 - loss: 0.6589 - acc: 0.6065
8512/9333 [==========================>...] - ETA: 1:26 - loss: 0.6590 - acc: 0.6066
8576/9333 [==========================>...] - ETA: 1:20 - loss: 0.6589 - acc: 0.6062
8640/9333 [==========================>...] - ETA: 1:13 - loss: 0.6592 - acc: 0.6056
8704/9333 [==========================>...] - ETA: 1:06 - loss: 0.6593 - acc: 0.6056
8768/9333 [===========================>..] - ETA: 59s - loss: 0.6591 - acc: 0.6063 
8832/9333 [===========================>..] - ETA: 52s - loss: 0.6589 - acc: 0.6069
8896/9333 [===========================>..] - ETA: 46s - loss: 0.6589 - acc: 0.6067
8960/9333 [===========================>..] - ETA: 39s - loss: 0.6590 - acc: 0.6061
9024/9333 [============================>.] - ETA: 32s - loss: 0.6592 - acc: 0.6059
9088/9333 [============================>.] - ETA: 25s - loss: 0.6591 - acc: 0.6066
9152/9333 [============================>.] - ETA: 19s - loss: 0.6587 - acc: 0.6070
9216/9333 [============================>.] - ETA: 12s - loss: 0.6588 - acc: 0.6067
9280/9333 [============================>.] - ETA: 5s - loss: 0.6588 - acc: 0.6066 
9333/9333 [==============================] - 1014s 109ms/step - loss: 0.6588 - acc: 0.6069 - val_loss: 0.6655 - val_acc: 0.5709

Epoch 00008: val_acc did not improve from 0.59306
Epoch 9/10

  64/9333 [..............................] - ETA: 15:08 - loss: 0.6900 - acc: 0.5000
 128/9333 [..............................] - ETA: 14:50 - loss: 0.6867 - acc: 0.5078
 192/9333 [..............................] - ETA: 14:58 - loss: 0.6810 - acc: 0.5312
 256/9333 [..............................] - ETA: 15:05 - loss: 0.6733 - acc: 0.5586
 320/9333 [>.............................] - ETA: 15:06 - loss: 0.6726 - acc: 0.5594
 384/9333 [>.............................] - ETA: 15:03 - loss: 0.6827 - acc: 0.5547
 448/9333 [>.............................] - ETA: 14:55 - loss: 0.6770 - acc: 0.5759
 512/9333 [>.............................] - ETA: 14:48 - loss: 0.6715 - acc: 0.5938
 576/9333 [>.............................] - ETA: 14:48 - loss: 0.6696 - acc: 0.5972
 640/9333 [=>............................] - ETA: 14:35 - loss: 0.6727 - acc: 0.5938
 704/9333 [=>............................] - ETA: 14:33 - loss: 0.6710 - acc: 0.5966
 768/9333 [=>............................] - ETA: 14:28 - loss: 0.6730 - acc: 0.5885
 832/9333 [=>............................] - ETA: 14:24 - loss: 0.6710 - acc: 0.5901
 896/9333 [=>............................] - ETA: 14:15 - loss: 0.6710 - acc: 0.5893
 960/9333 [==>...........................] - ETA: 14:11 - loss: 0.6667 - acc: 0.5906
1024/9333 [==>...........................] - ETA: 14:07 - loss: 0.6643 - acc: 0.5938
1088/9333 [==>...........................] - ETA: 13:57 - loss: 0.6648 - acc: 0.5928
1152/9333 [==>...........................] - ETA: 13:51 - loss: 0.6630 - acc: 0.5955
1216/9333 [==>...........................] - ETA: 13:45 - loss: 0.6627 - acc: 0.5970
1280/9333 [===>..........................] - ETA: 13:36 - loss: 0.6605 - acc: 0.6008
1344/9333 [===>..........................] - ETA: 13:27 - loss: 0.6631 - acc: 0.5982
1408/9333 [===>..........................] - ETA: 13:19 - loss: 0.6636 - acc: 0.5973
1472/9333 [===>..........................] - ETA: 13:10 - loss: 0.6633 - acc: 0.5999
1536/9333 [===>..........................] - ETA: 13:03 - loss: 0.6608 - acc: 0.6009
1600/9333 [====>.........................] - ETA: 12:54 - loss: 0.6607 - acc: 0.5975
1664/9333 [====>.........................] - ETA: 12:50 - loss: 0.6620 - acc: 0.5986
1728/9333 [====>.........................] - ETA: 12:43 - loss: 0.6606 - acc: 0.6007
1792/9333 [====>.........................] - ETA: 12:36 - loss: 0.6598 - acc: 0.6021
1856/9333 [====>.........................] - ETA: 12:30 - loss: 0.6591 - acc: 0.6051
1920/9333 [=====>........................] - ETA: 12:23 - loss: 0.6590 - acc: 0.6026
1984/9333 [=====>........................] - ETA: 12:17 - loss: 0.6592 - acc: 0.6018
2048/9333 [=====>........................] - ETA: 12:10 - loss: 0.6570 - acc: 0.6060
2112/9333 [=====>........................] - ETA: 12:03 - loss: 0.6592 - acc: 0.6037
2176/9333 [=====>........................] - ETA: 11:59 - loss: 0.6578 - acc: 0.6052
2240/9333 [======>.......................] - ETA: 11:53 - loss: 0.6573 - acc: 0.6071
2304/9333 [======>.......................] - ETA: 11:45 - loss: 0.6593 - acc: 0.6063
2368/9333 [======>.......................] - ETA: 11:39 - loss: 0.6607 - acc: 0.6047
2432/9333 [======>.......................] - ETA: 11:32 - loss: 0.6607 - acc: 0.6061
2496/9333 [=======>......................] - ETA: 11:25 - loss: 0.6598 - acc: 0.6074
2560/9333 [=======>......................] - ETA: 11:20 - loss: 0.6594 - acc: 0.6074
2624/9333 [=======>......................] - ETA: 11:13 - loss: 0.6604 - acc: 0.6059
2688/9333 [=======>......................] - ETA: 11:08 - loss: 0.6591 - acc: 0.6075
2752/9333 [=======>......................] - ETA: 11:01 - loss: 0.6592 - acc: 0.6068
2816/9333 [========>.....................] - ETA: 10:54 - loss: 0.6605 - acc: 0.6051
2880/9333 [========>.....................] - ETA: 10:48 - loss: 0.6602 - acc: 0.6045
2944/9333 [========>.....................] - ETA: 10:41 - loss: 0.6603 - acc: 0.6036
3008/9333 [========>.....................] - ETA: 10:35 - loss: 0.6608 - acc: 0.6044
3072/9333 [========>.....................] - ETA: 10:28 - loss: 0.6606 - acc: 0.6048
3136/9333 [=========>....................] - ETA: 10:22 - loss: 0.6596 - acc: 0.6052
3200/9333 [=========>....................] - ETA: 10:15 - loss: 0.6599 - acc: 0.6053
3264/9333 [=========>....................] - ETA: 10:10 - loss: 0.6599 - acc: 0.6042
3328/9333 [=========>....................] - ETA: 10:03 - loss: 0.6609 - acc: 0.6022
3392/9333 [=========>....................] - ETA: 9:57 - loss: 0.6613 - acc: 0.6008 
3456/9333 [==========>...................] - ETA: 9:51 - loss: 0.6624 - acc: 0.5990
3520/9333 [==========>...................] - ETA: 9:44 - loss: 0.6630 - acc: 0.6000
3584/9333 [==========>...................] - ETA: 9:37 - loss: 0.6625 - acc: 0.6013
3648/9333 [==========>...................] - ETA: 9:30 - loss: 0.6620 - acc: 0.6020
3712/9333 [==========>...................] - ETA: 9:24 - loss: 0.6616 - acc: 0.6034
3776/9333 [===========>..................] - ETA: 9:18 - loss: 0.6616 - acc: 0.6033
3840/9333 [===========>..................] - ETA: 9:11 - loss: 0.6609 - acc: 0.6047
3904/9333 [===========>..................] - ETA: 9:04 - loss: 0.6600 - acc: 0.6060
3968/9333 [===========>..................] - ETA: 8:58 - loss: 0.6598 - acc: 0.6058
4032/9333 [===========>..................] - ETA: 8:51 - loss: 0.6600 - acc: 0.6054
4096/9333 [============>.................] - ETA: 8:45 - loss: 0.6599 - acc: 0.6050
4160/9333 [============>.................] - ETA: 8:39 - loss: 0.6597 - acc: 0.6038
4224/9333 [============>.................] - ETA: 8:33 - loss: 0.6600 - acc: 0.6027
4288/9333 [============>.................] - ETA: 8:27 - loss: 0.6604 - acc: 0.6019
4352/9333 [============>.................] - ETA: 8:20 - loss: 0.6608 - acc: 0.6011
4416/9333 [=============>................] - ETA: 8:14 - loss: 0.6603 - acc: 0.6019
4480/9333 [=============>................] - ETA: 8:08 - loss: 0.6595 - acc: 0.6027
4544/9333 [=============>................] - ETA: 8:01 - loss: 0.6593 - acc: 0.6021
4608/9333 [=============>................] - ETA: 7:55 - loss: 0.6603 - acc: 0.6003
4672/9333 [==============>...............] - ETA: 7:49 - loss: 0.6599 - acc: 0.6010
4736/9333 [==============>...............] - ETA: 7:43 - loss: 0.6601 - acc: 0.6005
4800/9333 [==============>...............] - ETA: 7:36 - loss: 0.6601 - acc: 0.6002
4864/9333 [==============>...............] - ETA: 7:30 - loss: 0.6599 - acc: 0.6009
4928/9333 [==============>...............] - ETA: 7:24 - loss: 0.6606 - acc: 0.5994
4992/9333 [===============>..............] - ETA: 7:18 - loss: 0.6609 - acc: 0.5998
5056/9333 [===============>..............] - ETA: 7:11 - loss: 0.6605 - acc: 0.6007
5120/9333 [===============>..............] - ETA: 7:05 - loss: 0.6609 - acc: 0.5996
5184/9333 [===============>..............] - ETA: 6:59 - loss: 0.6609 - acc: 0.6001
5248/9333 [===============>..............] - ETA: 6:52 - loss: 0.6612 - acc: 0.5997
5312/9333 [================>.............] - ETA: 6:47 - loss: 0.6609 - acc: 0.6002
5376/9333 [================>.............] - ETA: 6:41 - loss: 0.6612 - acc: 0.5999
5440/9333 [================>.............] - ETA: 6:35 - loss: 0.6608 - acc: 0.6002
5504/9333 [================>.............] - ETA: 6:29 - loss: 0.6607 - acc: 0.6012
5568/9333 [================>.............] - ETA: 6:23 - loss: 0.6610 - acc: 0.6017
5632/9333 [=================>............] - ETA: 6:17 - loss: 0.6608 - acc: 0.6019
5696/9333 [=================>............] - ETA: 6:11 - loss: 0.6613 - acc: 0.6011
5760/9333 [=================>............] - ETA: 6:05 - loss: 0.6615 - acc: 0.6019
5824/9333 [=================>............] - ETA: 5:59 - loss: 0.6618 - acc: 0.6010
5888/9333 [=================>............] - ETA: 5:53 - loss: 0.6617 - acc: 0.6014
5952/9333 [==================>...........] - ETA: 5:46 - loss: 0.6614 - acc: 0.6025
6016/9333 [==================>...........] - ETA: 5:40 - loss: 0.6615 - acc: 0.6029
6080/9333 [==================>...........] - ETA: 5:34 - loss: 0.6615 - acc: 0.6033
6144/9333 [==================>...........] - ETA: 5:28 - loss: 0.6612 - acc: 0.6042
6208/9333 [==================>...........] - ETA: 5:21 - loss: 0.6612 - acc: 0.6036
6272/9333 [===================>..........] - ETA: 5:14 - loss: 0.6607 - acc: 0.6038
6336/9333 [===================>..........] - ETA: 5:08 - loss: 0.6610 - acc: 0.6031
6400/9333 [===================>..........] - ETA: 5:01 - loss: 0.6611 - acc: 0.6028
6464/9333 [===================>..........] - ETA: 4:55 - loss: 0.6608 - acc: 0.6029
6528/9333 [===================>..........] - ETA: 4:48 - loss: 0.6606 - acc: 0.6031
6592/9333 [====================>.........] - ETA: 4:41 - loss: 0.6608 - acc: 0.6033
6656/9333 [====================>.........] - ETA: 4:35 - loss: 0.6606 - acc: 0.6031
6720/9333 [====================>.........] - ETA: 4:28 - loss: 0.6604 - acc: 0.6033
6784/9333 [====================>.........] - ETA: 4:21 - loss: 0.6599 - acc: 0.6041
6848/9333 [=====================>........] - ETA: 4:15 - loss: 0.6591 - acc: 0.6054
6912/9333 [=====================>........] - ETA: 4:09 - loss: 0.6586 - acc: 0.6063
6976/9333 [=====================>........] - ETA: 4:03 - loss: 0.6583 - acc: 0.6068
7040/9333 [=====================>........] - ETA: 3:56 - loss: 0.6583 - acc: 0.6067
7104/9333 [=====================>........] - ETA: 3:50 - loss: 0.6593 - acc: 0.6052
7168/9333 [======================>.......] - ETA: 3:43 - loss: 0.6590 - acc: 0.6055
7232/9333 [======================>.......] - ETA: 3:37 - loss: 0.6586 - acc: 0.6062
7296/9333 [======================>.......] - ETA: 3:30 - loss: 0.6591 - acc: 0.6054
7360/9333 [======================>.......] - ETA: 3:24 - loss: 0.6586 - acc: 0.6065
7424/9333 [======================>.......] - ETA: 3:18 - loss: 0.6589 - acc: 0.6064
7488/9333 [=======================>......] - ETA: 3:11 - loss: 0.6595 - acc: 0.6056
7552/9333 [=======================>......] - ETA: 3:05 - loss: 0.6592 - acc: 0.6061
7616/9333 [=======================>......] - ETA: 2:58 - loss: 0.6595 - acc: 0.6058
7680/9333 [=======================>......] - ETA: 2:52 - loss: 0.6589 - acc: 0.6068
7744/9333 [=======================>......] - ETA: 2:45 - loss: 0.6591 - acc: 0.6061
7808/9333 [========================>.....] - ETA: 2:38 - loss: 0.6594 - acc: 0.6054
7872/9333 [========================>.....] - ETA: 2:32 - loss: 0.6594 - acc: 0.6049
7936/9333 [========================>.....] - ETA: 2:25 - loss: 0.6591 - acc: 0.6048
8000/9333 [========================>.....] - ETA: 2:19 - loss: 0.6597 - acc: 0.6038
8064/9333 [========================>.....] - ETA: 2:12 - loss: 0.6595 - acc: 0.6040
8128/9333 [=========================>....] - ETA: 2:06 - loss: 0.6592 - acc: 0.6038
8192/9333 [=========================>....] - ETA: 1:59 - loss: 0.6588 - acc: 0.6044
8256/9333 [=========================>....] - ETA: 1:52 - loss: 0.6587 - acc: 0.6047
8320/9333 [=========================>....] - ETA: 1:46 - loss: 0.6586 - acc: 0.6052
8384/9333 [=========================>....] - ETA: 1:39 - loss: 0.6590 - acc: 0.6046
8448/9333 [==========================>...] - ETA: 1:32 - loss: 0.6592 - acc: 0.6046
8512/9333 [==========================>...] - ETA: 1:26 - loss: 0.6584 - acc: 0.6060
8576/9333 [==========================>...] - ETA: 1:19 - loss: 0.6582 - acc: 0.6061
8640/9333 [==========================>...] - ETA: 1:12 - loss: 0.6583 - acc: 0.6059
8704/9333 [==========================>...] - ETA: 1:06 - loss: 0.6581 - acc: 0.6064
8768/9333 [===========================>..] - ETA: 59s - loss: 0.6576 - acc: 0.6071 
8832/9333 [===========================>..] - ETA: 52s - loss: 0.6574 - acc: 0.6076
8896/9333 [===========================>..] - ETA: 45s - loss: 0.6577 - acc: 0.6071
8960/9333 [===========================>..] - ETA: 39s - loss: 0.6573 - acc: 0.6074
9024/9333 [============================>.] - ETA: 32s - loss: 0.6569 - acc: 0.6079
9088/9333 [============================>.] - ETA: 25s - loss: 0.6570 - acc: 0.6077
9152/9333 [============================>.] - ETA: 19s - loss: 0.6570 - acc: 0.6076
9216/9333 [============================>.] - ETA: 12s - loss: 0.6573 - acc: 0.6070
9280/9333 [============================>.] - ETA: 5s - loss: 0.6574 - acc: 0.6067 
9333/9333 [==============================] - 1026s 110ms/step - loss: 0.6577 - acc: 0.6066 - val_loss: 0.6780 - val_acc: 0.5824

Epoch 00009: val_acc did not improve from 0.59306
Epoch 10/10

  64/9333 [..............................] - ETA: 19:47 - loss: 0.6431 - acc: 0.5781
 128/9333 [..............................] - ETA: 19:25 - loss: 0.6522 - acc: 0.5859
 192/9333 [..............................] - ETA: 19:45 - loss: 0.6690 - acc: 0.5625
 256/9333 [..............................] - ETA: 19:31 - loss: 0.6564 - acc: 0.5859
 320/9333 [>.............................] - ETA: 19:02 - loss: 0.6540 - acc: 0.5969
 384/9333 [>.............................] - ETA: 18:40 - loss: 0.6569 - acc: 0.5938
 448/9333 [>.............................] - ETA: 18:24 - loss: 0.6534 - acc: 0.6004
 512/9333 [>.............................] - ETA: 18:12 - loss: 0.6548 - acc: 0.5918
 576/9333 [>.............................] - ETA: 18:01 - loss: 0.6511 - acc: 0.5972
 640/9333 [=>............................] - ETA: 17:43 - loss: 0.6484 - acc: 0.6047
 704/9333 [=>............................] - ETA: 17:25 - loss: 0.6498 - acc: 0.6051
 768/9333 [=>............................] - ETA: 17:09 - loss: 0.6475 - acc: 0.6133
 832/9333 [=>............................] - ETA: 16:46 - loss: 0.6491 - acc: 0.6154
 896/9333 [=>............................] - ETA: 16:28 - loss: 0.6494 - acc: 0.6127
 960/9333 [==>...........................] - ETA: 16:09 - loss: 0.6482 - acc: 0.6156
1024/9333 [==>...........................] - ETA: 15:55 - loss: 0.6480 - acc: 0.6152
1088/9333 [==>...........................] - ETA: 15:49 - loss: 0.6506 - acc: 0.6121
1152/9333 [==>...........................] - ETA: 15:46 - loss: 0.6516 - acc: 0.6094
1216/9333 [==>...........................] - ETA: 15:41 - loss: 0.6492 - acc: 0.6118
1280/9333 [===>..........................] - ETA: 15:31 - loss: 0.6518 - acc: 0.6102
1344/9333 [===>..........................] - ETA: 15:22 - loss: 0.6512 - acc: 0.6094
1408/9333 [===>..........................] - ETA: 15:10 - loss: 0.6527 - acc: 0.6051
1472/9333 [===>..........................] - ETA: 15:03 - loss: 0.6546 - acc: 0.6019
1536/9333 [===>..........................] - ETA: 14:54 - loss: 0.6548 - acc: 0.6022
1600/9333 [====>.........................] - ETA: 14:48 - loss: 0.6563 - acc: 0.6006
1664/9333 [====>.........................] - ETA: 14:54 - loss: 0.6563 - acc: 0.5992
1728/9333 [====>.........................] - ETA: 14:50 - loss: 0.6576 - acc: 0.5966
1792/9333 [====>.........................] - ETA: 14:43 - loss: 0.6600 - acc: 0.5921
1856/9333 [====>.........................] - ETA: 14:35 - loss: 0.6608 - acc: 0.5900
1920/9333 [=====>........................] - ETA: 14:28 - loss: 0.6607 - acc: 0.5927
1984/9333 [=====>........................] - ETA: 14:19 - loss: 0.6606 - acc: 0.5938
2048/9333 [=====>........................] - ETA: 14:11 - loss: 0.6596 - acc: 0.5967
2112/9333 [=====>........................] - ETA: 14:02 - loss: 0.6594 - acc: 0.5971
2176/9333 [=====>........................] - ETA: 13:55 - loss: 0.6606 - acc: 0.5970
2240/9333 [======>.......................] - ETA: 13:49 - loss: 0.6617 - acc: 0.5964
2304/9333 [======>.......................] - ETA: 13:42 - loss: 0.6605 - acc: 0.5985
2368/9333 [======>.......................] - ETA: 13:35 - loss: 0.6617 - acc: 0.5967
2432/9333 [======>.......................] - ETA: 13:28 - loss: 0.6611 - acc: 0.6003
2496/9333 [=======>......................] - ETA: 13:20 - loss: 0.6611 - acc: 0.6002
2560/9333 [=======>......................] - ETA: 13:12 - loss: 0.6619 - acc: 0.6000
2624/9333 [=======>......................] - ETA: 13:03 - loss: 0.6616 - acc: 0.5995
2688/9333 [=======>......................] - ETA: 12:54 - loss: 0.6599 - acc: 0.6012
2752/9333 [=======>......................] - ETA: 12:47 - loss: 0.6597 - acc: 0.6014
2816/9333 [========>.....................] - ETA: 12:40 - loss: 0.6594 - acc: 0.6016
2880/9333 [========>.....................] - ETA: 12:38 - loss: 0.6583 - acc: 0.6035
2944/9333 [========>.....................] - ETA: 12:30 - loss: 0.6585 - acc: 0.6029
3008/9333 [========>.....................] - ETA: 12:24 - loss: 0.6597 - acc: 0.6017
3072/9333 [========>.....................] - ETA: 12:17 - loss: 0.6592 - acc: 0.6032
3136/9333 [=========>....................] - ETA: 12:10 - loss: 0.6600 - acc: 0.6024
3200/9333 [=========>....................] - ETA: 12:03 - loss: 0.6592 - acc: 0.6038
3264/9333 [=========>....................] - ETA: 11:57 - loss: 0.6599 - acc: 0.6032
3328/9333 [=========>....................] - ETA: 11:52 - loss: 0.6603 - acc: 0.6019
3392/9333 [=========>....................] - ETA: 11:47 - loss: 0.6597 - acc: 0.6029
3456/9333 [==========>...................] - ETA: 11:42 - loss: 0.6582 - acc: 0.6045
3520/9333 [==========>...................] - ETA: 11:35 - loss: 0.6580 - acc: 0.6051
3584/9333 [==========>...................] - ETA: 11:31 - loss: 0.6578 - acc: 0.6055
3648/9333 [==========>...................] - ETA: 11:25 - loss: 0.6576 - acc: 0.6050
3712/9333 [==========>...................] - ETA: 11:17 - loss: 0.6560 - acc: 0.6083
3776/9333 [===========>..................] - ETA: 11:11 - loss: 0.6563 - acc: 0.6075
3840/9333 [===========>..................] - ETA: 11:05 - loss: 0.6569 - acc: 0.6070
3904/9333 [===========>..................] - ETA: 10:58 - loss: 0.6568 - acc: 0.6066
3968/9333 [===========>..................] - ETA: 10:52 - loss: 0.6565 - acc: 0.6061
4032/9333 [===========>..................] - ETA: 10:45 - loss: 0.6561 - acc: 0.6064
4096/9333 [============>.................] - ETA: 10:37 - loss: 0.6559 - acc: 0.6082
4160/9333 [============>.................] - ETA: 10:30 - loss: 0.6572 - acc: 0.6065
4224/9333 [============>.................] - ETA: 10:22 - loss: 0.6582 - acc: 0.6063
4288/9333 [============>.................] - ETA: 10:15 - loss: 0.6567 - acc: 0.6075
4352/9333 [============>.................] - ETA: 10:08 - loss: 0.6566 - acc: 0.6071
4416/9333 [=============>................] - ETA: 10:01 - loss: 0.6564 - acc: 0.6082
4480/9333 [=============>................] - ETA: 9:54 - loss: 0.6567 - acc: 0.6080 
4544/9333 [=============>................] - ETA: 9:47 - loss: 0.6567 - acc: 0.6078
4608/9333 [=============>................] - ETA: 9:40 - loss: 0.6565 - acc: 0.6089
4672/9333 [==============>...............] - ETA: 9:34 - loss: 0.6565 - acc: 0.6094
4736/9333 [==============>...............] - ETA: 9:26 - loss: 0.6565 - acc: 0.6100
4800/9333 [==============>...............] - ETA: 9:18 - loss: 0.6560 - acc: 0.6106
4864/9333 [==============>...............] - ETA: 9:10 - loss: 0.6560 - acc: 0.6106
4928/9333 [==============>...............] - ETA: 9:02 - loss: 0.6561 - acc: 0.6100
4992/9333 [===============>..............] - ETA: 8:54 - loss: 0.6563 - acc: 0.6094
5056/9333 [===============>..............] - ETA: 8:46 - loss: 0.6558 - acc: 0.6098
5120/9333 [===============>..............] - ETA: 8:39 - loss: 0.6560 - acc: 0.6100
5184/9333 [===============>..............] - ETA: 8:30 - loss: 0.6565 - acc: 0.6092
5248/9333 [===============>..............] - ETA: 8:23 - loss: 0.6567 - acc: 0.6084
5312/9333 [================>.............] - ETA: 8:16 - loss: 0.6570 - acc: 0.6081
5376/9333 [================>.............] - ETA: 8:08 - loss: 0.6568 - acc: 0.6086
5440/9333 [================>.............] - ETA: 8:01 - loss: 0.6568 - acc: 0.6081
5504/9333 [================>.............] - ETA: 7:53 - loss: 0.6573 - acc: 0.6077
5568/9333 [================>.............] - ETA: 7:46 - loss: 0.6576 - acc: 0.6076
5632/9333 [=================>............] - ETA: 7:38 - loss: 0.6578 - acc: 0.6071
5696/9333 [=================>............] - ETA: 7:31 - loss: 0.6578 - acc: 0.6071
5760/9333 [=================>............] - ETA: 7:24 - loss: 0.6582 - acc: 0.6064
5824/9333 [=================>............] - ETA: 7:16 - loss: 0.6589 - acc: 0.6051
5888/9333 [=================>............] - ETA: 7:08 - loss: 0.6589 - acc: 0.6050
5952/9333 [==================>...........] - ETA: 7:01 - loss: 0.6595 - acc: 0.6038
6016/9333 [==================>...........] - ETA: 6:53 - loss: 0.6594 - acc: 0.6046
6080/9333 [==================>...........] - ETA: 6:46 - loss: 0.6589 - acc: 0.6059
6144/9333 [==================>...........] - ETA: 6:38 - loss: 0.6588 - acc: 0.6058
6208/9333 [==================>...........] - ETA: 6:30 - loss: 0.6590 - acc: 0.6052
6272/9333 [===================>..........] - ETA: 6:23 - loss: 0.6588 - acc: 0.6054
6336/9333 [===================>..........] - ETA: 6:15 - loss: 0.6586 - acc: 0.6053
6400/9333 [===================>..........] - ETA: 6:07 - loss: 0.6587 - acc: 0.6052
6464/9333 [===================>..........] - ETA: 6:00 - loss: 0.6586 - acc: 0.6055
6528/9333 [===================>..........] - ETA: 5:52 - loss: 0.6583 - acc: 0.6060
6592/9333 [====================>.........] - ETA: 5:44 - loss: 0.6582 - acc: 0.6060
6656/9333 [====================>.........] - ETA: 5:36 - loss: 0.6579 - acc: 0.6061
6720/9333 [====================>.........] - ETA: 5:28 - loss: 0.6578 - acc: 0.6058
6784/9333 [====================>.........] - ETA: 5:20 - loss: 0.6581 - acc: 0.6051
6848/9333 [=====================>........] - ETA: 5:11 - loss: 0.6576 - acc: 0.6051
6912/9333 [=====================>........] - ETA: 5:03 - loss: 0.6575 - acc: 0.6050
6976/9333 [=====================>........] - ETA: 4:55 - loss: 0.6574 - acc: 0.6049
7040/9333 [=====================>........] - ETA: 4:46 - loss: 0.6578 - acc: 0.6047
7104/9333 [=====================>........] - ETA: 4:38 - loss: 0.6576 - acc: 0.6047
7168/9333 [======================>.......] - ETA: 4:30 - loss: 0.6569 - acc: 0.6059
7232/9333 [======================>.......] - ETA: 4:22 - loss: 0.6570 - acc: 0.6062
7296/9333 [======================>.......] - ETA: 4:14 - loss: 0.6570 - acc: 0.6058
7360/9333 [======================>.......] - ETA: 4:06 - loss: 0.6569 - acc: 0.6057
7424/9333 [======================>.......] - ETA: 3:58 - loss: 0.6570 - acc: 0.6055
7488/9333 [=======================>......] - ETA: 3:49 - loss: 0.6571 - acc: 0.6054
7552/9333 [=======================>......] - ETA: 3:41 - loss: 0.6571 - acc: 0.6051
7616/9333 [=======================>......] - ETA: 3:33 - loss: 0.6563 - acc: 0.6061
7680/9333 [=======================>......] - ETA: 3:25 - loss: 0.6564 - acc: 0.6059
7744/9333 [=======================>......] - ETA: 3:17 - loss: 0.6566 - acc: 0.6059
7808/9333 [========================>.....] - ETA: 3:09 - loss: 0.6566 - acc: 0.6054
7872/9333 [========================>.....] - ETA: 3:01 - loss: 0.6572 - acc: 0.6048
7936/9333 [========================>.....] - ETA: 2:53 - loss: 0.6573 - acc: 0.6046
8000/9333 [========================>.....] - ETA: 2:45 - loss: 0.6572 - acc: 0.6049
8064/9333 [========================>.....] - ETA: 2:37 - loss: 0.6572 - acc: 0.6048
8128/9333 [=========================>....] - ETA: 2:29 - loss: 0.6574 - acc: 0.6042
8192/9333 [=========================>....] - ETA: 2:21 - loss: 0.6573 - acc: 0.6046
8256/9333 [=========================>....] - ETA: 2:13 - loss: 0.6570 - acc: 0.6050
8320/9333 [=========================>....] - ETA: 2:05 - loss: 0.6571 - acc: 0.6048
8384/9333 [=========================>....] - ETA: 1:57 - loss: 0.6574 - acc: 0.6041
8448/9333 [==========================>...] - ETA: 1:49 - loss: 0.6577 - acc: 0.6039
8512/9333 [==========================>...] - ETA: 1:41 - loss: 0.6576 - acc: 0.6039
8576/9333 [==========================>...] - ETA: 1:33 - loss: 0.6576 - acc: 0.6040
8640/9333 [==========================>...] - ETA: 1:25 - loss: 0.6574 - acc: 0.6043
8704/9333 [==========================>...] - ETA: 1:17 - loss: 0.6572 - acc: 0.6049
8768/9333 [===========================>..] - ETA: 1:09 - loss: 0.6569 - acc: 0.6052
8832/9333 [===========================>..] - ETA: 1:01 - loss: 0.6569 - acc: 0.6054
8896/9333 [===========================>..] - ETA: 53s - loss: 0.6566 - acc: 0.6057 
8960/9333 [===========================>..] - ETA: 45s - loss: 0.6562 - acc: 0.6061
9024/9333 [============================>.] - ETA: 37s - loss: 0.6565 - acc: 0.6058
9088/9333 [============================>.] - ETA: 30s - loss: 0.6566 - acc: 0.6053
9152/9333 [============================>.] - ETA: 22s - loss: 0.6568 - acc: 0.6050
9216/9333 [============================>.] - ETA: 14s - loss: 0.6570 - acc: 0.6044
9280/9333 [============================>.] - ETA: 6s - loss: 0.6571 - acc: 0.6044 
9333/9333 [==============================] - 1180s 126ms/step - loss: 0.6574 - acc: 0.6040 - val_loss: 0.6806 - val_acc: 0.5709

Epoch 00010: val_acc did not improve from 0.59306
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3c44051310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3c44051310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3c247e0210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f3c247e0210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40047d4110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f40047d4110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c24059710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c24059710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3be466e110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3be466e110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c0462e190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c0462e190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c0462ef90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c0462ef90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c240c5050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c240c5050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c046c3510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c046c3510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f36e0a38f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f36e0a38f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36e0a3c5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36e0a3c5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c046c3150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c046c3150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c0474fcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c0474fcd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c0433f490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c0433f490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c042a2b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c042a2b10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c043d9310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c043d9310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c0433f750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c0433f750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36e0a30750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36e0a30750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c0407f690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c0407f690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3be47085d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3be47085d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c0429e8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c0429e8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c0404f8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c0404f8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3be4705b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3be4705b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3be4518850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3be4518850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3be43ec090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3be43ec090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c04066490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c04066490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3be43da690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3be43da690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3be4299550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3be4299550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3be44624d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3be44624d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3be404df50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3be404df50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3be43d6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3be43d6a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3be41b9f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3be41b9f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3be40f9c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3be40f9c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3bc86648d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3bc86648d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3bc866f610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3bc866f610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3be40b8b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3be40b8b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3bc8664990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3bc8664990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3bc8584690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3bc8584690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3be403b2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3be403b2d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3bc8197750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3bc8197750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3bc8576250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3bc8576250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3bc866f1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3bc866f1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3acc57ddd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3acc57ddd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3bc85847d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3bc85847d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3aac3a7fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3aac3a7fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3acc50cf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3acc50cf90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3acc572250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3acc572250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3aac2878d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3aac2878d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3aac1c8690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3aac1c8690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3aac19ac10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3aac19ac10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3aac096510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3aac096510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3aac18c3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3aac18c3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3aac13d290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3aac13d290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3aac089f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3aac089f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a844fed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a844fed90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a84775a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a84775a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3aac082d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3aac082d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a845db610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a845db610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a84345c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a84345c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a844fe410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a844fe410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a84295cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a84295cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a84345590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a84345590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a840d28d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a840d28d0>>: AttributeError: module 'gast' has no attribute 'Str'
window_select.py:151: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

  64/2592 [..............................] - ETA: 19:39
 128/2592 [>.............................] - ETA: 10:20
 192/2592 [=>............................] - ETA: 7:13 
 256/2592 [=>............................] - ETA: 5:37
 320/2592 [==>...........................] - ETA: 4:42
 384/2592 [===>..........................] - ETA: 4:03
 448/2592 [====>.........................] - ETA: 3:35
 512/2592 [====>.........................] - ETA: 3:14
 576/2592 [=====>........................] - ETA: 2:57
 640/2592 [======>.......................] - ETA: 2:42
 704/2592 [=======>......................] - ETA: 2:30
 768/2592 [=======>......................] - ETA: 2:21
 832/2592 [========>.....................] - ETA: 2:11
 896/2592 [=========>....................] - ETA: 2:02
 960/2592 [==========>...................] - ETA: 1:55
1024/2592 [==========>...................] - ETA: 1:47
1088/2592 [===========>..................] - ETA: 1:41
1152/2592 [============>.................] - ETA: 1:34
1216/2592 [=============>................] - ETA: 1:28
1280/2592 [=============>................] - ETA: 1:22
1344/2592 [==============>...............] - ETA: 1:17
1408/2592 [===============>..............] - ETA: 1:12
1472/2592 [================>.............] - ETA: 1:07
1536/2592 [================>.............] - ETA: 1:02
1600/2592 [=================>............] - ETA: 57s 
1664/2592 [==================>...........] - ETA: 52s
1728/2592 [===================>..........] - ETA: 48s
1792/2592 [===================>..........] - ETA: 44s
1856/2592 [====================>.........] - ETA: 40s
1920/2592 [=====================>........] - ETA: 36s
1984/2592 [=====================>........] - ETA: 33s
2048/2592 [======================>.......] - ETA: 29s
2112/2592 [=======================>......] - ETA: 25s
2176/2592 [========================>.....] - ETA: 22s
2240/2592 [========================>.....] - ETA: 18s
2304/2592 [=========================>....] - ETA: 15s
2368/2592 [==========================>...] - ETA: 11s
2432/2592 [===========================>..] - ETA: 8s 
2496/2592 [===========================>..] - ETA: 5s
2560/2592 [============================>.] - ETA: 1s
2592/2592 [==============================] - 135s 52ms/step
loss: 0.6601818755820945
acc: 0.5875771604938271
样本个数 5185
样本个数 10370
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f36f8504d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f36f8504d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f36df3daad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f36df3daad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a2461d210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a2461d210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a2417bc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a2417bc90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f36df395dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f36df395dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36df302ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36df302ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a24761650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a24761650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c2426ee50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c2426ee50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a2417bc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a2417bc10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c2457b210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c2457b210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c245a5690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c245a5690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c24356a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c24356a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c24747b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c24747b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c245aa6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3c245aa6d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a241c0250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a241c0250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c2472d3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c2472d3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c24249a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3c24249a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c2465c990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3c2465c990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f36df1848d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f36df1848d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c24286550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c24286550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36df100690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36df100690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f36df20d290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f36df20d290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36def81f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36def81f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f36df103d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f36df103d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f36ded9a890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f36ded9a890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36decaa310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36decaa310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a241c08d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a241c08d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36ded8c150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36ded8c150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f36debe6110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f36debe6110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f36deb97710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f36deb97710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359bed5610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359bed5610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f36deb4bb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f36deb4bb90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359c04ecd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359c04ecd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359bde5710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359bde5710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359bcd97d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359bcd97d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359be64e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359be64e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359bde52d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359bde52d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359bbd7f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359bbd7f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359bad2c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359bad2c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359b9f4bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359b9f4bd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359bae2150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359bae2150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359bad29d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359bad29d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b825d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b825d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359ba99550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359ba99550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359ba7ab90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359ba7ab90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b728f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b728f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359b8a5650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359b8a5650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b70f650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b70f650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359b4a2550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359b4a2550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359b3b6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359b3b6910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b255910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b255910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359bb221d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359bb221d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b40fa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b40fa90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359b15f1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359b15f1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359b1813d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359b1813d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36dee22bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f36dee22bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359b25ed50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359b25ed50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b1b1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b1b1dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359b054dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f359b054dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359ad70fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f359ad70fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359ae96750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359ae96750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359b15c4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f359b15c4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359ad81310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359ad81310>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 9333 samples, validate on 1037 samples
Epoch 1/10

  64/9333 [..............................] - ETA: 4:54:16 - loss: 0.7530 - acc: 0.4688
 128/9333 [..............................] - ETA: 2:38:33 - loss: 0.7820 - acc: 0.4609
 192/9333 [..............................] - ETA: 1:53:33 - loss: 0.7677 - acc: 0.4740
 256/9333 [..............................] - ETA: 1:30:45 - loss: 0.7638 - acc: 0.4844
 320/9333 [>.............................] - ETA: 1:16:39 - loss: 0.7456 - acc: 0.4906
 384/9333 [>.............................] - ETA: 1:07:23 - loss: 0.7434 - acc: 0.4948
 448/9333 [>.............................] - ETA: 1:01:04 - loss: 0.7433 - acc: 0.5045
 512/9333 [>.............................] - ETA: 56:05 - loss: 0.7425 - acc: 0.5059  
 576/9333 [>.............................] - ETA: 52:30 - loss: 0.7423 - acc: 0.5104
 640/9333 [=>............................] - ETA: 49:12 - loss: 0.7374 - acc: 0.5172
 704/9333 [=>............................] - ETA: 46:26 - loss: 0.7328 - acc: 0.5185
 768/9333 [=>............................] - ETA: 44:03 - loss: 0.7291 - acc: 0.5208
 832/9333 [=>............................] - ETA: 42:19 - loss: 0.7257 - acc: 0.5264
 896/9333 [=>............................] - ETA: 40:32 - loss: 0.7304 - acc: 0.5234
 960/9333 [==>...........................] - ETA: 39:08 - loss: 0.7321 - acc: 0.5188
1024/9333 [==>...........................] - ETA: 37:43 - loss: 0.7372 - acc: 0.5098
1088/9333 [==>...........................] - ETA: 36:29 - loss: 0.7385 - acc: 0.5074
1152/9333 [==>...........................] - ETA: 35:26 - loss: 0.7385 - acc: 0.5087
1216/9333 [==>...........................] - ETA: 34:35 - loss: 0.7362 - acc: 0.5115
1280/9333 [===>..........................] - ETA: 33:38 - loss: 0.7348 - acc: 0.5125
1344/9333 [===>..........................] - ETA: 32:46 - loss: 0.7321 - acc: 0.5171
1408/9333 [===>..........................] - ETA: 32:04 - loss: 0.7320 - acc: 0.5128
1472/9333 [===>..........................] - ETA: 31:19 - loss: 0.7304 - acc: 0.5129
1536/9333 [===>..........................] - ETA: 30:36 - loss: 0.7278 - acc: 0.5163
1600/9333 [====>.........................] - ETA: 30:00 - loss: 0.7264 - acc: 0.5156
1664/9333 [====>.........................] - ETA: 29:19 - loss: 0.7279 - acc: 0.5084
1728/9333 [====>.........................] - ETA: 28:40 - loss: 0.7256 - acc: 0.5116
1792/9333 [====>.........................] - ETA: 28:05 - loss: 0.7237 - acc: 0.5140
1856/9333 [====>.........................] - ETA: 27:30 - loss: 0.7219 - acc: 0.5156
1920/9333 [=====>........................] - ETA: 26:57 - loss: 0.7228 - acc: 0.5130
1984/9333 [=====>........................] - ETA: 26:28 - loss: 0.7210 - acc: 0.5156
2048/9333 [=====>........................] - ETA: 26:01 - loss: 0.7221 - acc: 0.5137
2112/9333 [=====>........................] - ETA: 25:31 - loss: 0.7222 - acc: 0.5123
2176/9333 [=====>........................] - ETA: 25:07 - loss: 0.7217 - acc: 0.5115
2240/9333 [======>.......................] - ETA: 24:45 - loss: 0.7218 - acc: 0.5125
2304/9333 [======>.......................] - ETA: 24:21 - loss: 0.7220 - acc: 0.5139
2368/9333 [======>.......................] - ETA: 23:56 - loss: 0.7217 - acc: 0.5127
2432/9333 [======>.......................] - ETA: 23:34 - loss: 0.7216 - acc: 0.5136
2496/9333 [=======>......................] - ETA: 23:10 - loss: 0.7207 - acc: 0.5152
2560/9333 [=======>......................] - ETA: 22:47 - loss: 0.7194 - acc: 0.5180
2624/9333 [=======>......................] - ETA: 22:26 - loss: 0.7194 - acc: 0.5179
2688/9333 [=======>......................] - ETA: 22:03 - loss: 0.7194 - acc: 0.5186
2752/9333 [=======>......................] - ETA: 21:43 - loss: 0.7188 - acc: 0.5182
2816/9333 [========>.....................] - ETA: 21:20 - loss: 0.7190 - acc: 0.5170
2880/9333 [========>.....................] - ETA: 20:59 - loss: 0.7197 - acc: 0.5156
2944/9333 [========>.....................] - ETA: 20:37 - loss: 0.7208 - acc: 0.5149
3008/9333 [========>.....................] - ETA: 20:18 - loss: 0.7204 - acc: 0.5153
3072/9333 [========>.....................] - ETA: 20:00 - loss: 0.7207 - acc: 0.5146
3136/9333 [=========>....................] - ETA: 19:43 - loss: 0.7206 - acc: 0.5150
3200/9333 [=========>....................] - ETA: 19:24 - loss: 0.7209 - acc: 0.5141
3264/9333 [=========>....................] - ETA: 19:06 - loss: 0.7207 - acc: 0.5147
3328/9333 [=========>....................] - ETA: 18:47 - loss: 0.7201 - acc: 0.5159
3392/9333 [=========>....................] - ETA: 18:28 - loss: 0.7206 - acc: 0.5153
3456/9333 [==========>...................] - ETA: 18:12 - loss: 0.7197 - acc: 0.5168
3520/9333 [==========>...................] - ETA: 17:57 - loss: 0.7206 - acc: 0.5145
3584/9333 [==========>...................] - ETA: 17:40 - loss: 0.7201 - acc: 0.5148
3648/9333 [==========>...................] - ETA: 17:23 - loss: 0.7202 - acc: 0.5140
3712/9333 [==========>...................] - ETA: 17:07 - loss: 0.7194 - acc: 0.5159
3776/9333 [===========>..................] - ETA: 16:50 - loss: 0.7192 - acc: 0.5159
3840/9333 [===========>..................] - ETA: 16:34 - loss: 0.7189 - acc: 0.5156
3904/9333 [===========>..................] - ETA: 16:19 - loss: 0.7183 - acc: 0.5164
3968/9333 [===========>..................] - ETA: 16:03 - loss: 0.7183 - acc: 0.5164
4032/9333 [===========>..................] - ETA: 15:47 - loss: 0.7174 - acc: 0.5179
4096/9333 [============>.................] - ETA: 15:32 - loss: 0.7167 - acc: 0.5190
4160/9333 [============>.................] - ETA: 15:18 - loss: 0.7168 - acc: 0.5175
4224/9333 [============>.................] - ETA: 15:05 - loss: 0.7162 - acc: 0.5185
4288/9333 [============>.................] - ETA: 14:50 - loss: 0.7163 - acc: 0.5196
4352/9333 [============>.................] - ETA: 14:36 - loss: 0.7164 - acc: 0.5195
4416/9333 [=============>................] - ETA: 14:22 - loss: 0.7168 - acc: 0.5177
4480/9333 [=============>................] - ETA: 14:09 - loss: 0.7171 - acc: 0.5167
4544/9333 [=============>................] - ETA: 13:55 - loss: 0.7166 - acc: 0.5176
4608/9333 [=============>................] - ETA: 13:42 - loss: 0.7167 - acc: 0.5165
4672/9333 [==============>...............] - ETA: 13:28 - loss: 0.7163 - acc: 0.5173
4736/9333 [==============>...............] - ETA: 13:15 - loss: 0.7154 - acc: 0.5184
4800/9333 [==============>...............] - ETA: 13:02 - loss: 0.7163 - acc: 0.5171
4864/9333 [==============>...............] - ETA: 12:48 - loss: 0.7167 - acc: 0.5162
4928/9333 [==============>...............] - ETA: 12:35 - loss: 0.7162 - acc: 0.5175
4992/9333 [===============>..............] - ETA: 12:23 - loss: 0.7159 - acc: 0.5176
5056/9333 [===============>..............] - ETA: 12:11 - loss: 0.7162 - acc: 0.5158
5120/9333 [===============>..............] - ETA: 11:58 - loss: 0.7163 - acc: 0.5150
5184/9333 [===============>..............] - ETA: 11:46 - loss: 0.7160 - acc: 0.5145
5248/9333 [===============>..............] - ETA: 11:34 - loss: 0.7158 - acc: 0.5143
5312/9333 [================>.............] - ETA: 11:21 - loss: 0.7157 - acc: 0.5139
5376/9333 [================>.............] - ETA: 11:09 - loss: 0.7153 - acc: 0.5151
5440/9333 [================>.............] - ETA: 10:57 - loss: 0.7154 - acc: 0.5134
5504/9333 [================>.............] - ETA: 10:45 - loss: 0.7157 - acc: 0.5125
5568/9333 [================>.............] - ETA: 10:32 - loss: 0.7153 - acc: 0.5128
5632/9333 [=================>............] - ETA: 10:20 - loss: 0.7144 - acc: 0.5149
5696/9333 [=================>............] - ETA: 10:08 - loss: 0.7142 - acc: 0.5154
5760/9333 [=================>............] - ETA: 9:57 - loss: 0.7140 - acc: 0.5155 
5824/9333 [=================>............] - ETA: 9:45 - loss: 0.7133 - acc: 0.5168
5888/9333 [=================>............] - ETA: 9:33 - loss: 0.7131 - acc: 0.5173
5952/9333 [==================>...........] - ETA: 9:22 - loss: 0.7131 - acc: 0.5175
6016/9333 [==================>...........] - ETA: 9:11 - loss: 0.7130 - acc: 0.5176
6080/9333 [==================>...........] - ETA: 8:59 - loss: 0.7127 - acc: 0.5183
6144/9333 [==================>...........] - ETA: 8:47 - loss: 0.7126 - acc: 0.5187
6208/9333 [==================>...........] - ETA: 8:36 - loss: 0.7124 - acc: 0.5182
6272/9333 [===================>..........] - ETA: 8:25 - loss: 0.7127 - acc: 0.5175
6336/9333 [===================>..........] - ETA: 8:14 - loss: 0.7124 - acc: 0.5182
6400/9333 [===================>..........] - ETA: 8:02 - loss: 0.7123 - acc: 0.5183
6464/9333 [===================>..........] - ETA: 7:51 - loss: 0.7126 - acc: 0.5173
6528/9333 [===================>..........] - ETA: 7:40 - loss: 0.7126 - acc: 0.5172
6592/9333 [====================>.........] - ETA: 7:30 - loss: 0.7125 - acc: 0.5173
6656/9333 [====================>.........] - ETA: 7:19 - loss: 0.7125 - acc: 0.5179
6720/9333 [====================>.........] - ETA: 7:08 - loss: 0.7123 - acc: 0.5180
6784/9333 [====================>.........] - ETA: 6:57 - loss: 0.7120 - acc: 0.5186
6848/9333 [=====================>........] - ETA: 6:46 - loss: 0.7123 - acc: 0.5178
6912/9333 [=====================>........] - ETA: 6:35 - loss: 0.7122 - acc: 0.5174
6976/9333 [=====================>........] - ETA: 6:24 - loss: 0.7121 - acc: 0.5173
7040/9333 [=====================>........] - ETA: 6:13 - loss: 0.7119 - acc: 0.5182
7104/9333 [=====================>........] - ETA: 6:02 - loss: 0.7118 - acc: 0.5182
7168/9333 [======================>.......] - ETA: 5:51 - loss: 0.7116 - acc: 0.5184
7232/9333 [======================>.......] - ETA: 5:40 - loss: 0.7118 - acc: 0.5180
7296/9333 [======================>.......] - ETA: 5:30 - loss: 0.7119 - acc: 0.5174
7360/9333 [======================>.......] - ETA: 5:19 - loss: 0.7123 - acc: 0.5167
7424/9333 [======================>.......] - ETA: 5:09 - loss: 0.7128 - acc: 0.5159
7488/9333 [=======================>......] - ETA: 4:58 - loss: 0.7127 - acc: 0.5160
7552/9333 [=======================>......] - ETA: 4:47 - loss: 0.7127 - acc: 0.5160
7616/9333 [=======================>......] - ETA: 4:37 - loss: 0.7125 - acc: 0.5158
7680/9333 [=======================>......] - ETA: 4:26 - loss: 0.7126 - acc: 0.5152
7744/9333 [=======================>......] - ETA: 4:16 - loss: 0.7121 - acc: 0.5161
7808/9333 [========================>.....] - ETA: 4:05 - loss: 0.7122 - acc: 0.5163
7872/9333 [========================>.....] - ETA: 3:55 - loss: 0.7125 - acc: 0.5156
7936/9333 [========================>.....] - ETA: 3:44 - loss: 0.7129 - acc: 0.5147
8000/9333 [========================>.....] - ETA: 3:34 - loss: 0.7126 - acc: 0.5152
8064/9333 [========================>.....] - ETA: 3:23 - loss: 0.7126 - acc: 0.5150
8128/9333 [=========================>....] - ETA: 3:13 - loss: 0.7122 - acc: 0.5153
8192/9333 [=========================>....] - ETA: 3:02 - loss: 0.7121 - acc: 0.5153
8256/9333 [=========================>....] - ETA: 2:52 - loss: 0.7120 - acc: 0.5153
8320/9333 [=========================>....] - ETA: 2:41 - loss: 0.7120 - acc: 0.5153
8384/9333 [=========================>....] - ETA: 2:31 - loss: 0.7119 - acc: 0.5149
8448/9333 [==========================>...] - ETA: 2:20 - loss: 0.7118 - acc: 0.5149
8512/9333 [==========================>...] - ETA: 2:10 - loss: 0.7119 - acc: 0.5145
8576/9333 [==========================>...] - ETA: 2:00 - loss: 0.7119 - acc: 0.5139
8640/9333 [==========================>...] - ETA: 1:50 - loss: 0.7117 - acc: 0.5147
8704/9333 [==========================>...] - ETA: 1:39 - loss: 0.7113 - acc: 0.5149
8768/9333 [===========================>..] - ETA: 1:29 - loss: 0.7111 - acc: 0.5156
8832/9333 [===========================>..] - ETA: 1:19 - loss: 0.7111 - acc: 0.5155
8896/9333 [===========================>..] - ETA: 1:09 - loss: 0.7113 - acc: 0.5151
8960/9333 [===========================>..] - ETA: 59s - loss: 0.7109 - acc: 0.5155 
9024/9333 [============================>.] - ETA: 48s - loss: 0.7109 - acc: 0.5155
9088/9333 [============================>.] - ETA: 38s - loss: 0.7107 - acc: 0.5163
9152/9333 [============================>.] - ETA: 28s - loss: 0.7109 - acc: 0.5160
9216/9333 [============================>.] - ETA: 18s - loss: 0.7109 - acc: 0.5153
9280/9333 [============================>.] - ETA: 8s - loss: 0.7109 - acc: 0.5152 
9333/9333 [==============================] - 1539s 165ms/step - loss: 0.7108 - acc: 0.5154 - val_loss: 0.6940 - val_acc: 0.5024

Epoch 00001: val_acc improved from -inf to 0.50241, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window12/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 2/10

  64/9333 [..............................] - ETA: 24:07 - loss: 0.7133 - acc: 0.4688
 128/9333 [..............................] - ETA: 23:04 - loss: 0.7079 - acc: 0.4766
 192/9333 [..............................] - ETA: 22:52 - loss: 0.6997 - acc: 0.5052
 256/9333 [..............................] - ETA: 22:56 - loss: 0.6902 - acc: 0.5156
 320/9333 [>.............................] - ETA: 22:35 - loss: 0.6951 - acc: 0.5125
 384/9333 [>.............................] - ETA: 22:01 - loss: 0.6936 - acc: 0.5208
 448/9333 [>.............................] - ETA: 21:28 - loss: 0.6875 - acc: 0.5335
 512/9333 [>.............................] - ETA: 21:16 - loss: 0.6866 - acc: 0.5332
 576/9333 [>.............................] - ETA: 21:04 - loss: 0.6918 - acc: 0.5278
 640/9333 [=>............................] - ETA: 20:52 - loss: 0.6907 - acc: 0.5344
 704/9333 [=>............................] - ETA: 20:35 - loss: 0.6904 - acc: 0.5440
 768/9333 [=>............................] - ETA: 20:36 - loss: 0.6915 - acc: 0.5443
 832/9333 [=>............................] - ETA: 20:18 - loss: 0.6941 - acc: 0.5361
 896/9333 [=>............................] - ETA: 20:00 - loss: 0.6936 - acc: 0.5368
 960/9333 [==>...........................] - ETA: 19:52 - loss: 0.6937 - acc: 0.5396
1024/9333 [==>...........................] - ETA: 19:47 - loss: 0.6942 - acc: 0.5400
1088/9333 [==>...........................] - ETA: 19:34 - loss: 0.6931 - acc: 0.5423
1152/9333 [==>...........................] - ETA: 19:28 - loss: 0.6933 - acc: 0.5425
1216/9333 [==>...........................] - ETA: 19:13 - loss: 0.6935 - acc: 0.5411
1280/9333 [===>..........................] - ETA: 19:02 - loss: 0.6928 - acc: 0.5422
1344/9333 [===>..........................] - ETA: 18:47 - loss: 0.6949 - acc: 0.5372
1408/9333 [===>..........................] - ETA: 18:36 - loss: 0.6958 - acc: 0.5341
1472/9333 [===>..........................] - ETA: 18:30 - loss: 0.6964 - acc: 0.5306
1536/9333 [===>..........................] - ETA: 18:15 - loss: 0.6972 - acc: 0.5254
1600/9333 [====>.........................] - ETA: 18:00 - loss: 0.6983 - acc: 0.5238
1664/9333 [====>.........................] - ETA: 17:51 - loss: 0.6991 - acc: 0.5228
1728/9333 [====>.........................] - ETA: 17:38 - loss: 0.7011 - acc: 0.5174
1792/9333 [====>.........................] - ETA: 17:29 - loss: 0.7019 - acc: 0.5156
1856/9333 [====>.........................] - ETA: 17:17 - loss: 0.7018 - acc: 0.5156
1920/9333 [=====>........................] - ETA: 17:03 - loss: 0.7014 - acc: 0.5146
1984/9333 [=====>........................] - ETA: 16:55 - loss: 0.7018 - acc: 0.5131
2048/9333 [=====>........................] - ETA: 16:42 - loss: 0.7019 - acc: 0.5127
2112/9333 [=====>........................] - ETA: 16:33 - loss: 0.7015 - acc: 0.5133
2176/9333 [=====>........................] - ETA: 16:23 - loss: 0.7016 - acc: 0.5142
2240/9333 [======>.......................] - ETA: 16:15 - loss: 0.7006 - acc: 0.5165
2304/9333 [======>.......................] - ETA: 16:04 - loss: 0.7004 - acc: 0.5152
2368/9333 [======>.......................] - ETA: 15:56 - loss: 0.7011 - acc: 0.5122
2432/9333 [======>.......................] - ETA: 15:47 - loss: 0.7002 - acc: 0.5144
2496/9333 [=======>......................] - ETA: 15:38 - loss: 0.6999 - acc: 0.5140
2560/9333 [=======>......................] - ETA: 15:29 - loss: 0.6989 - acc: 0.5168
2624/9333 [=======>......................] - ETA: 15:18 - loss: 0.6983 - acc: 0.5179
2688/9333 [=======>......................] - ETA: 15:10 - loss: 0.6989 - acc: 0.5160
2752/9333 [=======>......................] - ETA: 15:02 - loss: 0.6981 - acc: 0.5182
2816/9333 [========>.....................] - ETA: 14:53 - loss: 0.6981 - acc: 0.5178
2880/9333 [========>.....................] - ETA: 14:46 - loss: 0.6984 - acc: 0.5163
2944/9333 [========>.....................] - ETA: 14:36 - loss: 0.6981 - acc: 0.5177
3008/9333 [========>.....................] - ETA: 14:27 - loss: 0.6984 - acc: 0.5166
3072/9333 [========>.....................] - ETA: 14:18 - loss: 0.6990 - acc: 0.5156
3136/9333 [=========>....................] - ETA: 14:09 - loss: 0.6989 - acc: 0.5153
3200/9333 [=========>....................] - ETA: 13:58 - loss: 0.6990 - acc: 0.5153
3264/9333 [=========>....................] - ETA: 13:48 - loss: 0.6990 - acc: 0.5147
3328/9333 [=========>....................] - ETA: 13:39 - loss: 0.6990 - acc: 0.5141
3392/9333 [=========>....................] - ETA: 13:30 - loss: 0.6991 - acc: 0.5133
3456/9333 [==========>...................] - ETA: 13:21 - loss: 0.6993 - acc: 0.5139
3520/9333 [==========>...................] - ETA: 13:12 - loss: 0.6987 - acc: 0.5153
3584/9333 [==========>...................] - ETA: 13:01 - loss: 0.6988 - acc: 0.5145
3648/9333 [==========>...................] - ETA: 12:51 - loss: 0.6984 - acc: 0.5159
3712/9333 [==========>...................] - ETA: 12:43 - loss: 0.6982 - acc: 0.5164
3776/9333 [===========>..................] - ETA: 12:34 - loss: 0.6983 - acc: 0.5151
3840/9333 [===========>..................] - ETA: 12:24 - loss: 0.6984 - acc: 0.5154
3904/9333 [===========>..................] - ETA: 12:15 - loss: 0.6983 - acc: 0.5149
3968/9333 [===========>..................] - ETA: 12:06 - loss: 0.6989 - acc: 0.5136
4032/9333 [===========>..................] - ETA: 11:57 - loss: 0.6982 - acc: 0.5154
4096/9333 [============>.................] - ETA: 11:49 - loss: 0.6982 - acc: 0.5144
4160/9333 [============>.................] - ETA: 11:43 - loss: 0.6981 - acc: 0.5149
4224/9333 [============>.................] - ETA: 11:35 - loss: 0.6980 - acc: 0.5142
4288/9333 [============>.................] - ETA: 11:26 - loss: 0.6975 - acc: 0.5154
4352/9333 [============>.................] - ETA: 11:16 - loss: 0.6971 - acc: 0.5161
4416/9333 [=============>................] - ETA: 11:07 - loss: 0.6970 - acc: 0.5156
4480/9333 [=============>................] - ETA: 10:59 - loss: 0.6968 - acc: 0.5156
4544/9333 [=============>................] - ETA: 10:50 - loss: 0.6969 - acc: 0.5154
4608/9333 [=============>................] - ETA: 10:42 - loss: 0.6969 - acc: 0.5154
4672/9333 [==============>...............] - ETA: 10:35 - loss: 0.6966 - acc: 0.5158
4736/9333 [==============>...............] - ETA: 10:25 - loss: 0.6967 - acc: 0.5156
4800/9333 [==============>...............] - ETA: 10:17 - loss: 0.6964 - acc: 0.5158
4864/9333 [==============>...............] - ETA: 10:08 - loss: 0.6967 - acc: 0.5144
4928/9333 [==============>...............] - ETA: 9:59 - loss: 0.6969 - acc: 0.5136 
4992/9333 [===============>..............] - ETA: 9:50 - loss: 0.6970 - acc: 0.5148
5056/9333 [===============>..............] - ETA: 9:43 - loss: 0.6967 - acc: 0.5150
5120/9333 [===============>..............] - ETA: 9:34 - loss: 0.6967 - acc: 0.5158
5184/9333 [===============>..............] - ETA: 9:26 - loss: 0.6970 - acc: 0.5149
5248/9333 [===============>..............] - ETA: 9:17 - loss: 0.6969 - acc: 0.5152
5312/9333 [================>.............] - ETA: 9:09 - loss: 0.6968 - acc: 0.5162
5376/9333 [================>.............] - ETA: 9:01 - loss: 0.6969 - acc: 0.5166
5440/9333 [================>.............] - ETA: 8:53 - loss: 0.6968 - acc: 0.5173
5504/9333 [================>.............] - ETA: 8:44 - loss: 0.6966 - acc: 0.5176
5568/9333 [================>.............] - ETA: 8:35 - loss: 0.6964 - acc: 0.5185
5632/9333 [=================>............] - ETA: 8:27 - loss: 0.6965 - acc: 0.5185
5696/9333 [=================>............] - ETA: 8:18 - loss: 0.6966 - acc: 0.5183
5760/9333 [=================>............] - ETA: 8:10 - loss: 0.6966 - acc: 0.5182
5824/9333 [=================>............] - ETA: 8:01 - loss: 0.6964 - acc: 0.5194
5888/9333 [=================>............] - ETA: 7:52 - loss: 0.6961 - acc: 0.5204
5952/9333 [==================>...........] - ETA: 7:45 - loss: 0.6958 - acc: 0.5215
6016/9333 [==================>...........] - ETA: 7:36 - loss: 0.6958 - acc: 0.5209
6080/9333 [==================>...........] - ETA: 7:27 - loss: 0.6957 - acc: 0.5214
6144/9333 [==================>...........] - ETA: 7:18 - loss: 0.6953 - acc: 0.5228
6208/9333 [==================>...........] - ETA: 7:09 - loss: 0.6954 - acc: 0.5219
6272/9333 [===================>..........] - ETA: 7:00 - loss: 0.6952 - acc: 0.5228
6336/9333 [===================>..........] - ETA: 6:51 - loss: 0.6949 - acc: 0.5241
6400/9333 [===================>..........] - ETA: 6:42 - loss: 0.6948 - acc: 0.5247
6464/9333 [===================>..........] - ETA: 6:33 - loss: 0.6947 - acc: 0.5252
6528/9333 [===================>..........] - ETA: 6:25 - loss: 0.6948 - acc: 0.5248
6592/9333 [====================>.........] - ETA: 6:16 - loss: 0.6949 - acc: 0.5241
6656/9333 [====================>.........] - ETA: 6:08 - loss: 0.6945 - acc: 0.5257
6720/9333 [====================>.........] - ETA: 5:59 - loss: 0.6945 - acc: 0.5249
6784/9333 [====================>.........] - ETA: 5:50 - loss: 0.6946 - acc: 0.5243
6848/9333 [=====================>........] - ETA: 5:41 - loss: 0.6947 - acc: 0.5242
6912/9333 [=====================>........] - ETA: 5:33 - loss: 0.6948 - acc: 0.5239
6976/9333 [=====================>........] - ETA: 5:23 - loss: 0.6944 - acc: 0.5248
7040/9333 [=====================>........] - ETA: 5:15 - loss: 0.6942 - acc: 0.5256
7104/9333 [=====================>........] - ETA: 5:06 - loss: 0.6942 - acc: 0.5258
7168/9333 [======================>.......] - ETA: 4:57 - loss: 0.6942 - acc: 0.5265
7232/9333 [======================>.......] - ETA: 4:48 - loss: 0.6943 - acc: 0.5260
7296/9333 [======================>.......] - ETA: 4:39 - loss: 0.6941 - acc: 0.5266
7360/9333 [======================>.......] - ETA: 4:31 - loss: 0.6941 - acc: 0.5270
7424/9333 [======================>.......] - ETA: 4:22 - loss: 0.6945 - acc: 0.5257
7488/9333 [=======================>......] - ETA: 4:13 - loss: 0.6946 - acc: 0.5255
7552/9333 [=======================>......] - ETA: 4:04 - loss: 0.6946 - acc: 0.5252
7616/9333 [=======================>......] - ETA: 3:55 - loss: 0.6948 - acc: 0.5246
7680/9333 [=======================>......] - ETA: 3:46 - loss: 0.6947 - acc: 0.5246
7744/9333 [=======================>......] - ETA: 3:38 - loss: 0.6948 - acc: 0.5249
7808/9333 [========================>.....] - ETA: 3:29 - loss: 0.6948 - acc: 0.5247
7872/9333 [========================>.....] - ETA: 3:20 - loss: 0.6947 - acc: 0.5250
7936/9333 [========================>.....] - ETA: 3:11 - loss: 0.6947 - acc: 0.5251
8000/9333 [========================>.....] - ETA: 3:02 - loss: 0.6948 - acc: 0.5252
8064/9333 [========================>.....] - ETA: 2:53 - loss: 0.6947 - acc: 0.5255
8128/9333 [=========================>....] - ETA: 2:44 - loss: 0.6950 - acc: 0.5247
8192/9333 [=========================>....] - ETA: 2:36 - loss: 0.6950 - acc: 0.5245
8256/9333 [=========================>....] - ETA: 2:27 - loss: 0.6947 - acc: 0.5251
8320/9333 [=========================>....] - ETA: 2:18 - loss: 0.6946 - acc: 0.5254
8384/9333 [=========================>....] - ETA: 2:09 - loss: 0.6946 - acc: 0.5250
8448/9333 [==========================>...] - ETA: 2:01 - loss: 0.6945 - acc: 0.5257
8512/9333 [==========================>...] - ETA: 1:52 - loss: 0.6945 - acc: 0.5258
8576/9333 [==========================>...] - ETA: 1:43 - loss: 0.6945 - acc: 0.5262
8640/9333 [==========================>...] - ETA: 1:35 - loss: 0.6948 - acc: 0.5259
8704/9333 [==========================>...] - ETA: 1:26 - loss: 0.6949 - acc: 0.5261
8768/9333 [===========================>..] - ETA: 1:17 - loss: 0.6949 - acc: 0.5260
8832/9333 [===========================>..] - ETA: 1:08 - loss: 0.6949 - acc: 0.5263
8896/9333 [===========================>..] - ETA: 1:00 - loss: 0.6949 - acc: 0.5266
8960/9333 [===========================>..] - ETA: 51s - loss: 0.6948 - acc: 0.5269 
9024/9333 [============================>.] - ETA: 42s - loss: 0.6947 - acc: 0.5267
9088/9333 [============================>.] - ETA: 33s - loss: 0.6947 - acc: 0.5268
9152/9333 [============================>.] - ETA: 24s - loss: 0.6946 - acc: 0.5275
9216/9333 [============================>.] - ETA: 16s - loss: 0.6945 - acc: 0.5280
9280/9333 [============================>.] - ETA: 7s - loss: 0.6947 - acc: 0.5274 
9333/9333 [==============================] - 1338s 143ms/step - loss: 0.6946 - acc: 0.5279 - val_loss: 0.6870 - val_acc: 0.5526

Epoch 00002: val_acc improved from 0.50241 to 0.55256, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window12/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 3/10

  64/9333 [..............................] - ETA: 22:22 - loss: 0.6915 - acc: 0.5156
 128/9333 [..............................] - ETA: 20:53 - loss: 0.6913 - acc: 0.5391
 192/9333 [..............................] - ETA: 21:12 - loss: 0.6926 - acc: 0.5469
 256/9333 [..............................] - ETA: 20:59 - loss: 0.6892 - acc: 0.5508
 320/9333 [>.............................] - ETA: 21:00 - loss: 0.6907 - acc: 0.5469
 384/9333 [>.............................] - ETA: 21:20 - loss: 0.6896 - acc: 0.5625
 448/9333 [>.............................] - ETA: 21:25 - loss: 0.6917 - acc: 0.5402
 512/9333 [>.............................] - ETA: 21:38 - loss: 0.6892 - acc: 0.5527
 576/9333 [>.............................] - ETA: 21:27 - loss: 0.6900 - acc: 0.5538
 640/9333 [=>............................] - ETA: 21:13 - loss: 0.6920 - acc: 0.5484
 704/9333 [=>............................] - ETA: 21:07 - loss: 0.6902 - acc: 0.5497
 768/9333 [=>............................] - ETA: 20:51 - loss: 0.6916 - acc: 0.5456
 832/9333 [=>............................] - ETA: 20:35 - loss: 0.6928 - acc: 0.5385
 896/9333 [=>............................] - ETA: 20:27 - loss: 0.6952 - acc: 0.5346
 960/9333 [==>...........................] - ETA: 20:12 - loss: 0.6952 - acc: 0.5323
1024/9333 [==>...........................] - ETA: 19:58 - loss: 0.6941 - acc: 0.5361
1088/9333 [==>...........................] - ETA: 19:51 - loss: 0.6942 - acc: 0.5358
1152/9333 [==>...........................] - ETA: 19:33 - loss: 0.6955 - acc: 0.5312
1216/9333 [==>...........................] - ETA: 19:28 - loss: 0.6955 - acc: 0.5312
1280/9333 [===>..........................] - ETA: 19:18 - loss: 0.6952 - acc: 0.5297
1344/9333 [===>..........................] - ETA: 19:05 - loss: 0.6945 - acc: 0.5305
1408/9333 [===>..........................] - ETA: 18:53 - loss: 0.6949 - acc: 0.5298
1472/9333 [===>..........................] - ETA: 18:50 - loss: 0.6946 - acc: 0.5312
1536/9333 [===>..........................] - ETA: 18:42 - loss: 0.6946 - acc: 0.5312
1600/9333 [====>.........................] - ETA: 18:31 - loss: 0.6953 - acc: 0.5288
1664/9333 [====>.........................] - ETA: 18:24 - loss: 0.6952 - acc: 0.5294
1728/9333 [====>.........................] - ETA: 18:13 - loss: 0.6940 - acc: 0.5312
1792/9333 [====>.........................] - ETA: 18:04 - loss: 0.6942 - acc: 0.5324
1856/9333 [====>.........................] - ETA: 17:52 - loss: 0.6948 - acc: 0.5329
1920/9333 [=====>........................] - ETA: 17:38 - loss: 0.6943 - acc: 0.5349
1984/9333 [=====>........................] - ETA: 17:26 - loss: 0.6936 - acc: 0.5413
2048/9333 [=====>........................] - ETA: 17:13 - loss: 0.6926 - acc: 0.5435
2112/9333 [=====>........................] - ETA: 17:04 - loss: 0.6929 - acc: 0.5426
2176/9333 [=====>........................] - ETA: 16:56 - loss: 0.6925 - acc: 0.5437
2240/9333 [======>.......................] - ETA: 16:44 - loss: 0.6924 - acc: 0.5442
2304/9333 [======>.......................] - ETA: 16:31 - loss: 0.6924 - acc: 0.5443
2368/9333 [======>.......................] - ETA: 16:20 - loss: 0.6926 - acc: 0.5448
2432/9333 [======>.......................] - ETA: 16:12 - loss: 0.6928 - acc: 0.5436
2496/9333 [=======>......................] - ETA: 16:00 - loss: 0.6922 - acc: 0.5453
2560/9333 [=======>......................] - ETA: 15:48 - loss: 0.6928 - acc: 0.5437
2624/9333 [=======>......................] - ETA: 15:38 - loss: 0.6928 - acc: 0.5419
2688/9333 [=======>......................] - ETA: 15:30 - loss: 0.6926 - acc: 0.5424
2752/9333 [=======>......................] - ETA: 15:21 - loss: 0.6924 - acc: 0.5411
2816/9333 [========>.....................] - ETA: 15:12 - loss: 0.6921 - acc: 0.5423
2880/9333 [========>.....................] - ETA: 15:02 - loss: 0.6918 - acc: 0.5427
2944/9333 [========>.....................] - ETA: 14:51 - loss: 0.6919 - acc: 0.5428
3008/9333 [========>.....................] - ETA: 14:47 - loss: 0.6915 - acc: 0.5439
3072/9333 [========>.....................] - ETA: 14:37 - loss: 0.6911 - acc: 0.5443
3136/9333 [=========>....................] - ETA: 14:27 - loss: 0.6917 - acc: 0.5437
3200/9333 [=========>....................] - ETA: 14:18 - loss: 0.6919 - acc: 0.5434
3264/9333 [=========>....................] - ETA: 14:08 - loss: 0.6917 - acc: 0.5438
3328/9333 [=========>....................] - ETA: 13:58 - loss: 0.6915 - acc: 0.5451
3392/9333 [=========>....................] - ETA: 13:48 - loss: 0.6918 - acc: 0.5451
3456/9333 [==========>...................] - ETA: 13:38 - loss: 0.6921 - acc: 0.5437
3520/9333 [==========>...................] - ETA: 13:29 - loss: 0.6917 - acc: 0.5455
3584/9333 [==========>...................] - ETA: 13:18 - loss: 0.6924 - acc: 0.5435
3648/9333 [==========>...................] - ETA: 13:08 - loss: 0.6933 - acc: 0.5417
3712/9333 [==========>...................] - ETA: 13:00 - loss: 0.6932 - acc: 0.5423
3776/9333 [===========>..................] - ETA: 12:50 - loss: 0.6929 - acc: 0.5421
3840/9333 [===========>..................] - ETA: 12:39 - loss: 0.6931 - acc: 0.5411
3904/9333 [===========>..................] - ETA: 12:31 - loss: 0.6925 - acc: 0.5418
3968/9333 [===========>..................] - ETA: 12:23 - loss: 0.6924 - acc: 0.5428
4032/9333 [===========>..................] - ETA: 12:13 - loss: 0.6922 - acc: 0.5422
4096/9333 [============>.................] - ETA: 12:03 - loss: 0.6921 - acc: 0.5408
4160/9333 [============>.................] - ETA: 11:55 - loss: 0.6926 - acc: 0.5399
4224/9333 [============>.................] - ETA: 11:46 - loss: 0.6926 - acc: 0.5388
4288/9333 [============>.................] - ETA: 11:38 - loss: 0.6924 - acc: 0.5385
4352/9333 [============>.................] - ETA: 11:29 - loss: 0.6925 - acc: 0.5388
4416/9333 [=============>................] - ETA: 11:21 - loss: 0.6928 - acc: 0.5374
4480/9333 [=============>................] - ETA: 11:12 - loss: 0.6927 - acc: 0.5384
4544/9333 [=============>................] - ETA: 11:04 - loss: 0.6929 - acc: 0.5385
4608/9333 [=============>................] - ETA: 10:54 - loss: 0.6927 - acc: 0.5388
4672/9333 [==============>...............] - ETA: 10:45 - loss: 0.6925 - acc: 0.5390
4736/9333 [==============>...............] - ETA: 10:36 - loss: 0.6923 - acc: 0.5393
4800/9333 [==============>...............] - ETA: 10:27 - loss: 0.6924 - acc: 0.5390
4864/9333 [==============>...............] - ETA: 10:18 - loss: 0.6922 - acc: 0.5397
4928/9333 [==============>...............] - ETA: 10:09 - loss: 0.6921 - acc: 0.5398
4992/9333 [===============>..............] - ETA: 10:00 - loss: 0.6920 - acc: 0.5391
5056/9333 [===============>..............] - ETA: 9:51 - loss: 0.6918 - acc: 0.5390 
5120/9333 [===============>..............] - ETA: 9:42 - loss: 0.6917 - acc: 0.5398
5184/9333 [===============>..............] - ETA: 9:33 - loss: 0.6916 - acc: 0.5401
5248/9333 [===============>..............] - ETA: 9:24 - loss: 0.6917 - acc: 0.5402
5312/9333 [================>.............] - ETA: 9:16 - loss: 0.6918 - acc: 0.5388
5376/9333 [================>.............] - ETA: 9:07 - loss: 0.6918 - acc: 0.5383
5440/9333 [================>.............] - ETA: 8:58 - loss: 0.6919 - acc: 0.5382
5504/9333 [================>.............] - ETA: 8:49 - loss: 0.6918 - acc: 0.5391
5568/9333 [================>.............] - ETA: 8:40 - loss: 0.6920 - acc: 0.5383
5632/9333 [=================>............] - ETA: 8:30 - loss: 0.6923 - acc: 0.5373
5696/9333 [=================>............] - ETA: 8:21 - loss: 0.6918 - acc: 0.5390
5760/9333 [=================>............] - ETA: 8:13 - loss: 0.6912 - acc: 0.5406
5824/9333 [=================>............] - ETA: 8:04 - loss: 0.6912 - acc: 0.5409
5888/9333 [=================>............] - ETA: 7:56 - loss: 0.6914 - acc: 0.5404
5952/9333 [==================>...........] - ETA: 7:47 - loss: 0.6910 - acc: 0.5408
6016/9333 [==================>...........] - ETA: 7:38 - loss: 0.6912 - acc: 0.5399
6080/9333 [==================>...........] - ETA: 7:29 - loss: 0.6915 - acc: 0.5393
6144/9333 [==================>...........] - ETA: 7:20 - loss: 0.6919 - acc: 0.5382
6208/9333 [==================>...........] - ETA: 7:11 - loss: 0.6920 - acc: 0.5382
6272/9333 [===================>..........] - ETA: 7:02 - loss: 0.6918 - acc: 0.5386
6336/9333 [===================>..........] - ETA: 6:53 - loss: 0.6918 - acc: 0.5385
6400/9333 [===================>..........] - ETA: 6:45 - loss: 0.6921 - acc: 0.5378
6464/9333 [===================>..........] - ETA: 6:36 - loss: 0.6919 - acc: 0.5387
6528/9333 [===================>..........] - ETA: 6:27 - loss: 0.6918 - acc: 0.5384
6592/9333 [====================>.........] - ETA: 6:18 - loss: 0.6917 - acc: 0.5387
6656/9333 [====================>.........] - ETA: 6:09 - loss: 0.6917 - acc: 0.5388
6720/9333 [====================>.........] - ETA: 6:00 - loss: 0.6916 - acc: 0.5391
6784/9333 [====================>.........] - ETA: 5:51 - loss: 0.6914 - acc: 0.5401
6848/9333 [=====================>........] - ETA: 5:42 - loss: 0.6912 - acc: 0.5407
6912/9333 [=====================>........] - ETA: 5:34 - loss: 0.6911 - acc: 0.5408
6976/9333 [=====================>........] - ETA: 5:25 - loss: 0.6910 - acc: 0.5413
7040/9333 [=====================>........] - ETA: 5:16 - loss: 0.6911 - acc: 0.5412
7104/9333 [=====================>........] - ETA: 5:07 - loss: 0.6909 - acc: 0.5411
7168/9333 [======================>.......] - ETA: 4:58 - loss: 0.6908 - acc: 0.5410
7232/9333 [======================>.......] - ETA: 4:49 - loss: 0.6908 - acc: 0.5409
7296/9333 [======================>.......] - ETA: 4:41 - loss: 0.6909 - acc: 0.5408
7360/9333 [======================>.......] - ETA: 4:32 - loss: 0.6909 - acc: 0.5402
7424/9333 [======================>.......] - ETA: 4:23 - loss: 0.6908 - acc: 0.5407
7488/9333 [=======================>......] - ETA: 4:14 - loss: 0.6907 - acc: 0.5413
7552/9333 [=======================>......] - ETA: 4:05 - loss: 0.6905 - acc: 0.5421
7616/9333 [=======================>......] - ETA: 3:56 - loss: 0.6903 - acc: 0.5424
7680/9333 [=======================>......] - ETA: 3:48 - loss: 0.6905 - acc: 0.5415
7744/9333 [=======================>......] - ETA: 3:39 - loss: 0.6903 - acc: 0.5418
7808/9333 [========================>.....] - ETA: 3:30 - loss: 0.6901 - acc: 0.5421
7872/9333 [========================>.....] - ETA: 3:21 - loss: 0.6902 - acc: 0.5418
7936/9333 [========================>.....] - ETA: 3:12 - loss: 0.6900 - acc: 0.5416
8000/9333 [========================>.....] - ETA: 3:03 - loss: 0.6898 - acc: 0.5423
8064/9333 [========================>.....] - ETA: 2:55 - loss: 0.6896 - acc: 0.5423
8128/9333 [=========================>....] - ETA: 2:46 - loss: 0.6897 - acc: 0.5423
8192/9333 [=========================>....] - ETA: 2:37 - loss: 0.6897 - acc: 0.5420
8256/9333 [=========================>....] - ETA: 2:28 - loss: 0.6898 - acc: 0.5417
8320/9333 [=========================>....] - ETA: 2:20 - loss: 0.6903 - acc: 0.5411
8384/9333 [=========================>....] - ETA: 2:11 - loss: 0.6901 - acc: 0.5417
8448/9333 [==========================>...] - ETA: 2:02 - loss: 0.6902 - acc: 0.5419
8512/9333 [==========================>...] - ETA: 1:53 - loss: 0.6902 - acc: 0.5418
8576/9333 [==========================>...] - ETA: 1:44 - loss: 0.6901 - acc: 0.5420
8640/9333 [==========================>...] - ETA: 1:35 - loss: 0.6903 - acc: 0.5412
8704/9333 [==========================>...] - ETA: 1:26 - loss: 0.6904 - acc: 0.5408
8768/9333 [===========================>..] - ETA: 1:18 - loss: 0.6904 - acc: 0.5411
8832/9333 [===========================>..] - ETA: 1:09 - loss: 0.6904 - acc: 0.5411
8896/9333 [===========================>..] - ETA: 1:00 - loss: 0.6903 - acc: 0.5416
8960/9333 [===========================>..] - ETA: 51s - loss: 0.6901 - acc: 0.5421 
9024/9333 [============================>.] - ETA: 42s - loss: 0.6901 - acc: 0.5416
9088/9333 [============================>.] - ETA: 33s - loss: 0.6899 - acc: 0.5424
9152/9333 [============================>.] - ETA: 25s - loss: 0.6899 - acc: 0.5424
9216/9333 [============================>.] - ETA: 16s - loss: 0.6898 - acc: 0.5425
9280/9333 [============================>.] - ETA: 7s - loss: 0.6896 - acc: 0.5429 
9333/9333 [==============================] - 1338s 143ms/step - loss: 0.6897 - acc: 0.5429 - val_loss: 0.6866 - val_acc: 0.5400

Epoch 00003: val_acc did not improve from 0.55256
Epoch 4/10

  64/9333 [..............................] - ETA: 23:35 - loss: 0.6927 - acc: 0.6094
 128/9333 [..............................] - ETA: 21:54 - loss: 0.6814 - acc: 0.5859
 192/9333 [..............................] - ETA: 22:11 - loss: 0.6838 - acc: 0.5729
 256/9333 [..............................] - ETA: 21:30 - loss: 0.6940 - acc: 0.5312
 320/9333 [>.............................] - ETA: 21:11 - loss: 0.6959 - acc: 0.5125
 384/9333 [>.............................] - ETA: 20:52 - loss: 0.6906 - acc: 0.5312
 448/9333 [>.............................] - ETA: 20:05 - loss: 0.6909 - acc: 0.5357
 512/9333 [>.............................] - ETA: 19:54 - loss: 0.6918 - acc: 0.5352
 576/9333 [>.............................] - ETA: 19:36 - loss: 0.6914 - acc: 0.5365
 640/9333 [=>............................] - ETA: 19:18 - loss: 0.6939 - acc: 0.5297
 704/9333 [=>............................] - ETA: 19:19 - loss: 0.6945 - acc: 0.5270
 768/9333 [=>............................] - ETA: 19:16 - loss: 0.6942 - acc: 0.5247
 832/9333 [=>............................] - ETA: 19:11 - loss: 0.6924 - acc: 0.5300
 896/9333 [=>............................] - ETA: 19:00 - loss: 0.6943 - acc: 0.5212
 960/9333 [==>...........................] - ETA: 18:54 - loss: 0.6945 - acc: 0.5260
1024/9333 [==>...........................] - ETA: 18:44 - loss: 0.6940 - acc: 0.5293
1088/9333 [==>...........................] - ETA: 18:40 - loss: 0.6918 - acc: 0.5331
1152/9333 [==>...........................] - ETA: 18:28 - loss: 0.6921 - acc: 0.5304
1216/9333 [==>...........................] - ETA: 18:12 - loss: 0.6917 - acc: 0.5362
1280/9333 [===>..........................] - ETA: 18:05 - loss: 0.6918 - acc: 0.5352
1344/9333 [===>..........................] - ETA: 18:02 - loss: 0.6912 - acc: 0.5335
1408/9333 [===>..........................] - ETA: 17:53 - loss: 0.6912 - acc: 0.5348
1472/9333 [===>..........................] - ETA: 17:45 - loss: 0.6916 - acc: 0.5333
1536/9333 [===>..........................] - ETA: 17:38 - loss: 0.6907 - acc: 0.5345
1600/9333 [====>.........................] - ETA: 17:30 - loss: 0.6904 - acc: 0.5375
1664/9333 [====>.........................] - ETA: 17:19 - loss: 0.6907 - acc: 0.5355
1728/9333 [====>.........................] - ETA: 17:07 - loss: 0.6921 - acc: 0.5295
1792/9333 [====>.........................] - ETA: 17:00 - loss: 0.6928 - acc: 0.5290
1856/9333 [====>.........................] - ETA: 16:47 - loss: 0.6927 - acc: 0.5291
1920/9333 [=====>........................] - ETA: 16:37 - loss: 0.6933 - acc: 0.5276
1984/9333 [=====>........................] - ETA: 16:30 - loss: 0.6930 - acc: 0.5277
2048/9333 [=====>........................] - ETA: 16:26 - loss: 0.6916 - acc: 0.5308
2112/9333 [=====>........................] - ETA: 16:24 - loss: 0.6912 - acc: 0.5322
2176/9333 [=====>........................] - ETA: 16:14 - loss: 0.6917 - acc: 0.5308
2240/9333 [======>.......................] - ETA: 16:09 - loss: 0.6923 - acc: 0.5281
2304/9333 [======>.......................] - ETA: 16:06 - loss: 0.6927 - acc: 0.5273
2368/9333 [======>.......................] - ETA: 15:57 - loss: 0.6928 - acc: 0.5279
2432/9333 [======>.......................] - ETA: 15:46 - loss: 0.6925 - acc: 0.5271
2496/9333 [=======>......................] - ETA: 15:37 - loss: 0.6917 - acc: 0.5292
2560/9333 [=======>......................] - ETA: 15:31 - loss: 0.6916 - acc: 0.5305
2624/9333 [=======>......................] - ETA: 15:21 - loss: 0.6916 - acc: 0.5305
2688/9333 [=======>......................] - ETA: 15:12 - loss: 0.6914 - acc: 0.5301
2752/9333 [=======>......................] - ETA: 15:07 - loss: 0.6919 - acc: 0.5276
2816/9333 [========>.....................] - ETA: 14:56 - loss: 0.6925 - acc: 0.5266
2880/9333 [========>.....................] - ETA: 14:52 - loss: 0.6927 - acc: 0.5247
2944/9333 [========>.....................] - ETA: 14:43 - loss: 0.6918 - acc: 0.5265
3008/9333 [========>.....................] - ETA: 14:38 - loss: 0.6922 - acc: 0.5266
3072/9333 [========>.....................] - ETA: 14:29 - loss: 0.6923 - acc: 0.5264
3136/9333 [=========>....................] - ETA: 14:19 - loss: 0.6919 - acc: 0.5284
3200/9333 [=========>....................] - ETA: 14:11 - loss: 0.6919 - acc: 0.5281
3264/9333 [=========>....................] - ETA: 14:05 - loss: 0.6916 - acc: 0.5294
3328/9333 [=========>....................] - ETA: 13:55 - loss: 0.6913 - acc: 0.5312
3392/9333 [=========>....................] - ETA: 13:46 - loss: 0.6911 - acc: 0.5333
3456/9333 [==========>...................] - ETA: 13:37 - loss: 0.6910 - acc: 0.5333
3520/9333 [==========>...................] - ETA: 13:29 - loss: 0.6907 - acc: 0.5341
3584/9333 [==========>...................] - ETA: 13:20 - loss: 0.6906 - acc: 0.5352
3648/9333 [==========>...................] - ETA: 13:10 - loss: 0.6902 - acc: 0.5373
3712/9333 [==========>...................] - ETA: 12:59 - loss: 0.6901 - acc: 0.5364
3776/9333 [===========>..................] - ETA: 12:50 - loss: 0.6897 - acc: 0.5384
3840/9333 [===========>..................] - ETA: 12:41 - loss: 0.6898 - acc: 0.5393
3904/9333 [===========>..................] - ETA: 12:33 - loss: 0.6899 - acc: 0.5389
3968/9333 [===========>..................] - ETA: 12:25 - loss: 0.6909 - acc: 0.5368
4032/9333 [===========>..................] - ETA: 12:16 - loss: 0.6910 - acc: 0.5360
4096/9333 [============>.................] - ETA: 12:07 - loss: 0.6906 - acc: 0.5378
4160/9333 [============>.................] - ETA: 11:59 - loss: 0.6903 - acc: 0.5394
4224/9333 [============>.................] - ETA: 11:50 - loss: 0.6899 - acc: 0.5407
4288/9333 [============>.................] - ETA: 11:41 - loss: 0.6898 - acc: 0.5406
4352/9333 [============>.................] - ETA: 11:33 - loss: 0.6898 - acc: 0.5393
4416/9333 [=============>................] - ETA: 11:26 - loss: 0.6897 - acc: 0.5389
4480/9333 [=============>................] - ETA: 11:19 - loss: 0.6899 - acc: 0.5388
4544/9333 [=============>................] - ETA: 11:10 - loss: 0.6898 - acc: 0.5383
4608/9333 [=============>................] - ETA: 11:01 - loss: 0.6896 - acc: 0.5382
4672/9333 [==============>...............] - ETA: 10:53 - loss: 0.6893 - acc: 0.5396
4736/9333 [==============>...............] - ETA: 10:44 - loss: 0.6887 - acc: 0.5403
4800/9333 [==============>...............] - ETA: 10:34 - loss: 0.6889 - acc: 0.5402
4864/9333 [==============>...............] - ETA: 10:25 - loss: 0.6888 - acc: 0.5407
4928/9333 [==============>...............] - ETA: 10:16 - loss: 0.6883 - acc: 0.5418
4992/9333 [===============>..............] - ETA: 10:06 - loss: 0.6885 - acc: 0.5415
5056/9333 [===============>..............] - ETA: 9:56 - loss: 0.6884 - acc: 0.5417 
5120/9333 [===============>..............] - ETA: 9:47 - loss: 0.6879 - acc: 0.5437
5184/9333 [===============>..............] - ETA: 9:39 - loss: 0.6881 - acc: 0.5436
5248/9333 [===============>..............] - ETA: 9:32 - loss: 0.6879 - acc: 0.5440
5312/9333 [================>.............] - ETA: 9:23 - loss: 0.6879 - acc: 0.5437
5376/9333 [================>.............] - ETA: 9:14 - loss: 0.6877 - acc: 0.5441
5440/9333 [================>.............] - ETA: 9:05 - loss: 0.6877 - acc: 0.5443
5504/9333 [================>.............] - ETA: 8:56 - loss: 0.6875 - acc: 0.5449
5568/9333 [================>.............] - ETA: 8:47 - loss: 0.6873 - acc: 0.5456
5632/9333 [=================>............] - ETA: 8:38 - loss: 0.6874 - acc: 0.5456
5696/9333 [=================>............] - ETA: 8:29 - loss: 0.6876 - acc: 0.5458
5760/9333 [=================>............] - ETA: 8:19 - loss: 0.6877 - acc: 0.5457
5824/9333 [=================>............] - ETA: 8:11 - loss: 0.6875 - acc: 0.5462
5888/9333 [=================>............] - ETA: 8:02 - loss: 0.6876 - acc: 0.5455
5952/9333 [==================>...........] - ETA: 7:53 - loss: 0.6875 - acc: 0.5457
6016/9333 [==================>...........] - ETA: 7:44 - loss: 0.6875 - acc: 0.5462
6080/9333 [==================>...........] - ETA: 7:35 - loss: 0.6873 - acc: 0.5459
6144/9333 [==================>...........] - ETA: 7:26 - loss: 0.6875 - acc: 0.5457
6208/9333 [==================>...........] - ETA: 7:17 - loss: 0.6873 - acc: 0.5457
6272/9333 [===================>..........] - ETA: 7:07 - loss: 0.6874 - acc: 0.5458
6336/9333 [===================>..........] - ETA: 6:59 - loss: 0.6875 - acc: 0.5455
6400/9333 [===================>..........] - ETA: 6:50 - loss: 0.6872 - acc: 0.5459
6464/9333 [===================>..........] - ETA: 6:41 - loss: 0.6874 - acc: 0.5452
6528/9333 [===================>..........] - ETA: 6:32 - loss: 0.6876 - acc: 0.5441
6592/9333 [====================>.........] - ETA: 6:23 - loss: 0.6877 - acc: 0.5432
6656/9333 [====================>.........] - ETA: 6:15 - loss: 0.6879 - acc: 0.5424
6720/9333 [====================>.........] - ETA: 6:05 - loss: 0.6878 - acc: 0.5436
6784/9333 [====================>.........] - ETA: 5:56 - loss: 0.6878 - acc: 0.5436
6848/9333 [=====================>........] - ETA: 5:48 - loss: 0.6878 - acc: 0.5434
6912/9333 [=====================>........] - ETA: 5:39 - loss: 0.6878 - acc: 0.5427
6976/9333 [=====================>........] - ETA: 5:30 - loss: 0.6877 - acc: 0.5434
7040/9333 [=====================>........] - ETA: 5:22 - loss: 0.6876 - acc: 0.5435
7104/9333 [=====================>........] - ETA: 5:13 - loss: 0.6876 - acc: 0.5439
7168/9333 [======================>.......] - ETA: 5:04 - loss: 0.6878 - acc: 0.5437
7232/9333 [======================>.......] - ETA: 4:55 - loss: 0.6876 - acc: 0.5438
7296/9333 [======================>.......] - ETA: 4:46 - loss: 0.6875 - acc: 0.5443
7360/9333 [======================>.......] - ETA: 4:37 - loss: 0.6876 - acc: 0.5447
7424/9333 [======================>.......] - ETA: 4:28 - loss: 0.6875 - acc: 0.5450
7488/9333 [=======================>......] - ETA: 4:19 - loss: 0.6876 - acc: 0.5447
7552/9333 [=======================>......] - ETA: 4:10 - loss: 0.6878 - acc: 0.5453
7616/9333 [=======================>......] - ETA: 4:01 - loss: 0.6877 - acc: 0.5453
7680/9333 [=======================>......] - ETA: 3:52 - loss: 0.6878 - acc: 0.5447
7744/9333 [=======================>......] - ETA: 3:43 - loss: 0.6879 - acc: 0.5443
7808/9333 [========================>.....] - ETA: 3:34 - loss: 0.6879 - acc: 0.5447
7872/9333 [========================>.....] - ETA: 3:24 - loss: 0.6879 - acc: 0.5448
7936/9333 [========================>.....] - ETA: 3:16 - loss: 0.6880 - acc: 0.5451
8000/9333 [========================>.....] - ETA: 3:06 - loss: 0.6880 - acc: 0.5447
8064/9333 [========================>.....] - ETA: 2:57 - loss: 0.6878 - acc: 0.5459
8128/9333 [=========================>....] - ETA: 2:48 - loss: 0.6879 - acc: 0.5456
8192/9333 [=========================>....] - ETA: 2:39 - loss: 0.6881 - acc: 0.5454
8256/9333 [=========================>....] - ETA: 2:30 - loss: 0.6881 - acc: 0.5458
8320/9333 [=========================>....] - ETA: 2:21 - loss: 0.6881 - acc: 0.5451
8384/9333 [=========================>....] - ETA: 2:12 - loss: 0.6881 - acc: 0.5454
8448/9333 [==========================>...] - ETA: 2:03 - loss: 0.6880 - acc: 0.5456
8512/9333 [==========================>...] - ETA: 1:54 - loss: 0.6880 - acc: 0.5455
8576/9333 [==========================>...] - ETA: 1:45 - loss: 0.6881 - acc: 0.5452
8640/9333 [==========================>...] - ETA: 1:36 - loss: 0.6880 - acc: 0.5457
8704/9333 [==========================>...] - ETA: 1:27 - loss: 0.6881 - acc: 0.5455
8768/9333 [===========================>..] - ETA: 1:18 - loss: 0.6880 - acc: 0.5458
8832/9333 [===========================>..] - ETA: 1:09 - loss: 0.6877 - acc: 0.5469
8896/9333 [===========================>..] - ETA: 1:00 - loss: 0.6877 - acc: 0.5473
8960/9333 [===========================>..] - ETA: 51s - loss: 0.6878 - acc: 0.5471 
9024/9333 [============================>.] - ETA: 43s - loss: 0.6877 - acc: 0.5473
9088/9333 [============================>.] - ETA: 34s - loss: 0.6876 - acc: 0.5475
9152/9333 [============================>.] - ETA: 25s - loss: 0.6877 - acc: 0.5473
9216/9333 [============================>.] - ETA: 16s - loss: 0.6876 - acc: 0.5475
9280/9333 [============================>.] - ETA: 7s - loss: 0.6878 - acc: 0.5471 
9333/9333 [==============================] - 1351s 145ms/step - loss: 0.6878 - acc: 0.5473 - val_loss: 0.6880 - val_acc: 0.5256

Epoch 00004: val_acc did not improve from 0.55256
Epoch 5/10

  64/9333 [..............................] - ETA: 21:28 - loss: 0.6992 - acc: 0.5781
 128/9333 [..............................] - ETA: 20:48 - loss: 0.6947 - acc: 0.5703
 192/9333 [..............................] - ETA: 20:57 - loss: 0.6905 - acc: 0.5521
 256/9333 [..............................] - ETA: 21:31 - loss: 0.6955 - acc: 0.5430
 320/9333 [>.............................] - ETA: 21:32 - loss: 0.6930 - acc: 0.5312
 384/9333 [>.............................] - ETA: 21:22 - loss: 0.6890 - acc: 0.5417
 448/9333 [>.............................] - ETA: 21:06 - loss: 0.6875 - acc: 0.5446
 512/9333 [>.............................] - ETA: 20:46 - loss: 0.6899 - acc: 0.5371
 576/9333 [>.............................] - ETA: 20:30 - loss: 0.6882 - acc: 0.5434
 640/9333 [=>............................] - ETA: 20:09 - loss: 0.6885 - acc: 0.5453
 704/9333 [=>............................] - ETA: 19:54 - loss: 0.6877 - acc: 0.5483
 768/9333 [=>............................] - ETA: 19:48 - loss: 0.6865 - acc: 0.5534
 832/9333 [=>............................] - ETA: 19:42 - loss: 0.6891 - acc: 0.5457
 896/9333 [=>............................] - ETA: 19:37 - loss: 0.6870 - acc: 0.5536
 960/9333 [==>...........................] - ETA: 19:26 - loss: 0.6871 - acc: 0.5479
1024/9333 [==>...........................] - ETA: 19:10 - loss: 0.6862 - acc: 0.5518
1088/9333 [==>...........................] - ETA: 18:59 - loss: 0.6844 - acc: 0.5551
1152/9333 [==>...........................] - ETA: 18:49 - loss: 0.6821 - acc: 0.5590
1216/9333 [==>...........................] - ETA: 18:44 - loss: 0.6827 - acc: 0.5584
1280/9333 [===>..........................] - ETA: 18:31 - loss: 0.6826 - acc: 0.5586
1344/9333 [===>..........................] - ETA: 18:25 - loss: 0.6824 - acc: 0.5595
1408/9333 [===>..........................] - ETA: 18:15 - loss: 0.6832 - acc: 0.5554
1472/9333 [===>..........................] - ETA: 18:09 - loss: 0.6842 - acc: 0.5584
1536/9333 [===>..........................] - ETA: 17:59 - loss: 0.6840 - acc: 0.5579
1600/9333 [====>.........................] - ETA: 17:51 - loss: 0.6833 - acc: 0.5581
1664/9333 [====>.........................] - ETA: 17:46 - loss: 0.6841 - acc: 0.5577
1728/9333 [====>.........................] - ETA: 17:34 - loss: 0.6850 - acc: 0.5538
1792/9333 [====>.........................] - ETA: 17:27 - loss: 0.6861 - acc: 0.5491
1856/9333 [====>.........................] - ETA: 17:16 - loss: 0.6859 - acc: 0.5496
1920/9333 [=====>........................] - ETA: 17:08 - loss: 0.6859 - acc: 0.5505
1984/9333 [=====>........................] - ETA: 16:58 - loss: 0.6857 - acc: 0.5494
2048/9333 [=====>........................] - ETA: 16:50 - loss: 0.6851 - acc: 0.5479
2112/9333 [=====>........................] - ETA: 16:47 - loss: 0.6856 - acc: 0.5459
2176/9333 [=====>........................] - ETA: 16:36 - loss: 0.6856 - acc: 0.5478
2240/9333 [======>.......................] - ETA: 16:28 - loss: 0.6850 - acc: 0.5496
2304/9333 [======>.......................] - ETA: 16:21 - loss: 0.6853 - acc: 0.5508
2368/9333 [======>.......................] - ETA: 16:14 - loss: 0.6847 - acc: 0.5545
2432/9333 [======>.......................] - ETA: 16:05 - loss: 0.6835 - acc: 0.5588
2496/9333 [=======>......................] - ETA: 15:57 - loss: 0.6840 - acc: 0.5597
2560/9333 [=======>......................] - ETA: 15:51 - loss: 0.6841 - acc: 0.5586
2624/9333 [=======>......................] - ETA: 15:41 - loss: 0.6845 - acc: 0.5579
2688/9333 [=======>......................] - ETA: 15:31 - loss: 0.6845 - acc: 0.5584
2752/9333 [=======>......................] - ETA: 15:26 - loss: 0.6854 - acc: 0.5560
2816/9333 [========>.....................] - ETA: 15:15 - loss: 0.6855 - acc: 0.5547
2880/9333 [========>.....................] - ETA: 15:08 - loss: 0.6855 - acc: 0.5538
2944/9333 [========>.....................] - ETA: 15:00 - loss: 0.6855 - acc: 0.5523
3008/9333 [========>.....................] - ETA: 14:52 - loss: 0.6857 - acc: 0.5509
3072/9333 [========>.....................] - ETA: 14:45 - loss: 0.6858 - acc: 0.5501
3136/9333 [=========>....................] - ETA: 14:37 - loss: 0.6854 - acc: 0.5497
3200/9333 [=========>....................] - ETA: 14:30 - loss: 0.6851 - acc: 0.5506
3264/9333 [=========>....................] - ETA: 14:21 - loss: 0.6852 - acc: 0.5493
3328/9333 [=========>....................] - ETA: 14:13 - loss: 0.6855 - acc: 0.5508
3392/9333 [=========>....................] - ETA: 14:03 - loss: 0.6854 - acc: 0.5513
3456/9333 [==========>...................] - ETA: 13:53 - loss: 0.6859 - acc: 0.5498
3520/9333 [==========>...................] - ETA: 13:43 - loss: 0.6854 - acc: 0.5509
3584/9333 [==========>...................] - ETA: 13:32 - loss: 0.6855 - acc: 0.5505
3648/9333 [==========>...................] - ETA: 13:22 - loss: 0.6859 - acc: 0.5502
3712/9333 [==========>...................] - ETA: 13:13 - loss: 0.6851 - acc: 0.5523
3776/9333 [===========>..................] - ETA: 13:04 - loss: 0.6846 - acc: 0.5524
3840/9333 [===========>..................] - ETA: 12:57 - loss: 0.6846 - acc: 0.5521
3904/9333 [===========>..................] - ETA: 12:48 - loss: 0.6844 - acc: 0.5525
3968/9333 [===========>..................] - ETA: 12:38 - loss: 0.6854 - acc: 0.5514
4032/9333 [===========>..................] - ETA: 12:29 - loss: 0.6852 - acc: 0.5523
4096/9333 [============>.................] - ETA: 12:19 - loss: 0.6847 - acc: 0.5535
4160/9333 [============>.................] - ETA: 12:09 - loss: 0.6847 - acc: 0.5536
4224/9333 [============>.................] - ETA: 11:59 - loss: 0.6851 - acc: 0.5535
4288/9333 [============>.................] - ETA: 11:51 - loss: 0.6849 - acc: 0.5541
4352/9333 [============>.................] - ETA: 11:42 - loss: 0.6853 - acc: 0.5535
4416/9333 [=============>................] - ETA: 11:34 - loss: 0.6858 - acc: 0.5523
4480/9333 [=============>................] - ETA: 11:24 - loss: 0.6860 - acc: 0.5520
4544/9333 [=============>................] - ETA: 11:14 - loss: 0.6857 - acc: 0.5526
4608/9333 [=============>................] - ETA: 11:05 - loss: 0.6856 - acc: 0.5530
4672/9333 [==============>...............] - ETA: 10:56 - loss: 0.6855 - acc: 0.5522
4736/9333 [==============>...............] - ETA: 10:45 - loss: 0.6855 - acc: 0.5526
4800/9333 [==============>...............] - ETA: 10:36 - loss: 0.6856 - acc: 0.5521
4864/9333 [==============>...............] - ETA: 10:27 - loss: 0.6857 - acc: 0.5524
4928/9333 [==============>...............] - ETA: 10:19 - loss: 0.6861 - acc: 0.5507
4992/9333 [===============>..............] - ETA: 10:10 - loss: 0.6860 - acc: 0.5511
5056/9333 [===============>..............] - ETA: 10:00 - loss: 0.6858 - acc: 0.5512
5120/9333 [===============>..............] - ETA: 9:51 - loss: 0.6860 - acc: 0.5512 
5184/9333 [===============>..............] - ETA: 9:42 - loss: 0.6858 - acc: 0.5515
5248/9333 [===============>..............] - ETA: 9:33 - loss: 0.6859 - acc: 0.5511
5312/9333 [================>.............] - ETA: 9:24 - loss: 0.6864 - acc: 0.5497
5376/9333 [================>.............] - ETA: 9:14 - loss: 0.6861 - acc: 0.5504
5440/9333 [================>.............] - ETA: 9:05 - loss: 0.6868 - acc: 0.5491
5504/9333 [================>.............] - ETA: 8:56 - loss: 0.6866 - acc: 0.5494
5568/9333 [================>.............] - ETA: 8:48 - loss: 0.6868 - acc: 0.5481
5632/9333 [=================>............] - ETA: 8:39 - loss: 0.6873 - acc: 0.5472
5696/9333 [=================>............] - ETA: 8:30 - loss: 0.6876 - acc: 0.5469
5760/9333 [=================>............] - ETA: 8:20 - loss: 0.6876 - acc: 0.5470
5824/9333 [=================>............] - ETA: 8:11 - loss: 0.6876 - acc: 0.5474
5888/9333 [=================>............] - ETA: 8:01 - loss: 0.6877 - acc: 0.5470
5952/9333 [==================>...........] - ETA: 7:52 - loss: 0.6876 - acc: 0.5475
6016/9333 [==================>...........] - ETA: 7:42 - loss: 0.6877 - acc: 0.5474
6080/9333 [==================>...........] - ETA: 7:33 - loss: 0.6877 - acc: 0.5477
6144/9333 [==================>...........] - ETA: 7:24 - loss: 0.6875 - acc: 0.5475
6208/9333 [==================>...........] - ETA: 7:15 - loss: 0.6878 - acc: 0.5467
6272/9333 [===================>..........] - ETA: 7:06 - loss: 0.6881 - acc: 0.5464
6336/9333 [===================>..........] - ETA: 6:57 - loss: 0.6885 - acc: 0.5453
6400/9333 [===================>..........] - ETA: 6:47 - loss: 0.6883 - acc: 0.5453
6464/9333 [===================>..........] - ETA: 6:39 - loss: 0.6883 - acc: 0.5455
6528/9333 [===================>..........] - ETA: 6:29 - loss: 0.6888 - acc: 0.5443
6592/9333 [====================>.........] - ETA: 6:20 - loss: 0.6886 - acc: 0.5449
6656/9333 [====================>.........] - ETA: 6:12 - loss: 0.6885 - acc: 0.5457
6720/9333 [====================>.........] - ETA: 6:03 - loss: 0.6885 - acc: 0.5461
6784/9333 [====================>.........] - ETA: 5:54 - loss: 0.6884 - acc: 0.5463
6848/9333 [=====================>........] - ETA: 5:45 - loss: 0.6888 - acc: 0.5454
6912/9333 [=====================>........] - ETA: 5:36 - loss: 0.6888 - acc: 0.5450
6976/9333 [=====================>........] - ETA: 5:28 - loss: 0.6889 - acc: 0.5447
7040/9333 [=====================>........] - ETA: 5:20 - loss: 0.6887 - acc: 0.5457
7104/9333 [=====================>........] - ETA: 5:11 - loss: 0.6885 - acc: 0.5466
7168/9333 [======================>.......] - ETA: 5:02 - loss: 0.6882 - acc: 0.5474
7232/9333 [======================>.......] - ETA: 4:53 - loss: 0.6883 - acc: 0.5477
7296/9333 [======================>.......] - ETA: 4:44 - loss: 0.6883 - acc: 0.5482
7360/9333 [======================>.......] - ETA: 4:35 - loss: 0.6883 - acc: 0.5484
7424/9333 [======================>.......] - ETA: 4:27 - loss: 0.6885 - acc: 0.5482
7488/9333 [=======================>......] - ETA: 4:18 - loss: 0.6884 - acc: 0.5481
7552/9333 [=======================>......] - ETA: 4:09 - loss: 0.6884 - acc: 0.5478
7616/9333 [=======================>......] - ETA: 4:00 - loss: 0.6883 - acc: 0.5481
7680/9333 [=======================>......] - ETA: 3:51 - loss: 0.6881 - acc: 0.5487
7744/9333 [=======================>......] - ETA: 3:43 - loss: 0.6880 - acc: 0.5488
7808/9333 [========================>.....] - ETA: 3:34 - loss: 0.6880 - acc: 0.5488
7872/9333 [========================>.....] - ETA: 3:25 - loss: 0.6880 - acc: 0.5490
7936/9333 [========================>.....] - ETA: 3:16 - loss: 0.6880 - acc: 0.5486
8000/9333 [========================>.....] - ETA: 3:07 - loss: 0.6883 - acc: 0.5477
8064/9333 [========================>.....] - ETA: 2:58 - loss: 0.6881 - acc: 0.5486
8128/9333 [=========================>....] - ETA: 2:49 - loss: 0.6880 - acc: 0.5486
8192/9333 [=========================>....] - ETA: 2:40 - loss: 0.6880 - acc: 0.5486
8256/9333 [=========================>....] - ETA: 2:31 - loss: 0.6879 - acc: 0.5482
8320/9333 [=========================>....] - ETA: 2:22 - loss: 0.6879 - acc: 0.5481
8384/9333 [=========================>....] - ETA: 2:13 - loss: 0.6879 - acc: 0.5484
8448/9333 [==========================>...] - ETA: 2:04 - loss: 0.6878 - acc: 0.5482
8512/9333 [==========================>...] - ETA: 1:55 - loss: 0.6880 - acc: 0.5479
8576/9333 [==========================>...] - ETA: 1:46 - loss: 0.6880 - acc: 0.5479
8640/9333 [==========================>...] - ETA: 1:37 - loss: 0.6879 - acc: 0.5479
8704/9333 [==========================>...] - ETA: 1:28 - loss: 0.6880 - acc: 0.5477
8768/9333 [===========================>..] - ETA: 1:19 - loss: 0.6878 - acc: 0.5486
8832/9333 [===========================>..] - ETA: 1:10 - loss: 0.6876 - acc: 0.5489
8896/9333 [===========================>..] - ETA: 1:01 - loss: 0.6877 - acc: 0.5490
8960/9333 [===========================>..] - ETA: 52s - loss: 0.6875 - acc: 0.5494 
9024/9333 [============================>.] - ETA: 43s - loss: 0.6874 - acc: 0.5499
9088/9333 [============================>.] - ETA: 34s - loss: 0.6873 - acc: 0.5501
9152/9333 [============================>.] - ETA: 25s - loss: 0.6873 - acc: 0.5497
9216/9333 [============================>.] - ETA: 16s - loss: 0.6873 - acc: 0.5497
9280/9333 [============================>.] - ETA: 7s - loss: 0.6871 - acc: 0.5504 
9333/9333 [==============================] - 1371s 147ms/step - loss: 0.6869 - acc: 0.5505 - val_loss: 0.6902 - val_acc: 0.5391

Epoch 00005: val_acc did not improve from 0.55256
Epoch 6/10

  64/9333 [..............................] - ETA: 24:42 - loss: 0.6892 - acc: 0.6094
 128/9333 [..............................] - ETA: 24:00 - loss: 0.6955 - acc: 0.5391
 192/9333 [..............................] - ETA: 23:18 - loss: 0.6905 - acc: 0.5469
 256/9333 [..............................] - ETA: 23:01 - loss: 0.6878 - acc: 0.5508
 320/9333 [>.............................] - ETA: 23:20 - loss: 0.6993 - acc: 0.5312
 384/9333 [>.............................] - ETA: 22:40 - loss: 0.6970 - acc: 0.5391
 448/9333 [>.............................] - ETA: 22:14 - loss: 0.6943 - acc: 0.5335
 512/9333 [>.............................] - ETA: 21:48 - loss: 0.6935 - acc: 0.5312
 576/9333 [>.............................] - ETA: 21:36 - loss: 0.6941 - acc: 0.5243
 640/9333 [=>............................] - ETA: 21:19 - loss: 0.6928 - acc: 0.5281
 704/9333 [=>............................] - ETA: 20:52 - loss: 0.6928 - acc: 0.5298
 768/9333 [=>............................] - ETA: 20:31 - loss: 0.6908 - acc: 0.5391
 832/9333 [=>............................] - ETA: 20:28 - loss: 0.6904 - acc: 0.5397
 896/9333 [=>............................] - ETA: 20:10 - loss: 0.6910 - acc: 0.5402
 960/9333 [==>...........................] - ETA: 20:01 - loss: 0.6922 - acc: 0.5323
1024/9333 [==>...........................] - ETA: 19:55 - loss: 0.6919 - acc: 0.5361
1088/9333 [==>...........................] - ETA: 19:44 - loss: 0.6928 - acc: 0.5349
1152/9333 [==>...........................] - ETA: 19:29 - loss: 0.6930 - acc: 0.5365
1216/9333 [==>...........................] - ETA: 19:28 - loss: 0.6928 - acc: 0.5378
1280/9333 [===>..........................] - ETA: 19:19 - loss: 0.6916 - acc: 0.5406
1344/9333 [===>..........................] - ETA: 19:14 - loss: 0.6928 - acc: 0.5365
1408/9333 [===>..........................] - ETA: 19:09 - loss: 0.6913 - acc: 0.5405
1472/9333 [===>..........................] - ETA: 19:05 - loss: 0.6905 - acc: 0.5414
1536/9333 [===>..........................] - ETA: 18:58 - loss: 0.6900 - acc: 0.5449
1600/9333 [====>.........................] - ETA: 18:51 - loss: 0.6889 - acc: 0.5494
1664/9333 [====>.........................] - ETA: 18:42 - loss: 0.6900 - acc: 0.5475
1728/9333 [====>.........................] - ETA: 18:33 - loss: 0.6897 - acc: 0.5498
1792/9333 [====>.........................] - ETA: 18:25 - loss: 0.6892 - acc: 0.5485
1856/9333 [====>.........................] - ETA: 18:19 - loss: 0.6896 - acc: 0.5496
1920/9333 [=====>........................] - ETA: 18:08 - loss: 0.6894 - acc: 0.5510
1984/9333 [=====>........................] - ETA: 18:01 - loss: 0.6898 - acc: 0.5479
2048/9333 [=====>........................] - ETA: 17:54 - loss: 0.6903 - acc: 0.5464
2112/9333 [=====>........................] - ETA: 17:49 - loss: 0.6901 - acc: 0.5464
2176/9333 [=====>........................] - ETA: 17:38 - loss: 0.6904 - acc: 0.5464
2240/9333 [======>.......................] - ETA: 17:27 - loss: 0.6905 - acc: 0.5451
2304/9333 [======>.......................] - ETA: 17:20 - loss: 0.6905 - acc: 0.5443
2368/9333 [======>.......................] - ETA: 17:09 - loss: 0.6906 - acc: 0.5435
2432/9333 [======>.......................] - ETA: 17:02 - loss: 0.6900 - acc: 0.5444
2496/9333 [=======>......................] - ETA: 16:56 - loss: 0.6893 - acc: 0.5469
2560/9333 [=======>......................] - ETA: 16:45 - loss: 0.6891 - acc: 0.5477
2624/9333 [=======>......................] - ETA: 16:33 - loss: 0.6890 - acc: 0.5457
2688/9333 [=======>......................] - ETA: 16:24 - loss: 0.6886 - acc: 0.5484
2752/9333 [=======>......................] - ETA: 16:14 - loss: 0.6886 - acc: 0.5501
2816/9333 [========>.....................] - ETA: 16:01 - loss: 0.6889 - acc: 0.5479
2880/9333 [========>.....................] - ETA: 15:50 - loss: 0.6883 - acc: 0.5486
2944/9333 [========>.....................] - ETA: 15:40 - loss: 0.6894 - acc: 0.5455
3008/9333 [========>.....................] - ETA: 15:29 - loss: 0.6901 - acc: 0.5429
3072/9333 [========>.....................] - ETA: 15:17 - loss: 0.6895 - acc: 0.5439
3136/9333 [=========>....................] - ETA: 15:08 - loss: 0.6891 - acc: 0.5453
3200/9333 [=========>....................] - ETA: 14:59 - loss: 0.6893 - acc: 0.5444
3264/9333 [=========>....................] - ETA: 14:47 - loss: 0.6894 - acc: 0.5444
3328/9333 [=========>....................] - ETA: 14:36 - loss: 0.6893 - acc: 0.5436
3392/9333 [=========>....................] - ETA: 14:26 - loss: 0.6889 - acc: 0.5451
3456/9333 [==========>...................] - ETA: 14:16 - loss: 0.6886 - acc: 0.5460
3520/9333 [==========>...................] - ETA: 14:05 - loss: 0.6881 - acc: 0.5477
3584/9333 [==========>...................] - ETA: 13:56 - loss: 0.6878 - acc: 0.5491
3648/9333 [==========>...................] - ETA: 13:47 - loss: 0.6881 - acc: 0.5488
3712/9333 [==========>...................] - ETA: 13:40 - loss: 0.6875 - acc: 0.5512
3776/9333 [===========>..................] - ETA: 13:30 - loss: 0.6877 - acc: 0.5506
3840/9333 [===========>..................] - ETA: 13:21 - loss: 0.6871 - acc: 0.5518
3904/9333 [===========>..................] - ETA: 13:12 - loss: 0.6871 - acc: 0.5510
3968/9333 [===========>..................] - ETA: 13:02 - loss: 0.6878 - acc: 0.5494
4032/9333 [===========>..................] - ETA: 12:53 - loss: 0.6876 - acc: 0.5499
4096/9333 [============>.................] - ETA: 12:44 - loss: 0.6876 - acc: 0.5498
4160/9333 [============>.................] - ETA: 12:33 - loss: 0.6878 - acc: 0.5481
4224/9333 [============>.................] - ETA: 12:24 - loss: 0.6880 - acc: 0.5473
4288/9333 [============>.................] - ETA: 12:13 - loss: 0.6878 - acc: 0.5485
4352/9333 [============>.................] - ETA: 12:03 - loss: 0.6880 - acc: 0.5485
4416/9333 [=============>................] - ETA: 11:53 - loss: 0.6879 - acc: 0.5491
4480/9333 [=============>................] - ETA: 11:43 - loss: 0.6876 - acc: 0.5511
4544/9333 [=============>................] - ETA: 11:34 - loss: 0.6873 - acc: 0.5515
4608/9333 [=============>................] - ETA: 11:24 - loss: 0.6868 - acc: 0.5521
4672/9333 [==============>...............] - ETA: 11:16 - loss: 0.6863 - acc: 0.5535
4736/9333 [==============>...............] - ETA: 11:06 - loss: 0.6862 - acc: 0.5536
4800/9333 [==============>...............] - ETA: 10:56 - loss: 0.6858 - acc: 0.5544
4864/9333 [==============>...............] - ETA: 10:47 - loss: 0.6859 - acc: 0.5545
4928/9333 [==============>...............] - ETA: 10:39 - loss: 0.6863 - acc: 0.5544
4992/9333 [===============>..............] - ETA: 10:29 - loss: 0.6862 - acc: 0.5551
5056/9333 [===============>..............] - ETA: 10:20 - loss: 0.6853 - acc: 0.5576
5120/9333 [===============>..............] - ETA: 10:10 - loss: 0.6851 - acc: 0.5584
5184/9333 [===============>..............] - ETA: 10:01 - loss: 0.6851 - acc: 0.5586
5248/9333 [===============>..............] - ETA: 9:51 - loss: 0.6849 - acc: 0.5595 
5312/9333 [================>.............] - ETA: 9:43 - loss: 0.6852 - acc: 0.5582
5376/9333 [================>.............] - ETA: 9:34 - loss: 0.6843 - acc: 0.5597
5440/9333 [================>.............] - ETA: 9:24 - loss: 0.6843 - acc: 0.5596
5504/9333 [================>.............] - ETA: 9:14 - loss: 0.6845 - acc: 0.5596
5568/9333 [================>.............] - ETA: 9:05 - loss: 0.6846 - acc: 0.5591
5632/9333 [=================>............] - ETA: 8:55 - loss: 0.6849 - acc: 0.5593
5696/9333 [=================>............] - ETA: 8:46 - loss: 0.6854 - acc: 0.5588
5760/9333 [=================>............] - ETA: 8:37 - loss: 0.6852 - acc: 0.5594
5824/9333 [=================>............] - ETA: 8:28 - loss: 0.6856 - acc: 0.5577
5888/9333 [=================>............] - ETA: 8:18 - loss: 0.6854 - acc: 0.5583
5952/9333 [==================>...........] - ETA: 8:09 - loss: 0.6854 - acc: 0.5585
6016/9333 [==================>...........] - ETA: 7:59 - loss: 0.6853 - acc: 0.5588
6080/9333 [==================>...........] - ETA: 7:50 - loss: 0.6850 - acc: 0.5595
6144/9333 [==================>...........] - ETA: 7:41 - loss: 0.6852 - acc: 0.5592
6208/9333 [==================>...........] - ETA: 7:31 - loss: 0.6853 - acc: 0.5590
6272/9333 [===================>..........] - ETA: 7:21 - loss: 0.6857 - acc: 0.5580
6336/9333 [===================>..........] - ETA: 7:12 - loss: 0.6855 - acc: 0.5584
6400/9333 [===================>..........] - ETA: 7:03 - loss: 0.6854 - acc: 0.5592
6464/9333 [===================>..........] - ETA: 6:54 - loss: 0.6853 - acc: 0.5593
6528/9333 [===================>..........] - ETA: 6:44 - loss: 0.6857 - acc: 0.5587
6592/9333 [====================>.........] - ETA: 6:35 - loss: 0.6857 - acc: 0.5586
6656/9333 [====================>.........] - ETA: 6:26 - loss: 0.6856 - acc: 0.5586
6720/9333 [====================>.........] - ETA: 6:17 - loss: 0.6856 - acc: 0.5589
6784/9333 [====================>.........] - ETA: 6:07 - loss: 0.6854 - acc: 0.5591
6848/9333 [=====================>........] - ETA: 5:58 - loss: 0.6851 - acc: 0.5597
6912/9333 [=====================>........] - ETA: 5:49 - loss: 0.6850 - acc: 0.5600
6976/9333 [=====================>........] - ETA: 5:40 - loss: 0.6852 - acc: 0.5596
7040/9333 [=====================>........] - ETA: 5:30 - loss: 0.6853 - acc: 0.5594
7104/9333 [=====================>........] - ETA: 5:21 - loss: 0.6855 - acc: 0.5591
7168/9333 [======================>.......] - ETA: 5:12 - loss: 0.6857 - acc: 0.5583
7232/9333 [======================>.......] - ETA: 5:03 - loss: 0.6857 - acc: 0.5581
7296/9333 [======================>.......] - ETA: 4:53 - loss: 0.6856 - acc: 0.5574
7360/9333 [======================>.......] - ETA: 4:44 - loss: 0.6855 - acc: 0.5576
7424/9333 [======================>.......] - ETA: 4:35 - loss: 0.6854 - acc: 0.5579
7488/9333 [=======================>......] - ETA: 4:25 - loss: 0.6854 - acc: 0.5577
7552/9333 [=======================>......] - ETA: 4:16 - loss: 0.6851 - acc: 0.5587
7616/9333 [=======================>......] - ETA: 4:06 - loss: 0.6848 - acc: 0.5591
7680/9333 [=======================>......] - ETA: 3:57 - loss: 0.6847 - acc: 0.5587
7744/9333 [=======================>......] - ETA: 3:48 - loss: 0.6847 - acc: 0.5594
7808/9333 [========================>.....] - ETA: 3:39 - loss: 0.6848 - acc: 0.5593
7872/9333 [========================>.....] - ETA: 3:30 - loss: 0.6852 - acc: 0.5584
7936/9333 [========================>.....] - ETA: 3:20 - loss: 0.6850 - acc: 0.5583
8000/9333 [========================>.....] - ETA: 3:11 - loss: 0.6850 - acc: 0.5585
8064/9333 [========================>.....] - ETA: 3:02 - loss: 0.6849 - acc: 0.5588
8128/9333 [=========================>....] - ETA: 2:52 - loss: 0.6851 - acc: 0.5582
8192/9333 [=========================>....] - ETA: 2:44 - loss: 0.6849 - acc: 0.5588
8256/9333 [=========================>....] - ETA: 2:34 - loss: 0.6850 - acc: 0.5587
8320/9333 [=========================>....] - ETA: 2:25 - loss: 0.6849 - acc: 0.5593
8384/9333 [=========================>....] - ETA: 2:16 - loss: 0.6847 - acc: 0.5599
8448/9333 [==========================>...] - ETA: 2:07 - loss: 0.6849 - acc: 0.5598
8512/9333 [==========================>...] - ETA: 1:58 - loss: 0.6848 - acc: 0.5599
8576/9333 [==========================>...] - ETA: 1:48 - loss: 0.6850 - acc: 0.5590
8640/9333 [==========================>...] - ETA: 1:39 - loss: 0.6848 - acc: 0.5598
8704/9333 [==========================>...] - ETA: 1:30 - loss: 0.6847 - acc: 0.5597
8768/9333 [===========================>..] - ETA: 1:21 - loss: 0.6850 - acc: 0.5586
8832/9333 [===========================>..] - ETA: 1:11 - loss: 0.6849 - acc: 0.5591
8896/9333 [===========================>..] - ETA: 1:02 - loss: 0.6849 - acc: 0.5590
8960/9333 [===========================>..] - ETA: 53s - loss: 0.6846 - acc: 0.5599 
9024/9333 [============================>.] - ETA: 44s - loss: 0.6847 - acc: 0.5601
9088/9333 [============================>.] - ETA: 35s - loss: 0.6844 - acc: 0.5608
9152/9333 [============================>.] - ETA: 26s - loss: 0.6844 - acc: 0.5609
9216/9333 [============================>.] - ETA: 16s - loss: 0.6845 - acc: 0.5604
9280/9333 [============================>.] - ETA: 7s - loss: 0.6845 - acc: 0.5601 
9333/9333 [==============================] - 1390s 149ms/step - loss: 0.6846 - acc: 0.5598 - val_loss: 0.6880 - val_acc: 0.5256

Epoch 00006: val_acc did not improve from 0.55256
Epoch 7/10

  64/9333 [..............................] - ETA: 22:43 - loss: 0.6790 - acc: 0.5000
 128/9333 [..............................] - ETA: 24:31 - loss: 0.6765 - acc: 0.5391
 192/9333 [..............................] - ETA: 23:26 - loss: 0.6672 - acc: 0.5781
 256/9333 [..............................] - ETA: 23:19 - loss: 0.6735 - acc: 0.5664
 320/9333 [>.............................] - ETA: 22:23 - loss: 0.6699 - acc: 0.5875
 384/9333 [>.............................] - ETA: 21:54 - loss: 0.6735 - acc: 0.5651
 448/9333 [>.............................] - ETA: 21:25 - loss: 0.6732 - acc: 0.5670
 512/9333 [>.............................] - ETA: 21:02 - loss: 0.6727 - acc: 0.5820
 576/9333 [>.............................] - ETA: 20:54 - loss: 0.6748 - acc: 0.5781
 640/9333 [=>............................] - ETA: 20:48 - loss: 0.6755 - acc: 0.5781
 704/9333 [=>............................] - ETA: 20:32 - loss: 0.6737 - acc: 0.5795
 768/9333 [=>............................] - ETA: 20:17 - loss: 0.6741 - acc: 0.5807
 832/9333 [=>............................] - ETA: 20:15 - loss: 0.6750 - acc: 0.5745
 896/9333 [=>............................] - ETA: 20:09 - loss: 0.6756 - acc: 0.5770
 960/9333 [==>...........................] - ETA: 19:57 - loss: 0.6754 - acc: 0.5750
1024/9333 [==>...........................] - ETA: 19:37 - loss: 0.6759 - acc: 0.5732
1088/9333 [==>...........................] - ETA: 19:13 - loss: 0.6778 - acc: 0.5680
1152/9333 [==>...........................] - ETA: 19:00 - loss: 0.6774 - acc: 0.5677
1216/9333 [==>...........................] - ETA: 18:54 - loss: 0.6769 - acc: 0.5699
1280/9333 [===>..........................] - ETA: 18:51 - loss: 0.6780 - acc: 0.5711
1344/9333 [===>..........................] - ETA: 18:37 - loss: 0.6771 - acc: 0.5707
1408/9333 [===>..........................] - ETA: 18:16 - loss: 0.6766 - acc: 0.5724
1472/9333 [===>..........................] - ETA: 18:06 - loss: 0.6783 - acc: 0.5727
1536/9333 [===>..........................] - ETA: 17:57 - loss: 0.6784 - acc: 0.5729
1600/9333 [====>.........................] - ETA: 17:44 - loss: 0.6776 - acc: 0.5744
1664/9333 [====>.........................] - ETA: 17:32 - loss: 0.6783 - acc: 0.5727
1728/9333 [====>.........................] - ETA: 17:28 - loss: 0.6798 - acc: 0.5706
1792/9333 [====>.........................] - ETA: 17:22 - loss: 0.6805 - acc: 0.5714
1856/9333 [====>.........................] - ETA: 17:11 - loss: 0.6803 - acc: 0.5706
1920/9333 [=====>........................] - ETA: 17:03 - loss: 0.6796 - acc: 0.5734
1984/9333 [=====>........................] - ETA: 16:51 - loss: 0.6790 - acc: 0.5751
2048/9333 [=====>........................] - ETA: 16:41 - loss: 0.6792 - acc: 0.5747
2112/9333 [=====>........................] - ETA: 16:28 - loss: 0.6800 - acc: 0.5734
2176/9333 [=====>........................] - ETA: 16:16 - loss: 0.6801 - acc: 0.5717
2240/9333 [======>.......................] - ETA: 16:08 - loss: 0.6811 - acc: 0.5696
2304/9333 [======>.......................] - ETA: 16:01 - loss: 0.6822 - acc: 0.5664
2368/9333 [======>.......................] - ETA: 15:48 - loss: 0.6812 - acc: 0.5676
2432/9333 [======>.......................] - ETA: 15:38 - loss: 0.6816 - acc: 0.5650
2496/9333 [=======>......................] - ETA: 15:31 - loss: 0.6812 - acc: 0.5645
2560/9333 [=======>......................] - ETA: 15:24 - loss: 0.6828 - acc: 0.5590
2624/9333 [=======>......................] - ETA: 15:14 - loss: 0.6827 - acc: 0.5598
2688/9333 [=======>......................] - ETA: 15:04 - loss: 0.6832 - acc: 0.5592
2752/9333 [=======>......................] - ETA: 14:54 - loss: 0.6834 - acc: 0.5581
2816/9333 [========>.....................] - ETA: 14:45 - loss: 0.6830 - acc: 0.5572
2880/9333 [========>.....................] - ETA: 14:41 - loss: 0.6832 - acc: 0.5559
2944/9333 [========>.....................] - ETA: 14:30 - loss: 0.6829 - acc: 0.5564
3008/9333 [========>.....................] - ETA: 14:22 - loss: 0.6826 - acc: 0.5575
3072/9333 [========>.....................] - ETA: 14:13 - loss: 0.6822 - acc: 0.5579
3136/9333 [=========>....................] - ETA: 14:03 - loss: 0.6828 - acc: 0.5574
3200/9333 [=========>....................] - ETA: 13:53 - loss: 0.6826 - acc: 0.5572
3264/9333 [=========>....................] - ETA: 13:47 - loss: 0.6822 - acc: 0.5597
3328/9333 [=========>....................] - ETA: 13:36 - loss: 0.6818 - acc: 0.5604
3392/9333 [=========>....................] - ETA: 13:27 - loss: 0.6822 - acc: 0.5578
3456/9333 [==========>...................] - ETA: 13:18 - loss: 0.6821 - acc: 0.5573
3520/9333 [==========>...................] - ETA: 13:10 - loss: 0.6820 - acc: 0.5577
3584/9333 [==========>...................] - ETA: 13:03 - loss: 0.6831 - acc: 0.5552
3648/9333 [==========>...................] - ETA: 12:54 - loss: 0.6827 - acc: 0.5554
3712/9333 [==========>...................] - ETA: 12:45 - loss: 0.6827 - acc: 0.5558
3776/9333 [===========>..................] - ETA: 12:35 - loss: 0.6823 - acc: 0.5567
3840/9333 [===========>..................] - ETA: 12:26 - loss: 0.6827 - acc: 0.5555
3904/9333 [===========>..................] - ETA: 12:18 - loss: 0.6828 - acc: 0.5548
3968/9333 [===========>..................] - ETA: 12:09 - loss: 0.6827 - acc: 0.5547
4032/9333 [===========>..................] - ETA: 12:01 - loss: 0.6824 - acc: 0.5558
4096/9333 [============>.................] - ETA: 11:54 - loss: 0.6823 - acc: 0.5557
4160/9333 [============>.................] - ETA: 11:46 - loss: 0.6816 - acc: 0.5575
4224/9333 [============>.................] - ETA: 11:37 - loss: 0.6815 - acc: 0.5575
4288/9333 [============>.................] - ETA: 11:29 - loss: 0.6812 - acc: 0.5588
4352/9333 [============>.................] - ETA: 11:19 - loss: 0.6810 - acc: 0.5588
4416/9333 [=============>................] - ETA: 11:10 - loss: 0.6803 - acc: 0.5602
4480/9333 [=============>................] - ETA: 11:01 - loss: 0.6799 - acc: 0.5616
4544/9333 [=============>................] - ETA: 10:53 - loss: 0.6800 - acc: 0.5614
4608/9333 [=============>................] - ETA: 10:45 - loss: 0.6802 - acc: 0.5616
4672/9333 [==============>...............] - ETA: 10:36 - loss: 0.6801 - acc: 0.5612
4736/9333 [==============>...............] - ETA: 10:27 - loss: 0.6794 - acc: 0.5625
4800/9333 [==============>...............] - ETA: 10:20 - loss: 0.6798 - acc: 0.5617
4864/9333 [==============>...............] - ETA: 10:10 - loss: 0.6803 - acc: 0.5606
4928/9333 [==============>...............] - ETA: 10:02 - loss: 0.6798 - acc: 0.5609
4992/9333 [===============>..............] - ETA: 9:54 - loss: 0.6799 - acc: 0.5607 
5056/9333 [===============>..............] - ETA: 9:46 - loss: 0.6796 - acc: 0.5611
5120/9333 [===============>..............] - ETA: 9:36 - loss: 0.6794 - acc: 0.5617
5184/9333 [===============>..............] - ETA: 9:27 - loss: 0.6801 - acc: 0.5602
5248/9333 [===============>..............] - ETA: 9:20 - loss: 0.6797 - acc: 0.5608
5312/9333 [================>.............] - ETA: 9:12 - loss: 0.6802 - acc: 0.5599
5376/9333 [================>.............] - ETA: 9:03 - loss: 0.6805 - acc: 0.5599
5440/9333 [================>.............] - ETA: 8:54 - loss: 0.6804 - acc: 0.5588
5504/9333 [================>.............] - ETA: 8:46 - loss: 0.6804 - acc: 0.5590
5568/9333 [================>.............] - ETA: 8:37 - loss: 0.6801 - acc: 0.5600
5632/9333 [=================>............] - ETA: 8:27 - loss: 0.6805 - acc: 0.5586
5696/9333 [=================>............] - ETA: 8:18 - loss: 0.6808 - acc: 0.5585
5760/9333 [=================>............] - ETA: 8:09 - loss: 0.6809 - acc: 0.5578
5824/9333 [=================>............] - ETA: 8:00 - loss: 0.6808 - acc: 0.5573
5888/9333 [=================>............] - ETA: 7:51 - loss: 0.6810 - acc: 0.5571
5952/9333 [==================>...........] - ETA: 7:41 - loss: 0.6814 - acc: 0.5568
6016/9333 [==================>...........] - ETA: 7:34 - loss: 0.6814 - acc: 0.5565
6080/9333 [==================>...........] - ETA: 7:25 - loss: 0.6811 - acc: 0.5566
6144/9333 [==================>...........] - ETA: 7:16 - loss: 0.6813 - acc: 0.5560
6208/9333 [==================>...........] - ETA: 7:07 - loss: 0.6814 - acc: 0.5561
6272/9333 [===================>..........] - ETA: 6:58 - loss: 0.6816 - acc: 0.5560
6336/9333 [===================>..........] - ETA: 6:50 - loss: 0.6819 - acc: 0.5556
6400/9333 [===================>..........] - ETA: 6:41 - loss: 0.6821 - acc: 0.5550
6464/9333 [===================>..........] - ETA: 6:32 - loss: 0.6824 - acc: 0.5545
6528/9333 [===================>..........] - ETA: 6:24 - loss: 0.6825 - acc: 0.5542
6592/9333 [====================>.........] - ETA: 6:15 - loss: 0.6827 - acc: 0.5542
6656/9333 [====================>.........] - ETA: 6:06 - loss: 0.6828 - acc: 0.5538
6720/9333 [====================>.........] - ETA: 5:57 - loss: 0.6827 - acc: 0.5534
6784/9333 [====================>.........] - ETA: 5:48 - loss: 0.6828 - acc: 0.5535
6848/9333 [=====================>........] - ETA: 5:40 - loss: 0.6829 - acc: 0.5533
6912/9333 [=====================>........] - ETA: 5:31 - loss: 0.6827 - acc: 0.5535
6976/9333 [=====================>........] - ETA: 5:22 - loss: 0.6824 - acc: 0.5542
7040/9333 [=====================>........] - ETA: 5:13 - loss: 0.6828 - acc: 0.5526
7104/9333 [=====================>........] - ETA: 5:05 - loss: 0.6828 - acc: 0.5522
7168/9333 [======================>.......] - ETA: 4:56 - loss: 0.6830 - acc: 0.5518
7232/9333 [======================>.......] - ETA: 4:47 - loss: 0.6831 - acc: 0.5514
7296/9333 [======================>.......] - ETA: 4:38 - loss: 0.6832 - acc: 0.5517
7360/9333 [======================>.......] - ETA: 4:29 - loss: 0.6835 - acc: 0.5503
7424/9333 [======================>.......] - ETA: 4:20 - loss: 0.6836 - acc: 0.5500
7488/9333 [=======================>......] - ETA: 4:12 - loss: 0.6835 - acc: 0.5503
7552/9333 [=======================>......] - ETA: 4:03 - loss: 0.6834 - acc: 0.5512
7616/9333 [=======================>......] - ETA: 3:54 - loss: 0.6833 - acc: 0.5515
7680/9333 [=======================>......] - ETA: 3:45 - loss: 0.6832 - acc: 0.5521
7744/9333 [=======================>......] - ETA: 3:37 - loss: 0.6834 - acc: 0.5517
7808/9333 [========================>.....] - ETA: 3:28 - loss: 0.6831 - acc: 0.5529
7872/9333 [========================>.....] - ETA: 3:19 - loss: 0.6832 - acc: 0.5532
7936/9333 [========================>.....] - ETA: 3:10 - loss: 0.6832 - acc: 0.5529
8000/9333 [========================>.....] - ETA: 3:01 - loss: 0.6830 - acc: 0.5534
8064/9333 [========================>.....] - ETA: 2:53 - loss: 0.6830 - acc: 0.5533
8128/9333 [=========================>....] - ETA: 2:44 - loss: 0.6828 - acc: 0.5533
8192/9333 [=========================>....] - ETA: 2:35 - loss: 0.6830 - acc: 0.5530
8256/9333 [=========================>....] - ETA: 2:27 - loss: 0.6828 - acc: 0.5534
8320/9333 [=========================>....] - ETA: 2:18 - loss: 0.6829 - acc: 0.5534
8384/9333 [=========================>....] - ETA: 2:09 - loss: 0.6826 - acc: 0.5540
8448/9333 [==========================>...] - ETA: 2:00 - loss: 0.6823 - acc: 0.5547
8512/9333 [==========================>...] - ETA: 1:52 - loss: 0.6823 - acc: 0.5549
8576/9333 [==========================>...] - ETA: 1:43 - loss: 0.6825 - acc: 0.5545
8640/9333 [==========================>...] - ETA: 1:34 - loss: 0.6825 - acc: 0.5541
8704/9333 [==========================>...] - ETA: 1:25 - loss: 0.6826 - acc: 0.5541
8768/9333 [===========================>..] - ETA: 1:17 - loss: 0.6828 - acc: 0.5535
8832/9333 [===========================>..] - ETA: 1:08 - loss: 0.6833 - acc: 0.5530
8896/9333 [===========================>..] - ETA: 59s - loss: 0.6834 - acc: 0.5525 
8960/9333 [===========================>..] - ETA: 50s - loss: 0.6837 - acc: 0.5519
9024/9333 [============================>.] - ETA: 42s - loss: 0.6838 - acc: 0.5516
9088/9333 [============================>.] - ETA: 33s - loss: 0.6839 - acc: 0.5511
9152/9333 [============================>.] - ETA: 24s - loss: 0.6839 - acc: 0.5512
9216/9333 [============================>.] - ETA: 15s - loss: 0.6836 - acc: 0.5515
9280/9333 [============================>.] - ETA: 7s - loss: 0.6837 - acc: 0.5508 
9333/9333 [==============================] - 1325s 142ms/step - loss: 0.6837 - acc: 0.5507 - val_loss: 0.6868 - val_acc: 0.5207

Epoch 00007: val_acc did not improve from 0.55256
Epoch 8/10

  64/9333 [..............................] - ETA: 24:31 - loss: 0.7036 - acc: 0.5312
 128/9333 [..............................] - ETA: 21:40 - loss: 0.6877 - acc: 0.5625
 192/9333 [..............................] - ETA: 20:32 - loss: 0.6829 - acc: 0.5781
 256/9333 [..............................] - ETA: 20:17 - loss: 0.6885 - acc: 0.5625
 320/9333 [>.............................] - ETA: 19:39 - loss: 0.6901 - acc: 0.5594
 384/9333 [>.............................] - ETA: 19:41 - loss: 0.6892 - acc: 0.5573
 448/9333 [>.............................] - ETA: 19:23 - loss: 0.6891 - acc: 0.5513
 512/9333 [>.............................] - ETA: 18:58 - loss: 0.6921 - acc: 0.5469
 576/9333 [>.............................] - ETA: 18:51 - loss: 0.6899 - acc: 0.5503
 640/9333 [=>............................] - ETA: 18:44 - loss: 0.6913 - acc: 0.5500
 704/9333 [=>............................] - ETA: 18:37 - loss: 0.6920 - acc: 0.5426
 768/9333 [=>............................] - ETA: 18:27 - loss: 0.6914 - acc: 0.5443
 832/9333 [=>............................] - ETA: 18:19 - loss: 0.6931 - acc: 0.5421
 896/9333 [=>............................] - ETA: 18:15 - loss: 0.6921 - acc: 0.5458
 960/9333 [==>...........................] - ETA: 18:11 - loss: 0.6913 - acc: 0.5448
1024/9333 [==>...........................] - ETA: 18:04 - loss: 0.6912 - acc: 0.5449
1088/9333 [==>...........................] - ETA: 17:55 - loss: 0.6893 - acc: 0.5496
1152/9333 [==>...........................] - ETA: 17:44 - loss: 0.6882 - acc: 0.5495
1216/9333 [==>...........................] - ETA: 17:31 - loss: 0.6877 - acc: 0.5526
1280/9333 [===>..........................] - ETA: 17:17 - loss: 0.6877 - acc: 0.5539
1344/9333 [===>..........................] - ETA: 17:12 - loss: 0.6877 - acc: 0.5528
1408/9333 [===>..........................] - ETA: 17:06 - loss: 0.6888 - acc: 0.5497
1472/9333 [===>..........................] - ETA: 16:58 - loss: 0.6883 - acc: 0.5496
1536/9333 [===>..........................] - ETA: 16:52 - loss: 0.6871 - acc: 0.5553
1600/9333 [====>.........................] - ETA: 16:42 - loss: 0.6874 - acc: 0.5550
1664/9333 [====>.........................] - ETA: 16:33 - loss: 0.6894 - acc: 0.5517
1728/9333 [====>.........................] - ETA: 16:25 - loss: 0.6885 - acc: 0.5532
1792/9333 [====>.........................] - ETA: 16:18 - loss: 0.6879 - acc: 0.5547
1856/9333 [====>.........................] - ETA: 16:11 - loss: 0.6876 - acc: 0.5539
1920/9333 [=====>........................] - ETA: 16:05 - loss: 0.6871 - acc: 0.5557
1984/9333 [=====>........................] - ETA: 15:56 - loss: 0.6876 - acc: 0.5549
2048/9333 [=====>........................] - ETA: 15:47 - loss: 0.6866 - acc: 0.5571
2112/9333 [=====>........................] - ETA: 15:40 - loss: 0.6854 - acc: 0.5606
2176/9333 [=====>........................] - ETA: 15:32 - loss: 0.6859 - acc: 0.5607
2240/9333 [======>.......................] - ETA: 15:23 - loss: 0.6852 - acc: 0.5621
2304/9333 [======>.......................] - ETA: 15:12 - loss: 0.6844 - acc: 0.5629
2368/9333 [======>.......................] - ETA: 15:09 - loss: 0.6850 - acc: 0.5604
2432/9333 [======>.......................] - ETA: 15:03 - loss: 0.6847 - acc: 0.5609
2496/9333 [=======>......................] - ETA: 14:56 - loss: 0.6845 - acc: 0.5617
2560/9333 [=======>......................] - ETA: 14:48 - loss: 0.6839 - acc: 0.5637
2624/9333 [=======>......................] - ETA: 14:39 - loss: 0.6841 - acc: 0.5633
2688/9333 [=======>......................] - ETA: 14:29 - loss: 0.6838 - acc: 0.5651
2752/9333 [=======>......................] - ETA: 14:20 - loss: 0.6831 - acc: 0.5643
2816/9333 [========>.....................] - ETA: 14:10 - loss: 0.6837 - acc: 0.5621
2880/9333 [========>.....................] - ETA: 14:03 - loss: 0.6834 - acc: 0.5628
2944/9333 [========>.....................] - ETA: 13:52 - loss: 0.6831 - acc: 0.5635
3008/9333 [========>.....................] - ETA: 13:43 - loss: 0.6826 - acc: 0.5642
3072/9333 [========>.....................] - ETA: 13:35 - loss: 0.6823 - acc: 0.5645
3136/9333 [=========>....................] - ETA: 13:29 - loss: 0.6826 - acc: 0.5638
3200/9333 [=========>....................] - ETA: 13:19 - loss: 0.6829 - acc: 0.5637
3264/9333 [=========>....................] - ETA: 13:10 - loss: 0.6827 - acc: 0.5640
3328/9333 [=========>....................] - ETA: 13:01 - loss: 0.6832 - acc: 0.5628
3392/9333 [=========>....................] - ETA: 12:54 - loss: 0.6827 - acc: 0.5637
3456/9333 [==========>...................] - ETA: 12:47 - loss: 0.6824 - acc: 0.5645
3520/9333 [==========>...................] - ETA: 12:38 - loss: 0.6826 - acc: 0.5651
3584/9333 [==========>...................] - ETA: 12:29 - loss: 0.6829 - acc: 0.5645
3648/9333 [==========>...................] - ETA: 12:22 - loss: 0.6830 - acc: 0.5650
3712/9333 [==========>...................] - ETA: 12:14 - loss: 0.6838 - acc: 0.5628
3776/9333 [===========>..................] - ETA: 12:06 - loss: 0.6836 - acc: 0.5630
3840/9333 [===========>..................] - ETA: 11:59 - loss: 0.6836 - acc: 0.5628
3904/9333 [===========>..................] - ETA: 11:53 - loss: 0.6833 - acc: 0.5643
3968/9333 [===========>..................] - ETA: 11:45 - loss: 0.6836 - acc: 0.5630
4032/9333 [===========>..................] - ETA: 11:37 - loss: 0.6831 - acc: 0.5647
4096/9333 [============>.................] - ETA: 11:30 - loss: 0.6825 - acc: 0.5667
4160/9333 [============>.................] - ETA: 11:23 - loss: 0.6819 - acc: 0.5690
4224/9333 [============>.................] - ETA: 11:14 - loss: 0.6820 - acc: 0.5675
4288/9333 [============>.................] - ETA: 11:05 - loss: 0.6819 - acc: 0.5686
4352/9333 [============>.................] - ETA: 10:57 - loss: 0.6816 - acc: 0.5701
4416/9333 [=============>................] - ETA: 10:49 - loss: 0.6820 - acc: 0.5684
4480/9333 [=============>................] - ETA: 10:40 - loss: 0.6830 - acc: 0.5658
4544/9333 [=============>................] - ETA: 10:32 - loss: 0.6828 - acc: 0.5662
4608/9333 [=============>................] - ETA: 10:24 - loss: 0.6830 - acc: 0.5660
4672/9333 [==============>...............] - ETA: 10:17 - loss: 0.6833 - acc: 0.5644
4736/9333 [==============>...............] - ETA: 10:08 - loss: 0.6830 - acc: 0.5650
4800/9333 [==============>...............] - ETA: 10:00 - loss: 0.6832 - acc: 0.5646
4864/9333 [==============>...............] - ETA: 9:53 - loss: 0.6830 - acc: 0.5639 
4928/9333 [==============>...............] - ETA: 9:44 - loss: 0.6825 - acc: 0.5657
4992/9333 [===============>..............] - ETA: 9:35 - loss: 0.6827 - acc: 0.5663
5056/9333 [===============>..............] - ETA: 9:27 - loss: 0.6828 - acc: 0.5667
5120/9333 [===============>..............] - ETA: 9:19 - loss: 0.6829 - acc: 0.5658
5184/9333 [===============>..............] - ETA: 9:11 - loss: 0.6830 - acc: 0.5662
5248/9333 [===============>..............] - ETA: 9:03 - loss: 0.6826 - acc: 0.5667
5312/9333 [================>.............] - ETA: 8:55 - loss: 0.6823 - acc: 0.5676
5376/9333 [================>.............] - ETA: 8:47 - loss: 0.6823 - acc: 0.5677
5440/9333 [================>.............] - ETA: 8:38 - loss: 0.6820 - acc: 0.5675
5504/9333 [================>.............] - ETA: 8:30 - loss: 0.6824 - acc: 0.5660
5568/9333 [================>.............] - ETA: 8:22 - loss: 0.6823 - acc: 0.5661
5632/9333 [=================>............] - ETA: 8:13 - loss: 0.6820 - acc: 0.5668
5696/9333 [=================>............] - ETA: 8:05 - loss: 0.6817 - acc: 0.5674
5760/9333 [=================>............] - ETA: 7:57 - loss: 0.6817 - acc: 0.5677
5824/9333 [=================>............] - ETA: 7:49 - loss: 0.6817 - acc: 0.5687
5888/9333 [=================>............] - ETA: 7:40 - loss: 0.6815 - acc: 0.5691
5952/9333 [==================>...........] - ETA: 7:31 - loss: 0.6820 - acc: 0.5687
6016/9333 [==================>...........] - ETA: 7:23 - loss: 0.6818 - acc: 0.5683
6080/9333 [==================>...........] - ETA: 7:15 - loss: 0.6821 - acc: 0.5674
6144/9333 [==================>...........] - ETA: 7:07 - loss: 0.6821 - acc: 0.5662
6208/9333 [==================>...........] - ETA: 6:58 - loss: 0.6823 - acc: 0.5659
6272/9333 [===================>..........] - ETA: 6:49 - loss: 0.6820 - acc: 0.5663
6336/9333 [===================>..........] - ETA: 6:41 - loss: 0.6817 - acc: 0.5674
6400/9333 [===================>..........] - ETA: 6:32 - loss: 0.6818 - acc: 0.5673
6464/9333 [===================>..........] - ETA: 6:24 - loss: 0.6818 - acc: 0.5671
6528/9333 [===================>..........] - ETA: 6:16 - loss: 0.6818 - acc: 0.5671
6592/9333 [====================>.........] - ETA: 6:08 - loss: 0.6818 - acc: 0.5669
6656/9333 [====================>.........] - ETA: 5:59 - loss: 0.6820 - acc: 0.5666
6720/9333 [====================>.........] - ETA: 5:51 - loss: 0.6820 - acc: 0.5661
6784/9333 [====================>.........] - ETA: 5:42 - loss: 0.6821 - acc: 0.5656
6848/9333 [=====================>........] - ETA: 5:34 - loss: 0.6820 - acc: 0.5656
6912/9333 [=====================>........] - ETA: 5:25 - loss: 0.6820 - acc: 0.5654
6976/9333 [=====================>........] - ETA: 5:16 - loss: 0.6822 - acc: 0.5649
7040/9333 [=====================>........] - ETA: 5:08 - loss: 0.6823 - acc: 0.5645
7104/9333 [=====================>........] - ETA: 4:59 - loss: 0.6821 - acc: 0.5650
7168/9333 [======================>.......] - ETA: 4:51 - loss: 0.6820 - acc: 0.5654
7232/9333 [======================>.......] - ETA: 4:42 - loss: 0.6817 - acc: 0.5658
7296/9333 [======================>.......] - ETA: 4:33 - loss: 0.6817 - acc: 0.5658
7360/9333 [======================>.......] - ETA: 4:25 - loss: 0.6816 - acc: 0.5666
7424/9333 [======================>.......] - ETA: 4:16 - loss: 0.6815 - acc: 0.5664
7488/9333 [=======================>......] - ETA: 4:07 - loss: 0.6814 - acc: 0.5668
7552/9333 [=======================>......] - ETA: 3:59 - loss: 0.6813 - acc: 0.5670
7616/9333 [=======================>......] - ETA: 3:50 - loss: 0.6815 - acc: 0.5663
7680/9333 [=======================>......] - ETA: 3:41 - loss: 0.6812 - acc: 0.5668
7744/9333 [=======================>......] - ETA: 3:33 - loss: 0.6812 - acc: 0.5675
7808/9333 [========================>.....] - ETA: 3:24 - loss: 0.6808 - acc: 0.5681
7872/9333 [========================>.....] - ETA: 3:15 - loss: 0.6808 - acc: 0.5683
7936/9333 [========================>.....] - ETA: 3:07 - loss: 0.6809 - acc: 0.5677
8000/9333 [========================>.....] - ETA: 2:58 - loss: 0.6809 - acc: 0.5681
8064/9333 [========================>.....] - ETA: 2:50 - loss: 0.6809 - acc: 0.5678
8128/9333 [=========================>....] - ETA: 2:41 - loss: 0.6808 - acc: 0.5677
8192/9333 [=========================>....] - ETA: 2:32 - loss: 0.6813 - acc: 0.5670
8256/9333 [=========================>....] - ETA: 2:24 - loss: 0.6816 - acc: 0.5664
8320/9333 [=========================>....] - ETA: 2:15 - loss: 0.6816 - acc: 0.5662
8384/9333 [=========================>....] - ETA: 2:07 - loss: 0.6817 - acc: 0.5660
8448/9333 [==========================>...] - ETA: 1:58 - loss: 0.6818 - acc: 0.5659
8512/9333 [==========================>...] - ETA: 1:50 - loss: 0.6816 - acc: 0.5665
8576/9333 [==========================>...] - ETA: 1:41 - loss: 0.6816 - acc: 0.5670
8640/9333 [==========================>...] - ETA: 1:33 - loss: 0.6814 - acc: 0.5676
8704/9333 [==========================>...] - ETA: 1:24 - loss: 0.6816 - acc: 0.5669
8768/9333 [===========================>..] - ETA: 1:15 - loss: 0.6817 - acc: 0.5664
8832/9333 [===========================>..] - ETA: 1:07 - loss: 0.6820 - acc: 0.5653
8896/9333 [===========================>..] - ETA: 58s - loss: 0.6821 - acc: 0.5654 
8960/9333 [===========================>..] - ETA: 50s - loss: 0.6822 - acc: 0.5647
9024/9333 [============================>.] - ETA: 41s - loss: 0.6821 - acc: 0.5648
9088/9333 [============================>.] - ETA: 32s - loss: 0.6821 - acc: 0.5651
9152/9333 [============================>.] - ETA: 24s - loss: 0.6823 - acc: 0.5644
9216/9333 [============================>.] - ETA: 15s - loss: 0.6821 - acc: 0.5650
9280/9333 [============================>.] - ETA: 7s - loss: 0.6819 - acc: 0.5656 
9333/9333 [==============================] - 1298s 139ms/step - loss: 0.6819 - acc: 0.5655 - val_loss: 0.6894 - val_acc: 0.5429

Epoch 00008: val_acc did not improve from 0.55256
Epoch 9/10

  64/9333 [..............................] - ETA: 18:01 - loss: 0.6782 - acc: 0.6094
 128/9333 [..............................] - ETA: 18:51 - loss: 0.6740 - acc: 0.6172
 192/9333 [..............................] - ETA: 19:35 - loss: 0.6793 - acc: 0.5990
 256/9333 [..............................] - ETA: 19:26 - loss: 0.6803 - acc: 0.5703
 320/9333 [>.............................] - ETA: 19:35 - loss: 0.6772 - acc: 0.5625
 384/9333 [>.............................] - ETA: 19:38 - loss: 0.6836 - acc: 0.5521
 448/9333 [>.............................] - ETA: 19:57 - loss: 0.6813 - acc: 0.5491
 512/9333 [>.............................] - ETA: 19:54 - loss: 0.6833 - acc: 0.5410
 576/9333 [>.............................] - ETA: 19:38 - loss: 0.6840 - acc: 0.5434
 640/9333 [=>............................] - ETA: 19:29 - loss: 0.6834 - acc: 0.5484
 704/9333 [=>............................] - ETA: 19:22 - loss: 0.6808 - acc: 0.5625
 768/9333 [=>............................] - ETA: 19:06 - loss: 0.6811 - acc: 0.5612
 832/9333 [=>............................] - ETA: 18:58 - loss: 0.6790 - acc: 0.5661
 896/9333 [=>............................] - ETA: 18:58 - loss: 0.6793 - acc: 0.5692
 960/9333 [==>...........................] - ETA: 18:46 - loss: 0.6796 - acc: 0.5687
1024/9333 [==>...........................] - ETA: 18:42 - loss: 0.6795 - acc: 0.5703
1088/9333 [==>...........................] - ETA: 18:34 - loss: 0.6807 - acc: 0.5680
1152/9333 [==>...........................] - ETA: 18:20 - loss: 0.6814 - acc: 0.5694
1216/9333 [==>...........................] - ETA: 18:15 - loss: 0.6801 - acc: 0.5715
1280/9333 [===>..........................] - ETA: 18:07 - loss: 0.6793 - acc: 0.5758
1344/9333 [===>..........................] - ETA: 17:53 - loss: 0.6811 - acc: 0.5692
1408/9333 [===>..........................] - ETA: 17:41 - loss: 0.6811 - acc: 0.5675
1472/9333 [===>..........................] - ETA: 17:32 - loss: 0.6797 - acc: 0.5686
1536/9333 [===>..........................] - ETA: 17:20 - loss: 0.6800 - acc: 0.5671
1600/9333 [====>.........................] - ETA: 17:10 - loss: 0.6802 - acc: 0.5656
1664/9333 [====>.........................] - ETA: 17:02 - loss: 0.6806 - acc: 0.5655
1728/9333 [====>.........................] - ETA: 16:53 - loss: 0.6808 - acc: 0.5654
1792/9333 [====>.........................] - ETA: 16:43 - loss: 0.6811 - acc: 0.5670
1856/9333 [====>.........................] - ETA: 16:35 - loss: 0.6811 - acc: 0.5690
1920/9333 [=====>........................] - ETA: 16:25 - loss: 0.6799 - acc: 0.5703
1984/9333 [=====>........................] - ETA: 16:18 - loss: 0.6789 - acc: 0.5746
2048/9333 [=====>........................] - ETA: 16:15 - loss: 0.6797 - acc: 0.5713
2112/9333 [=====>........................] - ETA: 16:07 - loss: 0.6793 - acc: 0.5729
2176/9333 [=====>........................] - ETA: 16:01 - loss: 0.6796 - acc: 0.5712
2240/9333 [======>.......................] - ETA: 15:58 - loss: 0.6793 - acc: 0.5728
2304/9333 [======>.......................] - ETA: 15:50 - loss: 0.6792 - acc: 0.5734
2368/9333 [======>.......................] - ETA: 15:42 - loss: 0.6794 - acc: 0.5726
2432/9333 [======>.......................] - ETA: 15:33 - loss: 0.6791 - acc: 0.5732
2496/9333 [=======>......................] - ETA: 15:22 - loss: 0.6792 - acc: 0.5717
2560/9333 [=======>......................] - ETA: 15:13 - loss: 0.6793 - acc: 0.5727
2624/9333 [=======>......................] - ETA: 15:04 - loss: 0.6786 - acc: 0.5751
2688/9333 [=======>......................] - ETA: 14:52 - loss: 0.6792 - acc: 0.5740
2752/9333 [=======>......................] - ETA: 14:42 - loss: 0.6788 - acc: 0.5749
2816/9333 [========>.....................] - ETA: 14:32 - loss: 0.6786 - acc: 0.5742
2880/9333 [========>.....................] - ETA: 14:24 - loss: 0.6786 - acc: 0.5747
2944/9333 [========>.....................] - ETA: 14:17 - loss: 0.6778 - acc: 0.5761
3008/9333 [========>.....................] - ETA: 14:07 - loss: 0.6785 - acc: 0.5735
3072/9333 [========>.....................] - ETA: 13:59 - loss: 0.6780 - acc: 0.5739
3136/9333 [=========>....................] - ETA: 13:54 - loss: 0.6778 - acc: 0.5753
3200/9333 [=========>....................] - ETA: 13:45 - loss: 0.6774 - acc: 0.5766
3264/9333 [=========>....................] - ETA: 13:38 - loss: 0.6774 - acc: 0.5763
3328/9333 [=========>....................] - ETA: 13:34 - loss: 0.6772 - acc: 0.5754
3392/9333 [=========>....................] - ETA: 13:26 - loss: 0.6766 - acc: 0.5775
3456/9333 [==========>...................] - ETA: 13:18 - loss: 0.6776 - acc: 0.5761
3520/9333 [==========>...................] - ETA: 13:09 - loss: 0.6779 - acc: 0.5759
3584/9333 [==========>...................] - ETA: 13:00 - loss: 0.6775 - acc: 0.5762
3648/9333 [==========>...................] - ETA: 12:52 - loss: 0.6783 - acc: 0.5740
3712/9333 [==========>...................] - ETA: 12:42 - loss: 0.6782 - acc: 0.5746
3776/9333 [===========>..................] - ETA: 12:34 - loss: 0.6792 - acc: 0.5726
3840/9333 [===========>..................] - ETA: 12:27 - loss: 0.6790 - acc: 0.5740
3904/9333 [===========>..................] - ETA: 12:21 - loss: 0.6790 - acc: 0.5743
3968/9333 [===========>..................] - ETA: 12:12 - loss: 0.6791 - acc: 0.5746
4032/9333 [===========>..................] - ETA: 12:04 - loss: 0.6790 - acc: 0.5737
4096/9333 [============>.................] - ETA: 11:56 - loss: 0.6789 - acc: 0.5737
4160/9333 [============>.................] - ETA: 11:48 - loss: 0.6793 - acc: 0.5724
4224/9333 [============>.................] - ETA: 11:39 - loss: 0.6791 - acc: 0.5729
4288/9333 [============>.................] - ETA: 11:30 - loss: 0.6793 - acc: 0.5732
4352/9333 [============>.................] - ETA: 11:21 - loss: 0.6787 - acc: 0.5742
4416/9333 [=============>................] - ETA: 11:12 - loss: 0.6789 - acc: 0.5743
4480/9333 [=============>................] - ETA: 11:03 - loss: 0.6790 - acc: 0.5737
4544/9333 [=============>................] - ETA: 10:54 - loss: 0.6786 - acc: 0.5742
4608/9333 [=============>................] - ETA: 10:45 - loss: 0.6789 - acc: 0.5734
4672/9333 [==============>...............] - ETA: 10:36 - loss: 0.6792 - acc: 0.5719
4736/9333 [==============>...............] - ETA: 10:26 - loss: 0.6791 - acc: 0.5718
4800/9333 [==============>...............] - ETA: 10:18 - loss: 0.6789 - acc: 0.5719
4864/9333 [==============>...............] - ETA: 10:10 - loss: 0.6786 - acc: 0.5724
4928/9333 [==============>...............] - ETA: 10:01 - loss: 0.6780 - acc: 0.5735
4992/9333 [===============>..............] - ETA: 9:52 - loss: 0.6783 - acc: 0.5723 
5056/9333 [===============>..............] - ETA: 9:43 - loss: 0.6786 - acc: 0.5718
5120/9333 [===============>..............] - ETA: 9:34 - loss: 0.6785 - acc: 0.5717
5184/9333 [===============>..............] - ETA: 9:24 - loss: 0.6787 - acc: 0.5721
5248/9333 [===============>..............] - ETA: 9:15 - loss: 0.6788 - acc: 0.5716
5312/9333 [================>.............] - ETA: 9:06 - loss: 0.6790 - acc: 0.5719
5376/9333 [================>.............] - ETA: 8:57 - loss: 0.6786 - acc: 0.5727
5440/9333 [================>.............] - ETA: 8:48 - loss: 0.6784 - acc: 0.5737
5504/9333 [================>.............] - ETA: 8:39 - loss: 0.6785 - acc: 0.5734
5568/9333 [================>.............] - ETA: 8:30 - loss: 0.6786 - acc: 0.5726
5632/9333 [=================>............] - ETA: 8:21 - loss: 0.6786 - acc: 0.5724
5696/9333 [=================>............] - ETA: 8:12 - loss: 0.6791 - acc: 0.5709
5760/9333 [=================>............] - ETA: 8:04 - loss: 0.6790 - acc: 0.5714
5824/9333 [=================>............] - ETA: 7:54 - loss: 0.6793 - acc: 0.5707
5888/9333 [=================>............] - ETA: 7:45 - loss: 0.6797 - acc: 0.5698
5952/9333 [==================>...........] - ETA: 7:37 - loss: 0.6798 - acc: 0.5696
6016/9333 [==================>...........] - ETA: 7:28 - loss: 0.6798 - acc: 0.5703
6080/9333 [==================>...........] - ETA: 7:19 - loss: 0.6801 - acc: 0.5704
6144/9333 [==================>...........] - ETA: 7:10 - loss: 0.6799 - acc: 0.5705
6208/9333 [==================>...........] - ETA: 7:01 - loss: 0.6795 - acc: 0.5717
6272/9333 [===================>..........] - ETA: 6:52 - loss: 0.6793 - acc: 0.5727
6336/9333 [===================>..........] - ETA: 6:44 - loss: 0.6798 - acc: 0.5718
6400/9333 [===================>..........] - ETA: 6:35 - loss: 0.6798 - acc: 0.5722
6464/9333 [===================>..........] - ETA: 6:27 - loss: 0.6798 - acc: 0.5726
6528/9333 [===================>..........] - ETA: 6:17 - loss: 0.6797 - acc: 0.5728
6592/9333 [====================>.........] - ETA: 6:08 - loss: 0.6794 - acc: 0.5740
6656/9333 [====================>.........] - ETA: 5:59 - loss: 0.6797 - acc: 0.5735
6720/9333 [====================>.........] - ETA: 5:50 - loss: 0.6796 - acc: 0.5734
6784/9333 [====================>.........] - ETA: 5:41 - loss: 0.6795 - acc: 0.5737
6848/9333 [=====================>........] - ETA: 5:33 - loss: 0.6795 - acc: 0.5735
6912/9333 [=====================>........] - ETA: 5:24 - loss: 0.6797 - acc: 0.5728
6976/9333 [=====================>........] - ETA: 5:15 - loss: 0.6800 - acc: 0.5720
7040/9333 [=====================>........] - ETA: 5:07 - loss: 0.6798 - acc: 0.5729
7104/9333 [=====================>........] - ETA: 4:58 - loss: 0.6798 - acc: 0.5732
7168/9333 [======================>.......] - ETA: 4:49 - loss: 0.6800 - acc: 0.5718
7232/9333 [======================>.......] - ETA: 4:41 - loss: 0.6802 - acc: 0.5709
7296/9333 [======================>.......] - ETA: 4:32 - loss: 0.6800 - acc: 0.5715
7360/9333 [======================>.......] - ETA: 4:23 - loss: 0.6803 - acc: 0.5707
7424/9333 [======================>.......] - ETA: 4:14 - loss: 0.6800 - acc: 0.5717
7488/9333 [=======================>......] - ETA: 4:06 - loss: 0.6799 - acc: 0.5721
7552/9333 [=======================>......] - ETA: 3:57 - loss: 0.6800 - acc: 0.5715
7616/9333 [=======================>......] - ETA: 3:49 - loss: 0.6797 - acc: 0.5721
7680/9333 [=======================>......] - ETA: 3:40 - loss: 0.6798 - acc: 0.5719
7744/9333 [=======================>......] - ETA: 3:31 - loss: 0.6796 - acc: 0.5713
7808/9333 [========================>.....] - ETA: 3:23 - loss: 0.6797 - acc: 0.5712
7872/9333 [========================>.....] - ETA: 3:14 - loss: 0.6796 - acc: 0.5708
7936/9333 [========================>.....] - ETA: 3:06 - loss: 0.6793 - acc: 0.5714
8000/9333 [========================>.....] - ETA: 2:57 - loss: 0.6792 - acc: 0.5716
8064/9333 [========================>.....] - ETA: 2:49 - loss: 0.6793 - acc: 0.5712
8128/9333 [=========================>....] - ETA: 2:40 - loss: 0.6796 - acc: 0.5704
8192/9333 [=========================>....] - ETA: 2:32 - loss: 0.6796 - acc: 0.5701
8256/9333 [=========================>....] - ETA: 2:23 - loss: 0.6796 - acc: 0.5704
8320/9333 [=========================>....] - ETA: 2:15 - loss: 0.6794 - acc: 0.5706
8384/9333 [=========================>....] - ETA: 2:06 - loss: 0.6792 - acc: 0.5713
8448/9333 [==========================>...] - ETA: 1:58 - loss: 0.6795 - acc: 0.5705
8512/9333 [==========================>...] - ETA: 1:49 - loss: 0.6797 - acc: 0.5698
8576/9333 [==========================>...] - ETA: 1:40 - loss: 0.6797 - acc: 0.5700
8640/9333 [==========================>...] - ETA: 1:32 - loss: 0.6797 - acc: 0.5699
8704/9333 [==========================>...] - ETA: 1:23 - loss: 0.6799 - acc: 0.5696
8768/9333 [===========================>..] - ETA: 1:15 - loss: 0.6799 - acc: 0.5697
8832/9333 [===========================>..] - ETA: 1:06 - loss: 0.6798 - acc: 0.5696
8896/9333 [===========================>..] - ETA: 58s - loss: 0.6797 - acc: 0.5699 
8960/9333 [===========================>..] - ETA: 49s - loss: 0.6795 - acc: 0.5708
9024/9333 [============================>.] - ETA: 41s - loss: 0.6795 - acc: 0.5711
9088/9333 [============================>.] - ETA: 32s - loss: 0.6795 - acc: 0.5712
9152/9333 [============================>.] - ETA: 24s - loss: 0.6795 - acc: 0.5712
9216/9333 [============================>.] - ETA: 15s - loss: 0.6797 - acc: 0.5704
9280/9333 [============================>.] - ETA: 7s - loss: 0.6795 - acc: 0.5709 
9333/9333 [==============================] - 1290s 138ms/step - loss: 0.6797 - acc: 0.5710 - val_loss: 0.6891 - val_acc: 0.5545

Epoch 00009: val_acc improved from 0.55256 to 0.55448, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window12/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
Epoch 10/10

  64/9333 [..............................] - ETA: 21:12 - loss: 0.6480 - acc: 0.6406
 128/9333 [..............................] - ETA: 20:12 - loss: 0.6794 - acc: 0.5859
 192/9333 [..............................] - ETA: 20:35 - loss: 0.6703 - acc: 0.6094
 256/9333 [..............................] - ETA: 20:10 - loss: 0.6628 - acc: 0.6172
 320/9333 [>.............................] - ETA: 19:23 - loss: 0.6636 - acc: 0.5938
 384/9333 [>.............................] - ETA: 19:11 - loss: 0.6613 - acc: 0.6068
 448/9333 [>.............................] - ETA: 18:56 - loss: 0.6623 - acc: 0.6004
 512/9333 [>.............................] - ETA: 18:42 - loss: 0.6690 - acc: 0.5898
 576/9333 [>.............................] - ETA: 18:25 - loss: 0.6680 - acc: 0.5955
 640/9333 [=>............................] - ETA: 18:21 - loss: 0.6639 - acc: 0.6031
 704/9333 [=>............................] - ETA: 18:26 - loss: 0.6647 - acc: 0.5980
 768/9333 [=>............................] - ETA: 18:11 - loss: 0.6654 - acc: 0.5924
 832/9333 [=>............................] - ETA: 17:59 - loss: 0.6690 - acc: 0.5865
 896/9333 [=>............................] - ETA: 17:42 - loss: 0.6706 - acc: 0.5826
 960/9333 [==>...........................] - ETA: 17:27 - loss: 0.6703 - acc: 0.5823
1024/9333 [==>...........................] - ETA: 17:18 - loss: 0.6743 - acc: 0.5752
1088/9333 [==>...........................] - ETA: 17:13 - loss: 0.6747 - acc: 0.5763
1152/9333 [==>...........................] - ETA: 16:55 - loss: 0.6740 - acc: 0.5764
1216/9333 [==>...........................] - ETA: 16:44 - loss: 0.6755 - acc: 0.5715
1280/9333 [===>..........................] - ETA: 16:33 - loss: 0.6771 - acc: 0.5656
1344/9333 [===>..........................] - ETA: 16:17 - loss: 0.6779 - acc: 0.5662
1408/9333 [===>..........................] - ETA: 16:10 - loss: 0.6779 - acc: 0.5668
1472/9333 [===>..........................] - ETA: 15:59 - loss: 0.6774 - acc: 0.5673
1536/9333 [===>..........................] - ETA: 15:47 - loss: 0.6770 - acc: 0.5684
1600/9333 [====>.........................] - ETA: 15:38 - loss: 0.6776 - acc: 0.5663
1664/9333 [====>.........................] - ETA: 15:32 - loss: 0.6773 - acc: 0.5655
1728/9333 [====>.........................] - ETA: 15:24 - loss: 0.6775 - acc: 0.5642
1792/9333 [====>.........................] - ETA: 15:18 - loss: 0.6777 - acc: 0.5608
1856/9333 [====>.........................] - ETA: 15:08 - loss: 0.6780 - acc: 0.5603
1920/9333 [=====>........................] - ETA: 15:00 - loss: 0.6780 - acc: 0.5620
1984/9333 [=====>........................] - ETA: 14:50 - loss: 0.6779 - acc: 0.5625
2048/9333 [=====>........................] - ETA: 14:44 - loss: 0.6775 - acc: 0.5635
2112/9333 [=====>........................] - ETA: 14:34 - loss: 0.6797 - acc: 0.5582
2176/9333 [=====>........................] - ETA: 14:25 - loss: 0.6796 - acc: 0.5570
2240/9333 [======>.......................] - ETA: 14:17 - loss: 0.6799 - acc: 0.5567
2304/9333 [======>.......................] - ETA: 14:09 - loss: 0.6804 - acc: 0.5560
2368/9333 [======>.......................] - ETA: 14:05 - loss: 0.6800 - acc: 0.5579
2432/9333 [======>.......................] - ETA: 13:56 - loss: 0.6805 - acc: 0.5572
2496/9333 [=======>......................] - ETA: 13:49 - loss: 0.6805 - acc: 0.5565
2560/9333 [=======>......................] - ETA: 13:42 - loss: 0.6804 - acc: 0.5566
2624/9333 [=======>......................] - ETA: 13:33 - loss: 0.6802 - acc: 0.5568
2688/9333 [=======>......................] - ETA: 13:25 - loss: 0.6800 - acc: 0.5565
2752/9333 [=======>......................] - ETA: 13:19 - loss: 0.6799 - acc: 0.5578
2816/9333 [========>.....................] - ETA: 13:09 - loss: 0.6799 - acc: 0.5582
2880/9333 [========>.....................] - ETA: 13:00 - loss: 0.6793 - acc: 0.5604
2944/9333 [========>.....................] - ETA: 12:52 - loss: 0.6791 - acc: 0.5608
3008/9333 [========>.....................] - ETA: 12:46 - loss: 0.6789 - acc: 0.5622
3072/9333 [========>.....................] - ETA: 12:38 - loss: 0.6779 - acc: 0.5641
3136/9333 [=========>....................] - ETA: 12:32 - loss: 0.6773 - acc: 0.5654
3200/9333 [=========>....................] - ETA: 12:23 - loss: 0.6775 - acc: 0.5653
3264/9333 [=========>....................] - ETA: 12:13 - loss: 0.6781 - acc: 0.5637
3328/9333 [=========>....................] - ETA: 12:03 - loss: 0.6780 - acc: 0.5637
3392/9333 [=========>....................] - ETA: 11:55 - loss: 0.6783 - acc: 0.5610
3456/9333 [==========>...................] - ETA: 11:46 - loss: 0.6776 - acc: 0.5616
3520/9333 [==========>...................] - ETA: 11:36 - loss: 0.6773 - acc: 0.5625
3584/9333 [==========>...................] - ETA: 11:28 - loss: 0.6770 - acc: 0.5628
3648/9333 [==========>...................] - ETA: 11:21 - loss: 0.6771 - acc: 0.5625
3712/9333 [==========>...................] - ETA: 11:12 - loss: 0.6763 - acc: 0.5652
3776/9333 [===========>..................] - ETA: 11:03 - loss: 0.6763 - acc: 0.5651
3840/9333 [===========>..................] - ETA: 10:56 - loss: 0.6762 - acc: 0.5648
3904/9333 [===========>..................] - ETA: 10:48 - loss: 0.6767 - acc: 0.5653
3968/9333 [===========>..................] - ETA: 10:41 - loss: 0.6769 - acc: 0.5658
4032/9333 [===========>..................] - ETA: 10:33 - loss: 0.6772 - acc: 0.5652
4096/9333 [============>.................] - ETA: 10:26 - loss: 0.6772 - acc: 0.5654
4160/9333 [============>.................] - ETA: 10:18 - loss: 0.6775 - acc: 0.5656
4224/9333 [============>.................] - ETA: 10:10 - loss: 0.6782 - acc: 0.5644
4288/9333 [============>.................] - ETA: 10:01 - loss: 0.6779 - acc: 0.5651
4352/9333 [============>.................] - ETA: 9:53 - loss: 0.6778 - acc: 0.5653 
4416/9333 [=============>................] - ETA: 9:46 - loss: 0.6771 - acc: 0.5652
4480/9333 [=============>................] - ETA: 9:38 - loss: 0.6767 - acc: 0.5667
4544/9333 [=============>................] - ETA: 9:30 - loss: 0.6767 - acc: 0.5665
4608/9333 [=============>................] - ETA: 9:22 - loss: 0.6767 - acc: 0.5666
4672/9333 [==============>...............] - ETA: 9:15 - loss: 0.6766 - acc: 0.5664
4736/9333 [==============>...............] - ETA: 9:07 - loss: 0.6772 - acc: 0.5652
4800/9333 [==============>...............] - ETA: 8:59 - loss: 0.6779 - acc: 0.5633
4864/9333 [==============>...............] - ETA: 8:51 - loss: 0.6776 - acc: 0.5641
4928/9333 [==============>...............] - ETA: 8:44 - loss: 0.6778 - acc: 0.5635
4992/9333 [===============>..............] - ETA: 8:36 - loss: 0.6772 - acc: 0.5647
5056/9333 [===============>..............] - ETA: 8:29 - loss: 0.6775 - acc: 0.5641
5120/9333 [===============>..............] - ETA: 8:21 - loss: 0.6779 - acc: 0.5639
5184/9333 [===============>..............] - ETA: 8:13 - loss: 0.6779 - acc: 0.5644
5248/9333 [===============>..............] - ETA: 8:05 - loss: 0.6781 - acc: 0.5648
5312/9333 [================>.............] - ETA: 7:57 - loss: 0.6782 - acc: 0.5653
5376/9333 [================>.............] - ETA: 7:50 - loss: 0.6783 - acc: 0.5658
5440/9333 [================>.............] - ETA: 7:42 - loss: 0.6780 - acc: 0.5667
5504/9333 [================>.............] - ETA: 7:34 - loss: 0.6786 - acc: 0.5647
5568/9333 [================>.............] - ETA: 7:27 - loss: 0.6790 - acc: 0.5643
5632/9333 [=================>............] - ETA: 7:19 - loss: 0.6792 - acc: 0.5646
5696/9333 [=================>............] - ETA: 7:11 - loss: 0.6790 - acc: 0.5655
5760/9333 [=================>............] - ETA: 7:03 - loss: 0.6790 - acc: 0.5658
5824/9333 [=================>............] - ETA: 6:56 - loss: 0.6791 - acc: 0.5658
5888/9333 [=================>............] - ETA: 6:48 - loss: 0.6790 - acc: 0.5657
5952/9333 [==================>...........] - ETA: 6:41 - loss: 0.6790 - acc: 0.5657
6016/9333 [==================>...........] - ETA: 6:34 - loss: 0.6791 - acc: 0.5653
6080/9333 [==================>...........] - ETA: 6:26 - loss: 0.6793 - acc: 0.5650
6144/9333 [==================>...........] - ETA: 6:18 - loss: 0.6794 - acc: 0.5648
6208/9333 [==================>...........] - ETA: 6:11 - loss: 0.6795 - acc: 0.5643
6272/9333 [===================>..........] - ETA: 6:04 - loss: 0.6794 - acc: 0.5658
6336/9333 [===================>..........] - ETA: 5:56 - loss: 0.6789 - acc: 0.5674
6400/9333 [===================>..........] - ETA: 5:48 - loss: 0.6788 - acc: 0.5678
6464/9333 [===================>..........] - ETA: 5:41 - loss: 0.6785 - acc: 0.5682
6528/9333 [===================>..........] - ETA: 5:34 - loss: 0.6786 - acc: 0.5679
6592/9333 [====================>.........] - ETA: 5:26 - loss: 0.6787 - acc: 0.5677
6656/9333 [====================>.........] - ETA: 5:18 - loss: 0.6787 - acc: 0.5676
6720/9333 [====================>.........] - ETA: 5:11 - loss: 0.6787 - acc: 0.5679
6784/9333 [====================>.........] - ETA: 5:03 - loss: 0.6788 - acc: 0.5672
6848/9333 [=====================>........] - ETA: 4:55 - loss: 0.6787 - acc: 0.5676
6912/9333 [=====================>........] - ETA: 4:48 - loss: 0.6785 - acc: 0.5681
6976/9333 [=====================>........] - ETA: 4:41 - loss: 0.6787 - acc: 0.5688
7040/9333 [=====================>........] - ETA: 4:33 - loss: 0.6785 - acc: 0.5697
7104/9333 [=====================>........] - ETA: 4:25 - loss: 0.6787 - acc: 0.5691
7168/9333 [======================>.......] - ETA: 4:18 - loss: 0.6790 - acc: 0.5679
7232/9333 [======================>.......] - ETA: 4:10 - loss: 0.6791 - acc: 0.5679
7296/9333 [======================>.......] - ETA: 4:03 - loss: 0.6792 - acc: 0.5680
7360/9333 [======================>.......] - ETA: 3:55 - loss: 0.6792 - acc: 0.5681
7424/9333 [======================>.......] - ETA: 3:48 - loss: 0.6789 - acc: 0.5684
7488/9333 [=======================>......] - ETA: 3:40 - loss: 0.6792 - acc: 0.5678
7552/9333 [=======================>......] - ETA: 3:32 - loss: 0.6794 - acc: 0.5674
7616/9333 [=======================>......] - ETA: 3:25 - loss: 0.6796 - acc: 0.5668
7680/9333 [=======================>......] - ETA: 3:17 - loss: 0.6795 - acc: 0.5674
7744/9333 [=======================>......] - ETA: 3:09 - loss: 0.6797 - acc: 0.5671
7808/9333 [========================>.....] - ETA: 3:01 - loss: 0.6797 - acc: 0.5671
7872/9333 [========================>.....] - ETA: 2:54 - loss: 0.6796 - acc: 0.5675
7936/9333 [========================>.....] - ETA: 2:46 - loss: 0.6795 - acc: 0.5675
8000/9333 [========================>.....] - ETA: 2:39 - loss: 0.6794 - acc: 0.5679
8064/9333 [========================>.....] - ETA: 2:31 - loss: 0.6796 - acc: 0.5677
8128/9333 [=========================>....] - ETA: 2:24 - loss: 0.6797 - acc: 0.5672
8192/9333 [=========================>....] - ETA: 2:16 - loss: 0.6795 - acc: 0.5679
8256/9333 [=========================>....] - ETA: 2:08 - loss: 0.6796 - acc: 0.5673
8320/9333 [=========================>....] - ETA: 2:01 - loss: 0.6798 - acc: 0.5671
8384/9333 [=========================>....] - ETA: 1:53 - loss: 0.6798 - acc: 0.5670
8448/9333 [==========================>...] - ETA: 1:45 - loss: 0.6798 - acc: 0.5666
8512/9333 [==========================>...] - ETA: 1:38 - loss: 0.6798 - acc: 0.5671
8576/9333 [==========================>...] - ETA: 1:30 - loss: 0.6798 - acc: 0.5668
8640/9333 [==========================>...] - ETA: 1:23 - loss: 0.6798 - acc: 0.5662
8704/9333 [==========================>...] - ETA: 1:15 - loss: 0.6798 - acc: 0.5662
8768/9333 [===========================>..] - ETA: 1:07 - loss: 0.6797 - acc: 0.5660
8832/9333 [===========================>..] - ETA: 59s - loss: 0.6799 - acc: 0.5657 
8896/9333 [===========================>..] - ETA: 52s - loss: 0.6800 - acc: 0.5661
8960/9333 [===========================>..] - ETA: 44s - loss: 0.6801 - acc: 0.5660
9024/9333 [============================>.] - ETA: 37s - loss: 0.6802 - acc: 0.5656
9088/9333 [============================>.] - ETA: 29s - loss: 0.6804 - acc: 0.5651
9152/9333 [============================>.] - ETA: 21s - loss: 0.6805 - acc: 0.5651
9216/9333 [============================>.] - ETA: 14s - loss: 0.6805 - acc: 0.5653
9280/9333 [============================>.] - ETA: 6s - loss: 0.6808 - acc: 0.5645 
9333/9333 [==============================] - 1158s 124ms/step - loss: 0.6808 - acc: 0.5643 - val_loss: 0.6863 - val_acc: 0.5603

Epoch 00010: val_acc improved from 0.55448 to 0.56027, saving model to /data/lyli/Lung/Lung-model/Seq_feature_exact/window12/checkpoints/final_seq_model/lung_seq_model_2_mer.hdf5
样本个数 1296
样本个数 2592
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3a44199d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f3a44199d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f357bb58ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f357bb58ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e243ad7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3e243ad7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a241c6b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a241c6b10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a2404a790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a2404a790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a440c4710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a440c4710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a241c6a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a241c6a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a241e2fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a241e2fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a047a6510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a047a6510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a0467f4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a0467f4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a0459b790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a0459b790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f357d2c5710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f357d2c5710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a044d0850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a044d0850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39e45ae810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39e45ae810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a043a4590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a043a4590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a047428d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a047428d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a24134410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a24134410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a0443e750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a0443e750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a0419f350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a0419f350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a04047650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3a04047650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a040d1a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a040d1a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a04254610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a04254610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39e45aefd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39e45aefd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a0403a990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f3a0403a990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39e44e8c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39e44e8c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b187cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f359b187cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a04726290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a04726290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39e431d590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39e431d590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39e4283f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39e4283f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39e418c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39e418c7d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39e42e7910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39e42e7910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a047260d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f3a047260d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39e4219690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39e4219690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39c470c690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39c470c690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39c466ec10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f39c466ec10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a24172790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3a24172790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39c470cb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39c470cb10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39c4773790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39c4773790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39c4402f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39c4402f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f38e4093310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f38e4093310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39c4508c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39c4508c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39c4402f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f39c4402f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39c461d650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f39c461d650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39c439a390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f39c439a390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f38a45691d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f38a45691d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38c465c390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38c465c390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f38c4737750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f38c4737750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38a4465b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38a4465b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f38a455a850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f38a455a850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c644c8710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3c644c8710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38e4561f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38e4561f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f38c460e450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f38c460e450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f357bb0c490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f357bb0c490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f38a409d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f38a409d6d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3884755410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3884755410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38847486d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38847486d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f38a4341310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f38a4341310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37097f1b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f37097f1b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f38a4215950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f38a4215950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3884472f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f3884472f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38843173d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f38843173d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f388473d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f388473d550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3884702450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f3884702450>>: AttributeError: module 'gast' has no attribute 'Str'
Traceback (most recent call last):
  File "window_select.py", line 276, in <module>
    X_seq_test = [extract_single_features(tokenizer, x['sequence']) for x in sequenceList]
  File "window_select.py", line 276, in <listcomp>
    X_seq_test = [extract_single_features(tokenizer, x['sequence']) for x in sequenceList]
  File "window_select.py", line 184, in extract_single_features
    indices, segments = tokenizer.encode(first=text, max_len=max_len)
  File "/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras_bert/tokenizer.py", line 73, in encode
    first_tokens = self._tokenize(first)
  File "window_select.py", line 175, in _tokenize
    elif self._is_space(tmp):
  File "/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras_bert/tokenizer.py", line 165, in _is_space
    unicodedata.category(ch) == 'Zs'
TypeError: category() argument must be a unicode character, not str
