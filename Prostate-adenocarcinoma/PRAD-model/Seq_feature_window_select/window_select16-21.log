nohup: ignoring input
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
样本个数 771
样本个数 1542
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fa389dafe50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fa389dafe50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa389d73490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa389d73490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3abad2f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3abad2f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa389ca9210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa389ca9210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa389bf2ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa389bf2ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389c333d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389c333d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa389c2ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa389c2ff90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389d443d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389d443d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa389c1db50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa389c1db50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa389910590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa389910590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3abf053d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3abf053d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa389c1ded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa389c1ded0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389807e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389807e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3898d4190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3898d4190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3895a94d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3895a94d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3897fb090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3897fb090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3898d48d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3898d48d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389453510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389453510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa38968aad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa38968aad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa389440b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa389440b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3892c64d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3892c64d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3894a85d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3894a85d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3893c8490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3893c8490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa389096850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa389096850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa389af9c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa389af9c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389294450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389294450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3890969d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3890969d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388e58950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388e58950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3890d6ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3890d6ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa388dd19d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa388dd19d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388ecd1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388ecd1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3891cb550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3891cb550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388cc4210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388cc4210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa388a771d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa388a771d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa388938c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa388938c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388b63990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388b63990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa388a99490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa388a99490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388a53e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388a53e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa388780750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa388780750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa388e66590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa388e66590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa38883a0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa38883a0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3887e9990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3887e9990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3886875d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3886875d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3890c4cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3890c4cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3882e8b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3882e8b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa38845f490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa38845f490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa38843c650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa38843c650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3883bffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3883bffd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa38832f790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa38832f790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3600cd2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3600cd2d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3600dad90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3600dad90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3883153d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3883153d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3600f2410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3600f2410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa35fdfb950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa35fdfb950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa35fd68110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa35fd68110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3893f65d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3893f65d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa35fdfba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa35fdfba90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa35fd7a090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa35fd7a090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa35fb3c4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa35fb3c4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa35f9b8c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa35f9b8c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa35fb1e8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa35fb1e8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa35fb3c750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa35fb3c750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa35fa8ca10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa35fa8ca10>>: AttributeError: module 'gast' has no attribute 'Str'
2023-01-12 22:20:22.208500: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-01-12 22:20:22.300083: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2023-01-12 22:20:22.346137: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eadcb4d370 executing computations on platform Host. Devices:
2023-01-12 22:20:22.346222: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-01-12 22:20:23.422805: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 2:05 - loss: 0.6805 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:25 - loss: 0.7050 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 1:10 - loss: 0.7278 - acc: 0.5365
 256/1387 [====>.........................] - ETA: 1:00 - loss: 0.7292 - acc: 0.5312
 320/1387 [=====>........................] - ETA: 54s - loss: 0.7335 - acc: 0.5219 
 384/1387 [=======>......................] - ETA: 51s - loss: 0.7252 - acc: 0.5260
 448/1387 [========>.....................] - ETA: 47s - loss: 0.7251 - acc: 0.5246
 512/1387 [==========>...................] - ETA: 44s - loss: 0.7204 - acc: 0.5312
 576/1387 [===========>..................] - ETA: 40s - loss: 0.7258 - acc: 0.5208
 640/1387 [============>.................] - ETA: 36s - loss: 0.7207 - acc: 0.5266
 704/1387 [==============>...............] - ETA: 37s - loss: 0.7166 - acc: 0.5284
 768/1387 [===============>..............] - ETA: 33s - loss: 0.7136 - acc: 0.5312
 832/1387 [================>.............] - ETA: 29s - loss: 0.7103 - acc: 0.5337
 896/1387 [==================>...........] - ETA: 26s - loss: 0.7171 - acc: 0.5234
 960/1387 [===================>..........] - ETA: 22s - loss: 0.7133 - acc: 0.5323
1024/1387 [=====================>........] - ETA: 18s - loss: 0.7162 - acc: 0.5303
1088/1387 [======================>.......] - ETA: 15s - loss: 0.7146 - acc: 0.5340
1152/1387 [=======================>......] - ETA: 12s - loss: 0.7156 - acc: 0.5339
1216/1387 [=========================>....] - ETA: 8s - loss: 0.7161 - acc: 0.5345 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.7136 - acc: 0.5422
1344/1387 [============================>.] - ETA: 2s - loss: 0.7141 - acc: 0.5432
1387/1387 [==============================] - 73s 53ms/step - loss: 0.7140 - acc: 0.5429 - val_loss: 0.7090 - val_acc: 0.5419

Epoch 00001: val_acc improved from -inf to 0.54194, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window16/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 1:06 - loss: 0.6760 - acc: 0.5938
 128/1387 [=>............................] - ETA: 1:02 - loss: 0.6505 - acc: 0.6562
 192/1387 [===>..........................] - ETA: 55s - loss: 0.6676 - acc: 0.6198 
 256/1387 [====>.........................] - ETA: 51s - loss: 0.6809 - acc: 0.6094
 320/1387 [=====>........................] - ETA: 49s - loss: 0.6728 - acc: 0.6219
 384/1387 [=======>......................] - ETA: 47s - loss: 0.6819 - acc: 0.6094
 448/1387 [========>.....................] - ETA: 44s - loss: 0.6900 - acc: 0.5759
 512/1387 [==========>...................] - ETA: 40s - loss: 0.6911 - acc: 0.5684
 576/1387 [===========>..................] - ETA: 36s - loss: 0.6923 - acc: 0.5660
 640/1387 [============>.................] - ETA: 34s - loss: 0.6903 - acc: 0.5594
 704/1387 [==============>...............] - ETA: 31s - loss: 0.6924 - acc: 0.5597
 768/1387 [===============>..............] - ETA: 28s - loss: 0.6953 - acc: 0.5586
 832/1387 [================>.............] - ETA: 25s - loss: 0.6932 - acc: 0.5637
 896/1387 [==================>...........] - ETA: 22s - loss: 0.6907 - acc: 0.5714
 960/1387 [===================>..........] - ETA: 19s - loss: 0.6990 - acc: 0.5625
1024/1387 [=====================>........] - ETA: 16s - loss: 0.7016 - acc: 0.5605
1088/1387 [======================>.......] - ETA: 13s - loss: 0.7055 - acc: 0.5561
1152/1387 [=======================>......] - ETA: 10s - loss: 0.7062 - acc: 0.5564
1216/1387 [=========================>....] - ETA: 7s - loss: 0.7057 - acc: 0.5584 
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7051 - acc: 0.5609
1344/1387 [============================>.] - ETA: 1s - loss: 0.7049 - acc: 0.5610
1387/1387 [==============================] - 64s 46ms/step - loss: 0.7051 - acc: 0.5588 - val_loss: 0.6817 - val_acc: 0.5806

Epoch 00002: val_acc improved from 0.54194 to 0.58065, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window16/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 52s - loss: 0.6661 - acc: 0.5469
 128/1387 [=>............................] - ETA: 50s - loss: 0.6912 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 47s - loss: 0.6962 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 47s - loss: 0.7006 - acc: 0.5234
 320/1387 [=====>........................] - ETA: 44s - loss: 0.7031 - acc: 0.5125
 384/1387 [=======>......................] - ETA: 42s - loss: 0.7096 - acc: 0.4948
 448/1387 [========>.....................] - ETA: 39s - loss: 0.7125 - acc: 0.4866
 512/1387 [==========>...................] - ETA: 36s - loss: 0.7061 - acc: 0.4980
 576/1387 [===========>..................] - ETA: 35s - loss: 0.7017 - acc: 0.5104
 640/1387 [============>.................] - ETA: 32s - loss: 0.7031 - acc: 0.5156
 704/1387 [==============>...............] - ETA: 30s - loss: 0.7035 - acc: 0.5156
 768/1387 [===============>..............] - ETA: 27s - loss: 0.7050 - acc: 0.5117
 832/1387 [================>.............] - ETA: 24s - loss: 0.7072 - acc: 0.5060
 896/1387 [==================>...........] - ETA: 22s - loss: 0.7099 - acc: 0.5056
 960/1387 [===================>..........] - ETA: 19s - loss: 0.7067 - acc: 0.5135
1024/1387 [=====================>........] - ETA: 16s - loss: 0.7079 - acc: 0.5117
1088/1387 [======================>.......] - ETA: 13s - loss: 0.7090 - acc: 0.5119
1152/1387 [=======================>......] - ETA: 11s - loss: 0.7091 - acc: 0.5139
1216/1387 [=========================>....] - ETA: 8s - loss: 0.7080 - acc: 0.5156 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.7049 - acc: 0.5195
1344/1387 [============================>.] - ETA: 2s - loss: 0.7035 - acc: 0.5231
1387/1387 [==============================] - 70s 51ms/step - loss: 0.7039 - acc: 0.5234 - val_loss: 0.6831 - val_acc: 0.5677

Epoch 00003: val_acc did not improve from 0.58065
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:06 - loss: 0.6838 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:06 - loss: 0.6936 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 1:06 - loss: 0.6942 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 59s - loss: 0.6751 - acc: 0.5625 
 320/1387 [=====>........................] - ETA: 57s - loss: 0.6765 - acc: 0.5656
 384/1387 [=======>......................] - ETA: 55s - loss: 0.6781 - acc: 0.5651
 448/1387 [========>.....................] - ETA: 51s - loss: 0.6743 - acc: 0.5781
 512/1387 [==========>...................] - ETA: 47s - loss: 0.6789 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 44s - loss: 0.6761 - acc: 0.5677
 640/1387 [============>.................] - ETA: 40s - loss: 0.6856 - acc: 0.5531
 704/1387 [==============>...............] - ETA: 37s - loss: 0.6892 - acc: 0.5469
 768/1387 [===============>..............] - ETA: 34s - loss: 0.6890 - acc: 0.5469
 832/1387 [================>.............] - ETA: 31s - loss: 0.6888 - acc: 0.5481
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6889 - acc: 0.5446
 960/1387 [===================>..........] - ETA: 23s - loss: 0.6882 - acc: 0.5500
1024/1387 [=====================>........] - ETA: 19s - loss: 0.6894 - acc: 0.5479
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6920 - acc: 0.5432
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6943 - acc: 0.5373
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6949 - acc: 0.5321 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6954 - acc: 0.5320
1344/1387 [============================>.] - ETA: 2s - loss: 0.6961 - acc: 0.5342
1387/1387 [==============================] - 81s 58ms/step - loss: 0.6957 - acc: 0.5350 - val_loss: 0.6818 - val_acc: 0.5613

Epoch 00004: val_acc did not improve from 0.58065
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:04 - loss: 0.7539 - acc: 0.4688
 128/1387 [=>............................] - ETA: 1:07 - loss: 0.7300 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 1:02 - loss: 0.7364 - acc: 0.5052
 256/1387 [====>.........................] - ETA: 57s - loss: 0.7236 - acc: 0.5078 
 320/1387 [=====>........................] - ETA: 53s - loss: 0.7100 - acc: 0.5312
 384/1387 [=======>......................] - ETA: 51s - loss: 0.7094 - acc: 0.5286
 448/1387 [========>.....................] - ETA: 48s - loss: 0.6982 - acc: 0.5402
 512/1387 [==========>...................] - ETA: 44s - loss: 0.6981 - acc: 0.5391
 576/1387 [===========>..................] - ETA: 41s - loss: 0.6987 - acc: 0.5347
 640/1387 [============>.................] - ETA: 38s - loss: 0.6968 - acc: 0.5375
 704/1387 [==============>...............] - ETA: 36s - loss: 0.6969 - acc: 0.5398
 768/1387 [===============>..............] - ETA: 33s - loss: 0.6983 - acc: 0.5326
 832/1387 [================>.............] - ETA: 29s - loss: 0.6988 - acc: 0.5288
 896/1387 [==================>...........] - ETA: 26s - loss: 0.6976 - acc: 0.5290
 960/1387 [===================>..........] - ETA: 23s - loss: 0.6965 - acc: 0.5281
1024/1387 [=====================>........] - ETA: 19s - loss: 0.6974 - acc: 0.5312
1088/1387 [======================>.......] - ETA: 15s - loss: 0.6953 - acc: 0.5358
1152/1387 [=======================>......] - ETA: 12s - loss: 0.6947 - acc: 0.5408
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6941 - acc: 0.5403 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6941 - acc: 0.5398
1344/1387 [============================>.] - ETA: 2s - loss: 0.6922 - acc: 0.5454
1387/1387 [==============================] - 75s 54ms/step - loss: 0.6930 - acc: 0.5436 - val_loss: 0.6821 - val_acc: 0.5677

Epoch 00005: val_acc did not improve from 0.58065
Epoch 6/10

  64/1387 [>.............................] - ETA: 51s - loss: 0.6957 - acc: 0.5312
 128/1387 [=>............................] - ETA: 48s - loss: 0.6889 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 46s - loss: 0.6773 - acc: 0.5885
 256/1387 [====>.........................] - ETA: 43s - loss: 0.6719 - acc: 0.5859
 320/1387 [=====>........................] - ETA: 40s - loss: 0.6848 - acc: 0.5687
 384/1387 [=======>......................] - ETA: 38s - loss: 0.6875 - acc: 0.5573
 448/1387 [========>.....................] - ETA: 35s - loss: 0.6839 - acc: 0.5625
 512/1387 [==========>...................] - ETA: 33s - loss: 0.6911 - acc: 0.5547
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6958 - acc: 0.5434
 640/1387 [============>.................] - ETA: 29s - loss: 0.6936 - acc: 0.5500
 704/1387 [==============>...............] - ETA: 26s - loss: 0.6904 - acc: 0.5554
 768/1387 [===============>..............] - ETA: 25s - loss: 0.6891 - acc: 0.5560
 832/1387 [================>.............] - ETA: 22s - loss: 0.6905 - acc: 0.5541
 896/1387 [==================>...........] - ETA: 19s - loss: 0.6924 - acc: 0.5469
 960/1387 [===================>..........] - ETA: 17s - loss: 0.6917 - acc: 0.5458
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6918 - acc: 0.5469
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6926 - acc: 0.5478
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6906 - acc: 0.5503 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6908 - acc: 0.5502
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6918 - acc: 0.5461
1344/1387 [============================>.] - ETA: 1s - loss: 0.6910 - acc: 0.5491
1387/1387 [==============================] - 58s 42ms/step - loss: 0.6925 - acc: 0.5465 - val_loss: 0.6972 - val_acc: 0.5226

Epoch 00006: val_acc did not improve from 0.58065
Epoch 7/10

  64/1387 [>.............................] - ETA: 55s - loss: 0.7078 - acc: 0.5469
 128/1387 [=>............................] - ETA: 49s - loss: 0.6925 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 46s - loss: 0.6989 - acc: 0.5312
 256/1387 [====>.........................] - ETA: 43s - loss: 0.6961 - acc: 0.5391
 320/1387 [=====>........................] - ETA: 40s - loss: 0.7007 - acc: 0.5219
 384/1387 [=======>......................] - ETA: 39s - loss: 0.7052 - acc: 0.5078
 448/1387 [========>.....................] - ETA: 36s - loss: 0.7025 - acc: 0.5089
 512/1387 [==========>...................] - ETA: 34s - loss: 0.7041 - acc: 0.5078
 576/1387 [===========>..................] - ETA: 31s - loss: 0.7041 - acc: 0.5052
 640/1387 [============>.................] - ETA: 29s - loss: 0.7021 - acc: 0.5000
 704/1387 [==============>...............] - ETA: 26s - loss: 0.7029 - acc: 0.5028
 768/1387 [===============>..............] - ETA: 24s - loss: 0.7013 - acc: 0.5039
 832/1387 [================>.............] - ETA: 21s - loss: 0.6973 - acc: 0.5168
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6944 - acc: 0.5212
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6934 - acc: 0.5250
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6934 - acc: 0.5273
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6939 - acc: 0.5230
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6935 - acc: 0.5243 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6928 - acc: 0.5288
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6951 - acc: 0.5258
1344/1387 [============================>.] - ETA: 1s - loss: 0.6958 - acc: 0.5283
1387/1387 [==============================] - 56s 40ms/step - loss: 0.6929 - acc: 0.5328 - val_loss: 0.6809 - val_acc: 0.5677

Epoch 00007: val_acc did not improve from 0.58065
Epoch 8/10

  64/1387 [>.............................] - ETA: 50s - loss: 0.6884 - acc: 0.5469
 128/1387 [=>............................] - ETA: 48s - loss: 0.6941 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 53s - loss: 0.6947 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 54s - loss: 0.6906 - acc: 0.5508
 320/1387 [=====>........................] - ETA: 53s - loss: 0.6971 - acc: 0.5344
 384/1387 [=======>......................] - ETA: 50s - loss: 0.6873 - acc: 0.5625
 448/1387 [========>.....................] - ETA: 47s - loss: 0.6908 - acc: 0.5536
 512/1387 [==========>...................] - ETA: 44s - loss: 0.6861 - acc: 0.5469
 576/1387 [===========>..................] - ETA: 41s - loss: 0.6881 - acc: 0.5451
 640/1387 [============>.................] - ETA: 38s - loss: 0.6903 - acc: 0.5453
 704/1387 [==============>...............] - ETA: 35s - loss: 0.6888 - acc: 0.5455
 768/1387 [===============>..............] - ETA: 31s - loss: 0.6855 - acc: 0.5534
 832/1387 [================>.............] - ETA: 28s - loss: 0.6861 - acc: 0.5541
 896/1387 [==================>...........] - ETA: 25s - loss: 0.6891 - acc: 0.5513
 960/1387 [===================>..........] - ETA: 22s - loss: 0.6902 - acc: 0.5490
1024/1387 [=====================>........] - ETA: 18s - loss: 0.6892 - acc: 0.5469
1088/1387 [======================>.......] - ETA: 15s - loss: 0.6900 - acc: 0.5450
1152/1387 [=======================>......] - ETA: 12s - loss: 0.6918 - acc: 0.5417
1216/1387 [=========================>....] - ETA: 8s - loss: 0.6914 - acc: 0.5395 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6914 - acc: 0.5391
1344/1387 [============================>.] - ETA: 2s - loss: 0.6937 - acc: 0.5357
1387/1387 [==============================] - 74s 53ms/step - loss: 0.6931 - acc: 0.5350 - val_loss: 0.6804 - val_acc: 0.5742

Epoch 00008: val_acc did not improve from 0.58065
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:00 - loss: 0.6569 - acc: 0.6094
 128/1387 [=>............................] - ETA: 1:03 - loss: 0.6523 - acc: 0.6172
 192/1387 [===>..........................] - ETA: 58s - loss: 0.6541 - acc: 0.6094 
 256/1387 [====>.........................] - ETA: 57s - loss: 0.6510 - acc: 0.6211
 320/1387 [=====>........................] - ETA: 55s - loss: 0.6496 - acc: 0.6281
 384/1387 [=======>......................] - ETA: 52s - loss: 0.6540 - acc: 0.6120
 448/1387 [========>.....................] - ETA: 48s - loss: 0.6632 - acc: 0.6027
 512/1387 [==========>...................] - ETA: 44s - loss: 0.6650 - acc: 0.5977
 576/1387 [===========>..................] - ETA: 40s - loss: 0.6638 - acc: 0.5955
 640/1387 [============>.................] - ETA: 38s - loss: 0.6660 - acc: 0.5844
 704/1387 [==============>...............] - ETA: 34s - loss: 0.6661 - acc: 0.5866
 768/1387 [===============>..............] - ETA: 31s - loss: 0.6675 - acc: 0.5820
 832/1387 [================>.............] - ETA: 28s - loss: 0.6726 - acc: 0.5781
 896/1387 [==================>...........] - ETA: 24s - loss: 0.6740 - acc: 0.5748
 960/1387 [===================>..........] - ETA: 21s - loss: 0.6745 - acc: 0.5750
1024/1387 [=====================>........] - ETA: 18s - loss: 0.6736 - acc: 0.5781
1088/1387 [======================>.......] - ETA: 15s - loss: 0.6752 - acc: 0.5754
1152/1387 [=======================>......] - ETA: 11s - loss: 0.6767 - acc: 0.5738
1216/1387 [=========================>....] - ETA: 8s - loss: 0.6789 - acc: 0.5699 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6788 - acc: 0.5734
1344/1387 [============================>.] - ETA: 2s - loss: 0.6800 - acc: 0.5729
1387/1387 [==============================] - 73s 53ms/step - loss: 0.6798 - acc: 0.5717 - val_loss: 0.6887 - val_acc: 0.5484

Epoch 00009: val_acc did not improve from 0.58065
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:12 - loss: 0.7374 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:11 - loss: 0.7012 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 1:04 - loss: 0.7116 - acc: 0.5312
 256/1387 [====>.........................] - ETA: 59s - loss: 0.7128 - acc: 0.5273 
 320/1387 [=====>........................] - ETA: 56s - loss: 0.7053 - acc: 0.5375
 384/1387 [=======>......................] - ETA: 53s - loss: 0.6989 - acc: 0.5365
 448/1387 [========>.....................] - ETA: 49s - loss: 0.6996 - acc: 0.5290
 512/1387 [==========>...................] - ETA: 47s - loss: 0.6950 - acc: 0.5312
 576/1387 [===========>..................] - ETA: 43s - loss: 0.6991 - acc: 0.5226
 640/1387 [============>.................] - ETA: 39s - loss: 0.6957 - acc: 0.5312
 704/1387 [==============>...............] - ETA: 35s - loss: 0.6912 - acc: 0.5398
 768/1387 [===============>..............] - ETA: 32s - loss: 0.6894 - acc: 0.5456
 832/1387 [================>.............] - ETA: 29s - loss: 0.6876 - acc: 0.5505
 896/1387 [==================>...........] - ETA: 25s - loss: 0.6862 - acc: 0.5569
 960/1387 [===================>..........] - ETA: 22s - loss: 0.6867 - acc: 0.5552
1024/1387 [=====================>........] - ETA: 18s - loss: 0.6831 - acc: 0.5615
1088/1387 [======================>.......] - ETA: 15s - loss: 0.6847 - acc: 0.5570
1152/1387 [=======================>......] - ETA: 12s - loss: 0.6842 - acc: 0.5590
1216/1387 [=========================>....] - ETA: 8s - loss: 0.6843 - acc: 0.5584 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6844 - acc: 0.5578
1344/1387 [============================>.] - ETA: 2s - loss: 0.6856 - acc: 0.5573
1387/1387 [==============================] - 75s 54ms/step - loss: 0.6862 - acc: 0.5552 - val_loss: 0.6882 - val_acc: 0.5742

Epoch 00010: val_acc did not improve from 0.58065
样本个数 193
样本个数 386
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 12s
128/386 [========>.....................] - ETA: 6s 
192/386 [=============>................] - ETA: 4s
256/386 [==================>...........] - ETA: 3s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 9s 23ms/step
loss: 0.6792005668032355
acc: 0.5777202072538861
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f9d4440c3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f9d4440c3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f9d00448ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f9d00448ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389d73890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389d73890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3abbc3a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3abbc3a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3abbb8b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3abbb8b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3abbc3f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3abbc3f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa39b11c850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa39b11c850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388d66fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa388d66fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9d44182b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9d44182b10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9d440a6fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9d440a6fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3abb57950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3abb57950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9d4446c0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9d4446c0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d4418f590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d4418f590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9d2067e050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9d2067e050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9d206ab310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9d206ab310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d2075ee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d2075ee10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9d2067ea90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9d2067ea90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d003fb150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d003fb150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9d0029f890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9d0029f890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9d002a0f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9d002a0f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d003fb250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d003fb250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9d00272710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9d00272710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d001ecf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d001ecf90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ce86e8710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ce86e8710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ce857b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ce857b550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d001702d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d001702d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9d001fa410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9d001fa410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ce84c2d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ce84c2d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ce84d4a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ce84d4a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ce8476d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ce8476d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ce86b1e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ce86b1e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ce837d490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ce837d490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ce819df10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ce819df10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ce80c2210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ce80c2210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9cc4704fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9cc4704fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ce80e6290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ce80e6290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ce80c2190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ce80c2190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ce8370390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ce8370390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9cc4576090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9cc4576090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9cc44eda90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9cc44eda90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9cc45766d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9cc45766d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9cc4542050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9cc4542050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d44477e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d44477e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9cc44566d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9cc44566d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9d4441d5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9d4441d5d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9cc4300590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9cc4300590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9cc422b250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9cc422b250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d20759e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9d20759e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9cc44136d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9cc44136d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ca46c1350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ca46c1350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ca4684fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ca4684fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ca478c910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ca478c910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ca45d5210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ca45d5210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ca45f4b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ca45f4b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ca4285290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ca4285290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ca42b0750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ca42b0750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ca418ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ca418ba50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ca4590ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ca4590ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ca40fad90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ca40fad90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ca40c7e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ca40c7e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ca4077610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ca4077610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ca43688d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ca43688d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9c845fd890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9c845fd890>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 3:16 - loss: 0.7462 - acc: 0.4844
 128/1387 [=>............................] - ETA: 1:55 - loss: 0.7967 - acc: 0.4688
 192/1387 [===>..........................] - ETA: 1:30 - loss: 0.7627 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 1:14 - loss: 0.7573 - acc: 0.5273
 320/1387 [=====>........................] - ETA: 1:07 - loss: 0.7294 - acc: 0.5594
 384/1387 [=======>......................] - ETA: 1:00 - loss: 0.7266 - acc: 0.5651
 448/1387 [========>.....................] - ETA: 54s - loss: 0.7247 - acc: 0.5513 
 512/1387 [==========>...................] - ETA: 49s - loss: 0.7273 - acc: 0.5410
 576/1387 [===========>..................] - ETA: 44s - loss: 0.7192 - acc: 0.5521
 640/1387 [============>.................] - ETA: 40s - loss: 0.7132 - acc: 0.5547
 704/1387 [==============>...............] - ETA: 35s - loss: 0.7159 - acc: 0.5511
 768/1387 [===============>..............] - ETA: 32s - loss: 0.7129 - acc: 0.5560
 832/1387 [================>.............] - ETA: 28s - loss: 0.7112 - acc: 0.5553
 896/1387 [==================>...........] - ETA: 24s - loss: 0.7097 - acc: 0.5569
 960/1387 [===================>..........] - ETA: 21s - loss: 0.7161 - acc: 0.5542
1024/1387 [=====================>........] - ETA: 18s - loss: 0.7154 - acc: 0.5537
1088/1387 [======================>.......] - ETA: 15s - loss: 0.7134 - acc: 0.5561
1152/1387 [=======================>......] - ETA: 11s - loss: 0.7122 - acc: 0.5556
1216/1387 [=========================>....] - ETA: 8s - loss: 0.7172 - acc: 0.5461 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.7142 - acc: 0.5492
1344/1387 [============================>.] - ETA: 2s - loss: 0.7134 - acc: 0.5499
1387/1387 [==============================] - 73s 53ms/step - loss: 0.7132 - acc: 0.5494 - val_loss: 0.6976 - val_acc: 0.5484

Epoch 00001: val_acc improved from -inf to 0.54839, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window17/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 59s - loss: 0.7671 - acc: 0.4844
 128/1387 [=>............................] - ETA: 53s - loss: 0.7459 - acc: 0.4922
 192/1387 [===>..........................] - ETA: 51s - loss: 0.7325 - acc: 0.5000
 256/1387 [====>.........................] - ETA: 50s - loss: 0.7273 - acc: 0.5000
 320/1387 [=====>........................] - ETA: 47s - loss: 0.7357 - acc: 0.5031
 384/1387 [=======>......................] - ETA: 43s - loss: 0.7239 - acc: 0.5182
 448/1387 [========>.....................] - ETA: 41s - loss: 0.7303 - acc: 0.5179
 512/1387 [==========>...................] - ETA: 38s - loss: 0.7265 - acc: 0.5137
 576/1387 [===========>..................] - ETA: 36s - loss: 0.7312 - acc: 0.5035
 640/1387 [============>.................] - ETA: 34s - loss: 0.7336 - acc: 0.4984
 704/1387 [==============>...............] - ETA: 30s - loss: 0.7330 - acc: 0.4957
 768/1387 [===============>..............] - ETA: 27s - loss: 0.7287 - acc: 0.5026
 832/1387 [================>.............] - ETA: 24s - loss: 0.7287 - acc: 0.5024
 896/1387 [==================>...........] - ETA: 21s - loss: 0.7332 - acc: 0.4955
 960/1387 [===================>..........] - ETA: 18s - loss: 0.7282 - acc: 0.5000
1024/1387 [=====================>........] - ETA: 15s - loss: 0.7253 - acc: 0.5068
1088/1387 [======================>.......] - ETA: 13s - loss: 0.7269 - acc: 0.5018
1152/1387 [=======================>......] - ETA: 10s - loss: 0.7240 - acc: 0.5069
1216/1387 [=========================>....] - ETA: 7s - loss: 0.7238 - acc: 0.5058 
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7255 - acc: 0.5016
1344/1387 [============================>.] - ETA: 1s - loss: 0.7242 - acc: 0.5022
1387/1387 [==============================] - 63s 46ms/step - loss: 0.7232 - acc: 0.5047 - val_loss: 0.6842 - val_acc: 0.6000

Epoch 00002: val_acc improved from 0.54839 to 0.60000, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window17/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 55s - loss: 0.6573 - acc: 0.6406
 128/1387 [=>............................] - ETA: 50s - loss: 0.6875 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 47s - loss: 0.6807 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 44s - loss: 0.6907 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 42s - loss: 0.6966 - acc: 0.5531
 384/1387 [=======>......................] - ETA: 41s - loss: 0.6941 - acc: 0.5573
 448/1387 [========>.....................] - ETA: 38s - loss: 0.6905 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 36s - loss: 0.6941 - acc: 0.5547
 576/1387 [===========>..................] - ETA: 34s - loss: 0.7002 - acc: 0.5417
 640/1387 [============>.................] - ETA: 31s - loss: 0.7021 - acc: 0.5375
 704/1387 [==============>...............] - ETA: 29s - loss: 0.7026 - acc: 0.5327
 768/1387 [===============>..............] - ETA: 26s - loss: 0.7001 - acc: 0.5352
 832/1387 [================>.............] - ETA: 23s - loss: 0.6987 - acc: 0.5373
 896/1387 [==================>...........] - ETA: 21s - loss: 0.7027 - acc: 0.5346
 960/1387 [===================>..........] - ETA: 19s - loss: 0.7034 - acc: 0.5344
1024/1387 [=====================>........] - ETA: 16s - loss: 0.7011 - acc: 0.5430
1088/1387 [======================>.......] - ETA: 13s - loss: 0.7010 - acc: 0.5460
1152/1387 [=======================>......] - ETA: 10s - loss: 0.7008 - acc: 0.5460
1216/1387 [=========================>....] - ETA: 7s - loss: 0.7012 - acc: 0.5403 
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7012 - acc: 0.5391
1344/1387 [============================>.] - ETA: 1s - loss: 0.7016 - acc: 0.5379
1387/1387 [==============================] - 67s 49ms/step - loss: 0.7004 - acc: 0.5393 - val_loss: 0.6843 - val_acc: 0.5742

Epoch 00003: val_acc did not improve from 0.60000
Epoch 4/10

  64/1387 [>.............................] - ETA: 58s - loss: 0.7217 - acc: 0.4688
 128/1387 [=>............................] - ETA: 57s - loss: 0.6937 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 52s - loss: 0.6796 - acc: 0.5625
 256/1387 [====>.........................] - ETA: 50s - loss: 0.6807 - acc: 0.5742
 320/1387 [=====>........................] - ETA: 47s - loss: 0.6697 - acc: 0.5969
 384/1387 [=======>......................] - ETA: 46s - loss: 0.6661 - acc: 0.6042
 448/1387 [========>.....................] - ETA: 43s - loss: 0.6681 - acc: 0.5915
 512/1387 [==========>...................] - ETA: 40s - loss: 0.6726 - acc: 0.5898
 576/1387 [===========>..................] - ETA: 37s - loss: 0.6759 - acc: 0.5885
 640/1387 [============>.................] - ETA: 34s - loss: 0.6797 - acc: 0.5781
 704/1387 [==============>...............] - ETA: 31s - loss: 0.6911 - acc: 0.5668
 768/1387 [===============>..............] - ETA: 28s - loss: 0.6953 - acc: 0.5612
 832/1387 [================>.............] - ETA: 25s - loss: 0.6934 - acc: 0.5649
 896/1387 [==================>...........] - ETA: 23s - loss: 0.7004 - acc: 0.5569
 960/1387 [===================>..........] - ETA: 19s - loss: 0.6979 - acc: 0.5594
1024/1387 [=====================>........] - ETA: 17s - loss: 0.6938 - acc: 0.5615
1088/1387 [======================>.......] - ETA: 14s - loss: 0.6952 - acc: 0.5607
1152/1387 [=======================>......] - ETA: 11s - loss: 0.6943 - acc: 0.5625
1216/1387 [=========================>....] - ETA: 8s - loss: 0.6934 - acc: 0.5600 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6952 - acc: 0.5539
1344/1387 [============================>.] - ETA: 2s - loss: 0.6938 - acc: 0.5551
1387/1387 [==============================] - 68s 49ms/step - loss: 0.6923 - acc: 0.5573 - val_loss: 0.6838 - val_acc: 0.5419

Epoch 00004: val_acc did not improve from 0.60000
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:16 - loss: 0.6781 - acc: 0.5781
 128/1387 [=>............................] - ETA: 1:02 - loss: 0.6843 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 58s - loss: 0.6772 - acc: 0.5781 
 256/1387 [====>.........................] - ETA: 55s - loss: 0.6755 - acc: 0.5898
 320/1387 [=====>........................] - ETA: 52s - loss: 0.6821 - acc: 0.5750
 384/1387 [=======>......................] - ETA: 49s - loss: 0.6792 - acc: 0.5833
 448/1387 [========>.....................] - ETA: 46s - loss: 0.6861 - acc: 0.5737
 512/1387 [==========>...................] - ETA: 43s - loss: 0.6817 - acc: 0.5820
 576/1387 [===========>..................] - ETA: 40s - loss: 0.6828 - acc: 0.5781
 640/1387 [============>.................] - ETA: 36s - loss: 0.6844 - acc: 0.5703
 704/1387 [==============>...............] - ETA: 34s - loss: 0.6872 - acc: 0.5668
 768/1387 [===============>..............] - ETA: 31s - loss: 0.6862 - acc: 0.5690
 832/1387 [================>.............] - ETA: 27s - loss: 0.6859 - acc: 0.5637
 896/1387 [==================>...........] - ETA: 24s - loss: 0.6835 - acc: 0.5625
 960/1387 [===================>..........] - ETA: 21s - loss: 0.6853 - acc: 0.5563
1024/1387 [=====================>........] - ETA: 17s - loss: 0.6841 - acc: 0.5576
1088/1387 [======================>.......] - ETA: 14s - loss: 0.6865 - acc: 0.5542
1152/1387 [=======================>......] - ETA: 11s - loss: 0.6838 - acc: 0.5599
1216/1387 [=========================>....] - ETA: 8s - loss: 0.6860 - acc: 0.5559 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6876 - acc: 0.5547
1344/1387 [============================>.] - ETA: 2s - loss: 0.6884 - acc: 0.5558
1387/1387 [==============================] - 73s 53ms/step - loss: 0.6856 - acc: 0.5609 - val_loss: 0.6955 - val_acc: 0.5613

Epoch 00005: val_acc did not improve from 0.60000
Epoch 6/10

  64/1387 [>.............................] - ETA: 59s - loss: 0.7484 - acc: 0.4531
 128/1387 [=>............................] - ETA: 1:03 - loss: 0.7373 - acc: 0.4531
 192/1387 [===>..........................] - ETA: 57s - loss: 0.7357 - acc: 0.4635 
 256/1387 [====>.........................] - ETA: 53s - loss: 0.7369 - acc: 0.4648
 320/1387 [=====>........................] - ETA: 49s - loss: 0.7285 - acc: 0.4719
 384/1387 [=======>......................] - ETA: 46s - loss: 0.7161 - acc: 0.5000
 448/1387 [========>.....................] - ETA: 42s - loss: 0.7148 - acc: 0.5045
 512/1387 [==========>...................] - ETA: 38s - loss: 0.7057 - acc: 0.5312
 576/1387 [===========>..................] - ETA: 35s - loss: 0.7031 - acc: 0.5295
 640/1387 [============>.................] - ETA: 31s - loss: 0.7020 - acc: 0.5328
 704/1387 [==============>...............] - ETA: 29s - loss: 0.7031 - acc: 0.5256
 768/1387 [===============>..............] - ETA: 26s - loss: 0.7028 - acc: 0.5221
 832/1387 [================>.............] - ETA: 23s - loss: 0.6996 - acc: 0.5252
 896/1387 [==================>...........] - ETA: 20s - loss: 0.7016 - acc: 0.5179
 960/1387 [===================>..........] - ETA: 17s - loss: 0.7013 - acc: 0.5188
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6989 - acc: 0.5254
1088/1387 [======================>.......] - ETA: 12s - loss: 0.6988 - acc: 0.5276
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6990 - acc: 0.5252 
1216/1387 [=========================>....] - ETA: 7s - loss: 0.6976 - acc: 0.5288
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6972 - acc: 0.5297
1344/1387 [============================>.] - ETA: 1s - loss: 0.6961 - acc: 0.5312
1387/1387 [==============================] - 59s 43ms/step - loss: 0.6964 - acc: 0.5321 - val_loss: 0.6832 - val_acc: 0.5613

Epoch 00006: val_acc did not improve from 0.60000
Epoch 7/10

  64/1387 [>.............................] - ETA: 52s - loss: 0.7025 - acc: 0.4844
 128/1387 [=>............................] - ETA: 56s - loss: 0.6628 - acc: 0.5859
 192/1387 [===>..........................] - ETA: 51s - loss: 0.6852 - acc: 0.5573
 256/1387 [====>.........................] - ETA: 46s - loss: 0.6841 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 43s - loss: 0.6829 - acc: 0.5625
 384/1387 [=======>......................] - ETA: 40s - loss: 0.6807 - acc: 0.5625
 448/1387 [========>.....................] - ETA: 37s - loss: 0.6782 - acc: 0.5670
 512/1387 [==========>...................] - ETA: 34s - loss: 0.6822 - acc: 0.5586
 576/1387 [===========>..................] - ETA: 32s - loss: 0.6782 - acc: 0.5677
 640/1387 [============>.................] - ETA: 30s - loss: 0.6773 - acc: 0.5750
 704/1387 [==============>...............] - ETA: 27s - loss: 0.6781 - acc: 0.5739
 768/1387 [===============>..............] - ETA: 24s - loss: 0.6775 - acc: 0.5716
 832/1387 [================>.............] - ETA: 22s - loss: 0.6791 - acc: 0.5709
 896/1387 [==================>...........] - ETA: 19s - loss: 0.6856 - acc: 0.5558
 960/1387 [===================>..........] - ETA: 17s - loss: 0.6847 - acc: 0.5604
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6859 - acc: 0.5586
1088/1387 [======================>.......] - ETA: 12s - loss: 0.6832 - acc: 0.5607
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6842 - acc: 0.5608 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6855 - acc: 0.5609
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6877 - acc: 0.5563
1344/1387 [============================>.] - ETA: 1s - loss: 0.6880 - acc: 0.5595
1387/1387 [==============================] - 59s 43ms/step - loss: 0.6857 - acc: 0.5638 - val_loss: 0.7002 - val_acc: 0.5613

Epoch 00007: val_acc did not improve from 0.60000
Epoch 8/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.7512 - acc: 0.4531
 128/1387 [=>............................] - ETA: 53s - loss: 0.7279 - acc: 0.5156
 192/1387 [===>..........................] - ETA: 48s - loss: 0.7050 - acc: 0.5312
 256/1387 [====>.........................] - ETA: 44s - loss: 0.6928 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 41s - loss: 0.6976 - acc: 0.5406
 384/1387 [=======>......................] - ETA: 38s - loss: 0.6896 - acc: 0.5495
 448/1387 [========>.....................] - ETA: 36s - loss: 0.6839 - acc: 0.5692
 512/1387 [==========>...................] - ETA: 33s - loss: 0.6824 - acc: 0.5684
 576/1387 [===========>..................] - ETA: 31s - loss: 0.6885 - acc: 0.5521
 640/1387 [============>.................] - ETA: 28s - loss: 0.6835 - acc: 0.5594
 704/1387 [==============>...............] - ETA: 26s - loss: 0.6799 - acc: 0.5625
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6780 - acc: 0.5651
 832/1387 [================>.............] - ETA: 21s - loss: 0.6775 - acc: 0.5685
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6772 - acc: 0.5692
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6774 - acc: 0.5698
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6770 - acc: 0.5693
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6766 - acc: 0.5735
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6792 - acc: 0.5712 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6787 - acc: 0.5715
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6814 - acc: 0.5734
1344/1387 [============================>.] - ETA: 1s - loss: 0.6825 - acc: 0.5722
1387/1387 [==============================] - 56s 40ms/step - loss: 0.6834 - acc: 0.5710 - val_loss: 0.6865 - val_acc: 0.5677

Epoch 00008: val_acc did not improve from 0.60000
Epoch 9/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7410 - acc: 0.4531
 128/1387 [=>............................] - ETA: 47s - loss: 0.7374 - acc: 0.4766
 192/1387 [===>..........................] - ETA: 44s - loss: 0.7163 - acc: 0.5104
 256/1387 [====>.........................] - ETA: 42s - loss: 0.7141 - acc: 0.5039
 320/1387 [=====>........................] - ETA: 39s - loss: 0.7028 - acc: 0.5344
 384/1387 [=======>......................] - ETA: 37s - loss: 0.7055 - acc: 0.5234
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7066 - acc: 0.5156
 512/1387 [==========>...................] - ETA: 32s - loss: 0.7009 - acc: 0.5273
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6994 - acc: 0.5347
 640/1387 [============>.................] - ETA: 28s - loss: 0.6942 - acc: 0.5453
 704/1387 [==============>...............] - ETA: 26s - loss: 0.6900 - acc: 0.5511
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6879 - acc: 0.5547
 832/1387 [================>.............] - ETA: 21s - loss: 0.6881 - acc: 0.5577
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6887 - acc: 0.5547
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6876 - acc: 0.5615
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6876 - acc: 0.5586
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6872 - acc: 0.5597
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6843 - acc: 0.5668 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6855 - acc: 0.5650
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6848 - acc: 0.5664
1344/1387 [============================>.] - ETA: 1s - loss: 0.6848 - acc: 0.5647
1387/1387 [==============================] - 56s 40ms/step - loss: 0.6855 - acc: 0.5638 - val_loss: 0.6896 - val_acc: 0.5548

Epoch 00009: val_acc did not improve from 0.60000
Epoch 10/10

  64/1387 [>.............................] - ETA: 50s - loss: 0.6647 - acc: 0.5938
 128/1387 [=>............................] - ETA: 47s - loss: 0.6656 - acc: 0.6172
 192/1387 [===>..........................] - ETA: 45s - loss: 0.6719 - acc: 0.5885
 256/1387 [====>.........................] - ETA: 42s - loss: 0.6889 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 41s - loss: 0.6831 - acc: 0.5750
 384/1387 [=======>......................] - ETA: 40s - loss: 0.6798 - acc: 0.5833
 448/1387 [========>.....................] - ETA: 38s - loss: 0.6869 - acc: 0.5670
 512/1387 [==========>...................] - ETA: 38s - loss: 0.6854 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 35s - loss: 0.6841 - acc: 0.5660
 640/1387 [============>.................] - ETA: 34s - loss: 0.6820 - acc: 0.5766
 704/1387 [==============>...............] - ETA: 31s - loss: 0.6814 - acc: 0.5781
 768/1387 [===============>..............] - ETA: 28s - loss: 0.6797 - acc: 0.5820
 832/1387 [================>.............] - ETA: 25s - loss: 0.6778 - acc: 0.5853
 896/1387 [==================>...........] - ETA: 22s - loss: 0.6783 - acc: 0.5826
 960/1387 [===================>..........] - ETA: 19s - loss: 0.6746 - acc: 0.5896
1024/1387 [=====================>........] - ETA: 16s - loss: 0.6780 - acc: 0.5869
1088/1387 [======================>.......] - ETA: 14s - loss: 0.6814 - acc: 0.5818
1152/1387 [=======================>......] - ETA: 11s - loss: 0.6795 - acc: 0.5816
1216/1387 [=========================>....] - ETA: 8s - loss: 0.6795 - acc: 0.5806 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6793 - acc: 0.5852
1344/1387 [============================>.] - ETA: 2s - loss: 0.6798 - acc: 0.5841
1387/1387 [==============================] - 70s 50ms/step - loss: 0.6818 - acc: 0.5768 - val_loss: 0.6799 - val_acc: 0.5935

Epoch 00010: val_acc did not improve from 0.60000
样本个数 193
样本个数 386
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 12s
128/386 [========>.....................] - ETA: 6s 
192/386 [=============>................] - ETA: 4s
256/386 [==================>...........] - ETA: 2s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 8s 21ms/step
loss: 0.6804612597035621
acc: 0.5803108808290155
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f9c001ef950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f9c001ef950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa3abad2ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa3abad2ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa39b0e39d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa39b0e39d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9bf8253c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9bf8253c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa39b146610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa39b146610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3927e1e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3927e1e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9bf8253cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9bf8253cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9bf82435d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9bf82435d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9bf86cfc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9bf86cfc50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9bf86b3d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9bf86b3d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9bf84a9e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9bf84a9e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa39b139dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa39b139dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa39b166850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa39b166850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9bf8454ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9bf8454ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9bc013ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9bc013ba90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9bf8350e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9bf8350e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9bf862f1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9bf862f1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9bc01abd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9bc01abd50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ba87911d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ba87911d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9bc0078ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9bc0078ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9cc4413050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9cc4413050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ba8791f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ba8791f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ba8609550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ba8609550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9bf835ac90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9bf835ac90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ba831ebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ba831ebd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ba86614d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ba86614d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ba8782110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ba8782110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ba865dd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ba865dd50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ba81a7d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9ba81a7d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ba8325190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9ba8325190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ba83e8f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ba83e8f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ba81327d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9ba81327d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ba811cad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9ba811cad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b8458b5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b8458b5d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b844ff510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b844ff510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b845412d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b845412d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b846efdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b846efdd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b844e4d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b844e4d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b8449ed50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b8449ed50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b842804d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b842804d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b842e90d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b842e90d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b8449e550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b8449e550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b841ee5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b841ee5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b84179110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b84179110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b60625a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b60625a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b84042950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b84042950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b84179310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b84179310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b842c9390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b842c9390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b6046ea50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b6046ea50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b602be8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b602be8d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b60303690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b60303690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b6046e0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b6046e0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b6022b250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b6022b250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b6032c790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b6032c790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b407d4650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b407d4650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b407e3490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b407e3490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b6030e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b6030e710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b6012ee90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b6012ee90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b4063a0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9b4063a0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b404428d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b404428d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b6011f490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b6011f490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b6021f690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9b6021f690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b40520c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9b40520c10>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 2:34 - loss: 0.7395 - acc: 0.5000
 128/1387 [=>............................] - ETA: 1:35 - loss: 0.8321 - acc: 0.4922
 192/1387 [===>..........................] - ETA: 1:13 - loss: 0.7933 - acc: 0.4896
 256/1387 [====>.........................] - ETA: 1:01 - loss: 0.7954 - acc: 0.4883
 320/1387 [=====>........................] - ETA: 56s - loss: 0.7861 - acc: 0.4750 
 384/1387 [=======>......................] - ETA: 49s - loss: 0.7758 - acc: 0.4792
 448/1387 [========>.....................] - ETA: 44s - loss: 0.7687 - acc: 0.4911
 512/1387 [==========>...................] - ETA: 40s - loss: 0.7552 - acc: 0.4980
 576/1387 [===========>..................] - ETA: 36s - loss: 0.7525 - acc: 0.5000
 640/1387 [============>.................] - ETA: 32s - loss: 0.7593 - acc: 0.4969
 704/1387 [==============>...............] - ETA: 29s - loss: 0.7574 - acc: 0.4915
 768/1387 [===============>..............] - ETA: 26s - loss: 0.7527 - acc: 0.4922
 832/1387 [================>.............] - ETA: 23s - loss: 0.7494 - acc: 0.4892
 896/1387 [==================>...........] - ETA: 20s - loss: 0.7470 - acc: 0.4955
 960/1387 [===================>..........] - ETA: 17s - loss: 0.7444 - acc: 0.4958
1024/1387 [=====================>........] - ETA: 14s - loss: 0.7437 - acc: 0.4912
1088/1387 [======================>.......] - ETA: 12s - loss: 0.7446 - acc: 0.4890
1152/1387 [=======================>......] - ETA: 9s - loss: 0.7406 - acc: 0.4974 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7375 - acc: 0.5016
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7354 - acc: 0.5055
1344/1387 [============================>.] - ETA: 1s - loss: 0.7339 - acc: 0.5067
1387/1387 [==============================] - 59s 43ms/step - loss: 0.7341 - acc: 0.5061 - val_loss: 0.6753 - val_acc: 0.5742

Epoch 00001: val_acc improved from -inf to 0.57419, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window18/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6858 - acc: 0.5469
 128/1387 [=>............................] - ETA: 44s - loss: 0.6836 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 41s - loss: 0.6693 - acc: 0.6094
 256/1387 [====>.........................] - ETA: 39s - loss: 0.6750 - acc: 0.5977
 320/1387 [=====>........................] - ETA: 37s - loss: 0.6772 - acc: 0.5969
 384/1387 [=======>......................] - ETA: 35s - loss: 0.6806 - acc: 0.5911
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6849 - acc: 0.5982
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6852 - acc: 0.5840
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6819 - acc: 0.5903
 640/1387 [============>.................] - ETA: 26s - loss: 0.6845 - acc: 0.5859
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6949 - acc: 0.5710
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6951 - acc: 0.5755
 832/1387 [================>.............] - ETA: 21s - loss: 0.6937 - acc: 0.5733
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6919 - acc: 0.5759
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6939 - acc: 0.5729
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6973 - acc: 0.5703
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6969 - acc: 0.5671
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6970 - acc: 0.5686 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6970 - acc: 0.5691
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7001 - acc: 0.5633
1344/1387 [============================>.] - ETA: 1s - loss: 0.6982 - acc: 0.5662
1387/1387 [==============================] - 56s 40ms/step - loss: 0.6982 - acc: 0.5624 - val_loss: 0.6778 - val_acc: 0.5677

Epoch 00002: val_acc did not improve from 0.57419
Epoch 3/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7219 - acc: 0.5156
 128/1387 [=>............................] - ETA: 47s - loss: 0.7245 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 44s - loss: 0.7122 - acc: 0.5312
 256/1387 [====>.........................] - ETA: 41s - loss: 0.7082 - acc: 0.5430
 320/1387 [=====>........................] - ETA: 39s - loss: 0.7091 - acc: 0.5469
 384/1387 [=======>......................] - ETA: 37s - loss: 0.7008 - acc: 0.5469
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7005 - acc: 0.5491
 512/1387 [==========>...................] - ETA: 32s - loss: 0.7044 - acc: 0.5469
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7069 - acc: 0.5417
 640/1387 [============>.................] - ETA: 27s - loss: 0.7033 - acc: 0.5469
 704/1387 [==============>...............] - ETA: 25s - loss: 0.7040 - acc: 0.5483
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6981 - acc: 0.5651
 832/1387 [================>.............] - ETA: 20s - loss: 0.6955 - acc: 0.5661
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6951 - acc: 0.5692
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6976 - acc: 0.5667
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6952 - acc: 0.5684
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6949 - acc: 0.5708
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6972 - acc: 0.5660 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6966 - acc: 0.5683
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6991 - acc: 0.5625
1344/1387 [============================>.] - ETA: 1s - loss: 0.6999 - acc: 0.5618
1387/1387 [==============================] - 55s 39ms/step - loss: 0.6999 - acc: 0.5602 - val_loss: 0.6788 - val_acc: 0.6000

Epoch 00003: val_acc improved from 0.57419 to 0.60000, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window18/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7080 - acc: 0.5469
 128/1387 [=>............................] - ETA: 44s - loss: 0.7187 - acc: 0.5156
 192/1387 [===>..........................] - ETA: 49s - loss: 0.7038 - acc: 0.5469
 256/1387 [====>.........................] - ETA: 45s - loss: 0.7115 - acc: 0.5234
 320/1387 [=====>........................] - ETA: 42s - loss: 0.7086 - acc: 0.5344
 384/1387 [=======>......................] - ETA: 39s - loss: 0.7034 - acc: 0.5443
 448/1387 [========>.....................] - ETA: 36s - loss: 0.7014 - acc: 0.5402
 512/1387 [==========>...................] - ETA: 34s - loss: 0.6988 - acc: 0.5410
 576/1387 [===========>..................] - ETA: 32s - loss: 0.6981 - acc: 0.5417
 640/1387 [============>.................] - ETA: 29s - loss: 0.6986 - acc: 0.5437
 704/1387 [==============>...............] - ETA: 26s - loss: 0.7009 - acc: 0.5412
 768/1387 [===============>..............] - ETA: 24s - loss: 0.7001 - acc: 0.5443
 832/1387 [================>.............] - ETA: 21s - loss: 0.6974 - acc: 0.5469
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6952 - acc: 0.5480
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6945 - acc: 0.5479
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6948 - acc: 0.5430
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6936 - acc: 0.5450
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6920 - acc: 0.5512 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6878 - acc: 0.5576
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6902 - acc: 0.5547
1344/1387 [============================>.] - ETA: 1s - loss: 0.6881 - acc: 0.5573
1387/1387 [==============================] - 57s 41ms/step - loss: 0.6882 - acc: 0.5580 - val_loss: 0.6893 - val_acc: 0.5677

Epoch 00004: val_acc did not improve from 0.60000
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:02 - loss: 0.6456 - acc: 0.6875
 128/1387 [=>............................] - ETA: 54s - loss: 0.6400 - acc: 0.6797 
 192/1387 [===>..........................] - ETA: 49s - loss: 0.6602 - acc: 0.6354
 256/1387 [====>.........................] - ETA: 44s - loss: 0.6706 - acc: 0.6094
 320/1387 [=====>........................] - ETA: 41s - loss: 0.6675 - acc: 0.6000
 384/1387 [=======>......................] - ETA: 39s - loss: 0.6746 - acc: 0.5807
 448/1387 [========>.....................] - ETA: 37s - loss: 0.6828 - acc: 0.5625
 512/1387 [==========>...................] - ETA: 34s - loss: 0.6808 - acc: 0.5684
 576/1387 [===========>..................] - ETA: 31s - loss: 0.6844 - acc: 0.5573
 640/1387 [============>.................] - ETA: 29s - loss: 0.6820 - acc: 0.5625
 704/1387 [==============>...............] - ETA: 27s - loss: 0.6822 - acc: 0.5597
 768/1387 [===============>..............] - ETA: 24s - loss: 0.6799 - acc: 0.5625
 832/1387 [================>.............] - ETA: 22s - loss: 0.6786 - acc: 0.5613
 896/1387 [==================>...........] - ETA: 19s - loss: 0.6794 - acc: 0.5592
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6816 - acc: 0.5573
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6837 - acc: 0.5576
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6829 - acc: 0.5597
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6839 - acc: 0.5590 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6855 - acc: 0.5567
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6851 - acc: 0.5570
1344/1387 [============================>.] - ETA: 1s - loss: 0.6850 - acc: 0.5565
1387/1387 [==============================] - 57s 41ms/step - loss: 0.6861 - acc: 0.5537 - val_loss: 0.6886 - val_acc: 0.5419

Epoch 00005: val_acc did not improve from 0.60000
Epoch 6/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6726 - acc: 0.6250
 128/1387 [=>............................] - ETA: 44s - loss: 0.6691 - acc: 0.5859
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6753 - acc: 0.5781
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6785 - acc: 0.5703
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6706 - acc: 0.5844
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6788 - acc: 0.5833
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6768 - acc: 0.5871
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6805 - acc: 0.5781
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6803 - acc: 0.5851
 640/1387 [============>.................] - ETA: 27s - loss: 0.6801 - acc: 0.5906
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6826 - acc: 0.5866
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6878 - acc: 0.5755
 832/1387 [================>.............] - ETA: 20s - loss: 0.6882 - acc: 0.5757
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6879 - acc: 0.5781
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6876 - acc: 0.5771
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6883 - acc: 0.5762
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6882 - acc: 0.5754
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6876 - acc: 0.5773 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6888 - acc: 0.5707
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6893 - acc: 0.5695
1344/1387 [============================>.] - ETA: 1s - loss: 0.6883 - acc: 0.5685
1387/1387 [==============================] - 55s 40ms/step - loss: 0.6894 - acc: 0.5638 - val_loss: 0.6882 - val_acc: 0.5548

Epoch 00006: val_acc did not improve from 0.60000
Epoch 7/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.7038 - acc: 0.5312
 128/1387 [=>............................] - ETA: 45s - loss: 0.6664 - acc: 0.6094
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6659 - acc: 0.6250
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6688 - acc: 0.6094
 320/1387 [=====>........................] - ETA: 39s - loss: 0.6722 - acc: 0.6000
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6752 - acc: 0.5885
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6750 - acc: 0.5915
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6773 - acc: 0.5859
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6776 - acc: 0.5816
 640/1387 [============>.................] - ETA: 27s - loss: 0.6777 - acc: 0.5813
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6749 - acc: 0.5895
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6713 - acc: 0.5977
 832/1387 [================>.............] - ETA: 20s - loss: 0.6719 - acc: 0.5950
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6759 - acc: 0.5882
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6772 - acc: 0.5854
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6764 - acc: 0.5869
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6746 - acc: 0.5892
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6757 - acc: 0.5894 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6784 - acc: 0.5863
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6793 - acc: 0.5859
1344/1387 [============================>.] - ETA: 1s - loss: 0.6767 - acc: 0.5900
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6788 - acc: 0.5847 - val_loss: 0.6839 - val_acc: 0.6000

Epoch 00007: val_acc improved from 0.60000 to 0.60000, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window18/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 8/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.6764 - acc: 0.5625
 128/1387 [=>............................] - ETA: 44s - loss: 0.6972 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6941 - acc: 0.5312
 256/1387 [====>.........................] - ETA: 43s - loss: 0.6919 - acc: 0.5469
 320/1387 [=====>........................] - ETA: 40s - loss: 0.6860 - acc: 0.5625
 384/1387 [=======>......................] - ETA: 38s - loss: 0.6749 - acc: 0.5807
 448/1387 [========>.....................] - ETA: 35s - loss: 0.6738 - acc: 0.5826
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6774 - acc: 0.5742
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6775 - acc: 0.5747
 640/1387 [============>.................] - ETA: 27s - loss: 0.6764 - acc: 0.5781
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6799 - acc: 0.5696
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6772 - acc: 0.5729
 832/1387 [================>.............] - ETA: 20s - loss: 0.6793 - acc: 0.5709
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6859 - acc: 0.5603
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6840 - acc: 0.5625
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6839 - acc: 0.5605
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6834 - acc: 0.5625
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6853 - acc: 0.5625 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6868 - acc: 0.5600
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6871 - acc: 0.5594
1344/1387 [============================>.] - ETA: 1s - loss: 0.6875 - acc: 0.5588
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6864 - acc: 0.5609 - val_loss: 0.6877 - val_acc: 0.5290

Epoch 00008: val_acc did not improve from 0.60000
Epoch 9/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6620 - acc: 0.5781
 128/1387 [=>............................] - ETA: 46s - loss: 0.6596 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6619 - acc: 0.5885
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6395 - acc: 0.6367
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6455 - acc: 0.6250
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6557 - acc: 0.6146
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6578 - acc: 0.6094
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6583 - acc: 0.6152
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6608 - acc: 0.6094
 640/1387 [============>.................] - ETA: 27s - loss: 0.6629 - acc: 0.6062
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6688 - acc: 0.5923
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6665 - acc: 0.5964
 832/1387 [================>.............] - ETA: 20s - loss: 0.6669 - acc: 0.5974
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6718 - acc: 0.5915
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6724 - acc: 0.5906
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6733 - acc: 0.5869
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6736 - acc: 0.5855
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6749 - acc: 0.5868 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6749 - acc: 0.5872
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6775 - acc: 0.5828
1344/1387 [============================>.] - ETA: 1s - loss: 0.6757 - acc: 0.5863
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6770 - acc: 0.5811 - val_loss: 0.6936 - val_acc: 0.5226

Epoch 00009: val_acc did not improve from 0.60000
Epoch 10/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.7259 - acc: 0.4531
 128/1387 [=>............................] - ETA: 45s - loss: 0.6929 - acc: 0.5547
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6883 - acc: 0.5521
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6878 - acc: 0.5430
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6959 - acc: 0.5344
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6962 - acc: 0.5391
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6903 - acc: 0.5491
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6868 - acc: 0.5605
 576/1387 [===========>..................] - ETA: 28s - loss: 0.6859 - acc: 0.5538
 640/1387 [============>.................] - ETA: 26s - loss: 0.6855 - acc: 0.5531
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6807 - acc: 0.5639
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6800 - acc: 0.5690
 832/1387 [================>.............] - ETA: 19s - loss: 0.6772 - acc: 0.5769
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6809 - acc: 0.5737
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6799 - acc: 0.5792
1024/1387 [=====================>........] - ETA: 12s - loss: 0.6806 - acc: 0.5791
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6806 - acc: 0.5790
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6808 - acc: 0.5790 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6804 - acc: 0.5789
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6808 - acc: 0.5758
1344/1387 [============================>.] - ETA: 1s - loss: 0.6815 - acc: 0.5774
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6827 - acc: 0.5739 - val_loss: 0.6766 - val_acc: 0.5935

Epoch 00010: val_acc did not improve from 0.60000
样本个数 193
样本个数 386
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 13s
128/386 [========>.....................] - ETA: 7s 
192/386 [=============>................] - ETA: 4s
256/386 [==================>...........] - ETA: 2s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 7s 19ms/step
loss: 0.6787913123560693
acc: 0.5880829015544041
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f9aa46d7c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f9aa46d7c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f9aa463f5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f9aa463f5d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a646e8f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a646e8f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3927b05d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3927b05d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9aa457d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9aa457d550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa35f30d590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa35f30d590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3927b0a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3927b0a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa39280dc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa39280dc90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9aa4655b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9aa4655b10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9aa44017d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9aa44017d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9aa4404f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9aa4404f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9aa43e4050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9aa43e4050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9aa4122290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9aa4122290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9aa4122c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9aa4122c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9aa4064050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9aa4064050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9aa4401e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9aa4401e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9aa4122710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9aa4122710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9aa427f910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9aa427f910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a646a0650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a646a0650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a6459c410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a6459c410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a6423cf90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a6423cf90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a646a0cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a646a0cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9aa4122bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9aa4122bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a64208c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a64208c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a641e08d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a641e08d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a641e4990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a641e4990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a641d8bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a641d8bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a640baa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a640baa10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a4462e290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a4462e290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a44510b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a44510b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a64076dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a64076dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a4461fe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a4461fe90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a4466aa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a4466aa50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a44558a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a44558a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a44577350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a44577350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a4431b190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a4431b190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a44363f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a44363f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a4405c6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a4405c6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a44223590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a44223590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a441da350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a441da350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a247abe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a247abe10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a44223210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a44223210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a2467d710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a2467d710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9aa46b7a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9aa46b7a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9aa463d290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9aa463d290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a247a3ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a247a3ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9c5c237350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9c5c237350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a24348090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a24348090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a2415d590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a2415d590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a047c5850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a047c5850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a2440d450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a2440d450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a24249690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a24249690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a240408d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a240408d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a04628e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a04628e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a0459e0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a0459e0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a045ee7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a045ee7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a046285d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a046285d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a043c9ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a043c9ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a0435d890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9a0435d890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a041e4dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9a041e4dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a04515cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a04515cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a0436ce50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a0436ce50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a044c6b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9a044c6b90>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 3:04 - loss: 0.7348 - acc: 0.4531
 128/1387 [=>............................] - ETA: 1:49 - loss: 0.7316 - acc: 0.5000
 192/1387 [===>..........................] - ETA: 1:23 - loss: 0.7531 - acc: 0.4740
 256/1387 [====>.........................] - ETA: 1:09 - loss: 0.7506 - acc: 0.4883
 320/1387 [=====>........................] - ETA: 59s - loss: 0.7428 - acc: 0.4906 
 384/1387 [=======>......................] - ETA: 52s - loss: 0.7330 - acc: 0.5026
 448/1387 [========>.....................] - ETA: 47s - loss: 0.7287 - acc: 0.5045
 512/1387 [==========>...................] - ETA: 42s - loss: 0.7304 - acc: 0.5000
 576/1387 [===========>..................] - ETA: 38s - loss: 0.7253 - acc: 0.5122
 640/1387 [============>.................] - ETA: 34s - loss: 0.7169 - acc: 0.5250
 704/1387 [==============>...............] - ETA: 30s - loss: 0.7173 - acc: 0.5227
 768/1387 [===============>..............] - ETA: 27s - loss: 0.7125 - acc: 0.5260
 832/1387 [================>.............] - ETA: 24s - loss: 0.7196 - acc: 0.5228
 896/1387 [==================>...........] - ETA: 21s - loss: 0.7172 - acc: 0.5268
 960/1387 [===================>..........] - ETA: 18s - loss: 0.7157 - acc: 0.5344
1024/1387 [=====================>........] - ETA: 15s - loss: 0.7166 - acc: 0.5342
1088/1387 [======================>.......] - ETA: 12s - loss: 0.7165 - acc: 0.5358
1152/1387 [=======================>......] - ETA: 9s - loss: 0.7180 - acc: 0.5330 
1216/1387 [=========================>....] - ETA: 7s - loss: 0.7145 - acc: 0.5378
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7144 - acc: 0.5352
1344/1387 [============================>.] - ETA: 1s - loss: 0.7160 - acc: 0.5357
1387/1387 [==============================] - 61s 44ms/step - loss: 0.7185 - acc: 0.5328 - val_loss: 0.6839 - val_acc: 0.6194

Epoch 00001: val_acc improved from -inf to 0.61935, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window19/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.7080 - acc: 0.5625
 128/1387 [=>............................] - ETA: 45s - loss: 0.6841 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6908 - acc: 0.5469
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6977 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 38s - loss: 0.7038 - acc: 0.5500
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6992 - acc: 0.5651
 448/1387 [========>.....................] - ETA: 33s - loss: 0.7048 - acc: 0.5603
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7191 - acc: 0.5371
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7236 - acc: 0.5347
 640/1387 [============>.................] - ETA: 26s - loss: 0.7189 - acc: 0.5391
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7246 - acc: 0.5256
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7261 - acc: 0.5273
 832/1387 [================>.............] - ETA: 19s - loss: 0.7270 - acc: 0.5240
 896/1387 [==================>...........] - ETA: 17s - loss: 0.7242 - acc: 0.5257
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7219 - acc: 0.5260
1024/1387 [=====================>........] - ETA: 12s - loss: 0.7225 - acc: 0.5244
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7189 - acc: 0.5322
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7174 - acc: 0.5373 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7177 - acc: 0.5354
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7156 - acc: 0.5406
1344/1387 [============================>.] - ETA: 1s - loss: 0.7182 - acc: 0.5379
1387/1387 [==============================] - 52s 38ms/step - loss: 0.7184 - acc: 0.5379 - val_loss: 0.6690 - val_acc: 0.6323

Epoch 00002: val_acc improved from 0.61935 to 0.63226, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window19/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7173 - acc: 0.5938
 128/1387 [=>............................] - ETA: 46s - loss: 0.7113 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 44s - loss: 0.7021 - acc: 0.5781
 256/1387 [====>.........................] - ETA: 41s - loss: 0.7103 - acc: 0.5625
 320/1387 [=====>........................] - ETA: 39s - loss: 0.7052 - acc: 0.5687
 384/1387 [=======>......................] - ETA: 37s - loss: 0.7107 - acc: 0.5521
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7024 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 32s - loss: 0.7025 - acc: 0.5566
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7080 - acc: 0.5399
 640/1387 [============>.................] - ETA: 27s - loss: 0.7040 - acc: 0.5500
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7060 - acc: 0.5469
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7063 - acc: 0.5430
 832/1387 [================>.............] - ETA: 20s - loss: 0.7013 - acc: 0.5505
 896/1387 [==================>...........] - ETA: 17s - loss: 0.7014 - acc: 0.5547
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7015 - acc: 0.5510
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7001 - acc: 0.5518
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6964 - acc: 0.5579
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6959 - acc: 0.5530 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6972 - acc: 0.5535
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6956 - acc: 0.5570
1344/1387 [============================>.] - ETA: 1s - loss: 0.6950 - acc: 0.5573
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6970 - acc: 0.5516 - val_loss: 0.6699 - val_acc: 0.6194

Epoch 00003: val_acc did not improve from 0.63226
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:01 - loss: 0.6650 - acc: 0.5625
 128/1387 [=>............................] - ETA: 51s - loss: 0.7086 - acc: 0.4922 
 192/1387 [===>..........................] - ETA: 46s - loss: 0.7146 - acc: 0.5104
 256/1387 [====>.........................] - ETA: 43s - loss: 0.7046 - acc: 0.5273
 320/1387 [=====>........................] - ETA: 40s - loss: 0.7149 - acc: 0.5219
 384/1387 [=======>......................] - ETA: 37s - loss: 0.7006 - acc: 0.5521
 448/1387 [========>.....................] - ETA: 35s - loss: 0.7015 - acc: 0.5513
 512/1387 [==========>...................] - ETA: 33s - loss: 0.6980 - acc: 0.5547
 576/1387 [===========>..................] - ETA: 31s - loss: 0.6982 - acc: 0.5660
 640/1387 [============>.................] - ETA: 28s - loss: 0.7007 - acc: 0.5625
 704/1387 [==============>...............] - ETA: 26s - loss: 0.6997 - acc: 0.5625
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6980 - acc: 0.5677
 832/1387 [================>.............] - ETA: 21s - loss: 0.7020 - acc: 0.5637
 896/1387 [==================>...........] - ETA: 19s - loss: 0.7003 - acc: 0.5636
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6976 - acc: 0.5667
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6998 - acc: 0.5586
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6990 - acc: 0.5570
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6972 - acc: 0.5564 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6941 - acc: 0.5609
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6982 - acc: 0.5539
1344/1387 [============================>.] - ETA: 1s - loss: 0.6987 - acc: 0.5528
1387/1387 [==============================] - 55s 40ms/step - loss: 0.6991 - acc: 0.5523 - val_loss: 0.6807 - val_acc: 0.6129

Epoch 00004: val_acc did not improve from 0.63226
Epoch 5/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.6703 - acc: 0.6406
 128/1387 [=>............................] - ETA: 46s - loss: 0.6898 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7060 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 41s - loss: 0.7091 - acc: 0.5352
 320/1387 [=====>........................] - ETA: 39s - loss: 0.7012 - acc: 0.5563
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6979 - acc: 0.5495
 448/1387 [========>.....................] - ETA: 36s - loss: 0.6930 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 33s - loss: 0.6932 - acc: 0.5586
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6997 - acc: 0.5451
 640/1387 [============>.................] - ETA: 28s - loss: 0.6965 - acc: 0.5500
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6934 - acc: 0.5511
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6927 - acc: 0.5508
 832/1387 [================>.............] - ETA: 21s - loss: 0.6932 - acc: 0.5529
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6936 - acc: 0.5580
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6919 - acc: 0.5625
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6905 - acc: 0.5635
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6911 - acc: 0.5643
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6917 - acc: 0.5642 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6913 - acc: 0.5658
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6946 - acc: 0.5633
1344/1387 [============================>.] - ETA: 1s - loss: 0.6919 - acc: 0.5670
1387/1387 [==============================] - 55s 39ms/step - loss: 0.6915 - acc: 0.5674 - val_loss: 0.6754 - val_acc: 0.5871

Epoch 00005: val_acc did not improve from 0.63226
Epoch 6/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7301 - acc: 0.4844
 128/1387 [=>............................] - ETA: 44s - loss: 0.7039 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6894 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6835 - acc: 0.5820
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6843 - acc: 0.5719
 384/1387 [=======>......................] - ETA: 35s - loss: 0.6783 - acc: 0.5833
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6819 - acc: 0.5737
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6795 - acc: 0.5723
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6766 - acc: 0.5799
 640/1387 [============>.................] - ETA: 26s - loss: 0.6750 - acc: 0.5797
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6778 - acc: 0.5795
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6812 - acc: 0.5677
 832/1387 [================>.............] - ETA: 20s - loss: 0.6800 - acc: 0.5697
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6814 - acc: 0.5714
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6841 - acc: 0.5667
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6831 - acc: 0.5654
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6865 - acc: 0.5588
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6838 - acc: 0.5634 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6817 - acc: 0.5650
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6813 - acc: 0.5617
1344/1387 [============================>.] - ETA: 1s - loss: 0.6825 - acc: 0.5640
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6832 - acc: 0.5602 - val_loss: 0.6728 - val_acc: 0.5613

Epoch 00006: val_acc did not improve from 0.63226
Epoch 7/10

  64/1387 [>.............................] - ETA: 45s - loss: 0.7497 - acc: 0.4219
 128/1387 [=>............................] - ETA: 46s - loss: 0.7124 - acc: 0.5000
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7065 - acc: 0.5000
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6996 - acc: 0.5234
 320/1387 [=====>........................] - ETA: 38s - loss: 0.7002 - acc: 0.5219
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7070 - acc: 0.5052
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7010 - acc: 0.5201
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6964 - acc: 0.5293
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6961 - acc: 0.5295
 640/1387 [============>.................] - ETA: 27s - loss: 0.6924 - acc: 0.5406
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6902 - acc: 0.5483
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6893 - acc: 0.5560
 832/1387 [================>.............] - ETA: 20s - loss: 0.6901 - acc: 0.5601
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6888 - acc: 0.5603
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6928 - acc: 0.5531
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6944 - acc: 0.5508
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6935 - acc: 0.5506
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6964 - acc: 0.5460 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6974 - acc: 0.5411
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6969 - acc: 0.5406
1344/1387 [============================>.] - ETA: 1s - loss: 0.6949 - acc: 0.5439
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6957 - acc: 0.5436 - val_loss: 0.6730 - val_acc: 0.6000

Epoch 00007: val_acc did not improve from 0.63226
Epoch 8/10

  64/1387 [>.............................] - ETA: 45s - loss: 0.6868 - acc: 0.6406
 128/1387 [=>............................] - ETA: 43s - loss: 0.6964 - acc: 0.5859
 192/1387 [===>..........................] - ETA: 41s - loss: 0.6844 - acc: 0.5990
 256/1387 [====>.........................] - ETA: 39s - loss: 0.6742 - acc: 0.6172
 320/1387 [=====>........................] - ETA: 37s - loss: 0.6813 - acc: 0.5938
 384/1387 [=======>......................] - ETA: 35s - loss: 0.6789 - acc: 0.5938
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6795 - acc: 0.5826
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6777 - acc: 0.5859
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6785 - acc: 0.5799
 640/1387 [============>.................] - ETA: 27s - loss: 0.6836 - acc: 0.5672
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6818 - acc: 0.5696
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6805 - acc: 0.5742
 832/1387 [================>.............] - ETA: 20s - loss: 0.6788 - acc: 0.5781
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6750 - acc: 0.5893
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6753 - acc: 0.5813
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6764 - acc: 0.5850
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6770 - acc: 0.5882
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6779 - acc: 0.5868 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6770 - acc: 0.5847
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6778 - acc: 0.5828
1344/1387 [============================>.] - ETA: 1s - loss: 0.6790 - acc: 0.5818
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6815 - acc: 0.5789 - val_loss: 0.6679 - val_acc: 0.6258

Epoch 00008: val_acc did not improve from 0.63226
Epoch 9/10

  64/1387 [>.............................] - ETA: 53s - loss: 0.7058 - acc: 0.5938
 128/1387 [=>............................] - ETA: 51s - loss: 0.7105 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 46s - loss: 0.6952 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 42s - loss: 0.6955 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 40s - loss: 0.6996 - acc: 0.5531
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6984 - acc: 0.5651
 448/1387 [========>.....................] - ETA: 35s - loss: 0.6996 - acc: 0.5580
 512/1387 [==========>...................] - ETA: 32s - loss: 0.7006 - acc: 0.5488
 576/1387 [===========>..................] - ETA: 30s - loss: 0.7023 - acc: 0.5382
 640/1387 [============>.................] - ETA: 27s - loss: 0.6995 - acc: 0.5453
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6962 - acc: 0.5469
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6967 - acc: 0.5495
 832/1387 [================>.............] - ETA: 21s - loss: 0.6967 - acc: 0.5505
 896/1387 [==================>...........] - ETA: 19s - loss: 0.6973 - acc: 0.5480
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6971 - acc: 0.5490
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6949 - acc: 0.5518
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6931 - acc: 0.5533
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6930 - acc: 0.5503 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6921 - acc: 0.5493
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6924 - acc: 0.5461
1344/1387 [============================>.] - ETA: 1s - loss: 0.6927 - acc: 0.5446
1387/1387 [==============================] - 56s 40ms/step - loss: 0.6920 - acc: 0.5436 - val_loss: 0.6721 - val_acc: 0.6323

Epoch 00009: val_acc improved from 0.63226 to 0.63226, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window19/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 10/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.7243 - acc: 0.5312
 128/1387 [=>............................] - ETA: 44s - loss: 0.6960 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6916 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 39s - loss: 0.6690 - acc: 0.5898
 320/1387 [=====>........................] - ETA: 37s - loss: 0.6663 - acc: 0.6000
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6765 - acc: 0.5781
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6863 - acc: 0.5513
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6797 - acc: 0.5605
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6716 - acc: 0.5747
 640/1387 [============>.................] - ETA: 26s - loss: 0.6744 - acc: 0.5687
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6757 - acc: 0.5653
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6789 - acc: 0.5612
 832/1387 [================>.............] - ETA: 20s - loss: 0.6758 - acc: 0.5697
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6755 - acc: 0.5714
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6768 - acc: 0.5708
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6757 - acc: 0.5762
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6811 - acc: 0.5689
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6814 - acc: 0.5686 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6808 - acc: 0.5699
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6813 - acc: 0.5680
1344/1387 [============================>.] - ETA: 1s - loss: 0.6830 - acc: 0.5685
1387/1387 [==============================] - 53s 39ms/step - loss: 0.6841 - acc: 0.5681 - val_loss: 0.6724 - val_acc: 0.6065

Epoch 00010: val_acc did not improve from 0.63226
样本个数 193
样本个数 386
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 15s
128/386 [========>.....................] - ETA: 8s 
192/386 [=============>................] - ETA: 4s
256/386 [==================>...........] - ETA: 2s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 8s 20ms/step
loss: 0.6750430001496034
acc: 0.5958549222797928
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f996840cc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f996840cc50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f99243c1dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f99243c1dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389d6b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa389d6b050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa35f2c0690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa35f2c0690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9968307e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9968307e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f994447f1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f994447f1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa35f2c0590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa35f2c0590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99683ac4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99683ac4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f99680fb750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f99680fb750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f99680eeb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f99680eeb10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99243eb290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99243eb290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9968066310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9968066310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9968059110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9968059110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f99445e9350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f99445e9350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f99445d5e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f99445d5e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99242f6910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99242f6910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a041bb450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9a041bb450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9944552110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9944552110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9944628910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9944628910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f99240d8050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f99240d8050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9924212610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9924212610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f99447d5610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f99447d5610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9904793f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9904793f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f99046ab090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f99046ab090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f990461d910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f990461d910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f990469f990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f990469f990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f99046ab550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f99046ab550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99240bf710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99240bf710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f990453f950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f990453f950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f990426da10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f990426da10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99044af310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99044af310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f990453f550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f990453f550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99240bf690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99240bf690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9904088c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9904088c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9904080b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9904080b10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99042b28d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f99042b28d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98e87e7710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98e87e7710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98e8799e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98e8799e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f99042ae410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f99042ae410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98e85584d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98e85584d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98e8511410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98e8511410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98e862e150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98e862e150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98e842bc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98e842bc10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98e81b9690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98e81b9690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98e8430390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98e8430390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98e8252fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98e8252fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98e81b9bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98e81b9bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc73cb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc73cb90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98cc64d890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98cc64d890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98cc60fc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98cc60fc50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc5fd490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc5fd490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98e843a090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98e843a090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc6d21d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc6d21d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98cc6b5910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98cc6b5910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98cc5af550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98cc5af550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc6d2cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc6d2cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98cc5bcb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98cc5bcb90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc369650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc369650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98c07cb490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98c07cb490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98c072d6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98c072d6d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc0a2510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98cc0a2510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98c07cbe90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98c07cbe90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98c07a3b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98c07a3b10>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 3:39 - loss: 0.6781 - acc: 0.5469
 128/1387 [=>............................] - ETA: 2:08 - loss: 0.7615 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 1:35 - loss: 0.7540 - acc: 0.5260
 256/1387 [====>.........................] - ETA: 1:18 - loss: 0.7388 - acc: 0.5312
 320/1387 [=====>........................] - ETA: 1:07 - loss: 0.7376 - acc: 0.5406
 384/1387 [=======>......................] - ETA: 58s - loss: 0.7383 - acc: 0.5260 
 448/1387 [========>.....................] - ETA: 51s - loss: 0.7395 - acc: 0.5312
 512/1387 [==========>...................] - ETA: 46s - loss: 0.7308 - acc: 0.5391
 576/1387 [===========>..................] - ETA: 41s - loss: 0.7391 - acc: 0.5312
 640/1387 [============>.................] - ETA: 37s - loss: 0.7363 - acc: 0.5344
 704/1387 [==============>...............] - ETA: 33s - loss: 0.7405 - acc: 0.5270
 768/1387 [===============>..............] - ETA: 29s - loss: 0.7361 - acc: 0.5339
 832/1387 [================>.............] - ETA: 26s - loss: 0.7302 - acc: 0.5397
 896/1387 [==================>...........] - ETA: 22s - loss: 0.7325 - acc: 0.5346
 960/1387 [===================>..........] - ETA: 19s - loss: 0.7316 - acc: 0.5344
1024/1387 [=====================>........] - ETA: 16s - loss: 0.7300 - acc: 0.5342
1088/1387 [======================>.......] - ETA: 13s - loss: 0.7303 - acc: 0.5331
1152/1387 [=======================>......] - ETA: 10s - loss: 0.7291 - acc: 0.5295
1216/1387 [=========================>....] - ETA: 7s - loss: 0.7301 - acc: 0.5321 
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7347 - acc: 0.5273
1344/1387 [============================>.] - ETA: 1s - loss: 0.7354 - acc: 0.5223
1387/1387 [==============================] - 63s 46ms/step - loss: 0.7329 - acc: 0.5234 - val_loss: 0.6912 - val_acc: 0.5742

Epoch 00001: val_acc improved from -inf to 0.57419, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window20/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6485 - acc: 0.5625
 128/1387 [=>............................] - ETA: 45s - loss: 0.7435 - acc: 0.5078
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7339 - acc: 0.5000
 256/1387 [====>.........................] - ETA: 40s - loss: 0.7304 - acc: 0.5117
 320/1387 [=====>........................] - ETA: 39s - loss: 0.7298 - acc: 0.4969
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7275 - acc: 0.5052
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7266 - acc: 0.5000
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7194 - acc: 0.5137
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7223 - acc: 0.5122
 640/1387 [============>.................] - ETA: 27s - loss: 0.7193 - acc: 0.5172
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7240 - acc: 0.5085
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7240 - acc: 0.5078
 832/1387 [================>.............] - ETA: 20s - loss: 0.7208 - acc: 0.5096
 896/1387 [==================>...........] - ETA: 17s - loss: 0.7183 - acc: 0.5145
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7196 - acc: 0.5177
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7177 - acc: 0.5244
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7180 - acc: 0.5257
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7162 - acc: 0.5269 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7157 - acc: 0.5255
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7158 - acc: 0.5211
1344/1387 [============================>.] - ETA: 1s - loss: 0.7157 - acc: 0.5223
1387/1387 [==============================] - 53s 38ms/step - loss: 0.7177 - acc: 0.5205 - val_loss: 0.6872 - val_acc: 0.5484

Epoch 00002: val_acc did not improve from 0.57419
Epoch 3/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6976 - acc: 0.5781
 128/1387 [=>............................] - ETA: 45s - loss: 0.6876 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6970 - acc: 0.5521
 256/1387 [====>.........................] - ETA: 40s - loss: 0.7006 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6996 - acc: 0.5469
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6962 - acc: 0.5573
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6968 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6957 - acc: 0.5566
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6943 - acc: 0.5556
 640/1387 [============>.................] - ETA: 27s - loss: 0.6946 - acc: 0.5516
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6965 - acc: 0.5426
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6981 - acc: 0.5404
 832/1387 [================>.............] - ETA: 20s - loss: 0.6947 - acc: 0.5481
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6928 - acc: 0.5513
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6925 - acc: 0.5542
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6938 - acc: 0.5527
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6950 - acc: 0.5469
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6962 - acc: 0.5443 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6946 - acc: 0.5510
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6931 - acc: 0.5547
1344/1387 [============================>.] - ETA: 1s - loss: 0.6916 - acc: 0.5551
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6911 - acc: 0.5544 - val_loss: 0.6711 - val_acc: 0.5935

Epoch 00003: val_acc improved from 0.57419 to 0.59355, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window20/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6496 - acc: 0.5312
 128/1387 [=>............................] - ETA: 45s - loss: 0.6987 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 44s - loss: 0.6881 - acc: 0.5833
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6901 - acc: 0.5703
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6873 - acc: 0.5719
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6801 - acc: 0.5833
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6885 - acc: 0.5692
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6949 - acc: 0.5586
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6978 - acc: 0.5556
 640/1387 [============>.................] - ETA: 27s - loss: 0.6966 - acc: 0.5516
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6898 - acc: 0.5597
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6881 - acc: 0.5664
 832/1387 [================>.............] - ETA: 20s - loss: 0.6826 - acc: 0.5769
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6842 - acc: 0.5703
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6842 - acc: 0.5708
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6856 - acc: 0.5654
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6848 - acc: 0.5680
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6855 - acc: 0.5651 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6857 - acc: 0.5625
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6865 - acc: 0.5625
1344/1387 [============================>.] - ETA: 1s - loss: 0.6902 - acc: 0.5573
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6892 - acc: 0.5573 - val_loss: 0.6757 - val_acc: 0.5742

Epoch 00004: val_acc did not improve from 0.59355
Epoch 5/10

  64/1387 [>.............................] - ETA: 45s - loss: 0.6757 - acc: 0.5938
 128/1387 [=>............................] - ETA: 44s - loss: 0.6986 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7038 - acc: 0.5365
 256/1387 [====>.........................] - ETA: 41s - loss: 0.7051 - acc: 0.5352
 320/1387 [=====>........................] - ETA: 38s - loss: 0.7162 - acc: 0.5156
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7175 - acc: 0.5156
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7092 - acc: 0.5290
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7143 - acc: 0.5234
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7118 - acc: 0.5226
 640/1387 [============>.................] - ETA: 27s - loss: 0.7016 - acc: 0.5406
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6989 - acc: 0.5426
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6975 - acc: 0.5456
 832/1387 [================>.............] - ETA: 20s - loss: 0.6959 - acc: 0.5493
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6929 - acc: 0.5547
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6925 - acc: 0.5573
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6981 - acc: 0.5469
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6957 - acc: 0.5533
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6967 - acc: 0.5547 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6953 - acc: 0.5559
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6940 - acc: 0.5555
1344/1387 [============================>.] - ETA: 1s - loss: 0.6933 - acc: 0.5536
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6937 - acc: 0.5544 - val_loss: 0.6836 - val_acc: 0.5419

Epoch 00005: val_acc did not improve from 0.59355
Epoch 6/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7113 - acc: 0.5312
 128/1387 [=>............................] - ETA: 44s - loss: 0.7034 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 42s - loss: 0.7042 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 40s - loss: 0.7076 - acc: 0.5195
 320/1387 [=====>........................] - ETA: 38s - loss: 0.7053 - acc: 0.5219
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7076 - acc: 0.5104
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7060 - acc: 0.5179
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7113 - acc: 0.5059
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7136 - acc: 0.5087
 640/1387 [============>.................] - ETA: 27s - loss: 0.7110 - acc: 0.5172
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7118 - acc: 0.5128
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7090 - acc: 0.5130
 832/1387 [================>.............] - ETA: 20s - loss: 0.7061 - acc: 0.5192
 896/1387 [==================>...........] - ETA: 17s - loss: 0.7041 - acc: 0.5301
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7051 - acc: 0.5292
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7059 - acc: 0.5264
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7051 - acc: 0.5257
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7042 - acc: 0.5260 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7011 - acc: 0.5329
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6989 - acc: 0.5406
1344/1387 [============================>.] - ETA: 1s - loss: 0.6988 - acc: 0.5409
1387/1387 [==============================] - 53s 39ms/step - loss: 0.6994 - acc: 0.5407 - val_loss: 0.6884 - val_acc: 0.5548

Epoch 00006: val_acc did not improve from 0.59355
Epoch 7/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7214 - acc: 0.4844
 128/1387 [=>............................] - ETA: 44s - loss: 0.6808 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6607 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6676 - acc: 0.5703
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6691 - acc: 0.5719
 384/1387 [=======>......................] - ETA: 35s - loss: 0.6836 - acc: 0.5651
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6769 - acc: 0.5737
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6817 - acc: 0.5684
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6875 - acc: 0.5642
 640/1387 [============>.................] - ETA: 26s - loss: 0.6916 - acc: 0.5531
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6913 - acc: 0.5526
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6932 - acc: 0.5482
 832/1387 [================>.............] - ETA: 20s - loss: 0.6924 - acc: 0.5433
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6901 - acc: 0.5513
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6907 - acc: 0.5542
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6891 - acc: 0.5518
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6899 - acc: 0.5515
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6904 - acc: 0.5460 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6897 - acc: 0.5469
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6889 - acc: 0.5500
1344/1387 [============================>.] - ETA: 1s - loss: 0.6893 - acc: 0.5521
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6908 - acc: 0.5516 - val_loss: 0.6803 - val_acc: 0.5677

Epoch 00007: val_acc did not improve from 0.59355
Epoch 8/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6971 - acc: 0.5469
 128/1387 [=>............................] - ETA: 45s - loss: 0.6778 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6891 - acc: 0.5938
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6921 - acc: 0.5820
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6857 - acc: 0.5875
 384/1387 [=======>......................] - ETA: 35s - loss: 0.6873 - acc: 0.5833
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6910 - acc: 0.5737
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6924 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6897 - acc: 0.5677
 640/1387 [============>.................] - ETA: 26s - loss: 0.6878 - acc: 0.5687
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6880 - acc: 0.5710
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6875 - acc: 0.5690
 832/1387 [================>.............] - ETA: 20s - loss: 0.6879 - acc: 0.5661
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6904 - acc: 0.5592
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6901 - acc: 0.5625
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6897 - acc: 0.5605
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6918 - acc: 0.5561
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6931 - acc: 0.5521 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6950 - acc: 0.5436
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6935 - acc: 0.5461
1344/1387 [============================>.] - ETA: 1s - loss: 0.6916 - acc: 0.5513
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6913 - acc: 0.5523 - val_loss: 0.6743 - val_acc: 0.6194

Epoch 00008: val_acc improved from 0.59355 to 0.61935, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window20/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 9/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6962 - acc: 0.5000
 128/1387 [=>............................] - ETA: 45s - loss: 0.6790 - acc: 0.5547
 192/1387 [===>..........................] - ETA: 44s - loss: 0.6886 - acc: 0.5312
 256/1387 [====>.........................] - ETA: 41s - loss: 0.7093 - acc: 0.5039
 320/1387 [=====>........................] - ETA: 40s - loss: 0.7027 - acc: 0.5156
 384/1387 [=======>......................] - ETA: 38s - loss: 0.7016 - acc: 0.5182
 448/1387 [========>.....................] - ETA: 35s - loss: 0.6989 - acc: 0.5179
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6988 - acc: 0.5195
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6957 - acc: 0.5295
 640/1387 [============>.................] - ETA: 27s - loss: 0.6894 - acc: 0.5500
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6885 - acc: 0.5511
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6841 - acc: 0.5599
 832/1387 [================>.............] - ETA: 20s - loss: 0.6801 - acc: 0.5709
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6819 - acc: 0.5658
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6820 - acc: 0.5635
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6816 - acc: 0.5654
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6831 - acc: 0.5634
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6794 - acc: 0.5686 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6781 - acc: 0.5715
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6788 - acc: 0.5711
1344/1387 [============================>.] - ETA: 1s - loss: 0.6795 - acc: 0.5692
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6818 - acc: 0.5667 - val_loss: 0.6738 - val_acc: 0.6258

Epoch 00009: val_acc improved from 0.61935 to 0.62581, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window20/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 10/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.5954 - acc: 0.7188
 128/1387 [=>............................] - ETA: 44s - loss: 0.6182 - acc: 0.6641
 192/1387 [===>..........................] - ETA: 41s - loss: 0.6481 - acc: 0.6406
 256/1387 [====>.........................] - ETA: 39s - loss: 0.6456 - acc: 0.6406
 320/1387 [=====>........................] - ETA: 37s - loss: 0.6527 - acc: 0.6281
 384/1387 [=======>......................] - ETA: 35s - loss: 0.6672 - acc: 0.6042
 448/1387 [========>.....................] - ETA: 32s - loss: 0.6755 - acc: 0.5915
 512/1387 [==========>...................] - ETA: 30s - loss: 0.6755 - acc: 0.5898
 576/1387 [===========>..................] - ETA: 28s - loss: 0.6757 - acc: 0.5851
 640/1387 [============>.................] - ETA: 26s - loss: 0.6771 - acc: 0.5844
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6792 - acc: 0.5739
 768/1387 [===============>..............] - ETA: 21s - loss: 0.6819 - acc: 0.5664
 832/1387 [================>.............] - ETA: 19s - loss: 0.6835 - acc: 0.5661
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6844 - acc: 0.5614
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6823 - acc: 0.5656
1024/1387 [=====================>........] - ETA: 12s - loss: 0.6819 - acc: 0.5684
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6815 - acc: 0.5726
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6809 - acc: 0.5720 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6825 - acc: 0.5666
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6830 - acc: 0.5648
1344/1387 [============================>.] - ETA: 1s - loss: 0.6857 - acc: 0.5618
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6843 - acc: 0.5624 - val_loss: 0.6803 - val_acc: 0.5484

Epoch 00010: val_acc did not improve from 0.62581
样本个数 193
样本个数 386
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 19s
128/386 [========>.....................] - ETA: 9s 
192/386 [=============>................] - ETA: 5s
256/386 [==================>...........] - ETA: 3s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 8s 22ms/step
loss: 0.6837532977366076
acc: 0.582901554404145
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f9824107810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f9824107810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f98240c6dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f98240c6dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa39b0ac190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa39b0ac190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98240f69d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98240f69d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b285ff4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9b285ff4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9c84079c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9c84079c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98240f6490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98240f6490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9c84043590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9c84043590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98240aa890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98240aa890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9804595290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9804595290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98240aa5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98240aa5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98240aab50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98240aab50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98043f5f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f98043f5f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f980462da10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f980462da10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f980422f790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f980422f790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f980429ced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f980429ced0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98045fcad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f98045fcad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f990478be90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f990478be90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98042265d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f98042265d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98240c2b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f98240c2b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9924065350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9924065350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9804226950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9804226950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f982415e790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f982415e790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97c46ab190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97c46ab190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f97c45cc450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f97c45cc450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97e4127050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97e4127050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f97c4421110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f97c4421110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97c418c150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97c418c150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97c40f7790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97c40f7790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f97a4787550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f97a4787550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a4646850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a4646850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f97c4115250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f97c4115250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a461ac90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a461ac90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97a479c950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97a479c950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f97a4471250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f97a4471250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a4342d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a4342d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f97a475f9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f97a475f9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a478ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a478ba90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97a41fe610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97a41fe610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f97a4240d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f97a4240d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97847cd250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97847cd250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f97a41fe410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f97a41fe410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a4255f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a4255f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97846de0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97846de0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9784648950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9784648950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f978475b8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f978475b8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9784760dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9784760dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a415f910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97a415f910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97843d5850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97843d5850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9784295f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9784295f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97844e72d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97844e72d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f97843d5490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f97843d5490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97844376d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97844376d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97841337d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f97841337d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f976473a5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f976473a5d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9764665dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9764665dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f978418dbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f978418dbd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9784462610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9784462610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9764565f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f9764565f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9764418e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f9764418e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97647acbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f97647acbd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9764565a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f9764565a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9764445fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f9764445fd0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 4:05 - loss: 0.7707 - acc: 0.4531
 128/1387 [=>............................] - ETA: 2:18 - loss: 0.7754 - acc: 0.5000
 192/1387 [===>..........................] - ETA: 1:41 - loss: 0.7786 - acc: 0.4896
 256/1387 [====>.........................] - ETA: 1:22 - loss: 0.7601 - acc: 0.5000
 320/1387 [=====>........................] - ETA: 1:09 - loss: 0.7630 - acc: 0.5125
 384/1387 [=======>......................] - ETA: 1:00 - loss: 0.7723 - acc: 0.5130
 448/1387 [========>.....................] - ETA: 53s - loss: 0.7675 - acc: 0.5045 
 512/1387 [==========>...................] - ETA: 47s - loss: 0.7592 - acc: 0.5137
 576/1387 [===========>..................] - ETA: 42s - loss: 0.7552 - acc: 0.5087
 640/1387 [============>.................] - ETA: 37s - loss: 0.7496 - acc: 0.5141
 704/1387 [==============>...............] - ETA: 33s - loss: 0.7447 - acc: 0.5199
 768/1387 [===============>..............] - ETA: 30s - loss: 0.7503 - acc: 0.5117
 832/1387 [================>.............] - ETA: 26s - loss: 0.7485 - acc: 0.5108
 896/1387 [==================>...........] - ETA: 23s - loss: 0.7509 - acc: 0.5100
 960/1387 [===================>..........] - ETA: 19s - loss: 0.7469 - acc: 0.5135
1024/1387 [=====================>........] - ETA: 16s - loss: 0.7437 - acc: 0.5156
1088/1387 [======================>.......] - ETA: 13s - loss: 0.7401 - acc: 0.5165
1152/1387 [=======================>......] - ETA: 10s - loss: 0.7410 - acc: 0.5113
1216/1387 [=========================>....] - ETA: 7s - loss: 0.7395 - acc: 0.5164 
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7382 - acc: 0.5148
1344/1387 [============================>.] - ETA: 1s - loss: 0.7376 - acc: 0.5134
1387/1387 [==============================] - 65s 47ms/step - loss: 0.7364 - acc: 0.5141 - val_loss: 0.6790 - val_acc: 0.6000

Epoch 00001: val_acc improved from -inf to 0.60000, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window21/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6481 - acc: 0.6094
 128/1387 [=>............................] - ETA: 45s - loss: 0.6571 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6705 - acc: 0.5885
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6750 - acc: 0.6055
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6918 - acc: 0.5844
 384/1387 [=======>......................] - ETA: 35s - loss: 0.6935 - acc: 0.5729
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6854 - acc: 0.5781
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6877 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6895 - acc: 0.5608
 640/1387 [============>.................] - ETA: 27s - loss: 0.6978 - acc: 0.5547
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7012 - acc: 0.5497
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7009 - acc: 0.5469
 832/1387 [================>.............] - ETA: 20s - loss: 0.6998 - acc: 0.5493
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6991 - acc: 0.5569
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6990 - acc: 0.5542
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6969 - acc: 0.5566
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6986 - acc: 0.5524
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6993 - acc: 0.5477 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7021 - acc: 0.5411
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7052 - acc: 0.5367
1344/1387 [============================>.] - ETA: 1s - loss: 0.7056 - acc: 0.5365
1387/1387 [==============================] - 53s 39ms/step - loss: 0.7070 - acc: 0.5357 - val_loss: 0.6786 - val_acc: 0.5742

Epoch 00002: val_acc did not improve from 0.60000
Epoch 3/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6919 - acc: 0.5938
 128/1387 [=>............................] - ETA: 45s - loss: 0.6752 - acc: 0.6172
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6726 - acc: 0.6094
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6824 - acc: 0.6055
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6896 - acc: 0.6000
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6978 - acc: 0.5859
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6970 - acc: 0.5759
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6979 - acc: 0.5723
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7029 - acc: 0.5677
 640/1387 [============>.................] - ETA: 27s - loss: 0.7058 - acc: 0.5578
 704/1387 [==============>...............] - ETA: 25s - loss: 0.7055 - acc: 0.5597
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7088 - acc: 0.5521
 832/1387 [================>.............] - ETA: 20s - loss: 0.7106 - acc: 0.5469
 896/1387 [==================>...........] - ETA: 18s - loss: 0.7064 - acc: 0.5536
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7079 - acc: 0.5490
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7065 - acc: 0.5518
1088/1387 [======================>.......] - ETA: 11s - loss: 0.7074 - acc: 0.5496
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7075 - acc: 0.5451 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7092 - acc: 0.5428
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7067 - acc: 0.5461
1344/1387 [============================>.] - ETA: 1s - loss: 0.7089 - acc: 0.5417
1387/1387 [==============================] - 54s 39ms/step - loss: 0.7088 - acc: 0.5400 - val_loss: 0.6722 - val_acc: 0.5548

Epoch 00003: val_acc did not improve from 0.60000
Epoch 4/10

  64/1387 [>.............................] - ETA: 45s - loss: 0.6681 - acc: 0.5781
 128/1387 [=>............................] - ETA: 44s - loss: 0.6760 - acc: 0.5547
 192/1387 [===>..........................] - ETA: 41s - loss: 0.6888 - acc: 0.5156
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6807 - acc: 0.5391
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6847 - acc: 0.5406
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6770 - acc: 0.5625
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6800 - acc: 0.5491
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6832 - acc: 0.5488
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6806 - acc: 0.5590
 640/1387 [============>.................] - ETA: 27s - loss: 0.6801 - acc: 0.5609
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6781 - acc: 0.5653
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6784 - acc: 0.5651
 832/1387 [================>.............] - ETA: 20s - loss: 0.6790 - acc: 0.5685
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6788 - acc: 0.5714
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6810 - acc: 0.5698
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6842 - acc: 0.5664
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6878 - acc: 0.5597
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6890 - acc: 0.5564 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6905 - acc: 0.5543
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6897 - acc: 0.5563
1344/1387 [============================>.] - ETA: 1s - loss: 0.6909 - acc: 0.5521
1387/1387 [==============================] - 52s 38ms/step - loss: 0.6916 - acc: 0.5508 - val_loss: 0.6795 - val_acc: 0.5935

Epoch 00004: val_acc did not improve from 0.60000
Epoch 5/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6964 - acc: 0.5000
 128/1387 [=>............................] - ETA: 44s - loss: 0.6887 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6938 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6882 - acc: 0.5352
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6959 - acc: 0.5219
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6934 - acc: 0.5208
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6897 - acc: 0.5268
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6861 - acc: 0.5332
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6844 - acc: 0.5382
 640/1387 [============>.................] - ETA: 27s - loss: 0.6831 - acc: 0.5422
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6864 - acc: 0.5398
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6859 - acc: 0.5469
 832/1387 [================>.............] - ETA: 20s - loss: 0.6903 - acc: 0.5397
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6916 - acc: 0.5379
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6975 - acc: 0.5281
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6975 - acc: 0.5273
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6982 - acc: 0.5294
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6981 - acc: 0.5269 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6980 - acc: 0.5288
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6986 - acc: 0.5289
1344/1387 [============================>.] - ETA: 1s - loss: 0.6961 - acc: 0.5335
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6979 - acc: 0.5314 - val_loss: 0.6770 - val_acc: 0.5742

Epoch 00005: val_acc did not improve from 0.60000
Epoch 6/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6862 - acc: 0.5156
 128/1387 [=>............................] - ETA: 44s - loss: 0.6824 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6868 - acc: 0.5625
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6898 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6977 - acc: 0.5344
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7016 - acc: 0.5286
 448/1387 [========>.....................] - ETA: 33s - loss: 0.7036 - acc: 0.5223
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7046 - acc: 0.5254
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7065 - acc: 0.5295
 640/1387 [============>.................] - ETA: 26s - loss: 0.7043 - acc: 0.5234
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7051 - acc: 0.5170
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7058 - acc: 0.5208
 832/1387 [================>.............] - ETA: 19s - loss: 0.7076 - acc: 0.5192
 896/1387 [==================>...........] - ETA: 17s - loss: 0.7070 - acc: 0.5212
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7063 - acc: 0.5219
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7064 - acc: 0.5244
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7064 - acc: 0.5221
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7068 - acc: 0.5234 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7053 - acc: 0.5255
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7032 - acc: 0.5320
1344/1387 [============================>.] - ETA: 1s - loss: 0.7007 - acc: 0.5350
1387/1387 [==============================] - 53s 38ms/step - loss: 0.7013 - acc: 0.5335 - val_loss: 0.6780 - val_acc: 0.6000

Epoch 00006: val_acc improved from 0.60000 to 0.60000, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window21/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 7/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.7111 - acc: 0.4844
 128/1387 [=>............................] - ETA: 45s - loss: 0.7058 - acc: 0.5156
 192/1387 [===>..........................] - ETA: 42s - loss: 0.7012 - acc: 0.5312
 256/1387 [====>.........................] - ETA: 40s - loss: 0.7160 - acc: 0.5117
 320/1387 [=====>........................] - ETA: 38s - loss: 0.7095 - acc: 0.5281
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7023 - acc: 0.5469
 448/1387 [========>.....................] - ETA: 33s - loss: 0.7008 - acc: 0.5469
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6962 - acc: 0.5488
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7011 - acc: 0.5469
 640/1387 [============>.................] - ETA: 26s - loss: 0.7001 - acc: 0.5484
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6974 - acc: 0.5568
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7004 - acc: 0.5508
 832/1387 [================>.............] - ETA: 19s - loss: 0.6960 - acc: 0.5589
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6989 - acc: 0.5525
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6973 - acc: 0.5542
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6980 - acc: 0.5508
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6975 - acc: 0.5524
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6960 - acc: 0.5547 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6940 - acc: 0.5576
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6937 - acc: 0.5555
1344/1387 [============================>.] - ETA: 1s - loss: 0.6954 - acc: 0.5528
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6936 - acc: 0.5566 - val_loss: 0.6694 - val_acc: 0.5677

Epoch 00007: val_acc did not improve from 0.60000
Epoch 8/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.7171 - acc: 0.4844
 128/1387 [=>............................] - ETA: 45s - loss: 0.7009 - acc: 0.5000
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7053 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6989 - acc: 0.5391
 320/1387 [=====>........................] - ETA: 39s - loss: 0.6915 - acc: 0.5469
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6938 - acc: 0.5469
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6911 - acc: 0.5580
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6916 - acc: 0.5508
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6952 - acc: 0.5486
 640/1387 [============>.................] - ETA: 27s - loss: 0.6926 - acc: 0.5531
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6931 - acc: 0.5582
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6905 - acc: 0.5638
 832/1387 [================>.............] - ETA: 20s - loss: 0.6915 - acc: 0.5625
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6910 - acc: 0.5614
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6925 - acc: 0.5583
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6906 - acc: 0.5615
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6892 - acc: 0.5625
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6871 - acc: 0.5668 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6886 - acc: 0.5658
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6867 - acc: 0.5664
1344/1387 [============================>.] - ETA: 1s - loss: 0.6865 - acc: 0.5662
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6877 - acc: 0.5660 - val_loss: 0.6719 - val_acc: 0.6129

Epoch 00008: val_acc improved from 0.60000 to 0.61290, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window21/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 9/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6966 - acc: 0.5469
 128/1387 [=>............................] - ETA: 45s - loss: 0.6607 - acc: 0.6250
 192/1387 [===>..........................] - ETA: 44s - loss: 0.6673 - acc: 0.5885
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6768 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 39s - loss: 0.6712 - acc: 0.5750
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6784 - acc: 0.5625
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6781 - acc: 0.5625
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6784 - acc: 0.5645
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6840 - acc: 0.5503
 640/1387 [============>.................] - ETA: 27s - loss: 0.6811 - acc: 0.5563
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6851 - acc: 0.5440
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6900 - acc: 0.5378
 832/1387 [================>.............] - ETA: 20s - loss: 0.6929 - acc: 0.5325
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6924 - acc: 0.5335
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6898 - acc: 0.5385
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6899 - acc: 0.5361
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6908 - acc: 0.5322
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6912 - acc: 0.5356 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6890 - acc: 0.5411
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6916 - acc: 0.5375
1344/1387 [============================>.] - ETA: 1s - loss: 0.6938 - acc: 0.5320
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6941 - acc: 0.5335 - val_loss: 0.6733 - val_acc: 0.5677

Epoch 00009: val_acc did not improve from 0.61290
Epoch 10/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6692 - acc: 0.6094
 128/1387 [=>............................] - ETA: 45s - loss: 0.6621 - acc: 0.6094
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6609 - acc: 0.5990
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6598 - acc: 0.5938
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6640 - acc: 0.5750
 384/1387 [=======>......................] - ETA: 35s - loss: 0.6737 - acc: 0.5599
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6757 - acc: 0.5536
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6744 - acc: 0.5605
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6714 - acc: 0.5677
 640/1387 [============>.................] - ETA: 27s - loss: 0.6753 - acc: 0.5672
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6755 - acc: 0.5668
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6746 - acc: 0.5742
 832/1387 [================>.............] - ETA: 20s - loss: 0.6757 - acc: 0.5769
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6735 - acc: 0.5759
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6753 - acc: 0.5750
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6765 - acc: 0.5723
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6769 - acc: 0.5744
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6781 - acc: 0.5712 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6779 - acc: 0.5691
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6774 - acc: 0.5695
1344/1387 [============================>.] - ETA: 1s - loss: 0.6781 - acc: 0.5670
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6785 - acc: 0.5660 - val_loss: 0.6709 - val_acc: 0.5613

Epoch 00010: val_acc did not improve from 0.61290
样本个数 193
样本个数 386
window_select16-21.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 22s
128/386 [========>.....................] - ETA: 10s
192/386 [=============>................] - ETA: 6s 
256/386 [==================>...........] - ETA: 3s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 9s 24ms/step
loss: 0.6786145472155951
acc: 0.5803108808290155
