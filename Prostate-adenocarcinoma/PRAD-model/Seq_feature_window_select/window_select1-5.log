nohup: ignoring input
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
样本个数 771
样本个数 1542
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fad8b69ca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fad8b69ca90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fadad4a3f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fadad4a3f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b624850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b624850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad8b624ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad8b624ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad8b4dccd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad8b4dccd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b65f810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b65f810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad8b624e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad8b624e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b309310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b309310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad8b533250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad8b533250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fadad7f84d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fadad7f84d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b3adc10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b3adc10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad8b620690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad8b620690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad831f4190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad831f4190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad83227450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad83227450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad82ff6090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad82ff6090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad832eca10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad832eca10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad83227910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad83227910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad82d982d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad82d982d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad82c7ef50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad82c7ef50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad82d28910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad82d28910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad82d2b050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad82d2b050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad82c7e9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad82c7e9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad82ca4310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad82ca4310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad7a9d5d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad7a9d5d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad82df5810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad82df5810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b62d450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b62d450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad830f7b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad830f7b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad7a9d5190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad7a9d5190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad7a647f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad7a647f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad7a645c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad7a645c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad7a5c1d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad7a5c1d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad7a6471d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad7a6471d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad7a890510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad7a890510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad7a6228d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad7a6228d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad7a678310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad7a678310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad7a388f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad7a388f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad7a622850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad7a622850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad72258f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad72258f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad8b532190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad8b532190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad71f6fb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad71f6fb50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad71f82850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad71f82850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad720d9c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad720d9c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad71f75d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad71f75d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad71e0ed10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad71e0ed10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad71d755d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad71d755d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad71d4d090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad71d4d090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad71dfdf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad71dfdf10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad71bfff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad71bfff90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad699c7610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad699c7610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad69a6ed10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad69a6ed10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad69a4abd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad69a4abd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad699c79d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad699c79d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad69a5bad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad69a5bad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad69930090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad69930090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad69731e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad69731e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad697adb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad697adb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad71c9fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad71c9fd50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad696d53d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad696d53d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad693eb450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad693eb450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad693d1710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad693d1710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad6113a650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad6113a650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad69657890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad69657890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad610c1ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad610c1ad0>>: AttributeError: module 'gast' has no attribute 'Str'
2023-01-12 11:18:48.286237: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-01-12 11:18:48.345509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2023-01-12 11:18:48.388026: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55641747b960 executing computations on platform Host. Devices:
2023-01-12 11:18:48.388109: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-01-12 11:18:48.862756: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 4:32 - loss: 0.7349 - acc: 0.5469
 128/1387 [=>............................] - ETA: 3:08 - loss: 0.7587 - acc: 0.5078
 192/1387 [===>..........................] - ETA: 2:45 - loss: 0.7580 - acc: 0.5052
 256/1387 [====>.........................] - ETA: 2:36 - loss: 0.7481 - acc: 0.5352
 320/1387 [=====>........................] - ETA: 2:18 - loss: 0.7464 - acc: 0.5312
 384/1387 [=======>......................] - ETA: 2:04 - loss: 0.7506 - acc: 0.5156
 448/1387 [========>.....................] - ETA: 1:52 - loss: 0.7546 - acc: 0.5000
 512/1387 [==========>...................] - ETA: 1:43 - loss: 0.7478 - acc: 0.5000
 576/1387 [===========>..................] - ETA: 1:33 - loss: 0.7433 - acc: 0.5156
 640/1387 [============>.................] - ETA: 1:24 - loss: 0.7416 - acc: 0.5203
 704/1387 [==============>...............] - ETA: 1:15 - loss: 0.7361 - acc: 0.5256
 768/1387 [===============>..............] - ETA: 1:05 - loss: 0.7329 - acc: 0.5260
 832/1387 [================>.............] - ETA: 57s - loss: 0.7285 - acc: 0.5288 
 896/1387 [==================>...........] - ETA: 50s - loss: 0.7264 - acc: 0.5324
 960/1387 [===================>..........] - ETA: 43s - loss: 0.7304 - acc: 0.5260
1024/1387 [=====================>........] - ETA: 36s - loss: 0.7309 - acc: 0.5225
1088/1387 [======================>.......] - ETA: 29s - loss: 0.7323 - acc: 0.5221
1152/1387 [=======================>......] - ETA: 23s - loss: 0.7343 - acc: 0.5208
1216/1387 [=========================>....] - ETA: 16s - loss: 0.7320 - acc: 0.5222
1280/1387 [==========================>...] - ETA: 10s - loss: 0.7291 - acc: 0.5250
1344/1387 [============================>.] - ETA: 4s - loss: 0.7286 - acc: 0.5231 
1387/1387 [==============================] - 142s 102ms/step - loss: 0.7290 - acc: 0.5227 - val_loss: 0.6755 - val_acc: 0.5677

Epoch 00001: val_acc improved from -inf to 0.56774, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window01/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 2:00 - loss: 0.6790 - acc: 0.6094
 128/1387 [=>............................] - ETA: 1:53 - loss: 0.7043 - acc: 0.5547
 192/1387 [===>..........................] - ETA: 1:38 - loss: 0.6940 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 1:35 - loss: 0.7025 - acc: 0.5469
 320/1387 [=====>........................] - ETA: 1:28 - loss: 0.7108 - acc: 0.5312
 384/1387 [=======>......................] - ETA: 1:23 - loss: 0.7049 - acc: 0.5312
 448/1387 [========>.....................] - ETA: 1:17 - loss: 0.7062 - acc: 0.5246
 512/1387 [==========>...................] - ETA: 1:11 - loss: 0.7094 - acc: 0.5254
 576/1387 [===========>..................] - ETA: 1:05 - loss: 0.7067 - acc: 0.5295
 640/1387 [============>.................] - ETA: 59s - loss: 0.7105 - acc: 0.5297 
 704/1387 [==============>...............] - ETA: 53s - loss: 0.7152 - acc: 0.5241
 768/1387 [===============>..............] - ETA: 47s - loss: 0.7170 - acc: 0.5221
 832/1387 [================>.............] - ETA: 42s - loss: 0.7176 - acc: 0.5228
 896/1387 [==================>...........] - ETA: 36s - loss: 0.7201 - acc: 0.5167
 960/1387 [===================>..........] - ETA: 31s - loss: 0.7193 - acc: 0.5167
1024/1387 [=====================>........] - ETA: 26s - loss: 0.7193 - acc: 0.5127
1088/1387 [======================>.......] - ETA: 21s - loss: 0.7241 - acc: 0.5055
1152/1387 [=======================>......] - ETA: 17s - loss: 0.7238 - acc: 0.5026
1216/1387 [=========================>....] - ETA: 12s - loss: 0.7202 - acc: 0.5066
1280/1387 [==========================>...] - ETA: 7s - loss: 0.7172 - acc: 0.5102 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7165 - acc: 0.5119
1387/1387 [==============================] - 108s 78ms/step - loss: 0.7167 - acc: 0.5119 - val_loss: 0.6818 - val_acc: 0.5806

Epoch 00002: val_acc improved from 0.56774 to 0.58065, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window01/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 1:58 - loss: 0.7027 - acc: 0.5625
 128/1387 [=>............................] - ETA: 1:57 - loss: 0.7058 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:47 - loss: 0.7209 - acc: 0.5312
 256/1387 [====>.........................] - ETA: 1:39 - loss: 0.7136 - acc: 0.5508
 320/1387 [=====>........................] - ETA: 1:31 - loss: 0.7110 - acc: 0.5437
 384/1387 [=======>......................] - ETA: 1:24 - loss: 0.7234 - acc: 0.5260
 448/1387 [========>.....................] - ETA: 1:17 - loss: 0.7165 - acc: 0.5379
 512/1387 [==========>...................] - ETA: 1:09 - loss: 0.7096 - acc: 0.5410
 576/1387 [===========>..................] - ETA: 1:04 - loss: 0.7115 - acc: 0.5347
 640/1387 [============>.................] - ETA: 59s - loss: 0.7068 - acc: 0.5328 
 704/1387 [==============>...............] - ETA: 54s - loss: 0.7048 - acc: 0.5384
 768/1387 [===============>..............] - ETA: 49s - loss: 0.7061 - acc: 0.5339
 832/1387 [================>.............] - ETA: 44s - loss: 0.7042 - acc: 0.5385
 896/1387 [==================>...........] - ETA: 39s - loss: 0.7012 - acc: 0.5435
 960/1387 [===================>..........] - ETA: 33s - loss: 0.7006 - acc: 0.5417
1024/1387 [=====================>........] - ETA: 28s - loss: 0.7031 - acc: 0.5400
1088/1387 [======================>.......] - ETA: 23s - loss: 0.7034 - acc: 0.5441
1152/1387 [=======================>......] - ETA: 18s - loss: 0.7056 - acc: 0.5417
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7075 - acc: 0.5403
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7087 - acc: 0.5422 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7115 - acc: 0.5372
1387/1387 [==============================] - 113s 81ms/step - loss: 0.7106 - acc: 0.5371 - val_loss: 0.6936 - val_acc: 0.5226

Epoch 00003: val_acc did not improve from 0.58065
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:23 - loss: 0.6983 - acc: 0.5625
 128/1387 [=>............................] - ETA: 1:22 - loss: 0.6914 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 1:20 - loss: 0.6890 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 1:19 - loss: 0.6897 - acc: 0.5664
 320/1387 [=====>........................] - ETA: 1:13 - loss: 0.6953 - acc: 0.5437
 384/1387 [=======>......................] - ETA: 1:10 - loss: 0.6960 - acc: 0.5339
 448/1387 [========>.....................] - ETA: 1:07 - loss: 0.6915 - acc: 0.5424
 512/1387 [==========>...................] - ETA: 1:02 - loss: 0.6994 - acc: 0.5195
 576/1387 [===========>..................] - ETA: 58s - loss: 0.6976 - acc: 0.5278 
 640/1387 [============>.................] - ETA: 53s - loss: 0.7007 - acc: 0.5234
 704/1387 [==============>...............] - ETA: 49s - loss: 0.7030 - acc: 0.5213
 768/1387 [===============>..............] - ETA: 43s - loss: 0.6994 - acc: 0.5247
 832/1387 [================>.............] - ETA: 39s - loss: 0.6983 - acc: 0.5240
 896/1387 [==================>...........] - ETA: 34s - loss: 0.7040 - acc: 0.5156
 960/1387 [===================>..........] - ETA: 30s - loss: 0.7038 - acc: 0.5167
1024/1387 [=====================>........] - ETA: 26s - loss: 0.7022 - acc: 0.5176
1088/1387 [======================>.......] - ETA: 21s - loss: 0.7027 - acc: 0.5202
1152/1387 [=======================>......] - ETA: 16s - loss: 0.7015 - acc: 0.5234
1216/1387 [=========================>....] - ETA: 12s - loss: 0.7008 - acc: 0.5230
1280/1387 [==========================>...] - ETA: 7s - loss: 0.7005 - acc: 0.5219 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7000 - acc: 0.5208
1387/1387 [==============================] - 106s 76ms/step - loss: 0.7002 - acc: 0.5234 - val_loss: 0.6924 - val_acc: 0.5355

Epoch 00004: val_acc did not improve from 0.58065
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:46 - loss: 0.6934 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:40 - loss: 0.6818 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:33 - loss: 0.6783 - acc: 0.5573
 256/1387 [====>.........................] - ETA: 1:24 - loss: 0.6891 - acc: 0.5352
 320/1387 [=====>........................] - ETA: 1:19 - loss: 0.6867 - acc: 0.5375
 384/1387 [=======>......................] - ETA: 1:15 - loss: 0.6827 - acc: 0.5599
 448/1387 [========>.....................] - ETA: 1:11 - loss: 0.6888 - acc: 0.5580
 512/1387 [==========>...................] - ETA: 1:06 - loss: 0.6834 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 1:03 - loss: 0.6855 - acc: 0.5642
 640/1387 [============>.................] - ETA: 58s - loss: 0.6861 - acc: 0.5672 
 704/1387 [==============>...............] - ETA: 52s - loss: 0.6898 - acc: 0.5625
 768/1387 [===============>..............] - ETA: 47s - loss: 0.6925 - acc: 0.5534
 832/1387 [================>.............] - ETA: 42s - loss: 0.6930 - acc: 0.5493
 896/1387 [==================>...........] - ETA: 37s - loss: 0.6929 - acc: 0.5547
 960/1387 [===================>..........] - ETA: 32s - loss: 0.6943 - acc: 0.5531
1024/1387 [=====================>........] - ETA: 27s - loss: 0.6941 - acc: 0.5518
1088/1387 [======================>.......] - ETA: 22s - loss: 0.6951 - acc: 0.5506
1152/1387 [=======================>......] - ETA: 17s - loss: 0.6945 - acc: 0.5512
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6956 - acc: 0.5469
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6942 - acc: 0.5500 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6934 - acc: 0.5499
1387/1387 [==============================] - 110s 80ms/step - loss: 0.6941 - acc: 0.5494 - val_loss: 0.6860 - val_acc: 0.6000

Epoch 00005: val_acc improved from 0.58065 to 0.60000, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window01/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1387 [>.............................] - ETA: 1:36 - loss: 0.6693 - acc: 0.6562
 128/1387 [=>............................] - ETA: 1:26 - loss: 0.7069 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 1:23 - loss: 0.7054 - acc: 0.5469
 256/1387 [====>.........................] - ETA: 1:22 - loss: 0.7090 - acc: 0.5000
 320/1387 [=====>........................] - ETA: 1:14 - loss: 0.7155 - acc: 0.4781
 384/1387 [=======>......................] - ETA: 1:09 - loss: 0.7114 - acc: 0.4870
 448/1387 [========>.....................] - ETA: 1:06 - loss: 0.7120 - acc: 0.4754
 512/1387 [==========>...................] - ETA: 1:01 - loss: 0.7076 - acc: 0.4844
 576/1387 [===========>..................] - ETA: 57s - loss: 0.7032 - acc: 0.4931 
 640/1387 [============>.................] - ETA: 53s - loss: 0.7014 - acc: 0.4969
 704/1387 [==============>...............] - ETA: 48s - loss: 0.6999 - acc: 0.5043
 768/1387 [===============>..............] - ETA: 43s - loss: 0.6996 - acc: 0.5065
 832/1387 [================>.............] - ETA: 39s - loss: 0.7006 - acc: 0.5060
 896/1387 [==================>...........] - ETA: 35s - loss: 0.7011 - acc: 0.5045
 960/1387 [===================>..........] - ETA: 30s - loss: 0.7006 - acc: 0.5052
1024/1387 [=====================>........] - ETA: 26s - loss: 0.7010 - acc: 0.5098
1088/1387 [======================>.......] - ETA: 21s - loss: 0.7008 - acc: 0.5101
1152/1387 [=======================>......] - ETA: 17s - loss: 0.6993 - acc: 0.5148
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6976 - acc: 0.5173
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6968 - acc: 0.5211 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6949 - acc: 0.5223
1387/1387 [==============================] - 105s 76ms/step - loss: 0.6942 - acc: 0.5213 - val_loss: 0.6854 - val_acc: 0.5742

Epoch 00006: val_acc did not improve from 0.60000
Epoch 7/10

  64/1387 [>.............................] - ETA: 1:30 - loss: 0.6797 - acc: 0.5781
 128/1387 [=>............................] - ETA: 1:15 - loss: 0.7074 - acc: 0.5000
 192/1387 [===>..........................] - ETA: 1:14 - loss: 0.6997 - acc: 0.5000
 256/1387 [====>.........................] - ETA: 1:10 - loss: 0.6850 - acc: 0.5430
 320/1387 [=====>........................] - ETA: 1:05 - loss: 0.6828 - acc: 0.5531
 384/1387 [=======>......................] - ETA: 58s - loss: 0.6830 - acc: 0.5573 
 448/1387 [========>.....................] - ETA: 56s - loss: 0.6838 - acc: 0.5469
 512/1387 [==========>...................] - ETA: 54s - loss: 0.6867 - acc: 0.5605
 576/1387 [===========>..................] - ETA: 52s - loss: 0.6897 - acc: 0.5521
 640/1387 [============>.................] - ETA: 48s - loss: 0.6883 - acc: 0.5547
 704/1387 [==============>...............] - ETA: 45s - loss: 0.6892 - acc: 0.5455
 768/1387 [===============>..............] - ETA: 40s - loss: 0.6890 - acc: 0.5469
 832/1387 [================>.............] - ETA: 37s - loss: 0.6877 - acc: 0.5529
 896/1387 [==================>...........] - ETA: 32s - loss: 0.6876 - acc: 0.5525
 960/1387 [===================>..........] - ETA: 28s - loss: 0.6907 - acc: 0.5469
1024/1387 [=====================>........] - ETA: 24s - loss: 0.6926 - acc: 0.5381
1088/1387 [======================>.......] - ETA: 20s - loss: 0.6938 - acc: 0.5331
1152/1387 [=======================>......] - ETA: 15s - loss: 0.6940 - acc: 0.5339
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6932 - acc: 0.5354
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6935 - acc: 0.5352 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6931 - acc: 0.5327
1387/1387 [==============================] - 97s 70ms/step - loss: 0.6939 - acc: 0.5285 - val_loss: 0.6980 - val_acc: 0.4903

Epoch 00007: val_acc did not improve from 0.60000
Epoch 8/10

  64/1387 [>.............................] - ETA: 1:37 - loss: 0.6737 - acc: 0.5938
 128/1387 [=>............................] - ETA: 1:28 - loss: 0.7067 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:24 - loss: 0.6918 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 1:23 - loss: 0.6819 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 1:21 - loss: 0.6781 - acc: 0.5531
 384/1387 [=======>......................] - ETA: 1:18 - loss: 0.6826 - acc: 0.5365
 448/1387 [========>.....................] - ETA: 1:13 - loss: 0.6833 - acc: 0.5491
 512/1387 [==========>...................] - ETA: 1:10 - loss: 0.6846 - acc: 0.5527
 576/1387 [===========>..................] - ETA: 1:04 - loss: 0.6878 - acc: 0.5486
 640/1387 [============>.................] - ETA: 59s - loss: 0.6849 - acc: 0.5484 
 704/1387 [==============>...............] - ETA: 55s - loss: 0.6869 - acc: 0.5412
 768/1387 [===============>..............] - ETA: 49s - loss: 0.6882 - acc: 0.5417
 832/1387 [================>.............] - ETA: 44s - loss: 0.6892 - acc: 0.5349
 896/1387 [==================>...........] - ETA: 39s - loss: 0.6905 - acc: 0.5413
 960/1387 [===================>..........] - ETA: 34s - loss: 0.6877 - acc: 0.5490
1024/1387 [=====================>........] - ETA: 29s - loss: 0.6875 - acc: 0.5479
1088/1387 [======================>.......] - ETA: 24s - loss: 0.6895 - acc: 0.5414
1152/1387 [=======================>......] - ETA: 19s - loss: 0.6883 - acc: 0.5460
1216/1387 [=========================>....] - ETA: 13s - loss: 0.6906 - acc: 0.5387
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6912 - acc: 0.5367 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6918 - acc: 0.5342
1387/1387 [==============================] - 117s 84ms/step - loss: 0.6913 - acc: 0.5371 - val_loss: 0.6878 - val_acc: 0.5742

Epoch 00008: val_acc did not improve from 0.60000
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:36 - loss: 0.6746 - acc: 0.5625
 128/1387 [=>............................] - ETA: 1:32 - loss: 0.6947 - acc: 0.5547
 192/1387 [===>..........................] - ETA: 1:29 - loss: 0.6930 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 1:25 - loss: 0.6898 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 1:19 - loss: 0.6877 - acc: 0.5594
 384/1387 [=======>......................] - ETA: 1:15 - loss: 0.6889 - acc: 0.5443
 448/1387 [========>.....................] - ETA: 1:11 - loss: 0.6864 - acc: 0.5580
 512/1387 [==========>...................] - ETA: 1:06 - loss: 0.6931 - acc: 0.5410
 576/1387 [===========>..................] - ETA: 1:01 - loss: 0.6946 - acc: 0.5330
 640/1387 [============>.................] - ETA: 57s - loss: 0.6959 - acc: 0.5281 
 704/1387 [==============>...............] - ETA: 52s - loss: 0.6949 - acc: 0.5270
 768/1387 [===============>..............] - ETA: 48s - loss: 0.6939 - acc: 0.5365
 832/1387 [================>.............] - ETA: 43s - loss: 0.6998 - acc: 0.5300
 896/1387 [==================>...........] - ETA: 38s - loss: 0.6997 - acc: 0.5324
 960/1387 [===================>..........] - ETA: 33s - loss: 0.7019 - acc: 0.5260
1024/1387 [=====================>........] - ETA: 28s - loss: 0.6997 - acc: 0.5293
1088/1387 [======================>.......] - ETA: 23s - loss: 0.7017 - acc: 0.5257
1152/1387 [=======================>......] - ETA: 18s - loss: 0.7000 - acc: 0.5269
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7001 - acc: 0.5263
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6985 - acc: 0.5273 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6973 - acc: 0.5275
1387/1387 [==============================] - 111s 80ms/step - loss: 0.6971 - acc: 0.5256 - val_loss: 0.7166 - val_acc: 0.4774

Epoch 00009: val_acc did not improve from 0.60000
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:22 - loss: 0.6678 - acc: 0.6406
 128/1387 [=>............................] - ETA: 1:25 - loss: 0.6763 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 1:20 - loss: 0.6938 - acc: 0.5625
 256/1387 [====>.........................] - ETA: 1:14 - loss: 0.6975 - acc: 0.5469
 320/1387 [=====>........................] - ETA: 1:09 - loss: 0.7018 - acc: 0.5375
 384/1387 [=======>......................] - ETA: 1:05 - loss: 0.6973 - acc: 0.5417
 448/1387 [========>.....................] - ETA: 1:02 - loss: 0.6945 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 58s - loss: 0.6889 - acc: 0.5703 
 576/1387 [===========>..................] - ETA: 54s - loss: 0.6901 - acc: 0.5642
 640/1387 [============>.................] - ETA: 50s - loss: 0.6906 - acc: 0.5672
 704/1387 [==============>...............] - ETA: 46s - loss: 0.6887 - acc: 0.5724
 768/1387 [===============>..............] - ETA: 42s - loss: 0.6853 - acc: 0.5703
 832/1387 [================>.............] - ETA: 37s - loss: 0.6853 - acc: 0.5709
 896/1387 [==================>...........] - ETA: 33s - loss: 0.6858 - acc: 0.5658
 960/1387 [===================>..........] - ETA: 29s - loss: 0.6850 - acc: 0.5677
1024/1387 [=====================>........] - ETA: 24s - loss: 0.6847 - acc: 0.5674
1088/1387 [======================>.......] - ETA: 20s - loss: 0.6845 - acc: 0.5680
1152/1387 [=======================>......] - ETA: 15s - loss: 0.6834 - acc: 0.5729
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6824 - acc: 0.5765
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6832 - acc: 0.5727 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6836 - acc: 0.5707
1387/1387 [==============================] - 97s 70ms/step - loss: 0.6828 - acc: 0.5710 - val_loss: 0.6958 - val_acc: 0.5548

Epoch 00010: val_acc did not improve from 0.60000
样本个数 193
样本个数 386
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 14s
128/386 [========>.....................] - ETA: 9s 
192/386 [=============>................] - ETA: 6s
256/386 [==================>...........] - ETA: 4s
320/386 [=======================>......] - ETA: 2s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 13s 33ms/step
loss: 0.6907716884514211
acc: 0.5440414507772021
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fa7384fa6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fa7384fa6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa738523dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa738523dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b65fd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b65fd90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad9ca65e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad9ca65e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fadad4c5fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fadad4c5fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fadad4b6350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fadad4b6350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad9ca65b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad9ca65b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa73855b790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa73855b790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa7386f9050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa7386f9050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa7381dd7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa7381dd7d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa738197550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa738197550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa73838b090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa73838b090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa738063c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa738063c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa73851ed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa73851ed90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa718678e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa718678e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa7381ec550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa7381ec550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa71877b190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa71877b190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa7381f8710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa7381f8710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa7186cf910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa7186cf910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa708220750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa708220750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa7082d0ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa7082d0ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa7186cf9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa7186cf9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa708220750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa708220750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6d87e5ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6d87e5ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6d86c7f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6d86c7f90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa708105210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa708105210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6d87e5ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6d87e5ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6d857c5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6d857c5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6d8732f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6d8732f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6d875af10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6d875af10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6d851c110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6d851c110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6d8732d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6d8732d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa70803b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa70803b550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6d817f110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6d817f110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6d80b8a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6d80b8a10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b876ff10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b876ff10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6d8296390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6d8296390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b8776d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b8776d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6b8657690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6b8657690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6b85fb310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6b85fb310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b83ff290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b83ff290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6b86575d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6b86575d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b8412890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b8412890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6b8568310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6b8568310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6b82ff910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6b82ff910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b828df90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b828df90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa73851d990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa73851d990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b8275850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6b8275850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa698782d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa698782d10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6987beb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa6987beb50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6986d41d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa6986d41d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6987821d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6987821d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa698769610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa698769610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6984f15d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa6984f15d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa69833e3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa69833e3d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa698414ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa698414ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6984f1b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa6984f1b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa698385cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa698385cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa698385c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa698385c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa69811bf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa69811bf50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa698095790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa698095790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa69809f410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa69809f410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa69819d0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa69819d0d0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 5:07 - loss: 0.7062 - acc: 0.5781
 128/1387 [=>............................] - ETA: 3:26 - loss: 0.8019 - acc: 0.5000
 192/1387 [===>..........................] - ETA: 2:50 - loss: 0.7901 - acc: 0.4948
 256/1387 [====>.........................] - ETA: 2:27 - loss: 0.7820 - acc: 0.4922
 320/1387 [=====>........................] - ETA: 2:12 - loss: 0.7754 - acc: 0.4938
 384/1387 [=======>......................] - ETA: 1:59 - loss: 0.7760 - acc: 0.5026
 448/1387 [========>.....................] - ETA: 1:49 - loss: 0.7713 - acc: 0.5000
 512/1387 [==========>...................] - ETA: 1:40 - loss: 0.7589 - acc: 0.5176
 576/1387 [===========>..................] - ETA: 1:30 - loss: 0.7509 - acc: 0.5243
 640/1387 [============>.................] - ETA: 1:22 - loss: 0.7493 - acc: 0.5281
 704/1387 [==============>...............] - ETA: 1:14 - loss: 0.7519 - acc: 0.5227
 768/1387 [===============>..............] - ETA: 1:07 - loss: 0.7491 - acc: 0.5221
 832/1387 [================>.............] - ETA: 59s - loss: 0.7446 - acc: 0.5216 
 896/1387 [==================>...........] - ETA: 52s - loss: 0.7425 - acc: 0.5190
 960/1387 [===================>..........] - ETA: 44s - loss: 0.7411 - acc: 0.5156
1024/1387 [=====================>........] - ETA: 37s - loss: 0.7403 - acc: 0.5176
1088/1387 [======================>.......] - ETA: 30s - loss: 0.7382 - acc: 0.5165
1152/1387 [=======================>......] - ETA: 24s - loss: 0.7384 - acc: 0.5130
1216/1387 [=========================>....] - ETA: 17s - loss: 0.7380 - acc: 0.5090
1280/1387 [==========================>...] - ETA: 10s - loss: 0.7360 - acc: 0.5148
1344/1387 [============================>.] - ETA: 4s - loss: 0.7315 - acc: 0.5201 
1387/1387 [==============================] - 145s 104ms/step - loss: 0.7327 - acc: 0.5169 - val_loss: 0.6932 - val_acc: 0.5613

Epoch 00001: val_acc improved from -inf to 0.56129, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window02/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 1:40 - loss: 0.6991 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:35 - loss: 0.7332 - acc: 0.5000
 192/1387 [===>..........................] - ETA: 1:33 - loss: 0.7128 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 1:27 - loss: 0.7035 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 1:22 - loss: 0.7056 - acc: 0.5500
 384/1387 [=======>......................] - ETA: 1:18 - loss: 0.7149 - acc: 0.5234
 448/1387 [========>.....................] - ETA: 1:13 - loss: 0.7139 - acc: 0.5246
 512/1387 [==========>...................] - ETA: 1:08 - loss: 0.7211 - acc: 0.5137
 576/1387 [===========>..................] - ETA: 1:03 - loss: 0.7167 - acc: 0.5208
 640/1387 [============>.................] - ETA: 58s - loss: 0.7174 - acc: 0.5141 
 704/1387 [==============>...............] - ETA: 53s - loss: 0.7129 - acc: 0.5170
 768/1387 [===============>..............] - ETA: 48s - loss: 0.7132 - acc: 0.5182
 832/1387 [================>.............] - ETA: 43s - loss: 0.7083 - acc: 0.5228
 896/1387 [==================>...........] - ETA: 38s - loss: 0.7149 - acc: 0.5156
 960/1387 [===================>..........] - ETA: 33s - loss: 0.7149 - acc: 0.5208
1024/1387 [=====================>........] - ETA: 28s - loss: 0.7160 - acc: 0.5195
1088/1387 [======================>.......] - ETA: 23s - loss: 0.7163 - acc: 0.5184
1152/1387 [=======================>......] - ETA: 18s - loss: 0.7185 - acc: 0.5174
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7190 - acc: 0.5173
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7192 - acc: 0.5148 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7181 - acc: 0.5179
1387/1387 [==============================] - 115s 83ms/step - loss: 0.7199 - acc: 0.5133 - val_loss: 0.6948 - val_acc: 0.4839

Epoch 00002: val_acc did not improve from 0.56129
Epoch 3/10

  64/1387 [>.............................] - ETA: 1:42 - loss: 0.7240 - acc: 0.6094
 128/1387 [=>............................] - ETA: 1:39 - loss: 0.7308 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 1:34 - loss: 0.7427 - acc: 0.4896
 256/1387 [====>.........................] - ETA: 1:29 - loss: 0.7480 - acc: 0.4648
 320/1387 [=====>........................] - ETA: 1:27 - loss: 0.7520 - acc: 0.4531
 384/1387 [=======>......................] - ETA: 1:21 - loss: 0.7429 - acc: 0.4635
 448/1387 [========>.....................] - ETA: 1:17 - loss: 0.7372 - acc: 0.4754
 512/1387 [==========>...................] - ETA: 1:11 - loss: 0.7304 - acc: 0.4941
 576/1387 [===========>..................] - ETA: 1:06 - loss: 0.7281 - acc: 0.4983
 640/1387 [============>.................] - ETA: 1:00 - loss: 0.7231 - acc: 0.5047
 704/1387 [==============>...............] - ETA: 54s - loss: 0.7200 - acc: 0.5142 
 768/1387 [===============>..............] - ETA: 48s - loss: 0.7174 - acc: 0.5169
 832/1387 [================>.............] - ETA: 43s - loss: 0.7148 - acc: 0.5216
 896/1387 [==================>...........] - ETA: 38s - loss: 0.7089 - acc: 0.5301
 960/1387 [===================>..........] - ETA: 33s - loss: 0.7091 - acc: 0.5312
1024/1387 [=====================>........] - ETA: 28s - loss: 0.7054 - acc: 0.5342
1088/1387 [======================>.......] - ETA: 23s - loss: 0.7078 - acc: 0.5368
1152/1387 [=======================>......] - ETA: 18s - loss: 0.7075 - acc: 0.5347
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7101 - acc: 0.5280
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7081 - acc: 0.5312 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7083 - acc: 0.5290
1387/1387 [==============================] - 112s 81ms/step - loss: 0.7095 - acc: 0.5242 - val_loss: 0.6746 - val_acc: 0.5935

Epoch 00003: val_acc improved from 0.56129 to 0.59355, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window02/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:32 - loss: 0.7049 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:26 - loss: 0.7028 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 1:21 - loss: 0.7060 - acc: 0.5365
 256/1387 [====>.........................] - ETA: 1:17 - loss: 0.6997 - acc: 0.5312
 320/1387 [=====>........................] - ETA: 1:13 - loss: 0.7084 - acc: 0.5031
 384/1387 [=======>......................] - ETA: 1:09 - loss: 0.7035 - acc: 0.5208
 448/1387 [========>.....................] - ETA: 1:04 - loss: 0.7045 - acc: 0.5335
 512/1387 [==========>...................] - ETA: 59s - loss: 0.7064 - acc: 0.5312 
 576/1387 [===========>..................] - ETA: 54s - loss: 0.7053 - acc: 0.5347
 640/1387 [============>.................] - ETA: 50s - loss: 0.7093 - acc: 0.5250
 704/1387 [==============>...............] - ETA: 45s - loss: 0.7043 - acc: 0.5327
 768/1387 [===============>..............] - ETA: 40s - loss: 0.7006 - acc: 0.5391
 832/1387 [================>.............] - ETA: 36s - loss: 0.7068 - acc: 0.5325
 896/1387 [==================>...........] - ETA: 32s - loss: 0.7037 - acc: 0.5402
 960/1387 [===================>..........] - ETA: 28s - loss: 0.7091 - acc: 0.5344
1024/1387 [=====================>........] - ETA: 24s - loss: 0.7095 - acc: 0.5342
1088/1387 [======================>.......] - ETA: 20s - loss: 0.7074 - acc: 0.5386
1152/1387 [=======================>......] - ETA: 15s - loss: 0.7065 - acc: 0.5434
1216/1387 [=========================>....] - ETA: 11s - loss: 0.7044 - acc: 0.5469
1280/1387 [==========================>...] - ETA: 7s - loss: 0.7057 - acc: 0.5437 
1344/1387 [============================>.] - ETA: 2s - loss: 0.7082 - acc: 0.5394
1387/1387 [==============================] - 99s 72ms/step - loss: 0.7093 - acc: 0.5371 - val_loss: 0.6788 - val_acc: 0.5677

Epoch 00004: val_acc did not improve from 0.59355
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:31 - loss: 0.6999 - acc: 0.5156
 128/1387 [=>............................] - ETA: 1:25 - loss: 0.7220 - acc: 0.5156
 192/1387 [===>..........................] - ETA: 1:22 - loss: 0.7194 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 1:16 - loss: 0.7058 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 1:12 - loss: 0.7090 - acc: 0.5344
 384/1387 [=======>......................] - ETA: 1:07 - loss: 0.7143 - acc: 0.5234
 448/1387 [========>.....................] - ETA: 1:03 - loss: 0.7119 - acc: 0.5335
 512/1387 [==========>...................] - ETA: 59s - loss: 0.7091 - acc: 0.5352 
 576/1387 [===========>..................] - ETA: 55s - loss: 0.7064 - acc: 0.5330
 640/1387 [============>.................] - ETA: 50s - loss: 0.7018 - acc: 0.5453
 704/1387 [==============>...............] - ETA: 46s - loss: 0.7043 - acc: 0.5412
 768/1387 [===============>..............] - ETA: 41s - loss: 0.7020 - acc: 0.5482
 832/1387 [================>.............] - ETA: 37s - loss: 0.6995 - acc: 0.5493
 896/1387 [==================>...........] - ETA: 33s - loss: 0.6959 - acc: 0.5580
 960/1387 [===================>..........] - ETA: 29s - loss: 0.6974 - acc: 0.5521
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6951 - acc: 0.5527
1088/1387 [======================>.......] - ETA: 20s - loss: 0.6946 - acc: 0.5542
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6934 - acc: 0.5564
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6936 - acc: 0.5551
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6910 - acc: 0.5594 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6894 - acc: 0.5610
1387/1387 [==============================] - 101s 73ms/step - loss: 0.6898 - acc: 0.5595 - val_loss: 0.6985 - val_acc: 0.5161

Epoch 00005: val_acc did not improve from 0.59355
Epoch 6/10

  64/1387 [>.............................] - ETA: 1:37 - loss: 0.7496 - acc: 0.3906
 128/1387 [=>............................] - ETA: 1:25 - loss: 0.7374 - acc: 0.4297
 192/1387 [===>..........................] - ETA: 1:19 - loss: 0.7243 - acc: 0.4583
 256/1387 [====>.........................] - ETA: 1:16 - loss: 0.7063 - acc: 0.4883
 320/1387 [=====>........................] - ETA: 1:14 - loss: 0.7087 - acc: 0.5000
 384/1387 [=======>......................] - ETA: 1:10 - loss: 0.7031 - acc: 0.5078
 448/1387 [========>.....................] - ETA: 1:05 - loss: 0.7007 - acc: 0.5223
 512/1387 [==========>...................] - ETA: 1:01 - loss: 0.7016 - acc: 0.5273
 576/1387 [===========>..................] - ETA: 56s - loss: 0.7065 - acc: 0.5208 
 640/1387 [============>.................] - ETA: 52s - loss: 0.7120 - acc: 0.5125
 704/1387 [==============>...............] - ETA: 48s - loss: 0.7047 - acc: 0.5256
 768/1387 [===============>..............] - ETA: 43s - loss: 0.7043 - acc: 0.5312
 832/1387 [================>.............] - ETA: 38s - loss: 0.7028 - acc: 0.5325
 896/1387 [==================>...........] - ETA: 34s - loss: 0.6989 - acc: 0.5346
 960/1387 [===================>..........] - ETA: 29s - loss: 0.6987 - acc: 0.5333
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6994 - acc: 0.5371
1088/1387 [======================>.......] - ETA: 20s - loss: 0.6978 - acc: 0.5386
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6967 - acc: 0.5425
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6980 - acc: 0.5395
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6995 - acc: 0.5336 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6979 - acc: 0.5365
1387/1387 [==============================] - 103s 74ms/step - loss: 0.6966 - acc: 0.5386 - val_loss: 0.6848 - val_acc: 0.5355

Epoch 00006: val_acc did not improve from 0.59355
Epoch 7/10

  64/1387 [>.............................] - ETA: 1:31 - loss: 0.7200 - acc: 0.4844
 128/1387 [=>............................] - ETA: 1:34 - loss: 0.7075 - acc: 0.5078
 192/1387 [===>..........................] - ETA: 1:28 - loss: 0.7019 - acc: 0.5156
 256/1387 [====>.........................] - ETA: 1:22 - loss: 0.7190 - acc: 0.4883
 320/1387 [=====>........................] - ETA: 1:16 - loss: 0.7215 - acc: 0.4719
 384/1387 [=======>......................] - ETA: 1:11 - loss: 0.7171 - acc: 0.4844
 448/1387 [========>.....................] - ETA: 1:06 - loss: 0.7172 - acc: 0.4911
 512/1387 [==========>...................] - ETA: 1:01 - loss: 0.7136 - acc: 0.5020
 576/1387 [===========>..................] - ETA: 56s - loss: 0.7099 - acc: 0.5069 
 640/1387 [============>.................] - ETA: 51s - loss: 0.7073 - acc: 0.5172
 704/1387 [==============>...............] - ETA: 47s - loss: 0.7073 - acc: 0.5227
 768/1387 [===============>..............] - ETA: 42s - loss: 0.7082 - acc: 0.5182
 832/1387 [================>.............] - ETA: 38s - loss: 0.7092 - acc: 0.5180
 896/1387 [==================>...........] - ETA: 34s - loss: 0.7058 - acc: 0.5212
 960/1387 [===================>..........] - ETA: 29s - loss: 0.7028 - acc: 0.5281
1024/1387 [=====================>........] - ETA: 25s - loss: 0.7028 - acc: 0.5273
1088/1387 [======================>.......] - ETA: 20s - loss: 0.7021 - acc: 0.5257
1152/1387 [=======================>......] - ETA: 16s - loss: 0.7009 - acc: 0.5312
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6997 - acc: 0.5304
1280/1387 [==========================>...] - ETA: 7s - loss: 0.7009 - acc: 0.5305 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6994 - acc: 0.5335
1387/1387 [==============================] - 101s 73ms/step - loss: 0.7001 - acc: 0.5321 - val_loss: 0.6767 - val_acc: 0.6065

Epoch 00007: val_acc improved from 0.59355 to 0.60645, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window02/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 8/10

  64/1387 [>.............................] - ETA: 1:34 - loss: 0.6841 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:29 - loss: 0.6938 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:30 - loss: 0.6908 - acc: 0.5469
 256/1387 [====>.........................] - ETA: 1:24 - loss: 0.6925 - acc: 0.5352
 320/1387 [=====>........................] - ETA: 1:18 - loss: 0.6958 - acc: 0.5437
 384/1387 [=======>......................] - ETA: 1:14 - loss: 0.6906 - acc: 0.5521
 448/1387 [========>.....................] - ETA: 1:10 - loss: 0.6893 - acc: 0.5580
 512/1387 [==========>...................] - ETA: 1:06 - loss: 0.6906 - acc: 0.5527
 576/1387 [===========>..................] - ETA: 1:01 - loss: 0.6958 - acc: 0.5399
 640/1387 [============>.................] - ETA: 57s - loss: 0.6981 - acc: 0.5312 
 704/1387 [==============>...............] - ETA: 52s - loss: 0.6957 - acc: 0.5341
 768/1387 [===============>..............] - ETA: 47s - loss: 0.6955 - acc: 0.5365
 832/1387 [================>.............] - ETA: 42s - loss: 0.6932 - acc: 0.5385
 896/1387 [==================>...........] - ETA: 37s - loss: 0.6938 - acc: 0.5368
 960/1387 [===================>..........] - ETA: 33s - loss: 0.6934 - acc: 0.5344
1024/1387 [=====================>........] - ETA: 28s - loss: 0.6918 - acc: 0.5410
1088/1387 [======================>.......] - ETA: 23s - loss: 0.6903 - acc: 0.5432
1152/1387 [=======================>......] - ETA: 18s - loss: 0.6909 - acc: 0.5382
1216/1387 [=========================>....] - ETA: 13s - loss: 0.6920 - acc: 0.5354
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6921 - acc: 0.5352 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6921 - acc: 0.5305
1387/1387 [==============================] - 114s 82ms/step - loss: 0.6919 - acc: 0.5335 - val_loss: 0.6770 - val_acc: 0.5935

Epoch 00008: val_acc did not improve from 0.60645
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:48 - loss: 0.6828 - acc: 0.5938
 128/1387 [=>............................] - ETA: 1:35 - loss: 0.6921 - acc: 0.5859
 192/1387 [===>..........................] - ETA: 1:32 - loss: 0.6921 - acc: 0.5781
 256/1387 [====>.........................] - ETA: 1:27 - loss: 0.6965 - acc: 0.5508
 320/1387 [=====>........................] - ETA: 1:24 - loss: 0.6965 - acc: 0.5375
 384/1387 [=======>......................] - ETA: 1:17 - loss: 0.6936 - acc: 0.5495
 448/1387 [========>.....................] - ETA: 1:13 - loss: 0.6908 - acc: 0.5536
 512/1387 [==========>...................] - ETA: 1:08 - loss: 0.6932 - acc: 0.5566
 576/1387 [===========>..................] - ETA: 1:03 - loss: 0.6867 - acc: 0.5660
 640/1387 [============>.................] - ETA: 58s - loss: 0.6901 - acc: 0.5578 
 704/1387 [==============>...............] - ETA: 53s - loss: 0.6870 - acc: 0.5639
 768/1387 [===============>..............] - ETA: 48s - loss: 0.6881 - acc: 0.5625
 832/1387 [================>.............] - ETA: 43s - loss: 0.6872 - acc: 0.5625
 896/1387 [==================>...........] - ETA: 38s - loss: 0.6892 - acc: 0.5603
 960/1387 [===================>..........] - ETA: 33s - loss: 0.6885 - acc: 0.5604
1024/1387 [=====================>........] - ETA: 28s - loss: 0.6926 - acc: 0.5557
1088/1387 [======================>.......] - ETA: 23s - loss: 0.6927 - acc: 0.5542
1152/1387 [=======================>......] - ETA: 18s - loss: 0.6941 - acc: 0.5521
1216/1387 [=========================>....] - ETA: 13s - loss: 0.6945 - acc: 0.5502
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6954 - acc: 0.5477 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6953 - acc: 0.5439
1387/1387 [==============================] - 114s 82ms/step - loss: 0.6940 - acc: 0.5458 - val_loss: 0.6770 - val_acc: 0.5935

Epoch 00009: val_acc did not improve from 0.60645
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:51 - loss: 0.6732 - acc: 0.5781
 128/1387 [=>............................] - ETA: 1:39 - loss: 0.6797 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 1:36 - loss: 0.6822 - acc: 0.5938
 256/1387 [====>.........................] - ETA: 1:32 - loss: 0.6761 - acc: 0.6016
 320/1387 [=====>........................] - ETA: 1:26 - loss: 0.6747 - acc: 0.6062
 384/1387 [=======>......................] - ETA: 1:20 - loss: 0.6771 - acc: 0.5990
 448/1387 [========>.....................] - ETA: 1:16 - loss: 0.6787 - acc: 0.5960
 512/1387 [==========>...................] - ETA: 1:11 - loss: 0.6831 - acc: 0.5801
 576/1387 [===========>..................] - ETA: 1:05 - loss: 0.6862 - acc: 0.5642
 640/1387 [============>.................] - ETA: 1:00 - loss: 0.6849 - acc: 0.5687
 704/1387 [==============>...............] - ETA: 54s - loss: 0.6872 - acc: 0.5625 
 768/1387 [===============>..............] - ETA: 48s - loss: 0.6871 - acc: 0.5612
 832/1387 [================>.............] - ETA: 43s - loss: 0.6880 - acc: 0.5601
 896/1387 [==================>...........] - ETA: 37s - loss: 0.6868 - acc: 0.5580
 960/1387 [===================>..........] - ETA: 32s - loss: 0.6885 - acc: 0.5594
1024/1387 [=====================>........] - ETA: 27s - loss: 0.6846 - acc: 0.5684
1088/1387 [======================>.......] - ETA: 22s - loss: 0.6847 - acc: 0.5699
1152/1387 [=======================>......] - ETA: 17s - loss: 0.6843 - acc: 0.5703
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6847 - acc: 0.5683
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6834 - acc: 0.5703 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6831 - acc: 0.5707
1387/1387 [==============================] - 104s 75ms/step - loss: 0.6821 - acc: 0.5710 - val_loss: 0.6747 - val_acc: 0.5871

Epoch 00010: val_acc did not improve from 0.60645
样本个数 193
样本个数 386
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 19s
128/386 [========>.....................] - ETA: 11s
192/386 [=============>................] - ETA: 7s 
256/386 [==================>...........] - ETA: 4s
320/386 [=======================>......] - ETA: 2s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 14s 37ms/step
loss: 0.6758513327089616
acc: 0.5854922279792746
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fa5f827af90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fa5f827af90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa5f82a1910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa5f82a1910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b65fb50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad8b65fb50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad94006090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad94006090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad9ca950d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad9ca950d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad940d6490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad940d6490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad94006fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad94006fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5f81109d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5f81109d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa5d8784c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa5d8784c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5d8777690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5d8777690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5d87d3150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5d87d3150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa5f8128ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa5f8128ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5d8764a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5d8764a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa5d848ed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa5d848ed90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5d855dd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5d855dd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5d849cb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5d849cb90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa5d855db90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa5d855db90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5c0169cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5c0169cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa5d83edc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa5d83edc50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5f82e7990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5f82e7990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5c00d4e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5c00d4e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa5d83edfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa5d83edfd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa59c632c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa59c632c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa59c745710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa59c745710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa59c518390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa59c518390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa59c503a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa59c503a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa59c745e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa59c745e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa59c56b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa59c56b3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa59c224d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa59c224d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa59c763290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa59c763290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa59c219550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa59c219550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa59c29ca50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa59c29ca50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa59c114350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa59c114350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa578719d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa578719d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5786e3e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5786e3e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad9ca95cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad9ca95cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa59c19aed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa59c19aed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5786e3a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5786e3a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa57867ffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa57867ffd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5783b07d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5783b07d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa578285210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa578285210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa57838b1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa57838b1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5783b0450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5783b0450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa578048910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa578048910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa55877e950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa55877e950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5587f7410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5587f7410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa578048310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa578048310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa55875e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa55875e350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa558717690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa558717690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa55871c4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa55871c4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa558590dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa558590dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa55851f210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa55851f210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5583bc050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5583bc050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa558409cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa558409cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5580ddf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5580ddf50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa558476d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa558476d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa5584a0c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa5584a0c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5581afe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5581afe10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa558222ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa558222ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5386ec0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa5386ec0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5386bde50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5386bde50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa558222550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa558222550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa558114e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa558114e50>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 5:04 - loss: 0.7171 - acc: 0.5156
 128/1387 [=>............................] - ETA: 3:10 - loss: 0.7484 - acc: 0.5000
 192/1387 [===>..........................] - ETA: 2:27 - loss: 0.7438 - acc: 0.5104
 256/1387 [====>.........................] - ETA: 2:04 - loss: 0.7422 - acc: 0.5039
 320/1387 [=====>........................] - ETA: 1:49 - loss: 0.7289 - acc: 0.5125
 384/1387 [=======>......................] - ETA: 1:38 - loss: 0.7239 - acc: 0.5234
 448/1387 [========>.....................] - ETA: 1:29 - loss: 0.7210 - acc: 0.5290
 512/1387 [==========>...................] - ETA: 1:21 - loss: 0.7179 - acc: 0.5352
 576/1387 [===========>..................] - ETA: 1:14 - loss: 0.7197 - acc: 0.5399
 640/1387 [============>.................] - ETA: 1:08 - loss: 0.7225 - acc: 0.5422
 704/1387 [==============>...............] - ETA: 1:02 - loss: 0.7249 - acc: 0.5384
 768/1387 [===============>..............] - ETA: 56s - loss: 0.7256 - acc: 0.5430 
 832/1387 [================>.............] - ETA: 50s - loss: 0.7235 - acc: 0.5409
 896/1387 [==================>...........] - ETA: 43s - loss: 0.7244 - acc: 0.5391
 960/1387 [===================>..........] - ETA: 37s - loss: 0.7243 - acc: 0.5375
1024/1387 [=====================>........] - ETA: 32s - loss: 0.7243 - acc: 0.5361
1088/1387 [======================>.......] - ETA: 26s - loss: 0.7243 - acc: 0.5358
1152/1387 [=======================>......] - ETA: 20s - loss: 0.7269 - acc: 0.5321
1216/1387 [=========================>....] - ETA: 14s - loss: 0.7267 - acc: 0.5345
1280/1387 [==========================>...] - ETA: 9s - loss: 0.7246 - acc: 0.5383 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7252 - acc: 0.5350
1387/1387 [==============================] - 127s 91ms/step - loss: 0.7264 - acc: 0.5328 - val_loss: 0.6996 - val_acc: 0.5548

Epoch 00001: val_acc improved from -inf to 0.55484, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window03/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 1:40 - loss: 0.6684 - acc: 0.5938
 128/1387 [=>............................] - ETA: 1:36 - loss: 0.6994 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 1:34 - loss: 0.6953 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 1:28 - loss: 0.6931 - acc: 0.5625
 320/1387 [=====>........................] - ETA: 1:25 - loss: 0.6967 - acc: 0.5656
 384/1387 [=======>......................] - ETA: 1:20 - loss: 0.7026 - acc: 0.5625
 448/1387 [========>.....................] - ETA: 1:15 - loss: 0.6965 - acc: 0.5737
 512/1387 [==========>...................] - ETA: 1:10 - loss: 0.6969 - acc: 0.5684
 576/1387 [===========>..................] - ETA: 1:04 - loss: 0.7031 - acc: 0.5608
 640/1387 [============>.................] - ETA: 59s - loss: 0.7056 - acc: 0.5531 
 704/1387 [==============>...............] - ETA: 54s - loss: 0.7049 - acc: 0.5483
 768/1387 [===============>..............] - ETA: 49s - loss: 0.7064 - acc: 0.5456
 832/1387 [================>.............] - ETA: 44s - loss: 0.7041 - acc: 0.5457
 896/1387 [==================>...........] - ETA: 39s - loss: 0.7044 - acc: 0.5469
 960/1387 [===================>..........] - ETA: 34s - loss: 0.7027 - acc: 0.5469
1024/1387 [=====================>........] - ETA: 29s - loss: 0.7005 - acc: 0.5498
1088/1387 [======================>.......] - ETA: 24s - loss: 0.7012 - acc: 0.5460
1152/1387 [=======================>......] - ETA: 18s - loss: 0.7009 - acc: 0.5477
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7018 - acc: 0.5493
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7051 - acc: 0.5437 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7041 - acc: 0.5484
1387/1387 [==============================] - 117s 84ms/step - loss: 0.7045 - acc: 0.5487 - val_loss: 0.6827 - val_acc: 0.5677

Epoch 00002: val_acc improved from 0.55484 to 0.56774, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window03/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 1:40 - loss: 0.6393 - acc: 0.6094
 128/1387 [=>............................] - ETA: 1:37 - loss: 0.6827 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 1:35 - loss: 0.6870 - acc: 0.5573
 256/1387 [====>.........................] - ETA: 1:31 - loss: 0.6931 - acc: 0.5664
 320/1387 [=====>........................] - ETA: 1:24 - loss: 0.7038 - acc: 0.5531
 384/1387 [=======>......................] - ETA: 1:19 - loss: 0.7002 - acc: 0.5443
 448/1387 [========>.....................] - ETA: 1:15 - loss: 0.7037 - acc: 0.5379
 512/1387 [==========>...................] - ETA: 1:10 - loss: 0.7068 - acc: 0.5410
 576/1387 [===========>..................] - ETA: 1:04 - loss: 0.7043 - acc: 0.5573
 640/1387 [============>.................] - ETA: 59s - loss: 0.7006 - acc: 0.5609 
 704/1387 [==============>...............] - ETA: 54s - loss: 0.7018 - acc: 0.5568
 768/1387 [===============>..............] - ETA: 49s - loss: 0.6994 - acc: 0.5495
 832/1387 [================>.............] - ETA: 44s - loss: 0.6959 - acc: 0.5553
 896/1387 [==================>...........] - ETA: 39s - loss: 0.6977 - acc: 0.5569
 960/1387 [===================>..........] - ETA: 34s - loss: 0.6951 - acc: 0.5615
1024/1387 [=====================>........] - ETA: 29s - loss: 0.6972 - acc: 0.5586
1088/1387 [======================>.......] - ETA: 23s - loss: 0.7014 - acc: 0.5542
1152/1387 [=======================>......] - ETA: 18s - loss: 0.7013 - acc: 0.5503
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7021 - acc: 0.5502
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7023 - acc: 0.5484 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7027 - acc: 0.5499
1387/1387 [==============================] - 115s 83ms/step - loss: 0.7033 - acc: 0.5465 - val_loss: 0.6814 - val_acc: 0.5871

Epoch 00003: val_acc improved from 0.56774 to 0.58710, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window03/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:32 - loss: 0.6728 - acc: 0.6094
 128/1387 [=>............................] - ETA: 1:24 - loss: 0.6577 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 1:24 - loss: 0.6647 - acc: 0.6042
 256/1387 [====>.........................] - ETA: 1:17 - loss: 0.6798 - acc: 0.5703
 320/1387 [=====>........................] - ETA: 1:15 - loss: 0.6803 - acc: 0.5656
 384/1387 [=======>......................] - ETA: 1:11 - loss: 0.6819 - acc: 0.5703
 448/1387 [========>.....................] - ETA: 1:06 - loss: 0.6764 - acc: 0.5915
 512/1387 [==========>...................] - ETA: 1:02 - loss: 0.6803 - acc: 0.5742
 576/1387 [===========>..................] - ETA: 58s - loss: 0.6807 - acc: 0.5764 
 640/1387 [============>.................] - ETA: 53s - loss: 0.6821 - acc: 0.5687
 704/1387 [==============>...............] - ETA: 49s - loss: 0.6817 - acc: 0.5724
 768/1387 [===============>..............] - ETA: 44s - loss: 0.6829 - acc: 0.5703
 832/1387 [================>.............] - ETA: 40s - loss: 0.6879 - acc: 0.5649
 896/1387 [==================>...........] - ETA: 35s - loss: 0.6886 - acc: 0.5670
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6889 - acc: 0.5635
1024/1387 [=====================>........] - ETA: 26s - loss: 0.6873 - acc: 0.5664
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6866 - acc: 0.5671
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6902 - acc: 0.5625
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6904 - acc: 0.5625
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6878 - acc: 0.5664 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6881 - acc: 0.5647
1387/1387 [==============================] - 106s 77ms/step - loss: 0.6888 - acc: 0.5631 - val_loss: 0.6852 - val_acc: 0.5871

Epoch 00004: val_acc improved from 0.58710 to 0.58710, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window03/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:44 - loss: 0.6914 - acc: 0.5156
 128/1387 [=>............................] - ETA: 1:36 - loss: 0.6664 - acc: 0.5859
 192/1387 [===>..........................] - ETA: 1:32 - loss: 0.6774 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 1:27 - loss: 0.6630 - acc: 0.5977
 320/1387 [=====>........................] - ETA: 1:22 - loss: 0.6704 - acc: 0.5969
 384/1387 [=======>......................] - ETA: 1:17 - loss: 0.6745 - acc: 0.5911
 448/1387 [========>.....................] - ETA: 1:10 - loss: 0.6782 - acc: 0.5848
 512/1387 [==========>...................] - ETA: 1:06 - loss: 0.6893 - acc: 0.5586
 576/1387 [===========>..................] - ETA: 1:00 - loss: 0.6904 - acc: 0.5573
 640/1387 [============>.................] - ETA: 55s - loss: 0.6909 - acc: 0.5547 
 704/1387 [==============>...............] - ETA: 51s - loss: 0.6900 - acc: 0.5582
 768/1387 [===============>..............] - ETA: 45s - loss: 0.6860 - acc: 0.5651
 832/1387 [================>.............] - ETA: 41s - loss: 0.6884 - acc: 0.5625
 896/1387 [==================>...........] - ETA: 36s - loss: 0.6916 - acc: 0.5525
 960/1387 [===================>..........] - ETA: 31s - loss: 0.6918 - acc: 0.5521
1024/1387 [=====================>........] - ETA: 26s - loss: 0.6922 - acc: 0.5469
1088/1387 [======================>.......] - ETA: 22s - loss: 0.6902 - acc: 0.5496
1152/1387 [=======================>......] - ETA: 17s - loss: 0.6891 - acc: 0.5521
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6886 - acc: 0.5510
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6882 - acc: 0.5547 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6905 - acc: 0.5528
1387/1387 [==============================] - 108s 78ms/step - loss: 0.6911 - acc: 0.5508 - val_loss: 0.6744 - val_acc: 0.6129

Epoch 00005: val_acc improved from 0.58710 to 0.61290, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window03/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1387 [>.............................] - ETA: 1:40 - loss: 0.6818 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:32 - loss: 0.7028 - acc: 0.4766
 192/1387 [===>..........................] - ETA: 1:23 - loss: 0.6895 - acc: 0.4948
 256/1387 [====>.........................] - ETA: 1:16 - loss: 0.6885 - acc: 0.5156
 320/1387 [=====>........................] - ETA: 1:10 - loss: 0.6929 - acc: 0.5094
 384/1387 [=======>......................] - ETA: 1:06 - loss: 0.6913 - acc: 0.5078
 448/1387 [========>.....................] - ETA: 1:00 - loss: 0.6875 - acc: 0.5223
 512/1387 [==========>...................] - ETA: 57s - loss: 0.6903 - acc: 0.5195 
 576/1387 [===========>..................] - ETA: 52s - loss: 0.6862 - acc: 0.5347
 640/1387 [============>.................] - ETA: 48s - loss: 0.6854 - acc: 0.5422
 704/1387 [==============>...............] - ETA: 44s - loss: 0.6869 - acc: 0.5426
 768/1387 [===============>..............] - ETA: 40s - loss: 0.6889 - acc: 0.5391
 832/1387 [================>.............] - ETA: 35s - loss: 0.6879 - acc: 0.5433
 896/1387 [==================>...........] - ETA: 32s - loss: 0.6875 - acc: 0.5391
 960/1387 [===================>..........] - ETA: 27s - loss: 0.6904 - acc: 0.5354
1024/1387 [=====================>........] - ETA: 23s - loss: 0.6907 - acc: 0.5352
1088/1387 [======================>.......] - ETA: 19s - loss: 0.6898 - acc: 0.5322
1152/1387 [=======================>......] - ETA: 15s - loss: 0.6893 - acc: 0.5347
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6899 - acc: 0.5321
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6870 - acc: 0.5398 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6842 - acc: 0.5454
1387/1387 [==============================] - 95s 68ms/step - loss: 0.6830 - acc: 0.5494 - val_loss: 0.6745 - val_acc: 0.6065

Epoch 00006: val_acc did not improve from 0.61290
Epoch 7/10

  64/1387 [>.............................] - ETA: 1:37 - loss: 0.7428 - acc: 0.4844
 128/1387 [=>............................] - ETA: 1:38 - loss: 0.6816 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 1:27 - loss: 0.6707 - acc: 0.5990
 256/1387 [====>.........................] - ETA: 1:20 - loss: 0.6757 - acc: 0.6133
 320/1387 [=====>........................] - ETA: 1:14 - loss: 0.6880 - acc: 0.5875
 384/1387 [=======>......................] - ETA: 1:08 - loss: 0.6801 - acc: 0.6068
 448/1387 [========>.....................] - ETA: 1:02 - loss: 0.6842 - acc: 0.6004
 512/1387 [==========>...................] - ETA: 57s - loss: 0.6798 - acc: 0.6055 
 576/1387 [===========>..................] - ETA: 53s - loss: 0.6838 - acc: 0.5990
 640/1387 [============>.................] - ETA: 48s - loss: 0.6839 - acc: 0.5906
 704/1387 [==============>...............] - ETA: 44s - loss: 0.6823 - acc: 0.5895
 768/1387 [===============>..............] - ETA: 40s - loss: 0.6777 - acc: 0.5924
 832/1387 [================>.............] - ETA: 36s - loss: 0.6803 - acc: 0.5889
 896/1387 [==================>...........] - ETA: 32s - loss: 0.6809 - acc: 0.5826
 960/1387 [===================>..........] - ETA: 27s - loss: 0.6807 - acc: 0.5802
1024/1387 [=====================>........] - ETA: 23s - loss: 0.6800 - acc: 0.5840
1088/1387 [======================>.......] - ETA: 19s - loss: 0.6808 - acc: 0.5818
1152/1387 [=======================>......] - ETA: 15s - loss: 0.6792 - acc: 0.5816
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6789 - acc: 0.5814
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6801 - acc: 0.5773 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6845 - acc: 0.5751
1387/1387 [==============================] - 94s 68ms/step - loss: 0.6837 - acc: 0.5768 - val_loss: 0.6975 - val_acc: 0.5548

Epoch 00007: val_acc did not improve from 0.61290
Epoch 8/10

  64/1387 [>.............................] - ETA: 1:26 - loss: 0.6460 - acc: 0.6406
 128/1387 [=>............................] - ETA: 1:23 - loss: 0.6638 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 1:18 - loss: 0.6771 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 1:16 - loss: 0.6838 - acc: 0.5469
 320/1387 [=====>........................] - ETA: 1:11 - loss: 0.6844 - acc: 0.5469
 384/1387 [=======>......................] - ETA: 1:06 - loss: 0.6900 - acc: 0.5417
 448/1387 [========>.....................] - ETA: 1:02 - loss: 0.6870 - acc: 0.5402
 512/1387 [==========>...................] - ETA: 58s - loss: 0.6850 - acc: 0.5566 
 576/1387 [===========>..................] - ETA: 53s - loss: 0.6812 - acc: 0.5694
 640/1387 [============>.................] - ETA: 49s - loss: 0.6845 - acc: 0.5641
 704/1387 [==============>...............] - ETA: 45s - loss: 0.6819 - acc: 0.5682
 768/1387 [===============>..............] - ETA: 41s - loss: 0.6818 - acc: 0.5729
 832/1387 [================>.............] - ETA: 37s - loss: 0.6817 - acc: 0.5745
 896/1387 [==================>...........] - ETA: 32s - loss: 0.6782 - acc: 0.5837
 960/1387 [===================>..........] - ETA: 28s - loss: 0.6766 - acc: 0.5865
1024/1387 [=====================>........] - ETA: 24s - loss: 0.6775 - acc: 0.5859
1088/1387 [======================>.......] - ETA: 20s - loss: 0.6774 - acc: 0.5836
1152/1387 [=======================>......] - ETA: 15s - loss: 0.6799 - acc: 0.5807
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6819 - acc: 0.5748
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6821 - acc: 0.5742 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6823 - acc: 0.5744
1387/1387 [==============================] - 98s 71ms/step - loss: 0.6828 - acc: 0.5717 - val_loss: 0.6783 - val_acc: 0.6129

Epoch 00008: val_acc did not improve from 0.61290
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:21 - loss: 0.6906 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:16 - loss: 0.6850 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 1:12 - loss: 0.6883 - acc: 0.5521
 256/1387 [====>.........................] - ETA: 1:08 - loss: 0.6860 - acc: 0.5625
 320/1387 [=====>........................] - ETA: 1:04 - loss: 0.6835 - acc: 0.5594
 384/1387 [=======>......................] - ETA: 1:01 - loss: 0.6803 - acc: 0.5599
 448/1387 [========>.....................] - ETA: 57s - loss: 0.6821 - acc: 0.5625 
 512/1387 [==========>...................] - ETA: 54s - loss: 0.6787 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 50s - loss: 0.6756 - acc: 0.5660
 640/1387 [============>.................] - ETA: 46s - loss: 0.6772 - acc: 0.5641
 704/1387 [==============>...............] - ETA: 42s - loss: 0.6748 - acc: 0.5739
 768/1387 [===============>..............] - ETA: 38s - loss: 0.6801 - acc: 0.5625
 832/1387 [================>.............] - ETA: 34s - loss: 0.6786 - acc: 0.5661
 896/1387 [==================>...........] - ETA: 30s - loss: 0.6792 - acc: 0.5670
 960/1387 [===================>..........] - ETA: 26s - loss: 0.6784 - acc: 0.5677
1024/1387 [=====================>........] - ETA: 22s - loss: 0.6807 - acc: 0.5684
1088/1387 [======================>.......] - ETA: 18s - loss: 0.6777 - acc: 0.5699
1152/1387 [=======================>......] - ETA: 14s - loss: 0.6796 - acc: 0.5668
1216/1387 [=========================>....] - ETA: 10s - loss: 0.6782 - acc: 0.5674
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6764 - acc: 0.5703 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6780 - acc: 0.5640
1387/1387 [==============================] - 93s 67ms/step - loss: 0.6773 - acc: 0.5667 - val_loss: 0.6731 - val_acc: 0.6000

Epoch 00009: val_acc did not improve from 0.61290
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:23 - loss: 0.7277 - acc: 0.5000
 128/1387 [=>............................] - ETA: 1:15 - loss: 0.7033 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 1:14 - loss: 0.6908 - acc: 0.5938
 256/1387 [====>.........................] - ETA: 1:08 - loss: 0.6993 - acc: 0.5625
 320/1387 [=====>........................] - ETA: 1:06 - loss: 0.6960 - acc: 0.5594
 384/1387 [=======>......................] - ETA: 1:03 - loss: 0.6976 - acc: 0.5573
 448/1387 [========>.....................] - ETA: 59s - loss: 0.6939 - acc: 0.5580 
 512/1387 [==========>...................] - ETA: 55s - loss: 0.6929 - acc: 0.5527
 576/1387 [===========>..................] - ETA: 51s - loss: 0.6956 - acc: 0.5469
 640/1387 [============>.................] - ETA: 47s - loss: 0.6946 - acc: 0.5469
 704/1387 [==============>...............] - ETA: 43s - loss: 0.6945 - acc: 0.5440
 768/1387 [===============>..............] - ETA: 40s - loss: 0.6938 - acc: 0.5482
 832/1387 [================>.............] - ETA: 35s - loss: 0.6904 - acc: 0.5529
 896/1387 [==================>...........] - ETA: 31s - loss: 0.6877 - acc: 0.5614
 960/1387 [===================>..........] - ETA: 27s - loss: 0.6866 - acc: 0.5625
1024/1387 [=====================>........] - ETA: 23s - loss: 0.6853 - acc: 0.5654
1088/1387 [======================>.......] - ETA: 19s - loss: 0.6863 - acc: 0.5634
1152/1387 [=======================>......] - ETA: 15s - loss: 0.6859 - acc: 0.5660
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6869 - acc: 0.5666
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6859 - acc: 0.5687 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6838 - acc: 0.5737
1387/1387 [==============================] - 99s 71ms/step - loss: 0.6848 - acc: 0.5732 - val_loss: 0.6739 - val_acc: 0.6000

Epoch 00010: val_acc did not improve from 0.61290
样本个数 193
样本个数 386
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 19s
128/386 [========>.....................] - ETA: 10s
192/386 [=============>................] - ETA: 6s 
256/386 [==================>...........] - ETA: 3s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 10s 26ms/step
loss: 0.684307936559687
acc: 0.5569948186528497
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fa4987d9990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fa4987d9990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa49873b3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa49873b3d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad60bf30d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad60bf30d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad8b65f4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fad8b65f4d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa49874ded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa49874ded0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa49872f3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa49872f3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad8b65f310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fad8b65f310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad9408b350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad9408b350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa4984e7910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa4984e7910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa49850e890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa49850e890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4982f4710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4982f4710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa4984e7890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa4984e7890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5386c4d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa5386c4d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa498191590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa498191590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa498105950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa498105950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa498223750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa498223750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa498191a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa498191a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa49817f2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa49817f2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa45858acd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa45858acd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa458494510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa458494510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa458629550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa458629550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa4981f3650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa4981f3650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa45848a750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa45848a750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa458251d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa458251d10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa458295a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa458295a10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4582d1390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4582d1390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa458251490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa458251490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4581b5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4581b5090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa458239210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa458239210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa4385c4ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa4385c4ad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa458159810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa458159810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa4387eb8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa4387eb8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4385bd1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4385bd1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa4384dc1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa4384dc1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa43838ab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa43838ab10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4383b5090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4383b5090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa43869e050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa43869e050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa43848cad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa43848cad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa4382e3990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa4382e3990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa4381bbd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa4381bbd90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4380fded0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4380fded0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa43812c910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa43812c910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa41873cf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa41873cf50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa49873c890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa49873c890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa41844ed90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa41844ed90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa41834be50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa41834be50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa418635ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa418635ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa41848d9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa41848d9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa418299390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa418299390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa41816c9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa41816c9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa418169450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa418169450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa418299050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa418299050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4187f8fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa4187f8fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3f86bb050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3f86bb050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3f85ca410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3f85ca410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3f860e310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3f860e310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3f86bba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3f86bba50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3f85ca410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3f85ca410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3f83d21d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3f83d21d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3f846db90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3f846db90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3f85c4d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3f85c4d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3f86aad50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3f86aad50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3f8182350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3f8182350>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 5:43 - loss: 0.6699 - acc: 0.6250
 128/1387 [=>............................] - ETA: 3:28 - loss: 0.7323 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 2:43 - loss: 0.7291 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 2:17 - loss: 0.7235 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 2:00 - loss: 0.7170 - acc: 0.5563
 384/1387 [=======>......................] - ETA: 1:47 - loss: 0.7181 - acc: 0.5651
 448/1387 [========>.....................] - ETA: 1:36 - loss: 0.7224 - acc: 0.5536
 512/1387 [==========>...................] - ETA: 1:26 - loss: 0.7241 - acc: 0.5488
 576/1387 [===========>..................] - ETA: 1:18 - loss: 0.7298 - acc: 0.5503
 640/1387 [============>.................] - ETA: 1:10 - loss: 0.7244 - acc: 0.5484
 704/1387 [==============>...............] - ETA: 1:03 - loss: 0.7273 - acc: 0.5384
 768/1387 [===============>..............] - ETA: 56s - loss: 0.7250 - acc: 0.5391 
 832/1387 [================>.............] - ETA: 50s - loss: 0.7245 - acc: 0.5409
 896/1387 [==================>...........] - ETA: 44s - loss: 0.7272 - acc: 0.5290
 960/1387 [===================>..........] - ETA: 38s - loss: 0.7247 - acc: 0.5333
1024/1387 [=====================>........] - ETA: 32s - loss: 0.7251 - acc: 0.5303
1088/1387 [======================>.......] - ETA: 26s - loss: 0.7244 - acc: 0.5294
1152/1387 [=======================>......] - ETA: 20s - loss: 0.7215 - acc: 0.5295
1216/1387 [=========================>....] - ETA: 14s - loss: 0.7256 - acc: 0.5238
1280/1387 [==========================>...] - ETA: 9s - loss: 0.7265 - acc: 0.5203 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7260 - acc: 0.5223
1387/1387 [==============================] - 125s 90ms/step - loss: 0.7264 - acc: 0.5213 - val_loss: 0.6863 - val_acc: 0.6000

Epoch 00001: val_acc improved from -inf to 0.60000, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window04/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 1:42 - loss: 0.7375 - acc: 0.5156
 128/1387 [=>............................] - ETA: 1:37 - loss: 0.7293 - acc: 0.4922
 192/1387 [===>..........................] - ETA: 1:28 - loss: 0.7463 - acc: 0.5000
 256/1387 [====>.........................] - ETA: 1:26 - loss: 0.7280 - acc: 0.5195
 320/1387 [=====>........................] - ETA: 1:20 - loss: 0.7173 - acc: 0.5312
 384/1387 [=======>......................] - ETA: 1:16 - loss: 0.7130 - acc: 0.5339
 448/1387 [========>.....................] - ETA: 1:12 - loss: 0.7071 - acc: 0.5513
 512/1387 [==========>...................] - ETA: 1:07 - loss: 0.7051 - acc: 0.5508
 576/1387 [===========>..................] - ETA: 1:02 - loss: 0.7055 - acc: 0.5469
 640/1387 [============>.................] - ETA: 57s - loss: 0.7087 - acc: 0.5391 
 704/1387 [==============>...............] - ETA: 52s - loss: 0.7104 - acc: 0.5384
 768/1387 [===============>..............] - ETA: 47s - loss: 0.7031 - acc: 0.5456
 832/1387 [================>.............] - ETA: 42s - loss: 0.7082 - acc: 0.5397
 896/1387 [==================>...........] - ETA: 37s - loss: 0.7053 - acc: 0.5435
 960/1387 [===================>..........] - ETA: 32s - loss: 0.7063 - acc: 0.5406
1024/1387 [=====================>........] - ETA: 27s - loss: 0.7024 - acc: 0.5449
1088/1387 [======================>.......] - ETA: 22s - loss: 0.7001 - acc: 0.5515
1152/1387 [=======================>......] - ETA: 17s - loss: 0.7004 - acc: 0.5521
1216/1387 [=========================>....] - ETA: 12s - loss: 0.7032 - acc: 0.5493
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7086 - acc: 0.5437 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7109 - acc: 0.5387
1387/1387 [==============================] - 110s 80ms/step - loss: 0.7099 - acc: 0.5386 - val_loss: 0.7039 - val_acc: 0.5806

Epoch 00002: val_acc did not improve from 0.60000
Epoch 3/10

  64/1387 [>.............................] - ETA: 1:58 - loss: 0.7147 - acc: 0.4688
 128/1387 [=>............................] - ETA: 1:46 - loss: 0.7142 - acc: 0.5078
 192/1387 [===>..........................] - ETA: 1:42 - loss: 0.7141 - acc: 0.4948
 256/1387 [====>.........................] - ETA: 1:33 - loss: 0.7121 - acc: 0.4961
 320/1387 [=====>........................] - ETA: 1:27 - loss: 0.7010 - acc: 0.5094
 384/1387 [=======>......................] - ETA: 1:22 - loss: 0.6959 - acc: 0.5234
 448/1387 [========>.....................] - ETA: 1:17 - loss: 0.6986 - acc: 0.5112
 512/1387 [==========>...................] - ETA: 1:12 - loss: 0.6945 - acc: 0.5195
 576/1387 [===========>..................] - ETA: 1:07 - loss: 0.6938 - acc: 0.5208
 640/1387 [============>.................] - ETA: 1:01 - loss: 0.6999 - acc: 0.5141
 704/1387 [==============>...............] - ETA: 56s - loss: 0.7036 - acc: 0.5128 
 768/1387 [===============>..............] - ETA: 51s - loss: 0.7037 - acc: 0.5143
 832/1387 [================>.............] - ETA: 45s - loss: 0.7040 - acc: 0.5144
 896/1387 [==================>...........] - ETA: 40s - loss: 0.7072 - acc: 0.5089
 960/1387 [===================>..........] - ETA: 34s - loss: 0.7076 - acc: 0.5135
1024/1387 [=====================>........] - ETA: 29s - loss: 0.7060 - acc: 0.5146
1088/1387 [======================>.......] - ETA: 24s - loss: 0.7051 - acc: 0.5202
1152/1387 [=======================>......] - ETA: 19s - loss: 0.7050 - acc: 0.5165
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7050 - acc: 0.5197
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7031 - acc: 0.5227 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7009 - acc: 0.5253
1387/1387 [==============================] - 116s 84ms/step - loss: 0.7011 - acc: 0.5278 - val_loss: 0.6905 - val_acc: 0.5742

Epoch 00003: val_acc did not improve from 0.60000
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:40 - loss: 0.7127 - acc: 0.5156
 128/1387 [=>............................] - ETA: 1:35 - loss: 0.6887 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 1:32 - loss: 0.6962 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 1:28 - loss: 0.7037 - acc: 0.5469
 320/1387 [=====>........................] - ETA: 1:23 - loss: 0.6962 - acc: 0.5469
 384/1387 [=======>......................] - ETA: 1:18 - loss: 0.6929 - acc: 0.5547
 448/1387 [========>.....................] - ETA: 1:12 - loss: 0.6964 - acc: 0.5491
 512/1387 [==========>...................] - ETA: 1:06 - loss: 0.7016 - acc: 0.5391
 576/1387 [===========>..................] - ETA: 1:00 - loss: 0.7005 - acc: 0.5451
 640/1387 [============>.................] - ETA: 55s - loss: 0.6989 - acc: 0.5469 
 704/1387 [==============>...............] - ETA: 50s - loss: 0.6958 - acc: 0.5483
 768/1387 [===============>..............] - ETA: 45s - loss: 0.6955 - acc: 0.5469
 832/1387 [================>.............] - ETA: 40s - loss: 0.6908 - acc: 0.5505
 896/1387 [==================>...........] - ETA: 36s - loss: 0.6891 - acc: 0.5491
 960/1387 [===================>..........] - ETA: 31s - loss: 0.6921 - acc: 0.5469
1024/1387 [=====================>........] - ETA: 27s - loss: 0.6921 - acc: 0.5498
1088/1387 [======================>.......] - ETA: 22s - loss: 0.6915 - acc: 0.5496
1152/1387 [=======================>......] - ETA: 17s - loss: 0.6913 - acc: 0.5530
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6931 - acc: 0.5493
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6916 - acc: 0.5516 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6928 - acc: 0.5491
1387/1387 [==============================] - 106s 77ms/step - loss: 0.6938 - acc: 0.5479 - val_loss: 0.6820 - val_acc: 0.5742

Epoch 00004: val_acc did not improve from 0.60000
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:37 - loss: 0.6939 - acc: 0.4844
 128/1387 [=>............................] - ETA: 1:28 - loss: 0.7001 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:19 - loss: 0.7040 - acc: 0.5260
 256/1387 [====>.........................] - ETA: 1:18 - loss: 0.7082 - acc: 0.5195
 320/1387 [=====>........................] - ETA: 1:12 - loss: 0.7113 - acc: 0.5156
 384/1387 [=======>......................] - ETA: 1:10 - loss: 0.7070 - acc: 0.5208
 448/1387 [========>.....................] - ETA: 1:06 - loss: 0.7101 - acc: 0.5156
 512/1387 [==========>...................] - ETA: 1:01 - loss: 0.7120 - acc: 0.5098
 576/1387 [===========>..................] - ETA: 56s - loss: 0.7109 - acc: 0.5156 
 640/1387 [============>.................] - ETA: 51s - loss: 0.7090 - acc: 0.5172
 704/1387 [==============>...............] - ETA: 47s - loss: 0.7018 - acc: 0.5355
 768/1387 [===============>..............] - ETA: 42s - loss: 0.7011 - acc: 0.5352
 832/1387 [================>.............] - ETA: 38s - loss: 0.6997 - acc: 0.5337
 896/1387 [==================>...........] - ETA: 33s - loss: 0.6995 - acc: 0.5312
 960/1387 [===================>..........] - ETA: 29s - loss: 0.7001 - acc: 0.5333
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6981 - acc: 0.5352
1088/1387 [======================>.......] - ETA: 20s - loss: 0.6959 - acc: 0.5395
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6981 - acc: 0.5330
1216/1387 [=========================>....] - ETA: 11s - loss: 0.7036 - acc: 0.5255
1280/1387 [==========================>...] - ETA: 7s - loss: 0.7045 - acc: 0.5234 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7064 - acc: 0.5208
1387/1387 [==============================] - 103s 74ms/step - loss: 0.7042 - acc: 0.5249 - val_loss: 0.6799 - val_acc: 0.5871

Epoch 00005: val_acc did not improve from 0.60000
Epoch 6/10

  64/1387 [>.............................] - ETA: 1:27 - loss: 0.6833 - acc: 0.5625
 128/1387 [=>............................] - ETA: 1:28 - loss: 0.6762 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 1:25 - loss: 0.6833 - acc: 0.5833
 256/1387 [====>.........................] - ETA: 1:22 - loss: 0.6899 - acc: 0.5469
 320/1387 [=====>........................] - ETA: 1:16 - loss: 0.6874 - acc: 0.5531
 384/1387 [=======>......................] - ETA: 1:12 - loss: 0.6875 - acc: 0.5495
 448/1387 [========>.....................] - ETA: 1:07 - loss: 0.6890 - acc: 0.5491
 512/1387 [==========>...................] - ETA: 1:02 - loss: 0.6821 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 57s - loss: 0.6826 - acc: 0.5660 
 640/1387 [============>.................] - ETA: 53s - loss: 0.6854 - acc: 0.5578
 704/1387 [==============>...............] - ETA: 48s - loss: 0.6863 - acc: 0.5582
 768/1387 [===============>..............] - ETA: 44s - loss: 0.6870 - acc: 0.5482
 832/1387 [================>.............] - ETA: 39s - loss: 0.6850 - acc: 0.5493
 896/1387 [==================>...........] - ETA: 34s - loss: 0.6866 - acc: 0.5446
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6843 - acc: 0.5510
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6846 - acc: 0.5479
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6850 - acc: 0.5469
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6850 - acc: 0.5460
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6844 - acc: 0.5461
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6846 - acc: 0.5461 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6853 - acc: 0.5461
1387/1387 [==============================] - 104s 75ms/step - loss: 0.6835 - acc: 0.5516 - val_loss: 0.6872 - val_acc: 0.5935

Epoch 00006: val_acc did not improve from 0.60000
Epoch 7/10

  64/1387 [>.............................] - ETA: 1:40 - loss: 0.6583 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:30 - loss: 0.6593 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 1:23 - loss: 0.6612 - acc: 0.6302
 256/1387 [====>.........................] - ETA: 1:20 - loss: 0.6736 - acc: 0.6094
 320/1387 [=====>........................] - ETA: 1:15 - loss: 0.6699 - acc: 0.6156
 384/1387 [=======>......................] - ETA: 1:09 - loss: 0.6694 - acc: 0.6146
 448/1387 [========>.....................] - ETA: 1:05 - loss: 0.6775 - acc: 0.5938
 512/1387 [==========>...................] - ETA: 1:00 - loss: 0.6756 - acc: 0.6016
 576/1387 [===========>..................] - ETA: 56s - loss: 0.6726 - acc: 0.6059 
 640/1387 [============>.................] - ETA: 52s - loss: 0.6732 - acc: 0.6047
 704/1387 [==============>...............] - ETA: 48s - loss: 0.6752 - acc: 0.5994
 768/1387 [===============>..............] - ETA: 43s - loss: 0.6707 - acc: 0.6081
 832/1387 [================>.............] - ETA: 39s - loss: 0.6749 - acc: 0.5974
 896/1387 [==================>...........] - ETA: 35s - loss: 0.6759 - acc: 0.5949
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6770 - acc: 0.5896
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6764 - acc: 0.5918
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6768 - acc: 0.5947
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6783 - acc: 0.5938
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6786 - acc: 0.5921
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6805 - acc: 0.5867 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6824 - acc: 0.5811
1387/1387 [==============================] - 96s 70ms/step - loss: 0.6815 - acc: 0.5833 - val_loss: 0.6821 - val_acc: 0.5677

Epoch 00007: val_acc did not improve from 0.60000
Epoch 8/10

  64/1387 [>.............................] - ETA: 1:06 - loss: 0.6375 - acc: 0.6406
 128/1387 [=>............................] - ETA: 58s - loss: 0.6748 - acc: 0.6172 
 192/1387 [===>..........................] - ETA: 1:01 - loss: 0.6781 - acc: 0.5885
 256/1387 [====>.........................] - ETA: 58s - loss: 0.6835 - acc: 0.5781 
 320/1387 [=====>........................] - ETA: 57s - loss: 0.6881 - acc: 0.5563
 384/1387 [=======>......................] - ETA: 56s - loss: 0.6851 - acc: 0.5573
 448/1387 [========>.....................] - ETA: 53s - loss: 0.6876 - acc: 0.5513
 512/1387 [==========>...................] - ETA: 49s - loss: 0.6904 - acc: 0.5332
 576/1387 [===========>..................] - ETA: 45s - loss: 0.6932 - acc: 0.5260
 640/1387 [============>.................] - ETA: 41s - loss: 0.6912 - acc: 0.5328
 704/1387 [==============>...............] - ETA: 37s - loss: 0.6949 - acc: 0.5256
 768/1387 [===============>..............] - ETA: 34s - loss: 0.6961 - acc: 0.5247
 832/1387 [================>.............] - ETA: 31s - loss: 0.6981 - acc: 0.5192
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6983 - acc: 0.5179
 960/1387 [===================>..........] - ETA: 23s - loss: 0.6964 - acc: 0.5229
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6933 - acc: 0.5283
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6943 - acc: 0.5257
1152/1387 [=======================>......] - ETA: 12s - loss: 0.6957 - acc: 0.5260
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6958 - acc: 0.5255 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6934 - acc: 0.5312
1344/1387 [============================>.] - ETA: 2s - loss: 0.6929 - acc: 0.5320
1387/1387 [==============================] - 78s 56ms/step - loss: 0.6939 - acc: 0.5299 - val_loss: 0.6787 - val_acc: 0.5935

Epoch 00008: val_acc did not improve from 0.60000
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:08 - loss: 0.6731 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:07 - loss: 0.6659 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 1:02 - loss: 0.6637 - acc: 0.5781
 256/1387 [====>.........................] - ETA: 56s - loss: 0.6657 - acc: 0.5859 
 320/1387 [=====>........................] - ETA: 53s - loss: 0.6685 - acc: 0.5938
 384/1387 [=======>......................] - ETA: 50s - loss: 0.6699 - acc: 0.5807
 448/1387 [========>.....................] - ETA: 47s - loss: 0.6671 - acc: 0.5871
 512/1387 [==========>...................] - ETA: 43s - loss: 0.6699 - acc: 0.5879
 576/1387 [===========>..................] - ETA: 41s - loss: 0.6711 - acc: 0.5885
 640/1387 [============>.................] - ETA: 38s - loss: 0.6761 - acc: 0.5781
 704/1387 [==============>...............] - ETA: 34s - loss: 0.6798 - acc: 0.5682
 768/1387 [===============>..............] - ETA: 31s - loss: 0.6768 - acc: 0.5742
 832/1387 [================>.............] - ETA: 28s - loss: 0.6762 - acc: 0.5721
 896/1387 [==================>...........] - ETA: 24s - loss: 0.6759 - acc: 0.5748
 960/1387 [===================>..........] - ETA: 21s - loss: 0.6741 - acc: 0.5823
1024/1387 [=====================>........] - ETA: 18s - loss: 0.6756 - acc: 0.5781
1088/1387 [======================>.......] - ETA: 15s - loss: 0.6749 - acc: 0.5790
1152/1387 [=======================>......] - ETA: 12s - loss: 0.6770 - acc: 0.5773
1216/1387 [=========================>....] - ETA: 8s - loss: 0.6780 - acc: 0.5765 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6797 - acc: 0.5742
1344/1387 [============================>.] - ETA: 2s - loss: 0.6820 - acc: 0.5722
1387/1387 [==============================] - 76s 54ms/step - loss: 0.6816 - acc: 0.5717 - val_loss: 0.6836 - val_acc: 0.5806

Epoch 00009: val_acc did not improve from 0.60000
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:27 - loss: 0.7033 - acc: 0.5625
 128/1387 [=>............................] - ETA: 1:18 - loss: 0.7064 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 1:08 - loss: 0.7034 - acc: 0.5365
 256/1387 [====>.........................] - ETA: 1:06 - loss: 0.6933 - acc: 0.5508
 320/1387 [=====>........................] - ETA: 1:01 - loss: 0.6908 - acc: 0.5563
 384/1387 [=======>......................] - ETA: 57s - loss: 0.6841 - acc: 0.5677 
 448/1387 [========>.....................] - ETA: 54s - loss: 0.6804 - acc: 0.5714
 512/1387 [==========>...................] - ETA: 51s - loss: 0.6818 - acc: 0.5703
 576/1387 [===========>..................] - ETA: 46s - loss: 0.6816 - acc: 0.5712
 640/1387 [============>.................] - ETA: 42s - loss: 0.6825 - acc: 0.5703
 704/1387 [==============>...............] - ETA: 38s - loss: 0.6848 - acc: 0.5668
 768/1387 [===============>..............] - ETA: 35s - loss: 0.6815 - acc: 0.5703
 832/1387 [================>.............] - ETA: 31s - loss: 0.6824 - acc: 0.5709
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6810 - acc: 0.5725
 960/1387 [===================>..........] - ETA: 23s - loss: 0.6838 - acc: 0.5698
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6836 - acc: 0.5664
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6845 - acc: 0.5634
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6811 - acc: 0.5677
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6830 - acc: 0.5666 
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6839 - acc: 0.5625
1344/1387 [============================>.] - ETA: 2s - loss: 0.6847 - acc: 0.5588
1387/1387 [==============================] - 83s 60ms/step - loss: 0.6845 - acc: 0.5580 - val_loss: 0.6885 - val_acc: 0.5419

Epoch 00010: val_acc did not improve from 0.60000
样本个数 193
样本个数 386
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 26s
128/386 [========>.....................] - ETA: 13s
192/386 [=============>................] - ETA: 8s 
256/386 [==================>...........] - ETA: 4s
320/386 [=======================>......] - ETA: 2s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 13s 34ms/step
loss: 0.6953812139639582
acc: 0.5466321243523317
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fa3704eb6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7fa3704eb6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa37052d910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fa37052d910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad60bb6050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fad60bb6050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa33858efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa33858efd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad60bbee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fad60bbee10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3304ef590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3304ef590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3304eff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa3304eff90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3704afcd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3704afcd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa370267e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa370267e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa370297c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa370297c50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa43842eb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa43842eb10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa370267dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa370267dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3701f3110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3701f3110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa370162790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa370162790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3386a5b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3386a5b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa338747f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa338747f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa33877cd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa33877cd50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3700717d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3700717d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa338645810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa338645810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3302f3e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3302f3e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3301db5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3301db5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa33027d5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa33027d5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3302e3d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3302e3d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3187a2590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa3187a2590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa31871b210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa31871b210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa318796cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa318796cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa330083690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa330083690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa31863f550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa31863f550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa318544550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa318544550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3183c6dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3183c6dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa318442190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa318442190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa318544e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa318544e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa318450110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa318450110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa31815f750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa31815f750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3180d81d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa3180d81d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3180e0d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3180e0d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa31823aed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa31823aed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2dc71e910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2dc71e910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa2dc6555d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa2dc6555d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa318130d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa318130d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa318152650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa318152650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa2dc6b3e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa2dc6b3e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2dc3e3150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2dc3e3150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa2dc5afd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa2dc5afd90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa2dc17ea10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa2dc17ea10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2dc2f9ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2dc2f9ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa2dc302050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa2dc302050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2dc4bd210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2dc4bd210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa2b87cca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa2b87cca90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa2b878ae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa2b878ae10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2b87dc090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2b87dc090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa2dc049b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa2dc049b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2b855fbd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2b855fbd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa2b86977d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa2b86977d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa2b8449f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa2b8449f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3187f0dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa3187f0dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa2b8697d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa2b8697d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2b8343d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2b8343d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa2b83afdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fa2b83afdd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa2987da9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7fa2987da9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2b816ac90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2b816ac90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa2dc0cec90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fa2dc0cec90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2b8069410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fa2b8069410>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 6:30 - loss: 0.7463 - acc: 0.5312
 128/1387 [=>............................] - ETA: 3:49 - loss: 0.7005 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 2:53 - loss: 0.7193 - acc: 0.5938
 256/1387 [====>.........................] - ETA: 2:23 - loss: 0.7203 - acc: 0.5781
 320/1387 [=====>........................] - ETA: 2:04 - loss: 0.7340 - acc: 0.5594
 384/1387 [=======>......................] - ETA: 1:49 - loss: 0.7200 - acc: 0.5703
 448/1387 [========>.....................] - ETA: 1:36 - loss: 0.7188 - acc: 0.5670
 512/1387 [==========>...................] - ETA: 1:25 - loss: 0.7236 - acc: 0.5566
 576/1387 [===========>..................] - ETA: 1:15 - loss: 0.7287 - acc: 0.5486
 640/1387 [============>.................] - ETA: 1:06 - loss: 0.7276 - acc: 0.5469
 704/1387 [==============>...............] - ETA: 58s - loss: 0.7235 - acc: 0.5511 
 768/1387 [===============>..............] - ETA: 51s - loss: 0.7313 - acc: 0.5443
 832/1387 [================>.............] - ETA: 45s - loss: 0.7304 - acc: 0.5481
 896/1387 [==================>...........] - ETA: 39s - loss: 0.7305 - acc: 0.5446
 960/1387 [===================>..........] - ETA: 34s - loss: 0.7267 - acc: 0.5500
1024/1387 [=====================>........] - ETA: 28s - loss: 0.7228 - acc: 0.5508
1088/1387 [======================>.......] - ETA: 23s - loss: 0.7220 - acc: 0.5496
1152/1387 [=======================>......] - ETA: 18s - loss: 0.7211 - acc: 0.5477
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7201 - acc: 0.5469
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7211 - acc: 0.5430 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7213 - acc: 0.5424
1387/1387 [==============================] - 111s 80ms/step - loss: 0.7196 - acc: 0.5436 - val_loss: 0.6925 - val_acc: 0.5097

Epoch 00001: val_acc improved from -inf to 0.50968, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window05/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 1:18 - loss: 0.6692 - acc: 0.5938
 128/1387 [=>............................] - ETA: 1:25 - loss: 0.6932 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:16 - loss: 0.7058 - acc: 0.5365
 256/1387 [====>.........................] - ETA: 1:12 - loss: 0.7121 - acc: 0.5156
 320/1387 [=====>........................] - ETA: 1:07 - loss: 0.7066 - acc: 0.5312
 384/1387 [=======>......................] - ETA: 1:04 - loss: 0.7097 - acc: 0.5182
 448/1387 [========>.....................] - ETA: 1:00 - loss: 0.7062 - acc: 0.5268
 512/1387 [==========>...................] - ETA: 56s - loss: 0.7023 - acc: 0.5273 
 576/1387 [===========>..................] - ETA: 51s - loss: 0.7093 - acc: 0.5226
 640/1387 [============>.................] - ETA: 47s - loss: 0.7090 - acc: 0.5203
 704/1387 [==============>...............] - ETA: 43s - loss: 0.7070 - acc: 0.5213
 768/1387 [===============>..............] - ETA: 38s - loss: 0.7061 - acc: 0.5247
 832/1387 [================>.............] - ETA: 34s - loss: 0.7047 - acc: 0.5349
 896/1387 [==================>...........] - ETA: 30s - loss: 0.7056 - acc: 0.5335
 960/1387 [===================>..........] - ETA: 26s - loss: 0.7074 - acc: 0.5333
1024/1387 [=====================>........] - ETA: 22s - loss: 0.7126 - acc: 0.5264
1088/1387 [======================>.......] - ETA: 18s - loss: 0.7078 - acc: 0.5312
1152/1387 [=======================>......] - ETA: 14s - loss: 0.7096 - acc: 0.5339
1216/1387 [=========================>....] - ETA: 10s - loss: 0.7090 - acc: 0.5362
1280/1387 [==========================>...] - ETA: 6s - loss: 0.7084 - acc: 0.5367 
1344/1387 [============================>.] - ETA: 2s - loss: 0.7112 - acc: 0.5327
1387/1387 [==============================] - 92s 66ms/step - loss: 0.7122 - acc: 0.5335 - val_loss: 0.6894 - val_acc: 0.5742

Epoch 00002: val_acc improved from 0.50968 to 0.57419, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window05/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 1:33 - loss: 0.6951 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:32 - loss: 0.6906 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:24 - loss: 0.6931 - acc: 0.5260
 256/1387 [====>.........................] - ETA: 1:18 - loss: 0.6980 - acc: 0.5195
 320/1387 [=====>........................] - ETA: 1:11 - loss: 0.7097 - acc: 0.5031
 384/1387 [=======>......................] - ETA: 1:07 - loss: 0.7116 - acc: 0.5156
 448/1387 [========>.....................] - ETA: 1:02 - loss: 0.7050 - acc: 0.5290
 512/1387 [==========>...................] - ETA: 58s - loss: 0.7054 - acc: 0.5215 
 576/1387 [===========>..................] - ETA: 54s - loss: 0.7045 - acc: 0.5191
 640/1387 [============>.................] - ETA: 50s - loss: 0.7061 - acc: 0.5141
 704/1387 [==============>...............] - ETA: 45s - loss: 0.7044 - acc: 0.5170
 768/1387 [===============>..............] - ETA: 41s - loss: 0.7070 - acc: 0.5052
 832/1387 [================>.............] - ETA: 37s - loss: 0.7055 - acc: 0.5072
 896/1387 [==================>...........] - ETA: 32s - loss: 0.7016 - acc: 0.5156
 960/1387 [===================>..........] - ETA: 28s - loss: 0.7009 - acc: 0.5188
1024/1387 [=====================>........] - ETA: 23s - loss: 0.7003 - acc: 0.5195
1088/1387 [======================>.......] - ETA: 19s - loss: 0.6975 - acc: 0.5294
1152/1387 [=======================>......] - ETA: 15s - loss: 0.6982 - acc: 0.5304
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6974 - acc: 0.5329
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6988 - acc: 0.5305 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6995 - acc: 0.5305
1387/1387 [==============================] - 96s 69ms/step - loss: 0.6989 - acc: 0.5292 - val_loss: 0.6890 - val_acc: 0.5871

Epoch 00003: val_acc improved from 0.57419 to 0.58710, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window05/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:20 - loss: 0.6620 - acc: 0.6094
 128/1387 [=>............................] - ETA: 1:20 - loss: 0.6638 - acc: 0.6172
 192/1387 [===>..........................] - ETA: 1:17 - loss: 0.6639 - acc: 0.5938
 256/1387 [====>.........................] - ETA: 1:13 - loss: 0.6836 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 1:08 - loss: 0.6792 - acc: 0.5656
 384/1387 [=======>......................] - ETA: 1:06 - loss: 0.6781 - acc: 0.5625
 448/1387 [========>.....................] - ETA: 1:01 - loss: 0.6749 - acc: 0.5737
 512/1387 [==========>...................] - ETA: 56s - loss: 0.6827 - acc: 0.5605 
 576/1387 [===========>..................] - ETA: 53s - loss: 0.6866 - acc: 0.5625
 640/1387 [============>.................] - ETA: 49s - loss: 0.6864 - acc: 0.5625
 704/1387 [==============>...............] - ETA: 44s - loss: 0.6878 - acc: 0.5597
 768/1387 [===============>..............] - ETA: 40s - loss: 0.6842 - acc: 0.5638
 832/1387 [================>.............] - ETA: 36s - loss: 0.6836 - acc: 0.5601
 896/1387 [==================>...........] - ETA: 31s - loss: 0.6881 - acc: 0.5525
 960/1387 [===================>..........] - ETA: 28s - loss: 0.6892 - acc: 0.5531
1024/1387 [=====================>........] - ETA: 23s - loss: 0.6880 - acc: 0.5576
1088/1387 [======================>.......] - ETA: 19s - loss: 0.6898 - acc: 0.5570
1152/1387 [=======================>......] - ETA: 15s - loss: 0.6899 - acc: 0.5556
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6913 - acc: 0.5551
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6912 - acc: 0.5563 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6912 - acc: 0.5558
1387/1387 [==============================] - 94s 68ms/step - loss: 0.6915 - acc: 0.5566 - val_loss: 0.6956 - val_acc: 0.5677

Epoch 00004: val_acc did not improve from 0.58710
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:26 - loss: 0.7043 - acc: 0.5938
 128/1387 [=>............................] - ETA: 1:17 - loss: 0.6673 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 1:16 - loss: 0.6717 - acc: 0.5938
 256/1387 [====>.........................] - ETA: 1:12 - loss: 0.6791 - acc: 0.5781
 320/1387 [=====>........................] - ETA: 1:05 - loss: 0.6788 - acc: 0.5781
 384/1387 [=======>......................] - ETA: 58s - loss: 0.6775 - acc: 0.5859 
 448/1387 [========>.....................] - ETA: 53s - loss: 0.6879 - acc: 0.5759
 512/1387 [==========>...................] - ETA: 49s - loss: 0.6847 - acc: 0.5840
 576/1387 [===========>..................] - ETA: 45s - loss: 0.6792 - acc: 0.5868
 640/1387 [============>.................] - ETA: 41s - loss: 0.6834 - acc: 0.5781
 704/1387 [==============>...............] - ETA: 38s - loss: 0.6875 - acc: 0.5668
 768/1387 [===============>..............] - ETA: 34s - loss: 0.6856 - acc: 0.5755
 832/1387 [================>.............] - ETA: 30s - loss: 0.6866 - acc: 0.5721
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6845 - acc: 0.5737
 960/1387 [===================>..........] - ETA: 23s - loss: 0.6842 - acc: 0.5719
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6829 - acc: 0.5723
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6833 - acc: 0.5735
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6845 - acc: 0.5703
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6840 - acc: 0.5699 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6849 - acc: 0.5719
1344/1387 [============================>.] - ETA: 2s - loss: 0.6856 - acc: 0.5729
1387/1387 [==============================] - 81s 58ms/step - loss: 0.6845 - acc: 0.5739 - val_loss: 0.6935 - val_acc: 0.5742

Epoch 00005: val_acc did not improve from 0.58710
Epoch 6/10

  64/1387 [>.............................] - ETA: 1:11 - loss: 0.7030 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:12 - loss: 0.6733 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 1:07 - loss: 0.6898 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 1:05 - loss: 0.6963 - acc: 0.5352
 320/1387 [=====>........................] - ETA: 1:01 - loss: 0.6955 - acc: 0.5281
 384/1387 [=======>......................] - ETA: 58s - loss: 0.6865 - acc: 0.5521 
 448/1387 [========>.....................] - ETA: 54s - loss: 0.6859 - acc: 0.5469
 512/1387 [==========>...................] - ETA: 50s - loss: 0.6846 - acc: 0.5508
 576/1387 [===========>..................] - ETA: 47s - loss: 0.6905 - acc: 0.5330
 640/1387 [============>.................] - ETA: 43s - loss: 0.6946 - acc: 0.5297
 704/1387 [==============>...............] - ETA: 39s - loss: 0.6935 - acc: 0.5298
 768/1387 [===============>..............] - ETA: 36s - loss: 0.6921 - acc: 0.5326
 832/1387 [================>.............] - ETA: 32s - loss: 0.6930 - acc: 0.5373
 896/1387 [==================>...........] - ETA: 28s - loss: 0.6921 - acc: 0.5402
 960/1387 [===================>..........] - ETA: 24s - loss: 0.6915 - acc: 0.5396
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6917 - acc: 0.5381
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6919 - acc: 0.5377
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6914 - acc: 0.5425
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6905 - acc: 0.5469 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6902 - acc: 0.5477
1344/1387 [============================>.] - ETA: 2s - loss: 0.6923 - acc: 0.5446
1387/1387 [==============================] - 82s 59ms/step - loss: 0.6929 - acc: 0.5415 - val_loss: 0.6940 - val_acc: 0.5677

Epoch 00006: val_acc did not improve from 0.58710
Epoch 7/10

  64/1387 [>.............................] - ETA: 1:07 - loss: 0.6591 - acc: 0.6094
 128/1387 [=>............................] - ETA: 1:04 - loss: 0.6593 - acc: 0.6172
 192/1387 [===>..........................] - ETA: 1:03 - loss: 0.6648 - acc: 0.6146
 256/1387 [====>.........................] - ETA: 1:01 - loss: 0.6667 - acc: 0.6133
 320/1387 [=====>........................] - ETA: 57s - loss: 0.6755 - acc: 0.6000 
 384/1387 [=======>......................] - ETA: 54s - loss: 0.6663 - acc: 0.6120
 448/1387 [========>.....................] - ETA: 52s - loss: 0.6662 - acc: 0.6071
 512/1387 [==========>...................] - ETA: 48s - loss: 0.6781 - acc: 0.5898
 576/1387 [===========>..................] - ETA: 46s - loss: 0.6764 - acc: 0.5955
 640/1387 [============>.................] - ETA: 42s - loss: 0.6796 - acc: 0.5922
 704/1387 [==============>...............] - ETA: 38s - loss: 0.6801 - acc: 0.5881
 768/1387 [===============>..............] - ETA: 35s - loss: 0.6829 - acc: 0.5807
 832/1387 [================>.............] - ETA: 31s - loss: 0.6812 - acc: 0.5805
 896/1387 [==================>...........] - ETA: 28s - loss: 0.6804 - acc: 0.5815
 960/1387 [===================>..........] - ETA: 24s - loss: 0.6820 - acc: 0.5813
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6821 - acc: 0.5791
1088/1387 [======================>.......] - ETA: 17s - loss: 0.6795 - acc: 0.5809
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6818 - acc: 0.5773
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6832 - acc: 0.5715 
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6837 - acc: 0.5695
1344/1387 [============================>.] - ETA: 2s - loss: 0.6851 - acc: 0.5677
1387/1387 [==============================] - 83s 60ms/step - loss: 0.6861 - acc: 0.5645 - val_loss: 0.6871 - val_acc: 0.5806

Epoch 00007: val_acc did not improve from 0.58710
Epoch 8/10

  64/1387 [>.............................] - ETA: 1:10 - loss: 0.7156 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:10 - loss: 0.7305 - acc: 0.4922
 192/1387 [===>..........................] - ETA: 1:04 - loss: 0.7122 - acc: 0.5156
 256/1387 [====>.........................] - ETA: 1:01 - loss: 0.7059 - acc: 0.5391
 320/1387 [=====>........................] - ETA: 57s - loss: 0.6917 - acc: 0.5563 
 384/1387 [=======>......................] - ETA: 54s - loss: 0.6922 - acc: 0.5495
 448/1387 [========>.....................] - ETA: 50s - loss: 0.6962 - acc: 0.5446
 512/1387 [==========>...................] - ETA: 46s - loss: 0.6930 - acc: 0.5469
 576/1387 [===========>..................] - ETA: 44s - loss: 0.6901 - acc: 0.5521
 640/1387 [============>.................] - ETA: 40s - loss: 0.6878 - acc: 0.5563
 704/1387 [==============>...............] - ETA: 37s - loss: 0.6853 - acc: 0.5611
 768/1387 [===============>..............] - ETA: 34s - loss: 0.6855 - acc: 0.5638
 832/1387 [================>.............] - ETA: 30s - loss: 0.6871 - acc: 0.5601
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6907 - acc: 0.5580
 960/1387 [===================>..........] - ETA: 23s - loss: 0.6895 - acc: 0.5604
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6912 - acc: 0.5596
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6924 - acc: 0.5542
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6927 - acc: 0.5547
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6944 - acc: 0.5510 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6945 - acc: 0.5516
1344/1387 [============================>.] - ETA: 2s - loss: 0.6929 - acc: 0.5551
1387/1387 [==============================] - 80s 58ms/step - loss: 0.6927 - acc: 0.5537 - val_loss: 0.6983 - val_acc: 0.5613

Epoch 00008: val_acc did not improve from 0.58710
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:20 - loss: 0.6634 - acc: 0.6875
 128/1387 [=>............................] - ETA: 1:11 - loss: 0.6655 - acc: 0.6250
 192/1387 [===>..........................] - ETA: 1:05 - loss: 0.6656 - acc: 0.6198
 256/1387 [====>.........................] - ETA: 1:03 - loss: 0.6676 - acc: 0.5938
 320/1387 [=====>........................] - ETA: 59s - loss: 0.6619 - acc: 0.6062 
 384/1387 [=======>......................] - ETA: 55s - loss: 0.6662 - acc: 0.5938
 448/1387 [========>.....................] - ETA: 52s - loss: 0.6678 - acc: 0.5804
 512/1387 [==========>...................] - ETA: 49s - loss: 0.6652 - acc: 0.5859
 576/1387 [===========>..................] - ETA: 45s - loss: 0.6664 - acc: 0.5816
 640/1387 [============>.................] - ETA: 41s - loss: 0.6674 - acc: 0.5766
 704/1387 [==============>...............] - ETA: 38s - loss: 0.6679 - acc: 0.5795
 768/1387 [===============>..............] - ETA: 34s - loss: 0.6657 - acc: 0.5820
 832/1387 [================>.............] - ETA: 31s - loss: 0.6653 - acc: 0.5829
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6661 - acc: 0.5848
 960/1387 [===================>..........] - ETA: 23s - loss: 0.6684 - acc: 0.5823
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6688 - acc: 0.5850
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6697 - acc: 0.5873
1152/1387 [=======================>......] - ETA: 12s - loss: 0.6718 - acc: 0.5790
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6743 - acc: 0.5765 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6750 - acc: 0.5758
1344/1387 [============================>.] - ETA: 2s - loss: 0.6757 - acc: 0.5737
1387/1387 [==============================] - 80s 58ms/step - loss: 0.6767 - acc: 0.5681 - val_loss: 0.6862 - val_acc: 0.5806

Epoch 00009: val_acc did not improve from 0.58710
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:22 - loss: 0.7187 - acc: 0.4531
 128/1387 [=>............................] - ETA: 1:13 - loss: 0.7216 - acc: 0.4531
 192/1387 [===>..........................] - ETA: 1:09 - loss: 0.7033 - acc: 0.5000
 256/1387 [====>.........................] - ETA: 1:03 - loss: 0.6993 - acc: 0.5000
 320/1387 [=====>........................] - ETA: 1:00 - loss: 0.6905 - acc: 0.5250
 384/1387 [=======>......................] - ETA: 56s - loss: 0.6929 - acc: 0.5260 
 448/1387 [========>.....................] - ETA: 53s - loss: 0.6925 - acc: 0.5179
 512/1387 [==========>...................] - ETA: 49s - loss: 0.6916 - acc: 0.5215
 576/1387 [===========>..................] - ETA: 46s - loss: 0.6851 - acc: 0.5312
 640/1387 [============>.................] - ETA: 41s - loss: 0.6872 - acc: 0.5281
 704/1387 [==============>...............] - ETA: 38s - loss: 0.6864 - acc: 0.5312
 768/1387 [===============>..............] - ETA: 34s - loss: 0.6856 - acc: 0.5352
 832/1387 [================>.............] - ETA: 31s - loss: 0.6863 - acc: 0.5349
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6813 - acc: 0.5413
 960/1387 [===================>..........] - ETA: 23s - loss: 0.6793 - acc: 0.5479
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6801 - acc: 0.5488
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6786 - acc: 0.5524
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6770 - acc: 0.5547
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6761 - acc: 0.5576 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6763 - acc: 0.5602
1344/1387 [============================>.] - ETA: 2s - loss: 0.6771 - acc: 0.5610
1387/1387 [==============================] - 78s 56ms/step - loss: 0.6785 - acc: 0.5566 - val_loss: 0.6926 - val_acc: 0.5806

Epoch 00010: val_acc did not improve from 0.58710
样本个数 193
样本个数 386
window_select1-5.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 28s
128/386 [========>.....................] - ETA: 14s
192/386 [=============>................] - ETA: 8s 
256/386 [==================>...........] - ETA: 5s
320/386 [=======================>......] - ETA: 2s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 13s 34ms/step
loss: 0.7000437295498626
acc: 0.5440414507772021
