nohup: ignoring input
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
样本个数 771
样本个数 1542
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f86c725dfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f86c725dfd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f86f171e650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f86f171e650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86f0f31890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86f0f31890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c71ea950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c71ea950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c70ab9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c70ab9d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86f0f8c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86f0f8c7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c71eab90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c71eab90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c70e0190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c70e0190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c6f70f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c6f70f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c6e2aa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c6e2aa10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c71ed510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c71ed510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c6f70cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c6f70cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6bd85d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6bd85d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c6ba3550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c6ba3550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c6b869d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c6b869d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6bdf290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6bdf290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c6ba3fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c6ba3fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6bc5e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6bc5e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c6bac650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c6bac650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c67d1290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c67d1290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6bb2310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6bb2310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c6c3dd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c6c3dd50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6658890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6658890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c6508b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c6508b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c64620d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c64620d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6778250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6778250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c67d1890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c67d1890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c64eafd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c64eafd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c6419f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c6419f90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c61400d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c61400d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6277b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6277b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c6309a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c6309a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6168850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6168850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c5f40490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86c5f40490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c5f7e190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86c5f7e190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6080b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c6080b50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c5f40290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86c5f40290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c5f7ed10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c5f7ed10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86bdbdcd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86bdbdcd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86bdb3f350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86bdb3f350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86bdb39490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86bdb39490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86bdc61390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86bdc61390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86bdb34810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86bdb34810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86bdc19e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86bdc19e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86bd8f1890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86bd8f1890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86bd6f4290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86bd6f4290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86bd984a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86bd984a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86bd8b4d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86bd8b4d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86bd6e8650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86bd6e8650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f869d61e850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f869d61e850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f869d5fb150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f869d5fb150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86bd7f7150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86bd7f7150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f869d36bd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f869d36bd90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f869d32bb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f869d32bb90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f869d4a0f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f869d4a0f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f869d05d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f869d05d850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f869d3a7b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f869d3a7b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f869d214510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f869d214510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f869d62bb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f869d62bb90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f869cf4edd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f869cf4edd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c5f17d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c5f17d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f869cfc7910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f869cfc7910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f869cdb3410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f869cdb3410>>: AttributeError: module 'gast' has no attribute 'Str'
2023-01-18 00:50:53.225047: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-01-18 00:50:53.258608: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2023-01-18 00:50:53.287269: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f63705d40 executing computations on platform Host. Devices:
2023-01-18 00:50:53.287334: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-01-18 00:50:53.604967: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

(?, ?, 128)
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

(?, ?, 128)
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
(?, ?, 128)
(?, 128)
(?, 128)
(?, 1)
window_select11-15.py:152: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 2:12 - loss: 0.7868 - acc: 0.4688
 128/1387 [=>............................] - ETA: 1:38 - loss: 0.9539 - acc: 0.4531
 192/1387 [===>..........................] - ETA: 1:19 - loss: 0.8798 - acc: 0.4896
 256/1387 [====>.........................] - ETA: 1:07 - loss: 0.8263 - acc: 0.5195
 320/1387 [=====>........................] - ETA: 1:00 - loss: 0.8027 - acc: 0.5250
 384/1387 [=======>......................] - ETA: 55s - loss: 0.7953 - acc: 0.5286 
 448/1387 [========>.....................] - ETA: 50s - loss: 0.7866 - acc: 0.5379
 512/1387 [==========>...................] - ETA: 46s - loss: 0.7782 - acc: 0.5332
 576/1387 [===========>..................] - ETA: 42s - loss: 0.7727 - acc: 0.5347
 640/1387 [============>.................] - ETA: 37s - loss: 0.7657 - acc: 0.5328
 704/1387 [==============>...............] - ETA: 33s - loss: 0.7607 - acc: 0.5284
 768/1387 [===============>..............] - ETA: 30s - loss: 0.7621 - acc: 0.5182
 832/1387 [================>.............] - ETA: 26s - loss: 0.7568 - acc: 0.5216
 896/1387 [==================>...........] - ETA: 23s - loss: 0.7556 - acc: 0.5246
 960/1387 [===================>..........] - ETA: 20s - loss: 0.7547 - acc: 0.5177
1024/1387 [=====================>........] - ETA: 17s - loss: 0.7561 - acc: 0.5127
1088/1387 [======================>.......] - ETA: 14s - loss: 0.7531 - acc: 0.5101
1152/1387 [=======================>......] - ETA: 11s - loss: 0.7502 - acc: 0.5104
1216/1387 [=========================>....] - ETA: 7s - loss: 0.7488 - acc: 0.5066 
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7471 - acc: 0.5094
1344/1387 [============================>.] - ETA: 1s - loss: 0.7425 - acc: 0.5119
1387/1387 [==============================] - 67s 48ms/step - loss: 0.7420 - acc: 0.5126 - val_loss: 0.6680 - val_acc: 0.6065

Epoch 00001: val_acc improved from -inf to 0.60645, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window11/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 53s - loss: 0.7419 - acc: 0.4844
 128/1387 [=>............................] - ETA: 50s - loss: 0.7242 - acc: 0.4844
 192/1387 [===>..........................] - ETA: 48s - loss: 0.6975 - acc: 0.5260
 256/1387 [====>.........................] - ETA: 45s - loss: 0.6905 - acc: 0.5312
 320/1387 [=====>........................] - ETA: 43s - loss: 0.6940 - acc: 0.5344
 384/1387 [=======>......................] - ETA: 41s - loss: 0.6858 - acc: 0.5521
 448/1387 [========>.....................] - ETA: 39s - loss: 0.6929 - acc: 0.5402
 512/1387 [==========>...................] - ETA: 36s - loss: 0.6880 - acc: 0.5430
 576/1387 [===========>..................] - ETA: 33s - loss: 0.6836 - acc: 0.5469
 640/1387 [============>.................] - ETA: 31s - loss: 0.6863 - acc: 0.5422
 704/1387 [==============>...............] - ETA: 28s - loss: 0.6899 - acc: 0.5398
 768/1387 [===============>..............] - ETA: 25s - loss: 0.6937 - acc: 0.5352
 832/1387 [================>.............] - ETA: 23s - loss: 0.6913 - acc: 0.5433
 896/1387 [==================>...........] - ETA: 21s - loss: 0.6906 - acc: 0.5502
 960/1387 [===================>..........] - ETA: 18s - loss: 0.6903 - acc: 0.5500
1024/1387 [=====================>........] - ETA: 15s - loss: 0.6922 - acc: 0.5488
1088/1387 [======================>.......] - ETA: 12s - loss: 0.6915 - acc: 0.5524
1152/1387 [=======================>......] - ETA: 10s - loss: 0.6926 - acc: 0.5495
1216/1387 [=========================>....] - ETA: 7s - loss: 0.6941 - acc: 0.5452 
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6923 - acc: 0.5469
1344/1387 [============================>.] - ETA: 1s - loss: 0.6942 - acc: 0.5454
1387/1387 [==============================] - 62s 45ms/step - loss: 0.6921 - acc: 0.5494 - val_loss: 0.6690 - val_acc: 0.6129

Epoch 00002: val_acc improved from 0.60645 to 0.61290, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window11/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 50s - loss: 0.6884 - acc: 0.5156
 128/1387 [=>............................] - ETA: 49s - loss: 0.6996 - acc: 0.5000
 192/1387 [===>..........................] - ETA: 46s - loss: 0.7125 - acc: 0.5052
 256/1387 [====>.........................] - ETA: 43s - loss: 0.7133 - acc: 0.5039
 320/1387 [=====>........................] - ETA: 41s - loss: 0.7047 - acc: 0.5125
 384/1387 [=======>......................] - ETA: 38s - loss: 0.7066 - acc: 0.5130
 448/1387 [========>.....................] - ETA: 36s - loss: 0.7069 - acc: 0.5045
 512/1387 [==========>...................] - ETA: 34s - loss: 0.6997 - acc: 0.5195
 576/1387 [===========>..................] - ETA: 31s - loss: 0.6982 - acc: 0.5278
 640/1387 [============>.................] - ETA: 29s - loss: 0.6961 - acc: 0.5344
 704/1387 [==============>...............] - ETA: 26s - loss: 0.6986 - acc: 0.5327
 768/1387 [===============>..............] - ETA: 24s - loss: 0.6974 - acc: 0.5365
 832/1387 [================>.............] - ETA: 21s - loss: 0.6994 - acc: 0.5325
 896/1387 [==================>...........] - ETA: 19s - loss: 0.6993 - acc: 0.5335
 960/1387 [===================>..........] - ETA: 17s - loss: 0.7003 - acc: 0.5354
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6976 - acc: 0.5400
1088/1387 [======================>.......] - ETA: 12s - loss: 0.6970 - acc: 0.5395
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6995 - acc: 0.5347 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6996 - acc: 0.5354
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7036 - acc: 0.5320
1344/1387 [============================>.] - ETA: 1s - loss: 0.7034 - acc: 0.5312
1387/1387 [==============================] - 60s 43ms/step - loss: 0.7047 - acc: 0.5292 - val_loss: 0.6680 - val_acc: 0.5806

Epoch 00003: val_acc did not improve from 0.61290
Epoch 4/10

  64/1387 [>.............................] - ETA: 54s - loss: 0.6840 - acc: 0.4688
 128/1387 [=>............................] - ETA: 52s - loss: 0.6782 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 53s - loss: 0.6995 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 49s - loss: 0.7046 - acc: 0.5312
 320/1387 [=====>........................] - ETA: 45s - loss: 0.7082 - acc: 0.5250
 384/1387 [=======>......................] - ETA: 42s - loss: 0.7032 - acc: 0.5365
 448/1387 [========>.....................] - ETA: 41s - loss: 0.6935 - acc: 0.5491
 512/1387 [==========>...................] - ETA: 38s - loss: 0.6919 - acc: 0.5449
 576/1387 [===========>..................] - ETA: 35s - loss: 0.6852 - acc: 0.5625
 640/1387 [============>.................] - ETA: 32s - loss: 0.6872 - acc: 0.5531
 704/1387 [==============>...............] - ETA: 29s - loss: 0.6863 - acc: 0.5540
 768/1387 [===============>..............] - ETA: 27s - loss: 0.6842 - acc: 0.5573
 832/1387 [================>.............] - ETA: 24s - loss: 0.6842 - acc: 0.5601
 896/1387 [==================>...........] - ETA: 21s - loss: 0.6855 - acc: 0.5569
 960/1387 [===================>..........] - ETA: 18s - loss: 0.6886 - acc: 0.5563
1024/1387 [=====================>........] - ETA: 15s - loss: 0.6913 - acc: 0.5508
1088/1387 [======================>.......] - ETA: 13s - loss: 0.6906 - acc: 0.5542
1152/1387 [=======================>......] - ETA: 10s - loss: 0.6879 - acc: 0.5590
1216/1387 [=========================>....] - ETA: 7s - loss: 0.6884 - acc: 0.5526 
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6916 - acc: 0.5500
1344/1387 [============================>.] - ETA: 1s - loss: 0.6936 - acc: 0.5469
1387/1387 [==============================] - 63s 45ms/step - loss: 0.6935 - acc: 0.5472 - val_loss: 0.6826 - val_acc: 0.5355

Epoch 00004: val_acc did not improve from 0.61290
Epoch 5/10

  64/1387 [>.............................] - ETA: 51s - loss: 0.6964 - acc: 0.5469
 128/1387 [=>............................] - ETA: 52s - loss: 0.6876 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 49s - loss: 0.6883 - acc: 0.5625
 256/1387 [====>.........................] - ETA: 45s - loss: 0.6888 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 42s - loss: 0.6869 - acc: 0.5531
 384/1387 [=======>......................] - ETA: 40s - loss: 0.6755 - acc: 0.5755
 448/1387 [========>.....................] - ETA: 37s - loss: 0.6776 - acc: 0.5759
 512/1387 [==========>...................] - ETA: 35s - loss: 0.6821 - acc: 0.5723
 576/1387 [===========>..................] - ETA: 32s - loss: 0.6838 - acc: 0.5799
 640/1387 [============>.................] - ETA: 30s - loss: 0.6810 - acc: 0.5813
 704/1387 [==============>...............] - ETA: 27s - loss: 0.6828 - acc: 0.5781
 768/1387 [===============>..............] - ETA: 25s - loss: 0.6846 - acc: 0.5742
 832/1387 [================>.............] - ETA: 22s - loss: 0.6825 - acc: 0.5757
 896/1387 [==================>...........] - ETA: 19s - loss: 0.6836 - acc: 0.5748
 960/1387 [===================>..........] - ETA: 17s - loss: 0.6825 - acc: 0.5760
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6816 - acc: 0.5742
1088/1387 [======================>.......] - ETA: 12s - loss: 0.6825 - acc: 0.5754
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6807 - acc: 0.5755 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6808 - acc: 0.5765
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6817 - acc: 0.5742
1344/1387 [============================>.] - ETA: 1s - loss: 0.6813 - acc: 0.5714
1387/1387 [==============================] - 59s 43ms/step - loss: 0.6809 - acc: 0.5710 - val_loss: 0.7010 - val_acc: 0.5355

Epoch 00005: val_acc did not improve from 0.61290
Epoch 6/10

  64/1387 [>.............................] - ETA: 52s - loss: 0.7063 - acc: 0.4062
 128/1387 [=>............................] - ETA: 49s - loss: 0.6804 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 47s - loss: 0.6992 - acc: 0.5104
 256/1387 [====>.........................] - ETA: 44s - loss: 0.6865 - acc: 0.5469
 320/1387 [=====>........................] - ETA: 43s - loss: 0.6743 - acc: 0.5719
 384/1387 [=======>......................] - ETA: 40s - loss: 0.6731 - acc: 0.5703
 448/1387 [========>.....................] - ETA: 38s - loss: 0.6725 - acc: 0.5759
 512/1387 [==========>...................] - ETA: 35s - loss: 0.6768 - acc: 0.5703
 576/1387 [===========>..................] - ETA: 32s - loss: 0.6757 - acc: 0.5781
 640/1387 [============>.................] - ETA: 30s - loss: 0.6769 - acc: 0.5750
 704/1387 [==============>...............] - ETA: 27s - loss: 0.6855 - acc: 0.5625
 768/1387 [===============>..............] - ETA: 24s - loss: 0.6820 - acc: 0.5690
 832/1387 [================>.............] - ETA: 22s - loss: 0.6801 - acc: 0.5721
 896/1387 [==================>...........] - ETA: 19s - loss: 0.6820 - acc: 0.5670
 960/1387 [===================>..........] - ETA: 17s - loss: 0.6777 - acc: 0.5729
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6792 - acc: 0.5713
1088/1387 [======================>.......] - ETA: 12s - loss: 0.6798 - acc: 0.5726
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6808 - acc: 0.5703 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6784 - acc: 0.5740
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6786 - acc: 0.5750
1344/1387 [============================>.] - ETA: 1s - loss: 0.6783 - acc: 0.5744
1387/1387 [==============================] - 59s 42ms/step - loss: 0.6795 - acc: 0.5739 - val_loss: 0.6870 - val_acc: 0.5548

Epoch 00006: val_acc did not improve from 0.61290
Epoch 7/10

  64/1387 [>.............................] - ETA: 53s - loss: 0.6378 - acc: 0.5938
 128/1387 [=>............................] - ETA: 49s - loss: 0.6550 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 47s - loss: 0.6705 - acc: 0.5833
 256/1387 [====>.........................] - ETA: 45s - loss: 0.6590 - acc: 0.5977
 320/1387 [=====>........................] - ETA: 43s - loss: 0.6583 - acc: 0.5906
 384/1387 [=======>......................] - ETA: 40s - loss: 0.6587 - acc: 0.6016
 448/1387 [========>.....................] - ETA: 38s - loss: 0.6589 - acc: 0.6049
 512/1387 [==========>...................] - ETA: 35s - loss: 0.6684 - acc: 0.5859
 576/1387 [===========>..................] - ETA: 33s - loss: 0.6716 - acc: 0.5851
 640/1387 [============>.................] - ETA: 30s - loss: 0.6779 - acc: 0.5734
 704/1387 [==============>...............] - ETA: 28s - loss: 0.6762 - acc: 0.5781
 768/1387 [===============>..............] - ETA: 25s - loss: 0.6778 - acc: 0.5781
 832/1387 [================>.............] - ETA: 23s - loss: 0.6787 - acc: 0.5721
 896/1387 [==================>...........] - ETA: 20s - loss: 0.6754 - acc: 0.5737
 960/1387 [===================>..........] - ETA: 17s - loss: 0.6775 - acc: 0.5719
1024/1387 [=====================>........] - ETA: 15s - loss: 0.6774 - acc: 0.5713
1088/1387 [======================>.......] - ETA: 12s - loss: 0.6796 - acc: 0.5689
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6839 - acc: 0.5634 
1216/1387 [=========================>....] - ETA: 7s - loss: 0.6840 - acc: 0.5641
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6855 - acc: 0.5594
1344/1387 [============================>.] - ETA: 1s - loss: 0.6812 - acc: 0.5662
1387/1387 [==============================] - 61s 44ms/step - loss: 0.6838 - acc: 0.5645 - val_loss: 0.6645 - val_acc: 0.5935

Epoch 00007: val_acc did not improve from 0.61290
Epoch 8/10

  64/1387 [>.............................] - ETA: 51s - loss: 0.6985 - acc: 0.5625
 128/1387 [=>............................] - ETA: 54s - loss: 0.6891 - acc: 0.6094
 192/1387 [===>..........................] - ETA: 50s - loss: 0.6709 - acc: 0.6042
 256/1387 [====>.........................] - ETA: 46s - loss: 0.6697 - acc: 0.6055
 320/1387 [=====>........................] - ETA: 44s - loss: 0.6768 - acc: 0.5938
 384/1387 [=======>......................] - ETA: 42s - loss: 0.6766 - acc: 0.5885
 448/1387 [========>.....................] - ETA: 39s - loss: 0.6673 - acc: 0.5982
 512/1387 [==========>...................] - ETA: 36s - loss: 0.6729 - acc: 0.5879
 576/1387 [===========>..................] - ETA: 34s - loss: 0.6725 - acc: 0.5868
 640/1387 [============>.................] - ETA: 31s - loss: 0.6674 - acc: 0.5969
 704/1387 [==============>...............] - ETA: 28s - loss: 0.6693 - acc: 0.5994
 768/1387 [===============>..............] - ETA: 25s - loss: 0.6735 - acc: 0.5859
 832/1387 [================>.............] - ETA: 23s - loss: 0.6719 - acc: 0.5877
 896/1387 [==================>...........] - ETA: 20s - loss: 0.6729 - acc: 0.5871
 960/1387 [===================>..........] - ETA: 17s - loss: 0.6746 - acc: 0.5833
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6746 - acc: 0.5830
1088/1387 [======================>.......] - ETA: 12s - loss: 0.6733 - acc: 0.5864
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6735 - acc: 0.5833 
1216/1387 [=========================>....] - ETA: 7s - loss: 0.6734 - acc: 0.5822
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6729 - acc: 0.5813
1344/1387 [============================>.] - ETA: 1s - loss: 0.6759 - acc: 0.5789
1387/1387 [==============================] - 60s 43ms/step - loss: 0.6768 - acc: 0.5768 - val_loss: 0.6655 - val_acc: 0.6129

Epoch 00008: val_acc did not improve from 0.61290
Epoch 9/10

  64/1387 [>.............................] - ETA: 50s - loss: 0.6485 - acc: 0.6562
 128/1387 [=>............................] - ETA: 47s - loss: 0.6653 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 46s - loss: 0.6637 - acc: 0.6198
 256/1387 [====>.........................] - ETA: 43s - loss: 0.6759 - acc: 0.5938
 320/1387 [=====>........................] - ETA: 41s - loss: 0.6798 - acc: 0.5844
 384/1387 [=======>......................] - ETA: 38s - loss: 0.6838 - acc: 0.5755
 448/1387 [========>.....................] - ETA: 36s - loss: 0.6774 - acc: 0.5938
 512/1387 [==========>...................] - ETA: 34s - loss: 0.6831 - acc: 0.5801
 576/1387 [===========>..................] - ETA: 31s - loss: 0.6846 - acc: 0.5799
 640/1387 [============>.................] - ETA: 29s - loss: 0.6868 - acc: 0.5734
 704/1387 [==============>...............] - ETA: 26s - loss: 0.6838 - acc: 0.5824
 768/1387 [===============>..............] - ETA: 24s - loss: 0.6831 - acc: 0.5781
 832/1387 [================>.............] - ETA: 21s - loss: 0.6821 - acc: 0.5781
 896/1387 [==================>...........] - ETA: 19s - loss: 0.6798 - acc: 0.5826
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6785 - acc: 0.5865
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6777 - acc: 0.5830
1088/1387 [======================>.......] - ETA: 12s - loss: 0.6769 - acc: 0.5836
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6761 - acc: 0.5877 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6749 - acc: 0.5905
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6783 - acc: 0.5859
1344/1387 [============================>.] - ETA: 1s - loss: 0.6768 - acc: 0.5893
1387/1387 [==============================] - 59s 43ms/step - loss: 0.6740 - acc: 0.5941 - val_loss: 0.6514 - val_acc: 0.6258

Epoch 00009: val_acc improved from 0.61290 to 0.62581, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window11/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 10/10

  64/1387 [>.............................] - ETA: 52s - loss: 0.6980 - acc: 0.5469
 128/1387 [=>............................] - ETA: 52s - loss: 0.6654 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 48s - loss: 0.6608 - acc: 0.5938
 256/1387 [====>.........................] - ETA: 45s - loss: 0.6422 - acc: 0.6289
 320/1387 [=====>........................] - ETA: 43s - loss: 0.6635 - acc: 0.5969
 384/1387 [=======>......................] - ETA: 41s - loss: 0.6560 - acc: 0.6120
 448/1387 [========>.....................] - ETA: 38s - loss: 0.6672 - acc: 0.5938
 512/1387 [==========>...................] - ETA: 35s - loss: 0.6679 - acc: 0.5957
 576/1387 [===========>..................] - ETA: 33s - loss: 0.6615 - acc: 0.5990
 640/1387 [============>.................] - ETA: 30s - loss: 0.6575 - acc: 0.5969
 704/1387 [==============>...............] - ETA: 27s - loss: 0.6594 - acc: 0.5923
 768/1387 [===============>..............] - ETA: 24s - loss: 0.6623 - acc: 0.5898
 832/1387 [================>.............] - ETA: 22s - loss: 0.6609 - acc: 0.5925
 896/1387 [==================>...........] - ETA: 19s - loss: 0.6602 - acc: 0.5971
 960/1387 [===================>..........] - ETA: 17s - loss: 0.6576 - acc: 0.6021
1024/1387 [=====================>........] - ETA: 14s - loss: 0.6556 - acc: 0.6094
1088/1387 [======================>.......] - ETA: 12s - loss: 0.6592 - acc: 0.6029
1152/1387 [=======================>......] - ETA: 9s - loss: 0.6598 - acc: 0.6042 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6598 - acc: 0.6036
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6609 - acc: 0.6039
1344/1387 [============================>.] - ETA: 1s - loss: 0.6631 - acc: 0.6012
1387/1387 [==============================] - 59s 42ms/step - loss: 0.6631 - acc: 0.6013 - val_loss: 0.6645 - val_acc: 0.5806

Epoch 00010: val_acc did not improve from 0.62581
样本个数 193
样本个数 386
(?, ?, 128)
(?, ?, 128)
(?, ?, 128)
(?, 128)
(?, 128)
(?, 1)
window_select11-15.py:152: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 7s
128/386 [========>.....................] - ETA: 4s
192/386 [=============>................] - ETA: 3s
256/386 [==================>...........] - ETA: 1s
320/386 [=======================>......] - ETA: 0s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 6s 16ms/step
loss: 0.6747067209352483
acc: 0.5803108808290155
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f80740fe090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f80740fe090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f80740df290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f80740df290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c722c150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c722c150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86f108c1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86f108c1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8074048f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f8074048f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f80740a38d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f80740a38d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86f108c5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86f108c5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86f1072a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86f1072a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8074125590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8074125590>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f806c6a07d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f806c6a07d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f80740e6b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f80740e6b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8074048210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8074048210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f80740b1350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f80740b1350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f806c32e350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f806c32e350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f806c238c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f806c238c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f806c33d590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f806c33d590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f806c2fd650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f806c2fd650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f806c5656d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f806c5656d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8014689750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8014689750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f806c294050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f806c294050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f806c276810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f806c276810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8014689990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8014689990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f80145dd790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f80145dd790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8014498dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8014498dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f801424aa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f801424aa50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f80144f3a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f80144f3a50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f801449e690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f801449e690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f801428e710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f801428e710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8014083b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f8014083b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7ff47c3ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7ff47c3ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8014046b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f8014046b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8014155050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f8014155050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff4751850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff4751850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ff45295d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ff45295d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7ff4409390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7ff4409390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff4768a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff4768a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ff43fb510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ff43fb510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff4470410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff4470410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ff41c6150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ff41c6150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7ff41a4750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7ff41a4750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff41b7310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff41b7310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ff4335fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ff4335fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff4124310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff4124310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ff4216b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ff4216b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7fd468d790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7fd468d790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff4104d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ff4104d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ff476c4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ff476c4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fd457e950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fd457e950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7fd44b5810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7fd44b5810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7fd42fdd90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7fd42fdd90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fd4607590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fd4607590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7fd43d4e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7fd43d4e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fd42a4b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fd42a4b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7fd4061e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7fd4061e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7fd413ec90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7fd413ec90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fd4252a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fd4252a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7fd4332150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7fd4332150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fb4636550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fb4636550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7fb44bbed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7fb44bbed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7fb43d3a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7fb43d3a10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fb4627090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fb4627090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7fb44bba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7fb44bba50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fb43cc510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7fb43cc510>>: AttributeError: module 'gast' has no attribute 'Str'
(?, ?, 128)
(?, ?, 128)
(?, ?, 128)
(?, 128)
(?, 128)
(?, 1)
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 2:08 - loss: 0.6735 - acc: 0.5781
 128/1387 [=>............................] - ETA: 1:25 - loss: 0.7085 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 1:08 - loss: 0.7021 - acc: 0.5833
 256/1387 [====>.........................] - ETA: 59s - loss: 0.7237 - acc: 0.5625 
 320/1387 [=====>........................] - ETA: 52s - loss: 0.7171 - acc: 0.5625
 384/1387 [=======>......................] - ETA: 47s - loss: 0.7216 - acc: 0.5547
 448/1387 [========>.....................] - ETA: 43s - loss: 0.7224 - acc: 0.5491
 512/1387 [==========>...................] - ETA: 39s - loss: 0.7238 - acc: 0.5469
 576/1387 [===========>..................] - ETA: 36s - loss: 0.7277 - acc: 0.5399
 640/1387 [============>.................] - ETA: 32s - loss: 0.7288 - acc: 0.5391
 704/1387 [==============>...............] - ETA: 29s - loss: 0.7290 - acc: 0.5384
 768/1387 [===============>..............] - ETA: 26s - loss: 0.7348 - acc: 0.5312
 832/1387 [================>.............] - ETA: 23s - loss: 0.7351 - acc: 0.5300
 896/1387 [==================>...........] - ETA: 20s - loss: 0.7292 - acc: 0.5391
 960/1387 [===================>..........] - ETA: 17s - loss: 0.7288 - acc: 0.5354
1024/1387 [=====================>........] - ETA: 15s - loss: 0.7293 - acc: 0.5303
1088/1387 [======================>.......] - ETA: 12s - loss: 0.7281 - acc: 0.5294
1152/1387 [=======================>......] - ETA: 9s - loss: 0.7263 - acc: 0.5312 
1216/1387 [=========================>....] - ETA: 7s - loss: 0.7263 - acc: 0.5288
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7248 - acc: 0.5273
1344/1387 [============================>.] - ETA: 1s - loss: 0.7231 - acc: 0.5298
1387/1387 [==============================] - 60s 43ms/step - loss: 0.7224 - acc: 0.5299 - val_loss: 0.7206 - val_acc: 0.5032

Epoch 00001: val_acc improved from -inf to 0.50323, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window12/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 54s - loss: 0.7731 - acc: 0.5469
 128/1387 [=>............................] - ETA: 48s - loss: 0.7929 - acc: 0.4844
 192/1387 [===>..........................] - ETA: 45s - loss: 0.7611 - acc: 0.5104
 256/1387 [====>.........................] - ETA: 42s - loss: 0.7440 - acc: 0.5078
 320/1387 [=====>........................] - ETA: 40s - loss: 0.7326 - acc: 0.5094
 384/1387 [=======>......................] - ETA: 37s - loss: 0.7341 - acc: 0.5026
 448/1387 [========>.....................] - ETA: 35s - loss: 0.7321 - acc: 0.5022
 512/1387 [==========>...................] - ETA: 32s - loss: 0.7412 - acc: 0.4941
 576/1387 [===========>..................] - ETA: 30s - loss: 0.7378 - acc: 0.4896
 640/1387 [============>.................] - ETA: 27s - loss: 0.7352 - acc: 0.4922
 704/1387 [==============>...............] - ETA: 25s - loss: 0.7311 - acc: 0.4943
 768/1387 [===============>..............] - ETA: 23s - loss: 0.7292 - acc: 0.4922
 832/1387 [================>.............] - ETA: 20s - loss: 0.7288 - acc: 0.4964
 896/1387 [==================>...........] - ETA: 18s - loss: 0.7259 - acc: 0.5022
 960/1387 [===================>..........] - ETA: 16s - loss: 0.7249 - acc: 0.5052
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7234 - acc: 0.5088
1088/1387 [======================>.......] - ETA: 11s - loss: 0.7245 - acc: 0.5083
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7225 - acc: 0.5122 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7192 - acc: 0.5156
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7176 - acc: 0.5195
1344/1387 [============================>.] - ETA: 1s - loss: 0.7140 - acc: 0.5246
1387/1387 [==============================] - 55s 40ms/step - loss: 0.7117 - acc: 0.5292 - val_loss: 0.7195 - val_acc: 0.4774

Epoch 00002: val_acc did not improve from 0.50323
Epoch 3/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.7423 - acc: 0.5156
 128/1387 [=>............................] - ETA: 46s - loss: 0.7383 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7239 - acc: 0.5469
 256/1387 [====>.........................] - ETA: 41s - loss: 0.7061 - acc: 0.5703
 320/1387 [=====>........................] - ETA: 39s - loss: 0.6950 - acc: 0.5781
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6936 - acc: 0.5677
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6943 - acc: 0.5625
 512/1387 [==========>...................] - ETA: 32s - loss: 0.7016 - acc: 0.5449
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6932 - acc: 0.5503
 640/1387 [============>.................] - ETA: 27s - loss: 0.6956 - acc: 0.5453
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6904 - acc: 0.5540
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6892 - acc: 0.5586
 832/1387 [================>.............] - ETA: 20s - loss: 0.6912 - acc: 0.5517
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6891 - acc: 0.5525
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6926 - acc: 0.5490
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6925 - acc: 0.5498
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6919 - acc: 0.5487
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6940 - acc: 0.5451 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6945 - acc: 0.5452
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6928 - acc: 0.5492
1344/1387 [============================>.] - ETA: 1s - loss: 0.6932 - acc: 0.5491
1387/1387 [==============================] - 55s 40ms/step - loss: 0.6949 - acc: 0.5472 - val_loss: 0.7029 - val_acc: 0.4839

Epoch 00003: val_acc did not improve from 0.50323
Epoch 4/10

  64/1387 [>.............................] - ETA: 54s - loss: 0.7333 - acc: 0.4375
 128/1387 [=>............................] - ETA: 49s - loss: 0.6920 - acc: 0.4922
 192/1387 [===>..........................] - ETA: 46s - loss: 0.6931 - acc: 0.5052
 256/1387 [====>.........................] - ETA: 43s - loss: 0.6919 - acc: 0.5352
 320/1387 [=====>........................] - ETA: 40s - loss: 0.6936 - acc: 0.5281
 384/1387 [=======>......................] - ETA: 38s - loss: 0.6862 - acc: 0.5469
 448/1387 [========>.....................] - ETA: 35s - loss: 0.6822 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 33s - loss: 0.6864 - acc: 0.5469
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6879 - acc: 0.5451
 640/1387 [============>.................] - ETA: 27s - loss: 0.6940 - acc: 0.5312
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6922 - acc: 0.5384
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6915 - acc: 0.5391
 832/1387 [================>.............] - ETA: 20s - loss: 0.6932 - acc: 0.5312
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6912 - acc: 0.5379
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6925 - acc: 0.5375
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6900 - acc: 0.5439
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6914 - acc: 0.5414
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6904 - acc: 0.5434 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6889 - acc: 0.5452
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6904 - acc: 0.5445
1344/1387 [============================>.] - ETA: 1s - loss: 0.6911 - acc: 0.5461
1387/1387 [==============================] - 55s 39ms/step - loss: 0.6911 - acc: 0.5429 - val_loss: 0.6869 - val_acc: 0.5484

Epoch 00004: val_acc improved from 0.50323 to 0.54839, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window12/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 5/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6404 - acc: 0.6094
 128/1387 [=>............................] - ETA: 45s - loss: 0.7061 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7066 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 40s - loss: 0.7163 - acc: 0.5078
 320/1387 [=====>........................] - ETA: 38s - loss: 0.7141 - acc: 0.5062
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7081 - acc: 0.5365
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7086 - acc: 0.5312
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7089 - acc: 0.5312
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7072 - acc: 0.5295
 640/1387 [============>.................] - ETA: 27s - loss: 0.6992 - acc: 0.5516
 704/1387 [==============>...............] - ETA: 25s - loss: 0.7009 - acc: 0.5455
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7003 - acc: 0.5456
 832/1387 [================>.............] - ETA: 20s - loss: 0.7025 - acc: 0.5409
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6993 - acc: 0.5502
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6971 - acc: 0.5563
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6955 - acc: 0.5566
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6948 - acc: 0.5597
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6945 - acc: 0.5582 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6954 - acc: 0.5551
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6946 - acc: 0.5523
1344/1387 [============================>.] - ETA: 1s - loss: 0.6948 - acc: 0.5528
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6965 - acc: 0.5508 - val_loss: 0.6771 - val_acc: 0.6065

Epoch 00005: val_acc improved from 0.54839 to 0.60645, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window12/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1387 [>.............................] - ETA: 54s - loss: 0.6853 - acc: 0.5938
 128/1387 [=>............................] - ETA: 52s - loss: 0.6738 - acc: 0.5859
 192/1387 [===>..........................] - ETA: 48s - loss: 0.6794 - acc: 0.5885
 256/1387 [====>.........................] - ETA: 44s - loss: 0.6855 - acc: 0.5703
 320/1387 [=====>........................] - ETA: 41s - loss: 0.6828 - acc: 0.5781
 384/1387 [=======>......................] - ETA: 39s - loss: 0.6851 - acc: 0.5703
 448/1387 [========>.....................] - ETA: 36s - loss: 0.6890 - acc: 0.5580
 512/1387 [==========>...................] - ETA: 33s - loss: 0.6919 - acc: 0.5527
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6923 - acc: 0.5573
 640/1387 [============>.................] - ETA: 28s - loss: 0.6890 - acc: 0.5625
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6869 - acc: 0.5625
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6848 - acc: 0.5651
 832/1387 [================>.............] - ETA: 20s - loss: 0.6845 - acc: 0.5661
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6858 - acc: 0.5647
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6838 - acc: 0.5667
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6874 - acc: 0.5557
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6897 - acc: 0.5551
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6866 - acc: 0.5599 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6883 - acc: 0.5567
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6903 - acc: 0.5516
1344/1387 [============================>.] - ETA: 1s - loss: 0.6878 - acc: 0.5573
1387/1387 [==============================] - 55s 39ms/step - loss: 0.6884 - acc: 0.5552 - val_loss: 0.6940 - val_acc: 0.5161

Epoch 00006: val_acc did not improve from 0.60645
Epoch 7/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.6829 - acc: 0.5000
 128/1387 [=>............................] - ETA: 46s - loss: 0.6714 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 44s - loss: 0.6627 - acc: 0.5625
 256/1387 [====>.........................] - ETA: 42s - loss: 0.6631 - acc: 0.5742
 320/1387 [=====>........................] - ETA: 39s - loss: 0.6691 - acc: 0.5625
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6713 - acc: 0.5495
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6799 - acc: 0.5379
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6767 - acc: 0.5449
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6821 - acc: 0.5365
 640/1387 [============>.................] - ETA: 27s - loss: 0.6802 - acc: 0.5344
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6810 - acc: 0.5312
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6826 - acc: 0.5260
 832/1387 [================>.............] - ETA: 20s - loss: 0.6856 - acc: 0.5240
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6855 - acc: 0.5279
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6878 - acc: 0.5250
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6882 - acc: 0.5293
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6905 - acc: 0.5276
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6883 - acc: 0.5304 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6879 - acc: 0.5288
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6894 - acc: 0.5305
1344/1387 [============================>.] - ETA: 1s - loss: 0.6915 - acc: 0.5305
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6917 - acc: 0.5292 - val_loss: 0.6987 - val_acc: 0.5097

Epoch 00007: val_acc did not improve from 0.60645
Epoch 8/10

  64/1387 [>.............................] - ETA: 49s - loss: 0.7177 - acc: 0.4531
 128/1387 [=>............................] - ETA: 46s - loss: 0.6818 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6702 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6760 - acc: 0.5664
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6721 - acc: 0.5844
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6806 - acc: 0.5729
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6851 - acc: 0.5625
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6872 - acc: 0.5547
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6906 - acc: 0.5486
 640/1387 [============>.................] - ETA: 27s - loss: 0.6933 - acc: 0.5391
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6947 - acc: 0.5384
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6934 - acc: 0.5417
 832/1387 [================>.............] - ETA: 20s - loss: 0.6901 - acc: 0.5505
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6905 - acc: 0.5502
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6900 - acc: 0.5542
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6875 - acc: 0.5557
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6883 - acc: 0.5506
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6905 - acc: 0.5477 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6907 - acc: 0.5452
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6918 - acc: 0.5430
1344/1387 [============================>.] - ETA: 1s - loss: 0.6913 - acc: 0.5432
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6934 - acc: 0.5415 - val_loss: 0.6795 - val_acc: 0.5742

Epoch 00008: val_acc did not improve from 0.60645
Epoch 9/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.6598 - acc: 0.5781
 128/1387 [=>............................] - ETA: 50s - loss: 0.6706 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 47s - loss: 0.6769 - acc: 0.5469
 256/1387 [====>.........................] - ETA: 44s - loss: 0.6858 - acc: 0.5391
 320/1387 [=====>........................] - ETA: 41s - loss: 0.6899 - acc: 0.5437
 384/1387 [=======>......................] - ETA: 39s - loss: 0.6885 - acc: 0.5469
 448/1387 [========>.....................] - ETA: 36s - loss: 0.6888 - acc: 0.5446
 512/1387 [==========>...................] - ETA: 33s - loss: 0.6882 - acc: 0.5527
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6864 - acc: 0.5573
 640/1387 [============>.................] - ETA: 28s - loss: 0.6846 - acc: 0.5516
 704/1387 [==============>...............] - ETA: 26s - loss: 0.6839 - acc: 0.5554
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6818 - acc: 0.5651
 832/1387 [================>.............] - ETA: 21s - loss: 0.6801 - acc: 0.5709
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6831 - acc: 0.5614
 960/1387 [===================>..........] - ETA: 16s - loss: 0.6848 - acc: 0.5552
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6855 - acc: 0.5547
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6845 - acc: 0.5561
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6837 - acc: 0.5564 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6839 - acc: 0.5551
1280/1387 [==========================>...] - ETA: 4s - loss: 0.6829 - acc: 0.5555
1344/1387 [============================>.] - ETA: 1s - loss: 0.6805 - acc: 0.5580
1387/1387 [==============================] - 55s 40ms/step - loss: 0.6801 - acc: 0.5588 - val_loss: 0.6826 - val_acc: 0.6000

Epoch 00009: val_acc did not improve from 0.60645
Epoch 10/10

  64/1387 [>.............................] - ETA: 55s - loss: 0.6633 - acc: 0.5938
 128/1387 [=>............................] - ETA: 49s - loss: 0.6769 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 45s - loss: 0.6750 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 43s - loss: 0.6715 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 40s - loss: 0.6694 - acc: 0.5656
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6689 - acc: 0.5677
 448/1387 [========>.....................] - ETA: 35s - loss: 0.6757 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 33s - loss: 0.6791 - acc: 0.5566
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6819 - acc: 0.5556
 640/1387 [============>.................] - ETA: 28s - loss: 0.6783 - acc: 0.5656
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6783 - acc: 0.5668
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6779 - acc: 0.5677
 832/1387 [================>.............] - ETA: 20s - loss: 0.6756 - acc: 0.5685
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6767 - acc: 0.5647
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6795 - acc: 0.5604
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6801 - acc: 0.5615
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6797 - acc: 0.5616
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6802 - acc: 0.5634 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6789 - acc: 0.5658
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6780 - acc: 0.5672
1344/1387 [============================>.] - ETA: 1s - loss: 0.6776 - acc: 0.5699
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6757 - acc: 0.5761 - val_loss: 0.6875 - val_acc: 0.5548

Epoch 00010: val_acc did not improve from 0.60645
样本个数 193
样本个数 386
(?, ?, 128)
(?, ?, 128)
(?, ?, 128)
(?, 128)
(?, 128)
(?, 1)
window_select11-15.py:152: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 9s
128/386 [========>.....................] - ETA: 5s
192/386 [=============>................] - ETA: 3s
256/386 [==================>...........] - ETA: 2s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 6s 17ms/step
loss: 0.6808785879550202
acc: 0.582901554404145
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f7f14601810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f7f14601810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f7f145cbf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f7f145cbf50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c722c450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c722c450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ef46ce3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ef46ce3d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86dfcc4a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f86dfcc4a90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7f145f1250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7f145f1250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ef46ce550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ef46ce550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7f1446cd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7f1446cd50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7f143c6d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7f143c6d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7f14260b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7f14260b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7f143a6450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7f143a6450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7f143c6210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7f143c6210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7f143dc5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7f143dc5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7f143d2d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7f143d2d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7f140b3990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7f140b3990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7f143dc390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7f143dc390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7f142540d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7f142540d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ef476ebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ef476ebd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ed442ff50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ed442ff50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7f14059750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7f14059750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ef4705bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ef4705bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7f1428c2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7f1428c2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ed4441190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ed4441190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ed41df0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7ed41df0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7eb473e890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7eb473e890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ed4194f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ed4194f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ed41df8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ed41df8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ed43854d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ed43854d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7eb45b2790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7eb45b2790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7eb4450610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7eb4450610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ed40d6290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ed40d6290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7eb45b2cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7eb45b2cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7eb43a6350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7eb43a6350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7eb4344150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7eb4344150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7eb41b29d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7eb41b29d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7eb42e76d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7eb42e76d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ed4169410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7ed4169410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e94739a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e94739a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7e94772d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7e94772d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7e946f7ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7e946f7ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7eb415f710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7eb415f710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7e94772290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7e94772290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e94715650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e94715650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7e943d1d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7e943d1d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7e942f7e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7e942f7e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e94521f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e94521f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7e94324650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7e94324650>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e941dec90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e941dec90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7e940db2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7e940db2d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7e94060d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7e94060d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e9405e0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e9405e0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7eb4158990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7eb4158990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e7463d850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e7463d850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7e747f8e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7e747f8e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7e7445eed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7e7445eed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ed40bd390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ed40bd390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7e74637110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7e74637110>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e74589290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e74589290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7e744baad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7e744baad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7e741d93d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7e741d93d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e7426a710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e7426a710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7e94100810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7e94100810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e7435dd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7e7435dd50>>: AttributeError: module 'gast' has no attribute 'Str'
(?, ?, 128)
(?, ?, 128)
(?, ?, 128)
(?, 128)
(?, 128)
(?, 1)
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 2:36 - loss: 0.7425 - acc: 0.5156
 128/1387 [=>............................] - ETA: 1:36 - loss: 0.7091 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 1:14 - loss: 0.7279 - acc: 0.4844
 256/1387 [====>.........................] - ETA: 1:02 - loss: 0.7385 - acc: 0.4805
 320/1387 [=====>........................] - ETA: 54s - loss: 0.7420 - acc: 0.4781 
 384/1387 [=======>......................] - ETA: 49s - loss: 0.7431 - acc: 0.4792
 448/1387 [========>.....................] - ETA: 44s - loss: 0.7402 - acc: 0.4844
 512/1387 [==========>...................] - ETA: 40s - loss: 0.7303 - acc: 0.4980
 576/1387 [===========>..................] - ETA: 36s - loss: 0.7277 - acc: 0.5069
 640/1387 [============>.................] - ETA: 33s - loss: 0.7279 - acc: 0.5078
 704/1387 [==============>...............] - ETA: 29s - loss: 0.7222 - acc: 0.5142
 768/1387 [===============>..............] - ETA: 26s - loss: 0.7188 - acc: 0.5195
 832/1387 [================>.............] - ETA: 23s - loss: 0.7152 - acc: 0.5264
 896/1387 [==================>...........] - ETA: 20s - loss: 0.7131 - acc: 0.5312
 960/1387 [===================>..........] - ETA: 17s - loss: 0.7112 - acc: 0.5396
1024/1387 [=====================>........] - ETA: 15s - loss: 0.7163 - acc: 0.5322
1088/1387 [======================>.......] - ETA: 12s - loss: 0.7148 - acc: 0.5322
1152/1387 [=======================>......] - ETA: 9s - loss: 0.7185 - acc: 0.5312 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7165 - acc: 0.5370
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7158 - acc: 0.5383
1344/1387 [============================>.] - ETA: 1s - loss: 0.7129 - acc: 0.5402
1387/1387 [==============================] - 59s 43ms/step - loss: 0.7125 - acc: 0.5415 - val_loss: 0.6977 - val_acc: 0.5419

Epoch 00001: val_acc improved from -inf to 0.54194, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window13/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.7250 - acc: 0.5781
 128/1387 [=>............................] - ETA: 46s - loss: 0.7586 - acc: 0.4766
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7343 - acc: 0.4948
 256/1387 [====>.........................] - ETA: 41s - loss: 0.7227 - acc: 0.5117
 320/1387 [=====>........................] - ETA: 39s - loss: 0.7238 - acc: 0.4938
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7221 - acc: 0.5000
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7246 - acc: 0.4888
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7211 - acc: 0.4961
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7155 - acc: 0.5087
 640/1387 [============>.................] - ETA: 27s - loss: 0.7174 - acc: 0.5000
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7141 - acc: 0.5085
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7206 - acc: 0.5026
 832/1387 [================>.............] - ETA: 20s - loss: 0.7174 - acc: 0.5060
 896/1387 [==================>...........] - ETA: 17s - loss: 0.7170 - acc: 0.5067
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7175 - acc: 0.5000
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7151 - acc: 0.5039
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7155 - acc: 0.5055
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7128 - acc: 0.5130 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7112 - acc: 0.5173
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7112 - acc: 0.5195
1344/1387 [============================>.] - ETA: 1s - loss: 0.7125 - acc: 0.5208
1387/1387 [==============================] - 54s 39ms/step - loss: 0.7131 - acc: 0.5205 - val_loss: 0.6932 - val_acc: 0.5484

Epoch 00002: val_acc improved from 0.54194 to 0.54839, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window13/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.7288 - acc: 0.4531
 128/1387 [=>............................] - ETA: 45s - loss: 0.6910 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 44s - loss: 0.6761 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6913 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 39s - loss: 0.6918 - acc: 0.5500
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6914 - acc: 0.5573
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6883 - acc: 0.5536
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6909 - acc: 0.5430
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6869 - acc: 0.5503
 640/1387 [============>.................] - ETA: 27s - loss: 0.6891 - acc: 0.5484
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6888 - acc: 0.5455
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6921 - acc: 0.5391
 832/1387 [================>.............] - ETA: 20s - loss: 0.6956 - acc: 0.5337
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6960 - acc: 0.5301
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6983 - acc: 0.5271
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6988 - acc: 0.5273
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7000 - acc: 0.5239
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6981 - acc: 0.5243 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6966 - acc: 0.5288
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6933 - acc: 0.5359
1344/1387 [============================>.] - ETA: 1s - loss: 0.6943 - acc: 0.5320
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6944 - acc: 0.5321 - val_loss: 0.6821 - val_acc: 0.5677

Epoch 00003: val_acc improved from 0.54839 to 0.56774, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window13/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.6319 - acc: 0.6875
 128/1387 [=>............................] - ETA: 47s - loss: 0.6328 - acc: 0.6719
 192/1387 [===>..........................] - ETA: 44s - loss: 0.6383 - acc: 0.6615
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6408 - acc: 0.6484
 320/1387 [=====>........................] - ETA: 40s - loss: 0.6488 - acc: 0.6281
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6587 - acc: 0.6120
 448/1387 [========>.....................] - ETA: 35s - loss: 0.6667 - acc: 0.6071
 512/1387 [==========>...................] - ETA: 33s - loss: 0.6671 - acc: 0.6055
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6662 - acc: 0.6111
 640/1387 [============>.................] - ETA: 28s - loss: 0.6700 - acc: 0.6078
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6739 - acc: 0.5994
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6791 - acc: 0.5898
 832/1387 [================>.............] - ETA: 20s - loss: 0.6796 - acc: 0.5877
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6840 - acc: 0.5848
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6852 - acc: 0.5823
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6837 - acc: 0.5859
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6848 - acc: 0.5846
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6811 - acc: 0.5885 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6834 - acc: 0.5839
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6825 - acc: 0.5875
1344/1387 [============================>.] - ETA: 1s - loss: 0.6822 - acc: 0.5863
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6828 - acc: 0.5833 - val_loss: 0.6862 - val_acc: 0.5355

Epoch 00004: val_acc did not improve from 0.56774
Epoch 5/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.6906 - acc: 0.5625
 128/1387 [=>............................] - ETA: 45s - loss: 0.6731 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6667 - acc: 0.6042
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6727 - acc: 0.6016
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6631 - acc: 0.6156
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6716 - acc: 0.6042
 448/1387 [========>.....................] - ETA: 35s - loss: 0.6819 - acc: 0.5871
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6787 - acc: 0.5918
 576/1387 [===========>..................] - ETA: 30s - loss: 0.6759 - acc: 0.5955
 640/1387 [============>.................] - ETA: 27s - loss: 0.6770 - acc: 0.5953
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6766 - acc: 0.5980
 768/1387 [===============>..............] - ETA: 23s - loss: 0.6724 - acc: 0.6016
 832/1387 [================>.............] - ETA: 20s - loss: 0.6753 - acc: 0.5962
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6770 - acc: 0.5915
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6787 - acc: 0.5854
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6866 - acc: 0.5732
1088/1387 [======================>.......] - ETA: 11s - loss: 0.6897 - acc: 0.5735
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6907 - acc: 0.5729 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6901 - acc: 0.5748
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6896 - acc: 0.5734
1344/1387 [============================>.] - ETA: 1s - loss: 0.6883 - acc: 0.5751
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6880 - acc: 0.5732 - val_loss: 0.6761 - val_acc: 0.5806

Epoch 00005: val_acc improved from 0.56774 to 0.58065, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window13/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6972 - acc: 0.5469
 128/1387 [=>............................] - ETA: 45s - loss: 0.6912 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6972 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6993 - acc: 0.5195
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6982 - acc: 0.5250
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6976 - acc: 0.5234
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6934 - acc: 0.5424
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6895 - acc: 0.5547
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6861 - acc: 0.5642
 640/1387 [============>.................] - ETA: 27s - loss: 0.6892 - acc: 0.5563
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6871 - acc: 0.5582
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6851 - acc: 0.5638
 832/1387 [================>.............] - ETA: 20s - loss: 0.6844 - acc: 0.5625
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6817 - acc: 0.5714
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6800 - acc: 0.5750
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6778 - acc: 0.5762
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6813 - acc: 0.5744
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6833 - acc: 0.5694 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6830 - acc: 0.5674
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6793 - acc: 0.5742
1344/1387 [============================>.] - ETA: 1s - loss: 0.6802 - acc: 0.5737
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6819 - acc: 0.5717 - val_loss: 0.6836 - val_acc: 0.5613

Epoch 00006: val_acc did not improve from 0.58065
Epoch 7/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6862 - acc: 0.6094
 128/1387 [=>............................] - ETA: 44s - loss: 0.6691 - acc: 0.6172
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6750 - acc: 0.5990
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6783 - acc: 0.5859
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6748 - acc: 0.6000
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6733 - acc: 0.5990
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6738 - acc: 0.6049
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6757 - acc: 0.6035
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6787 - acc: 0.5990
 640/1387 [============>.................] - ETA: 27s - loss: 0.6791 - acc: 0.6016
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6828 - acc: 0.5895
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6797 - acc: 0.5911
 832/1387 [================>.............] - ETA: 20s - loss: 0.6775 - acc: 0.5950
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6803 - acc: 0.5893
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6807 - acc: 0.5854
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6819 - acc: 0.5830
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6838 - acc: 0.5809
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6833 - acc: 0.5799 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6832 - acc: 0.5806
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6841 - acc: 0.5789
1344/1387 [============================>.] - ETA: 1s - loss: 0.6846 - acc: 0.5766
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6836 - acc: 0.5782 - val_loss: 0.6790 - val_acc: 0.5806

Epoch 00007: val_acc did not improve from 0.58065
Epoch 8/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6635 - acc: 0.6094
 128/1387 [=>............................] - ETA: 44s - loss: 0.6641 - acc: 0.6172
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6689 - acc: 0.6094
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6725 - acc: 0.6133
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6742 - acc: 0.6094
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6758 - acc: 0.5990
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6696 - acc: 0.6205
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6758 - acc: 0.6113
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6792 - acc: 0.6042
 640/1387 [============>.................] - ETA: 26s - loss: 0.6796 - acc: 0.6016
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6835 - acc: 0.5994
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6817 - acc: 0.6003
 832/1387 [================>.............] - ETA: 20s - loss: 0.6787 - acc: 0.6010
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6776 - acc: 0.5982
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6814 - acc: 0.5865
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6834 - acc: 0.5830
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6843 - acc: 0.5827
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6833 - acc: 0.5833 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6804 - acc: 0.5855
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6809 - acc: 0.5859
1344/1387 [============================>.] - ETA: 1s - loss: 0.6838 - acc: 0.5826
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6833 - acc: 0.5833 - val_loss: 0.6848 - val_acc: 0.5548

Epoch 00008: val_acc did not improve from 0.58065
Epoch 9/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7257 - acc: 0.4688
 128/1387 [=>............................] - ETA: 45s - loss: 0.6911 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6908 - acc: 0.5469
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6940 - acc: 0.5664
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6927 - acc: 0.5656
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6891 - acc: 0.5729
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6827 - acc: 0.5848
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6904 - acc: 0.5840
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6907 - acc: 0.5816
 640/1387 [============>.................] - ETA: 27s - loss: 0.6933 - acc: 0.5750
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6942 - acc: 0.5597
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6916 - acc: 0.5612
 832/1387 [================>.............] - ETA: 20s - loss: 0.6902 - acc: 0.5613
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6911 - acc: 0.5603
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6889 - acc: 0.5646
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6854 - acc: 0.5703
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6863 - acc: 0.5689
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6843 - acc: 0.5755 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6820 - acc: 0.5798
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6828 - acc: 0.5797
1344/1387 [============================>.] - ETA: 1s - loss: 0.6834 - acc: 0.5759
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6854 - acc: 0.5681 - val_loss: 0.6782 - val_acc: 0.5935

Epoch 00009: val_acc improved from 0.58065 to 0.59355, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window13/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 10/10

  64/1387 [>.............................] - ETA: 49s - loss: 0.6136 - acc: 0.7188
 128/1387 [=>............................] - ETA: 46s - loss: 0.6158 - acc: 0.7031
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6381 - acc: 0.6510
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6582 - acc: 0.6094
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6561 - acc: 0.6094
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6567 - acc: 0.6094
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6581 - acc: 0.6049
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6684 - acc: 0.5898
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6690 - acc: 0.5920
 640/1387 [============>.................] - ETA: 27s - loss: 0.6693 - acc: 0.5906
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6699 - acc: 0.5938
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6704 - acc: 0.5951
 832/1387 [================>.............] - ETA: 20s - loss: 0.6698 - acc: 0.5962
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6708 - acc: 0.5904
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6701 - acc: 0.5938
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6699 - acc: 0.5938
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6731 - acc: 0.5910
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6761 - acc: 0.5885 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6793 - acc: 0.5855
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6798 - acc: 0.5859
1344/1387 [============================>.] - ETA: 1s - loss: 0.6798 - acc: 0.5826
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6785 - acc: 0.5854 - val_loss: 0.6791 - val_acc: 0.5613

Epoch 00010: val_acc did not improve from 0.59355
样本个数 193
样本个数 386
(?, ?, 128)
(?, ?, 128)
(?, ?, 128)
(?, 128)
(?, 128)
(?, 1)
window_select11-15.py:152: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 12s
128/386 [========>.....................] - ETA: 6s 
192/386 [=============>................] - ETA: 4s
256/386 [==================>...........] - ETA: 2s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 7s 19ms/step
loss: 0.6830682368476156
acc: 0.5621761658031088
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f7dd438a7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f7dd438a7d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f7dd4307390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f7dd4307390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c722c590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c722c590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86dfcbc690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f86dfcbc690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7dd42b7c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7dd42b7c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86dfd023d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86dfd023d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86dfcbc190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f86dfcbc190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7dd4305a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7dd4305a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7dd403f450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7dd403f450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7dd40bb110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7dd40bb110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7dd40a9fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7dd40a9fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7dd4196510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7dd4196510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7db46236d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7db46236d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7db451a690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7db451a690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7dd430ebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7dd430ebd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7db47ee4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7db47ee4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7db465ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7db465ff90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d9417de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d9417de10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d941b6490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d941b6490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d940dd210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d940dd210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d940c9c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d940c9c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7db45aed10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7db45aed10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d940ba890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d940ba890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d74616ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d74616ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d7451ce10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d7451ce10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d74734050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d74734050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d74616f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d74616f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d7439cc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d7439cc90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d742e2710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d742e2710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d744da810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d744da810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d742ad750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d742ad750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d742e2910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d742e2910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d74265750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d74265750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d54757250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d54757250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d7423c450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d7423c450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d54743090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d54743090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d7457de50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d7457de50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d546a6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d546a6c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d546c0050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d546c0050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d543d5210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d543d5210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d54662690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d54662690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d54662850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d54662850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7dd43a7850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7dd43a7850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7dd433c750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7dd433c750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7dd4303910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7dd4303910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d54436890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d54436890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d54203350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d54203350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7dd43a7bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7dd43a7bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d540400d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d540400d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d345c7250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d345c7250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d345344d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d345344d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7dd434f150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7dd434f150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d3462b690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d3462b690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d342d4290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d342d4290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d341c4b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d341c4b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d34311850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d34311850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d342d40d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d342d40d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d341b9410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d341b9410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d341c4c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7d341c4c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d14746d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7d14746d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d147f0a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d147f0a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d34054810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7d34054810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d341c4b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d341c4b90>>: AttributeError: module 'gast' has no attribute 'Str'
(?, ?, 128)
(?, ?, 128)
(?, ?, 128)
(?, 128)
(?, 128)
(?, 1)
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 3:05 - loss: 0.7549 - acc: 0.5000
 128/1387 [=>............................] - ETA: 1:50 - loss: 0.8358 - acc: 0.4844
 192/1387 [===>..........................] - ETA: 1:24 - loss: 0.8184 - acc: 0.5156
 256/1387 [====>.........................] - ETA: 1:10 - loss: 0.8329 - acc: 0.5078
 320/1387 [=====>........................] - ETA: 1:00 - loss: 0.8199 - acc: 0.5094
 384/1387 [=======>......................] - ETA: 53s - loss: 0.8099 - acc: 0.4922 
 448/1387 [========>.....................] - ETA: 47s - loss: 0.7941 - acc: 0.5045
 512/1387 [==========>...................] - ETA: 42s - loss: 0.7973 - acc: 0.5039
 576/1387 [===========>..................] - ETA: 38s - loss: 0.7833 - acc: 0.5122
 640/1387 [============>.................] - ETA: 34s - loss: 0.7822 - acc: 0.5125
 704/1387 [==============>...............] - ETA: 31s - loss: 0.7778 - acc: 0.5142
 768/1387 [===============>..............] - ETA: 27s - loss: 0.7727 - acc: 0.5169
 832/1387 [================>.............] - ETA: 24s - loss: 0.7691 - acc: 0.5180
 896/1387 [==================>...........] - ETA: 21s - loss: 0.7622 - acc: 0.5234
 960/1387 [===================>..........] - ETA: 18s - loss: 0.7627 - acc: 0.5188
1024/1387 [=====================>........] - ETA: 15s - loss: 0.7596 - acc: 0.5186
1088/1387 [======================>.......] - ETA: 12s - loss: 0.7575 - acc: 0.5202
1152/1387 [=======================>......] - ETA: 9s - loss: 0.7580 - acc: 0.5156 
1216/1387 [=========================>....] - ETA: 7s - loss: 0.7550 - acc: 0.5181
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7502 - acc: 0.5242
1344/1387 [============================>.] - ETA: 1s - loss: 0.7446 - acc: 0.5290
1387/1387 [==============================] - 60s 43ms/step - loss: 0.7425 - acc: 0.5314 - val_loss: 0.6973 - val_acc: 0.5677

Epoch 00001: val_acc improved from -inf to 0.56774, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window14/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.7630 - acc: 0.5156
 128/1387 [=>............................] - ETA: 45s - loss: 0.7596 - acc: 0.5078
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7679 - acc: 0.5000
 256/1387 [====>.........................] - ETA: 40s - loss: 0.7589 - acc: 0.5234
 320/1387 [=====>........................] - ETA: 39s - loss: 0.7466 - acc: 0.5344
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7339 - acc: 0.5391
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7180 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7157 - acc: 0.5449
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7163 - acc: 0.5399
 640/1387 [============>.................] - ETA: 27s - loss: 0.7129 - acc: 0.5422
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7102 - acc: 0.5412
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7178 - acc: 0.5260
 832/1387 [================>.............] - ETA: 20s - loss: 0.7225 - acc: 0.5168
 896/1387 [==================>...........] - ETA: 17s - loss: 0.7185 - acc: 0.5179
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7156 - acc: 0.5198
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7120 - acc: 0.5273
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7100 - acc: 0.5303
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7100 - acc: 0.5295 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7092 - acc: 0.5280
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7066 - acc: 0.5305
1344/1387 [============================>.] - ETA: 1s - loss: 0.7073 - acc: 0.5305
1387/1387 [==============================] - 53s 38ms/step - loss: 0.7045 - acc: 0.5364 - val_loss: 0.7200 - val_acc: 0.4903

Epoch 00002: val_acc did not improve from 0.56774
Epoch 3/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6665 - acc: 0.5781
 128/1387 [=>............................] - ETA: 44s - loss: 0.6683 - acc: 0.6094
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6718 - acc: 0.6146
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6674 - acc: 0.6133
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6621 - acc: 0.6219
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6663 - acc: 0.6120
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6669 - acc: 0.6138
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6762 - acc: 0.5977
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6784 - acc: 0.5851
 640/1387 [============>.................] - ETA: 26s - loss: 0.6794 - acc: 0.5844
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6773 - acc: 0.5852
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6767 - acc: 0.5807
 832/1387 [================>.............] - ETA: 20s - loss: 0.6831 - acc: 0.5697
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6876 - acc: 0.5625
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6887 - acc: 0.5625
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6849 - acc: 0.5693
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6890 - acc: 0.5607
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6923 - acc: 0.5573 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6936 - acc: 0.5567
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6969 - acc: 0.5516
1344/1387 [============================>.] - ETA: 1s - loss: 0.6954 - acc: 0.5536
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6957 - acc: 0.5544 - val_loss: 0.7028 - val_acc: 0.5097

Epoch 00003: val_acc did not improve from 0.56774
Epoch 4/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7216 - acc: 0.5625
 128/1387 [=>............................] - ETA: 48s - loss: 0.7081 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 44s - loss: 0.7043 - acc: 0.5833
 256/1387 [====>.........................] - ETA: 42s - loss: 0.6979 - acc: 0.5898
 320/1387 [=====>........................] - ETA: 39s - loss: 0.6970 - acc: 0.5687
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6939 - acc: 0.5781
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6914 - acc: 0.5692
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6909 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6954 - acc: 0.5573
 640/1387 [============>.................] - ETA: 27s - loss: 0.7032 - acc: 0.5500
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7022 - acc: 0.5568
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6960 - acc: 0.5677
 832/1387 [================>.............] - ETA: 20s - loss: 0.6980 - acc: 0.5637
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6967 - acc: 0.5681
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6989 - acc: 0.5615
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7014 - acc: 0.5586
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7016 - acc: 0.5597
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7027 - acc: 0.5547 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7001 - acc: 0.5584
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6994 - acc: 0.5570
1344/1387 [============================>.] - ETA: 1s - loss: 0.6989 - acc: 0.5536
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6973 - acc: 0.5559 - val_loss: 0.7001 - val_acc: 0.5355

Epoch 00004: val_acc did not improve from 0.56774
Epoch 5/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.7133 - acc: 0.4844
 128/1387 [=>............................] - ETA: 45s - loss: 0.7054 - acc: 0.5391
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7130 - acc: 0.5104
 256/1387 [====>.........................] - ETA: 41s - loss: 0.7185 - acc: 0.4961
 320/1387 [=====>........................] - ETA: 38s - loss: 0.7133 - acc: 0.5094
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7050 - acc: 0.5417
 448/1387 [========>.....................] - ETA: 33s - loss: 0.7090 - acc: 0.5290
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7083 - acc: 0.5293
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7050 - acc: 0.5260
 640/1387 [============>.................] - ETA: 26s - loss: 0.6987 - acc: 0.5422
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6986 - acc: 0.5440
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6979 - acc: 0.5430
 832/1387 [================>.............] - ETA: 19s - loss: 0.6956 - acc: 0.5481
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6962 - acc: 0.5446
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6998 - acc: 0.5375
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6977 - acc: 0.5439
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6935 - acc: 0.5524
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6946 - acc: 0.5503 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6935 - acc: 0.5477
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6922 - acc: 0.5500
1344/1387 [============================>.] - ETA: 1s - loss: 0.6915 - acc: 0.5528
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6918 - acc: 0.5544 - val_loss: 0.7100 - val_acc: 0.5419

Epoch 00005: val_acc did not improve from 0.56774
Epoch 6/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6259 - acc: 0.6719
 128/1387 [=>............................] - ETA: 45s - loss: 0.6566 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6600 - acc: 0.6094
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6758 - acc: 0.5742
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6794 - acc: 0.5687
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6799 - acc: 0.5755
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6849 - acc: 0.5625
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6821 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6803 - acc: 0.5747
 640/1387 [============>.................] - ETA: 27s - loss: 0.6813 - acc: 0.5766
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6850 - acc: 0.5710
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6837 - acc: 0.5716
 832/1387 [================>.............] - ETA: 20s - loss: 0.6792 - acc: 0.5745
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6872 - acc: 0.5647
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6852 - acc: 0.5667
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6857 - acc: 0.5635
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6863 - acc: 0.5634
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6870 - acc: 0.5616 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6867 - acc: 0.5617
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6868 - acc: 0.5602
1344/1387 [============================>.] - ETA: 1s - loss: 0.6863 - acc: 0.5618
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6867 - acc: 0.5602 - val_loss: 0.6991 - val_acc: 0.5161

Epoch 00006: val_acc did not improve from 0.56774
Epoch 7/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7249 - acc: 0.5156
 128/1387 [=>............................] - ETA: 45s - loss: 0.6902 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 44s - loss: 0.6817 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 42s - loss: 0.6831 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 39s - loss: 0.6851 - acc: 0.5500
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6875 - acc: 0.5521
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6960 - acc: 0.5424
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6956 - acc: 0.5371
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6966 - acc: 0.5330
 640/1387 [============>.................] - ETA: 27s - loss: 0.6941 - acc: 0.5375
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6955 - acc: 0.5384
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6977 - acc: 0.5286
 832/1387 [================>.............] - ETA: 20s - loss: 0.6977 - acc: 0.5288
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6983 - acc: 0.5257
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6991 - acc: 0.5219
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6981 - acc: 0.5225
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6965 - acc: 0.5248
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6977 - acc: 0.5226 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6981 - acc: 0.5263
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6972 - acc: 0.5305
1344/1387 [============================>.] - ETA: 1s - loss: 0.6967 - acc: 0.5260
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6953 - acc: 0.5299 - val_loss: 0.7136 - val_acc: 0.5097

Epoch 00007: val_acc did not improve from 0.56774
Epoch 8/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.7028 - acc: 0.5469
 128/1387 [=>............................] - ETA: 45s - loss: 0.7074 - acc: 0.5156
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6925 - acc: 0.5365
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6849 - acc: 0.5469
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6854 - acc: 0.5437
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6917 - acc: 0.5417
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6903 - acc: 0.5491
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6874 - acc: 0.5508
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6844 - acc: 0.5590
 640/1387 [============>.................] - ETA: 26s - loss: 0.6829 - acc: 0.5672
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6843 - acc: 0.5668
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6845 - acc: 0.5716
 832/1387 [================>.............] - ETA: 19s - loss: 0.6829 - acc: 0.5685
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6817 - acc: 0.5692
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6803 - acc: 0.5729
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6798 - acc: 0.5801
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6792 - acc: 0.5790
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6806 - acc: 0.5773 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6818 - acc: 0.5748
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6822 - acc: 0.5758
1344/1387 [============================>.] - ETA: 1s - loss: 0.6825 - acc: 0.5766
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6851 - acc: 0.5739 - val_loss: 0.7225 - val_acc: 0.5161

Epoch 00008: val_acc did not improve from 0.56774
Epoch 9/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6607 - acc: 0.5938
 128/1387 [=>............................] - ETA: 46s - loss: 0.6704 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6736 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6674 - acc: 0.5820
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6807 - acc: 0.5625
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6786 - acc: 0.5703
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6838 - acc: 0.5625
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6822 - acc: 0.5625
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6828 - acc: 0.5625
 640/1387 [============>.................] - ETA: 27s - loss: 0.6844 - acc: 0.5609
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6852 - acc: 0.5597
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6876 - acc: 0.5547
 832/1387 [================>.............] - ETA: 20s - loss: 0.6890 - acc: 0.5529
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6871 - acc: 0.5536
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6870 - acc: 0.5521
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6860 - acc: 0.5537
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6839 - acc: 0.5551
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6830 - acc: 0.5582 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6822 - acc: 0.5592
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6842 - acc: 0.5586
1344/1387 [============================>.] - ETA: 1s - loss: 0.6842 - acc: 0.5595
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6839 - acc: 0.5588 - val_loss: 0.7274 - val_acc: 0.4903

Epoch 00009: val_acc did not improve from 0.56774
Epoch 10/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.6468 - acc: 0.6562
 128/1387 [=>............................] - ETA: 45s - loss: 0.6409 - acc: 0.6562
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6555 - acc: 0.6198
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6679 - acc: 0.6055
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6736 - acc: 0.5875
 384/1387 [=======>......................] - ETA: 35s - loss: 0.6690 - acc: 0.5911
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6676 - acc: 0.6004
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6748 - acc: 0.5918
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6768 - acc: 0.5920
 640/1387 [============>.................] - ETA: 26s - loss: 0.6766 - acc: 0.5906
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6791 - acc: 0.5852
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6795 - acc: 0.5846
 832/1387 [================>.............] - ETA: 19s - loss: 0.6779 - acc: 0.5865
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6785 - acc: 0.5871
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6776 - acc: 0.5906
1024/1387 [=====================>........] - ETA: 12s - loss: 0.6770 - acc: 0.5908
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6772 - acc: 0.5892
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6815 - acc: 0.5816 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6818 - acc: 0.5814
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6821 - acc: 0.5797
1344/1387 [============================>.] - ETA: 1s - loss: 0.6839 - acc: 0.5774
1387/1387 [==============================] - 52s 38ms/step - loss: 0.6843 - acc: 0.5753 - val_loss: 0.7016 - val_acc: 0.5419

Epoch 00010: val_acc did not improve from 0.56774
样本个数 193
样本个数 386
(?, ?, 128)
(?, ?, 128)
(?, ?, 128)
(?, 128)
(?, 128)
(?, 1)
window_select11-15.py:152: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 16s
128/386 [========>.....................] - ETA: 8s 
192/386 [=============>................] - ETA: 5s
256/386 [==================>...........] - ETA: 3s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 8s 21ms/step
loss: 0.6862426857256518
acc: 0.5569948186528497
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f7ccc09b790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f7ccc09b790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f7ccc08f950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f7ccc08f950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c722c1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c722c1d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c741511d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c741511d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c540b7610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c540b7610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d144b7c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7d144b7c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c74151250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c74151250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c7329ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f86c7329ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c7413ae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c7413ae10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c7453d250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c7453d250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ccc057310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7ccc057310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c74642b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c74642b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c7453de90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c7453de90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c742f7650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c742f7650>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c741841d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c741841d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c74309f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c74309f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c742f7850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c742f7850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c74be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c74be10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c4c659210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c4c659210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c4c50ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c4c50ba90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c744dc510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c744dc510>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c4c659810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c4c659810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c640090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c640090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c4c697510>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c4c697510>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c4c550110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c4c550110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c5ec250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c5ec250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c4c356590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c4c356590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c254450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c254450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c4c202dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c4c202dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c2067a710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c2067a710>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c2d1790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c2d1790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c4c163e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c4c163e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c206e0150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c206e0150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c204ef150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c204ef150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c20459290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c20459290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c206e2890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c206e2890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c4c0a6cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c4c0a6cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c2037c0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c2037c0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c202d7e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c202d7e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c20229550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c20229550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c200e6490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c200e6490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c20455f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c20455f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c0a4c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c4c0a4c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c14682e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c14682e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c144ff810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c144ff810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c200a00d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c200a00d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c14542550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c14542550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c200cbb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c200cbb10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c143106d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7c143106d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c1434b910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7c1434b910>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c1421b450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c1421b450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c14310cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c14310cd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c14360d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c14360d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7bd47f1390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7bd47f1390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7bd467ed50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7bd467ed50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c140419d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7c140419d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c14242d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c14242d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7bd45f8890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7bd45f8890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7bd4484e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f7bd4484e10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7bd4467150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f7bd4467150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7bd443fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7bd443fb90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c1421e250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f7c1421e250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7bd44c7490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f7bd44c7490>>: AttributeError: module 'gast' has no attribute 'Str'
(?, ?, 128)
(?, ?, 128)
(?, ?, 128)
(?, 128)
(?, 128)
(?, 1)
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 3:40 - loss: 0.7753 - acc: 0.4844
 128/1387 [=>............................] - ETA: 2:06 - loss: 0.7719 - acc: 0.4922
 192/1387 [===>..........................] - ETA: 1:34 - loss: 0.7722 - acc: 0.4896
 256/1387 [====>.........................] - ETA: 1:17 - loss: 0.7683 - acc: 0.4844
 320/1387 [=====>........................] - ETA: 1:06 - loss: 0.7606 - acc: 0.4906
 384/1387 [=======>......................] - ETA: 57s - loss: 0.7430 - acc: 0.5182 
 448/1387 [========>.....................] - ETA: 51s - loss: 0.7371 - acc: 0.5179
 512/1387 [==========>...................] - ETA: 45s - loss: 0.7351 - acc: 0.5156
 576/1387 [===========>..................] - ETA: 41s - loss: 0.7382 - acc: 0.5087
 640/1387 [============>.................] - ETA: 36s - loss: 0.7341 - acc: 0.5156
 704/1387 [==============>...............] - ETA: 32s - loss: 0.7341 - acc: 0.5142
 768/1387 [===============>..............] - ETA: 29s - loss: 0.7323 - acc: 0.5182
 832/1387 [================>.............] - ETA: 25s - loss: 0.7361 - acc: 0.5156
 896/1387 [==================>...........] - ETA: 22s - loss: 0.7304 - acc: 0.5201
 960/1387 [===================>..........] - ETA: 19s - loss: 0.7280 - acc: 0.5229
1024/1387 [=====================>........] - ETA: 16s - loss: 0.7266 - acc: 0.5215
1088/1387 [======================>.......] - ETA: 13s - loss: 0.7289 - acc: 0.5193
1152/1387 [=======================>......] - ETA: 10s - loss: 0.7339 - acc: 0.5182
1216/1387 [=========================>....] - ETA: 7s - loss: 0.7298 - acc: 0.5214 
1280/1387 [==========================>...] - ETA: 4s - loss: 0.7286 - acc: 0.5219
1344/1387 [============================>.] - ETA: 1s - loss: 0.7267 - acc: 0.5231
1387/1387 [==============================] - 62s 45ms/step - loss: 0.7237 - acc: 0.5278 - val_loss: 0.6966 - val_acc: 0.5484

Epoch 00001: val_acc improved from -inf to 0.54839, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window15/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6792 - acc: 0.5781
 128/1387 [=>............................] - ETA: 45s - loss: 0.6817 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6820 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6893 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6975 - acc: 0.5500
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7025 - acc: 0.5469
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7050 - acc: 0.5446
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6973 - acc: 0.5566
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7008 - acc: 0.5556
 640/1387 [============>.................] - ETA: 27s - loss: 0.6997 - acc: 0.5594
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7027 - acc: 0.5540
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7039 - acc: 0.5508
 832/1387 [================>.............] - ETA: 20s - loss: 0.7060 - acc: 0.5469
 896/1387 [==================>...........] - ETA: 17s - loss: 0.7071 - acc: 0.5446
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7054 - acc: 0.5448
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7078 - acc: 0.5410
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7071 - acc: 0.5414
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7082 - acc: 0.5382 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7113 - acc: 0.5354
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7094 - acc: 0.5344
1344/1387 [============================>.] - ETA: 1s - loss: 0.7066 - acc: 0.5365
1387/1387 [==============================] - 53s 38ms/step - loss: 0.7040 - acc: 0.5393 - val_loss: 0.7036 - val_acc: 0.5548

Epoch 00002: val_acc improved from 0.54839 to 0.55484, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window15/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7418 - acc: 0.4688
 128/1387 [=>............................] - ETA: 46s - loss: 0.7088 - acc: 0.4922
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7240 - acc: 0.4896
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6979 - acc: 0.5273
 320/1387 [=====>........................] - ETA: 38s - loss: 0.7082 - acc: 0.5062
 384/1387 [=======>......................] - ETA: 35s - loss: 0.7111 - acc: 0.5104
 448/1387 [========>.....................] - ETA: 33s - loss: 0.7101 - acc: 0.5089
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7028 - acc: 0.5273
 576/1387 [===========>..................] - ETA: 28s - loss: 0.6957 - acc: 0.5365
 640/1387 [============>.................] - ETA: 26s - loss: 0.7012 - acc: 0.5359
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7010 - acc: 0.5355
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7017 - acc: 0.5365
 832/1387 [================>.............] - ETA: 19s - loss: 0.6968 - acc: 0.5385
 896/1387 [==================>...........] - ETA: 17s - loss: 0.7014 - acc: 0.5368
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7020 - acc: 0.5354
1024/1387 [=====================>........] - ETA: 12s - loss: 0.7067 - acc: 0.5322
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7068 - acc: 0.5303
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7107 - acc: 0.5286 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7100 - acc: 0.5312
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7093 - acc: 0.5320
1344/1387 [============================>.] - ETA: 1s - loss: 0.7064 - acc: 0.5379
1387/1387 [==============================] - 52s 38ms/step - loss: 0.7071 - acc: 0.5364 - val_loss: 0.6868 - val_acc: 0.5677

Epoch 00003: val_acc improved from 0.55484 to 0.56774, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window15/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.6688 - acc: 0.5938
 128/1387 [=>............................] - ETA: 46s - loss: 0.6914 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7183 - acc: 0.5365
 256/1387 [====>.........................] - ETA: 40s - loss: 0.7193 - acc: 0.5312
 320/1387 [=====>........................] - ETA: 38s - loss: 0.7198 - acc: 0.5281
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7286 - acc: 0.5182
 448/1387 [========>.....................] - ETA: 34s - loss: 0.7234 - acc: 0.5179
 512/1387 [==========>...................] - ETA: 31s - loss: 0.7275 - acc: 0.5039
 576/1387 [===========>..................] - ETA: 29s - loss: 0.7226 - acc: 0.5087
 640/1387 [============>.................] - ETA: 27s - loss: 0.7191 - acc: 0.5141
 704/1387 [==============>...............] - ETA: 24s - loss: 0.7198 - acc: 0.5099
 768/1387 [===============>..............] - ETA: 22s - loss: 0.7172 - acc: 0.5130
 832/1387 [================>.............] - ETA: 20s - loss: 0.7157 - acc: 0.5216
 896/1387 [==================>...........] - ETA: 17s - loss: 0.7151 - acc: 0.5201
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7128 - acc: 0.5208
1024/1387 [=====================>........] - ETA: 13s - loss: 0.7098 - acc: 0.5244
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7077 - acc: 0.5285
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7096 - acc: 0.5252 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7120 - acc: 0.5189
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7078 - acc: 0.5258
1344/1387 [============================>.] - ETA: 1s - loss: 0.7063 - acc: 0.5312
1387/1387 [==============================] - 53s 38ms/step - loss: 0.7057 - acc: 0.5299 - val_loss: 0.6785 - val_acc: 0.6000

Epoch 00004: val_acc improved from 0.56774 to 0.60000, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window15/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 5/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6799 - acc: 0.5781
 128/1387 [=>............................] - ETA: 45s - loss: 0.6567 - acc: 0.6094
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6718 - acc: 0.5990
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6865 - acc: 0.5742
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6947 - acc: 0.5625
 384/1387 [=======>......................] - ETA: 37s - loss: 0.6929 - acc: 0.5729
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6880 - acc: 0.5781
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6923 - acc: 0.5645
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6927 - acc: 0.5608
 640/1387 [============>.................] - ETA: 27s - loss: 0.6955 - acc: 0.5547
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6947 - acc: 0.5554
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6968 - acc: 0.5534
 832/1387 [================>.............] - ETA: 20s - loss: 0.6979 - acc: 0.5541
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6980 - acc: 0.5558
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6988 - acc: 0.5552
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6991 - acc: 0.5518
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6960 - acc: 0.5579
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6964 - acc: 0.5564 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6996 - acc: 0.5502
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6987 - acc: 0.5484
1344/1387 [============================>.] - ETA: 1s - loss: 0.7003 - acc: 0.5446
1387/1387 [==============================] - 53s 38ms/step - loss: 0.7020 - acc: 0.5400 - val_loss: 0.6816 - val_acc: 0.5806

Epoch 00005: val_acc did not improve from 0.60000
Epoch 6/10

  64/1387 [>.............................] - ETA: 47s - loss: 0.7025 - acc: 0.5000
 128/1387 [=>............................] - ETA: 45s - loss: 0.6966 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 43s - loss: 0.7031 - acc: 0.4948
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6990 - acc: 0.5039
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6882 - acc: 0.5281
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6910 - acc: 0.5260
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6919 - acc: 0.5223
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6928 - acc: 0.5215
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6912 - acc: 0.5295
 640/1387 [============>.................] - ETA: 27s - loss: 0.6926 - acc: 0.5328
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6922 - acc: 0.5298
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6970 - acc: 0.5260
 832/1387 [================>.............] - ETA: 20s - loss: 0.6993 - acc: 0.5228
 896/1387 [==================>...........] - ETA: 18s - loss: 0.6989 - acc: 0.5290
 960/1387 [===================>..........] - ETA: 15s - loss: 0.7001 - acc: 0.5229
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6991 - acc: 0.5225
1088/1387 [======================>.......] - ETA: 10s - loss: 0.7016 - acc: 0.5184
1152/1387 [=======================>......] - ETA: 8s - loss: 0.7015 - acc: 0.5165 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.7004 - acc: 0.5214
1280/1387 [==========================>...] - ETA: 3s - loss: 0.7022 - acc: 0.5211
1344/1387 [============================>.] - ETA: 1s - loss: 0.7005 - acc: 0.5253
1387/1387 [==============================] - 54s 39ms/step - loss: 0.6988 - acc: 0.5285 - val_loss: 0.6859 - val_acc: 0.5742

Epoch 00006: val_acc did not improve from 0.60000
Epoch 7/10

  64/1387 [>.............................] - ETA: 45s - loss: 0.6977 - acc: 0.5938
 128/1387 [=>............................] - ETA: 44s - loss: 0.6916 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6891 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6895 - acc: 0.5742
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6908 - acc: 0.5625
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6983 - acc: 0.5573
 448/1387 [========>.....................] - ETA: 33s - loss: 0.7005 - acc: 0.5513
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6976 - acc: 0.5488
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6947 - acc: 0.5521
 640/1387 [============>.................] - ETA: 26s - loss: 0.6943 - acc: 0.5516
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6932 - acc: 0.5554
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6912 - acc: 0.5547
 832/1387 [================>.............] - ETA: 20s - loss: 0.6899 - acc: 0.5577
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6912 - acc: 0.5569
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6899 - acc: 0.5604
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6933 - acc: 0.5518
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6922 - acc: 0.5533
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6936 - acc: 0.5503 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6913 - acc: 0.5518
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6901 - acc: 0.5563
1344/1387 [============================>.] - ETA: 1s - loss: 0.6897 - acc: 0.5528
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6897 - acc: 0.5566 - val_loss: 0.6862 - val_acc: 0.5677

Epoch 00007: val_acc did not improve from 0.60000
Epoch 8/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.6748 - acc: 0.5625
 128/1387 [=>............................] - ETA: 44s - loss: 0.6883 - acc: 0.5547
 192/1387 [===>..........................] - ETA: 42s - loss: 0.6882 - acc: 0.5521
 256/1387 [====>.........................] - ETA: 40s - loss: 0.6833 - acc: 0.5664
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6843 - acc: 0.5656
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6872 - acc: 0.5521
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6876 - acc: 0.5513
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6804 - acc: 0.5723
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6865 - acc: 0.5712
 640/1387 [============>.................] - ETA: 26s - loss: 0.6812 - acc: 0.5891
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6814 - acc: 0.5810
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6818 - acc: 0.5807
 832/1387 [================>.............] - ETA: 19s - loss: 0.6843 - acc: 0.5769
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6842 - acc: 0.5737
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6827 - acc: 0.5781
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6817 - acc: 0.5801
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6864 - acc: 0.5754
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6821 - acc: 0.5833 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6816 - acc: 0.5863
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6825 - acc: 0.5820
1344/1387 [============================>.] - ETA: 1s - loss: 0.6832 - acc: 0.5811
1387/1387 [==============================] - 52s 38ms/step - loss: 0.6850 - acc: 0.5789 - val_loss: 0.6869 - val_acc: 0.5871

Epoch 00008: val_acc did not improve from 0.60000
Epoch 9/10

  64/1387 [>.............................] - ETA: 46s - loss: 0.7446 - acc: 0.4688
 128/1387 [=>............................] - ETA: 44s - loss: 0.7200 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 44s - loss: 0.7149 - acc: 0.5312
 256/1387 [====>.........................] - ETA: 41s - loss: 0.7141 - acc: 0.5234
 320/1387 [=====>........................] - ETA: 38s - loss: 0.7060 - acc: 0.5312
 384/1387 [=======>......................] - ETA: 36s - loss: 0.7049 - acc: 0.5339
 448/1387 [========>.....................] - ETA: 34s - loss: 0.6956 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 32s - loss: 0.6954 - acc: 0.5527
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6937 - acc: 0.5486
 640/1387 [============>.................] - ETA: 27s - loss: 0.6881 - acc: 0.5594
 704/1387 [==============>...............] - ETA: 25s - loss: 0.6887 - acc: 0.5526
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6843 - acc: 0.5599
 832/1387 [================>.............] - ETA: 20s - loss: 0.6832 - acc: 0.5601
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6816 - acc: 0.5647
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6826 - acc: 0.5646
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6835 - acc: 0.5654
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6823 - acc: 0.5643
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6803 - acc: 0.5677 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6807 - acc: 0.5650
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6794 - acc: 0.5648
1344/1387 [============================>.] - ETA: 1s - loss: 0.6791 - acc: 0.5677
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6790 - acc: 0.5689 - val_loss: 0.6886 - val_acc: 0.5871

Epoch 00009: val_acc did not improve from 0.60000
Epoch 10/10

  64/1387 [>.............................] - ETA: 48s - loss: 0.6811 - acc: 0.6250
 128/1387 [=>............................] - ETA: 46s - loss: 0.6841 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 43s - loss: 0.6886 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 41s - loss: 0.6899 - acc: 0.5742
 320/1387 [=====>........................] - ETA: 38s - loss: 0.6924 - acc: 0.5563
 384/1387 [=======>......................] - ETA: 36s - loss: 0.6903 - acc: 0.5599
 448/1387 [========>.....................] - ETA: 33s - loss: 0.6884 - acc: 0.5491
 512/1387 [==========>...................] - ETA: 31s - loss: 0.6841 - acc: 0.5605
 576/1387 [===========>..................] - ETA: 29s - loss: 0.6843 - acc: 0.5538
 640/1387 [============>.................] - ETA: 27s - loss: 0.6889 - acc: 0.5422
 704/1387 [==============>...............] - ETA: 24s - loss: 0.6846 - acc: 0.5497
 768/1387 [===============>..............] - ETA: 22s - loss: 0.6852 - acc: 0.5495
 832/1387 [================>.............] - ETA: 20s - loss: 0.6819 - acc: 0.5613
 896/1387 [==================>...........] - ETA: 17s - loss: 0.6810 - acc: 0.5603
 960/1387 [===================>..........] - ETA: 15s - loss: 0.6824 - acc: 0.5573
1024/1387 [=====================>........] - ETA: 13s - loss: 0.6820 - acc: 0.5566
1088/1387 [======================>.......] - ETA: 10s - loss: 0.6815 - acc: 0.5561
1152/1387 [=======================>......] - ETA: 8s - loss: 0.6800 - acc: 0.5564 
1216/1387 [=========================>....] - ETA: 6s - loss: 0.6799 - acc: 0.5543
1280/1387 [==========================>...] - ETA: 3s - loss: 0.6769 - acc: 0.5586
1344/1387 [============================>.] - ETA: 1s - loss: 0.6770 - acc: 0.5603
1387/1387 [==============================] - 53s 38ms/step - loss: 0.6795 - acc: 0.5573 - val_loss: 0.6873 - val_acc: 0.5871

Epoch 00010: val_acc did not improve from 0.60000
样本个数 193
样本个数 386
(?, ?, 128)
(?, ?, 128)
(?, ?, 128)
(?, 128)
(?, 128)
(?, 1)
window_select11-15.py:152: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 19s
128/386 [========>.....................] - ETA: 9s 
192/386 [=============>................] - ETA: 5s
256/386 [==================>...........] - ETA: 3s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 9s 22ms/step
loss: 0.6842085901319672
acc: 0.5777202072538861
