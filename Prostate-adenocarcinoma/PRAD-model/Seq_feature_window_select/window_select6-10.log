nohup: ignoring input
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
样本个数 771
样本个数 1542
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f003aed4b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7f003aed4b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f003aef3e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7f003aef3e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003ae5d390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003ae5d390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f003ae5d0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f003ae5d0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f003ae94150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f003ae94150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003ae63350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003ae63350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f003ad58c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f003ad58c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003ad12490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003ad12490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f003ab3bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f003ab3bc50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f00329bcf10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f00329bcf10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003ab57b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003ab57b10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f003ad6c310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f003ad6c310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003ad73490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003ad73490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0032b14350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0032b14350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0032720210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0032720210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003adcdfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003adcdfd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0032a94710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0032a94710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0032711a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0032711a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0032569190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0032569190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0032379dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0032379dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0032433590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0032433590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f00327aae50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f00327aae50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f002a2cbf50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f002a2cbf50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f00324b72d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f00324b72d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f002a1fa750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f002a1fa750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003280e450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003280e450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f002a2cb250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f002a2cb250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f002a1f43d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f002a1f43d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0029ee7050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0029ee7050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0029d35b10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0029d35b10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0029dec6d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0029dec6d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0029f28b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0029f28b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0029ed5550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0029ed5550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0029d9fd50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0029d9fd50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0019a425d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0019a425d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0029bca990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0029bca990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0029ef0ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0029ef0ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00199b1950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00199b1950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0019a96250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0019a96250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0019769ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0019769ed0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f005cdfced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f005cdfced0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0019a7d390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0019a7d390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f007eea8f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f007eea8f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0019558250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0019558250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f001941c7d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f001941c7d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f001951e9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f001951e9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0019558050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0019558050>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00194386d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00194386d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f001946e490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f001946e490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f00191e21d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f00191e21d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f001924ec10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f001924ec10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f00193f7f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f00193f7f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0019853610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0019853610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0018f05d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0018f05d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0018ef12d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0018ef12d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0018f35250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0018f35250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0018f05f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0018f05f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003adee3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f003adee3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0018c09890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0018c09890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0010b23950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f0010b23950>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0018c7de50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0018c7de50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0018c09f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0018c09f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0018c2f110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f0018c2f110>>: AttributeError: module 'gast' has no attribute 'Str'
2023-01-12 11:18:51.168967: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2023-01-12 11:18:51.238946: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2023-01-12 11:18:51.303336: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5586f3165b60 executing computations on platform Host. Devices:
2023-01-12 11:18:51.303445: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2023-01-12 11:18:51.828915: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])
WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From /home/lyli/miniconda3/envs/SeqPose/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 4:37 - loss: 0.7545 - acc: 0.4688
 128/1387 [=>............................] - ETA: 3:20 - loss: 0.7142 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 3:06 - loss: 0.7724 - acc: 0.4896
 256/1387 [====>.........................] - ETA: 2:44 - loss: 0.7643 - acc: 0.4844
 320/1387 [=====>........................] - ETA: 2:23 - loss: 0.7550 - acc: 0.4938
 384/1387 [=======>......................] - ETA: 2:07 - loss: 0.7594 - acc: 0.4870
 448/1387 [========>.....................] - ETA: 1:59 - loss: 0.7516 - acc: 0.4911
 512/1387 [==========>...................] - ETA: 1:47 - loss: 0.7522 - acc: 0.4844
 576/1387 [===========>..................] - ETA: 1:36 - loss: 0.7487 - acc: 0.4896
 640/1387 [============>.................] - ETA: 1:27 - loss: 0.7453 - acc: 0.4891
 704/1387 [==============>...............] - ETA: 1:17 - loss: 0.7428 - acc: 0.4915
 768/1387 [===============>..............] - ETA: 1:08 - loss: 0.7430 - acc: 0.4974
 832/1387 [================>.............] - ETA: 1:00 - loss: 0.7414 - acc: 0.4976
 896/1387 [==================>...........] - ETA: 52s - loss: 0.7380 - acc: 0.5000 
 960/1387 [===================>..........] - ETA: 45s - loss: 0.7373 - acc: 0.4969
1024/1387 [=====================>........] - ETA: 37s - loss: 0.7352 - acc: 0.4961
1088/1387 [======================>.......] - ETA: 30s - loss: 0.7329 - acc: 0.4972
1152/1387 [=======================>......] - ETA: 23s - loss: 0.7344 - acc: 0.4913
1216/1387 [=========================>....] - ETA: 16s - loss: 0.7361 - acc: 0.4926
1280/1387 [==========================>...] - ETA: 10s - loss: 0.7349 - acc: 0.4953
1344/1387 [============================>.] - ETA: 4s - loss: 0.7349 - acc: 0.4926 
1387/1387 [==============================] - 137s 99ms/step - loss: 0.7335 - acc: 0.4939 - val_loss: 0.6937 - val_acc: 0.5613

Epoch 00001: val_acc improved from -inf to 0.56129, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window06/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 1:34 - loss: 0.6631 - acc: 0.6406
 128/1387 [=>............................] - ETA: 1:29 - loss: 0.6884 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:32 - loss: 0.6827 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 1:25 - loss: 0.6814 - acc: 0.5742
 320/1387 [=====>........................] - ETA: 1:20 - loss: 0.6807 - acc: 0.5750
 384/1387 [=======>......................] - ETA: 1:14 - loss: 0.6801 - acc: 0.5703
 448/1387 [========>.....................] - ETA: 1:11 - loss: 0.6816 - acc: 0.5647
 512/1387 [==========>...................] - ETA: 1:08 - loss: 0.6801 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 1:05 - loss: 0.6883 - acc: 0.5521
 640/1387 [============>.................] - ETA: 59s - loss: 0.6921 - acc: 0.5531 
 704/1387 [==============>...............] - ETA: 54s - loss: 0.6961 - acc: 0.5469
 768/1387 [===============>..............] - ETA: 49s - loss: 0.6971 - acc: 0.5430
 832/1387 [================>.............] - ETA: 44s - loss: 0.6983 - acc: 0.5373
 896/1387 [==================>...........] - ETA: 39s - loss: 0.6947 - acc: 0.5424
 960/1387 [===================>..........] - ETA: 33s - loss: 0.6933 - acc: 0.5479
1024/1387 [=====================>........] - ETA: 29s - loss: 0.6952 - acc: 0.5449
1088/1387 [======================>.......] - ETA: 23s - loss: 0.6967 - acc: 0.5460
1152/1387 [=======================>......] - ETA: 19s - loss: 0.6940 - acc: 0.5503
1216/1387 [=========================>....] - ETA: 13s - loss: 0.6929 - acc: 0.5543
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6938 - acc: 0.5508 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6936 - acc: 0.5506
1387/1387 [==============================] - 117s 84ms/step - loss: 0.6944 - acc: 0.5479 - val_loss: 0.6882 - val_acc: 0.5484

Epoch 00002: val_acc did not improve from 0.56129
Epoch 3/10

  64/1387 [>.............................] - ETA: 1:44 - loss: 0.6759 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:40 - loss: 0.6876 - acc: 0.5078
 192/1387 [===>..........................] - ETA: 1:34 - loss: 0.6832 - acc: 0.5312
 256/1387 [====>.........................] - ETA: 1:29 - loss: 0.6943 - acc: 0.5430
 320/1387 [=====>........................] - ETA: 1:26 - loss: 0.6979 - acc: 0.5469
 384/1387 [=======>......................] - ETA: 1:21 - loss: 0.7050 - acc: 0.5260
 448/1387 [========>.....................] - ETA: 1:15 - loss: 0.7057 - acc: 0.5223
 512/1387 [==========>...................] - ETA: 1:09 - loss: 0.7076 - acc: 0.5117
 576/1387 [===========>..................] - ETA: 1:04 - loss: 0.7087 - acc: 0.5035
 640/1387 [============>.................] - ETA: 58s - loss: 0.7042 - acc: 0.5156 
 704/1387 [==============>...............] - ETA: 53s - loss: 0.7066 - acc: 0.5142
 768/1387 [===============>..............] - ETA: 47s - loss: 0.7120 - acc: 0.5052
 832/1387 [================>.............] - ETA: 43s - loss: 0.7115 - acc: 0.5120
 896/1387 [==================>...........] - ETA: 38s - loss: 0.7149 - acc: 0.5112
 960/1387 [===================>..........] - ETA: 33s - loss: 0.7119 - acc: 0.5188
1024/1387 [=====================>........] - ETA: 28s - loss: 0.7108 - acc: 0.5234
1088/1387 [======================>.......] - ETA: 23s - loss: 0.7125 - acc: 0.5248
1152/1387 [=======================>......] - ETA: 18s - loss: 0.7102 - acc: 0.5252
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7109 - acc: 0.5230
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7111 - acc: 0.5227 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7087 - acc: 0.5246
1387/1387 [==============================] - 114s 82ms/step - loss: 0.7087 - acc: 0.5256 - val_loss: 0.6995 - val_acc: 0.5355

Epoch 00003: val_acc did not improve from 0.56129
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:37 - loss: 0.7055 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:32 - loss: 0.6916 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 1:30 - loss: 0.6873 - acc: 0.5781
 256/1387 [====>.........................] - ETA: 1:25 - loss: 0.6968 - acc: 0.5664
 320/1387 [=====>........................] - ETA: 1:23 - loss: 0.6998 - acc: 0.5500
 384/1387 [=======>......................] - ETA: 1:18 - loss: 0.7029 - acc: 0.5417
 448/1387 [========>.....................] - ETA: 1:13 - loss: 0.7015 - acc: 0.5469
 512/1387 [==========>...................] - ETA: 1:07 - loss: 0.6989 - acc: 0.5508
 576/1387 [===========>..................] - ETA: 1:02 - loss: 0.7052 - acc: 0.5503
 640/1387 [============>.................] - ETA: 57s - loss: 0.7055 - acc: 0.5484 
 704/1387 [==============>...............] - ETA: 53s - loss: 0.7011 - acc: 0.5554
 768/1387 [===============>..............] - ETA: 48s - loss: 0.7032 - acc: 0.5495
 832/1387 [================>.............] - ETA: 43s - loss: 0.7038 - acc: 0.5469
 896/1387 [==================>...........] - ETA: 38s - loss: 0.7055 - acc: 0.5435
 960/1387 [===================>..........] - ETA: 33s - loss: 0.7054 - acc: 0.5406
1024/1387 [=====================>........] - ETA: 28s - loss: 0.7033 - acc: 0.5430
1088/1387 [======================>.......] - ETA: 23s - loss: 0.7024 - acc: 0.5441
1152/1387 [=======================>......] - ETA: 18s - loss: 0.6998 - acc: 0.5460
1216/1387 [=========================>....] - ETA: 13s - loss: 0.6980 - acc: 0.5502
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6993 - acc: 0.5500 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7030 - acc: 0.5432
1387/1387 [==============================] - 117s 85ms/step - loss: 0.7046 - acc: 0.5407 - val_loss: 0.6834 - val_acc: 0.5613

Epoch 00004: val_acc improved from 0.56129 to 0.56129, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window06/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:50 - loss: 0.6977 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:44 - loss: 0.6902 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:41 - loss: 0.6828 - acc: 0.5781
 256/1387 [====>.........................] - ETA: 1:32 - loss: 0.6813 - acc: 0.5781
 320/1387 [=====>........................] - ETA: 1:26 - loss: 0.6807 - acc: 0.5781
 384/1387 [=======>......................] - ETA: 1:22 - loss: 0.6931 - acc: 0.5443
 448/1387 [========>.....................] - ETA: 1:15 - loss: 0.6931 - acc: 0.5402
 512/1387 [==========>...................] - ETA: 1:09 - loss: 0.6951 - acc: 0.5332
 576/1387 [===========>..................] - ETA: 1:04 - loss: 0.6949 - acc: 0.5295
 640/1387 [============>.................] - ETA: 59s - loss: 0.6949 - acc: 0.5328 
 704/1387 [==============>...............] - ETA: 54s - loss: 0.6923 - acc: 0.5327
 768/1387 [===============>..............] - ETA: 49s - loss: 0.6911 - acc: 0.5378
 832/1387 [================>.............] - ETA: 43s - loss: 0.6940 - acc: 0.5312
 896/1387 [==================>...........] - ETA: 38s - loss: 0.6930 - acc: 0.5335
 960/1387 [===================>..........] - ETA: 33s - loss: 0.6926 - acc: 0.5354
1024/1387 [=====================>........] - ETA: 28s - loss: 0.6904 - acc: 0.5420
1088/1387 [======================>.......] - ETA: 23s - loss: 0.6924 - acc: 0.5386
1152/1387 [=======================>......] - ETA: 18s - loss: 0.6912 - acc: 0.5417
1216/1387 [=========================>....] - ETA: 13s - loss: 0.6930 - acc: 0.5378
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6910 - acc: 0.5422 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6934 - acc: 0.5379
1387/1387 [==============================] - 113s 82ms/step - loss: 0.6926 - acc: 0.5400 - val_loss: 0.6829 - val_acc: 0.5742

Epoch 00005: val_acc improved from 0.56129 to 0.57419, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window06/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1387 [>.............................] - ETA: 1:35 - loss: 0.7052 - acc: 0.4688
 128/1387 [=>............................] - ETA: 1:37 - loss: 0.7077 - acc: 0.5156
 192/1387 [===>..........................] - ETA: 1:24 - loss: 0.7170 - acc: 0.4896
 256/1387 [====>.........................] - ETA: 1:21 - loss: 0.7088 - acc: 0.5078
 320/1387 [=====>........................] - ETA: 1:16 - loss: 0.6974 - acc: 0.5375
 384/1387 [=======>......................] - ETA: 1:09 - loss: 0.6949 - acc: 0.5391
 448/1387 [========>.....................] - ETA: 1:04 - loss: 0.6956 - acc: 0.5379
 512/1387 [==========>...................] - ETA: 1:00 - loss: 0.6948 - acc: 0.5332
 576/1387 [===========>..................] - ETA: 56s - loss: 0.6991 - acc: 0.5208 
 640/1387 [============>.................] - ETA: 52s - loss: 0.6983 - acc: 0.5250
 704/1387 [==============>...............] - ETA: 48s - loss: 0.6961 - acc: 0.5298
 768/1387 [===============>..............] - ETA: 44s - loss: 0.6923 - acc: 0.5352
 832/1387 [================>.............] - ETA: 40s - loss: 0.6926 - acc: 0.5361
 896/1387 [==================>...........] - ETA: 35s - loss: 0.6943 - acc: 0.5346
 960/1387 [===================>..........] - ETA: 31s - loss: 0.6914 - acc: 0.5427
1024/1387 [=====================>........] - ETA: 26s - loss: 0.6927 - acc: 0.5420
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6905 - acc: 0.5460
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6900 - acc: 0.5460
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6902 - acc: 0.5436
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6907 - acc: 0.5430 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6906 - acc: 0.5446
1387/1387 [==============================] - 105s 76ms/step - loss: 0.6898 - acc: 0.5465 - val_loss: 0.6878 - val_acc: 0.5097

Epoch 00006: val_acc did not improve from 0.57419
Epoch 7/10

  64/1387 [>.............................] - ETA: 1:42 - loss: 0.7083 - acc: 0.6094
 128/1387 [=>............................] - ETA: 1:35 - loss: 0.7091 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 1:30 - loss: 0.7101 - acc: 0.5000
 256/1387 [====>.........................] - ETA: 1:27 - loss: 0.7085 - acc: 0.5117
 320/1387 [=====>........................] - ETA: 1:24 - loss: 0.7043 - acc: 0.5250
 384/1387 [=======>......................] - ETA: 1:19 - loss: 0.6918 - acc: 0.5443
 448/1387 [========>.....................] - ETA: 1:15 - loss: 0.6896 - acc: 0.5446
 512/1387 [==========>...................] - ETA: 1:10 - loss: 0.6860 - acc: 0.5566
 576/1387 [===========>..................] - ETA: 1:05 - loss: 0.6881 - acc: 0.5503
 640/1387 [============>.................] - ETA: 1:00 - loss: 0.6910 - acc: 0.5422
 704/1387 [==============>...............] - ETA: 55s - loss: 0.6883 - acc: 0.5455 
 768/1387 [===============>..............] - ETA: 50s - loss: 0.6895 - acc: 0.5443
 832/1387 [================>.............] - ETA: 45s - loss: 0.6930 - acc: 0.5385
 896/1387 [==================>...........] - ETA: 40s - loss: 0.6910 - acc: 0.5435
 960/1387 [===================>..........] - ETA: 35s - loss: 0.6904 - acc: 0.5417
1024/1387 [=====================>........] - ETA: 29s - loss: 0.6909 - acc: 0.5469
1088/1387 [======================>.......] - ETA: 24s - loss: 0.6896 - acc: 0.5515
1152/1387 [=======================>......] - ETA: 19s - loss: 0.6927 - acc: 0.5451
1216/1387 [=========================>....] - ETA: 14s - loss: 0.6902 - acc: 0.5493
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6912 - acc: 0.5469 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6928 - acc: 0.5446
1387/1387 [==============================] - 118s 85ms/step - loss: 0.6916 - acc: 0.5501 - val_loss: 0.6865 - val_acc: 0.5677

Epoch 00007: val_acc did not improve from 0.57419
Epoch 8/10

  64/1387 [>.............................] - ETA: 1:50 - loss: 0.6990 - acc: 0.5781
 128/1387 [=>............................] - ETA: 1:42 - loss: 0.6803 - acc: 0.6094
 192/1387 [===>..........................] - ETA: 1:37 - loss: 0.6939 - acc: 0.5833
 256/1387 [====>.........................] - ETA: 1:30 - loss: 0.7180 - acc: 0.5234
 320/1387 [=====>........................] - ETA: 1:24 - loss: 0.7099 - acc: 0.5312
 384/1387 [=======>......................] - ETA: 1:20 - loss: 0.7018 - acc: 0.5443
 448/1387 [========>.....................] - ETA: 1:14 - loss: 0.7103 - acc: 0.5268
 512/1387 [==========>...................] - ETA: 1:09 - loss: 0.7138 - acc: 0.5273
 576/1387 [===========>..................] - ETA: 1:03 - loss: 0.7075 - acc: 0.5451
 640/1387 [============>.................] - ETA: 59s - loss: 0.7108 - acc: 0.5469 
 704/1387 [==============>...............] - ETA: 55s - loss: 0.7087 - acc: 0.5440
 768/1387 [===============>..............] - ETA: 51s - loss: 0.7052 - acc: 0.5521
 832/1387 [================>.............] - ETA: 45s - loss: 0.7053 - acc: 0.5517
 896/1387 [==================>...........] - ETA: 40s - loss: 0.7014 - acc: 0.5547
 960/1387 [===================>..........] - ETA: 35s - loss: 0.7054 - acc: 0.5406
1024/1387 [=====================>........] - ETA: 29s - loss: 0.7021 - acc: 0.5459
1088/1387 [======================>.......] - ETA: 24s - loss: 0.7014 - acc: 0.5469
1152/1387 [=======================>......] - ETA: 19s - loss: 0.7009 - acc: 0.5495
1216/1387 [=========================>....] - ETA: 13s - loss: 0.6997 - acc: 0.5493
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6988 - acc: 0.5516 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6984 - acc: 0.5551
1387/1387 [==============================] - 115s 83ms/step - loss: 0.6985 - acc: 0.5516 - val_loss: 0.6847 - val_acc: 0.5419

Epoch 00008: val_acc did not improve from 0.57419
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:28 - loss: 0.7365 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:19 - loss: 0.6875 - acc: 0.6484
 192/1387 [===>..........................] - ETA: 1:15 - loss: 0.6765 - acc: 0.6354
 256/1387 [====>.........................] - ETA: 1:11 - loss: 0.6766 - acc: 0.6094
 320/1387 [=====>........................] - ETA: 1:10 - loss: 0.6896 - acc: 0.5813
 384/1387 [=======>......................] - ETA: 1:07 - loss: 0.6914 - acc: 0.5729
 448/1387 [========>.....................] - ETA: 1:05 - loss: 0.6916 - acc: 0.5692
 512/1387 [==========>...................] - ETA: 1:00 - loss: 0.6894 - acc: 0.5645
 576/1387 [===========>..................] - ETA: 56s - loss: 0.6916 - acc: 0.5556 
 640/1387 [============>.................] - ETA: 51s - loss: 0.6896 - acc: 0.5578
 704/1387 [==============>...............] - ETA: 47s - loss: 0.6893 - acc: 0.5597
 768/1387 [===============>..............] - ETA: 43s - loss: 0.6881 - acc: 0.5586
 832/1387 [================>.............] - ETA: 39s - loss: 0.6885 - acc: 0.5613
 896/1387 [==================>...........] - ETA: 34s - loss: 0.6863 - acc: 0.5681
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6880 - acc: 0.5698
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6862 - acc: 0.5732
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6862 - acc: 0.5689
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6866 - acc: 0.5668
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6877 - acc: 0.5674
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6877 - acc: 0.5656 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6891 - acc: 0.5632
1387/1387 [==============================] - 102s 73ms/step - loss: 0.6903 - acc: 0.5609 - val_loss: 0.6792 - val_acc: 0.6065

Epoch 00009: val_acc improved from 0.57419 to 0.60645, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window06/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:58 - loss: 0.6923 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:56 - loss: 0.6724 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 1:46 - loss: 0.6771 - acc: 0.5573
 256/1387 [====>.........................] - ETA: 1:37 - loss: 0.6770 - acc: 0.5781
 320/1387 [=====>........................] - ETA: 1:29 - loss: 0.6782 - acc: 0.5625
 384/1387 [=======>......................] - ETA: 1:23 - loss: 0.6757 - acc: 0.5677
 448/1387 [========>.....................] - ETA: 1:19 - loss: 0.6787 - acc: 0.5580
 512/1387 [==========>...................] - ETA: 1:14 - loss: 0.6852 - acc: 0.5547
 576/1387 [===========>..................] - ETA: 1:09 - loss: 0.6856 - acc: 0.5556
 640/1387 [============>.................] - ETA: 1:03 - loss: 0.6890 - acc: 0.5516
 704/1387 [==============>...............] - ETA: 58s - loss: 0.6888 - acc: 0.5511 
 768/1387 [===============>..............] - ETA: 53s - loss: 0.6878 - acc: 0.5495
 832/1387 [================>.............] - ETA: 48s - loss: 0.6891 - acc: 0.5529
 896/1387 [==================>...........] - ETA: 42s - loss: 0.6897 - acc: 0.5513
 960/1387 [===================>..........] - ETA: 37s - loss: 0.6897 - acc: 0.5542
1024/1387 [=====================>........] - ETA: 31s - loss: 0.6912 - acc: 0.5479
1088/1387 [======================>.......] - ETA: 26s - loss: 0.6890 - acc: 0.5533
1152/1387 [=======================>......] - ETA: 20s - loss: 0.6869 - acc: 0.5582
1216/1387 [=========================>....] - ETA: 14s - loss: 0.6875 - acc: 0.5543
1280/1387 [==========================>...] - ETA: 9s - loss: 0.6857 - acc: 0.5578 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6870 - acc: 0.5506
1387/1387 [==============================] - 126s 91ms/step - loss: 0.6875 - acc: 0.5494 - val_loss: 0.6836 - val_acc: 0.5806

Epoch 00010: val_acc did not improve from 0.60645
样本个数 193
样本个数 386
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 14s
128/386 [========>.....................] - ETA: 8s 
192/386 [=============>................] - ETA: 5s
256/386 [==================>...........] - ETA: 3s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 11s 29ms/step
loss: 0.6846523192262403
acc: 0.5621761658031088
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7ef9ec580fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7ef9ec580fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7ef9ec5643d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7ef9ec5643d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f005ccdc610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f005ccdc610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f005ccdc250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f005ccdc250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9ec4c6d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9ec4c6d50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ec3cbc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ec3cbc50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f005ccdcd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f005ccdcd10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9cc65ad10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9cc65ad10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f005cc00750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f005cc00750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9ec2c5cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9ec2c5cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ec5621d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ec5621d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9ac5af3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9ac5af3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ec580490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ec580490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9ec580890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9ec580890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9ec569190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9ec569190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9cc7c1e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9cc7c1e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9ec05f410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9ec05f410>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ac53b210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ac53b210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9cc68c490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9cc68c490>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9ac348750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9ac348750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ac430ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ac430ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9cc68c810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9cc68c810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ac103f90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ac103f90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9ac331b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9ac331b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9ac348c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9ac348c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef990786210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef990786210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9ac03a310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9ac03a310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9906ba350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9906ba350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9ac0962d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9ac0962d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9904a8f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef9904a8f10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef99041b090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef99041b090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef990425a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef990425a10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9903d5c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9903d5c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef99041dd10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef99041dd10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef99042a290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef99042a290>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9901bb750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9901bb750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef99041d550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef99041d550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9901ac910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9901ac910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9902f4550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9902f4550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef99014bad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef99014bad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef96c6a7ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef96c6a7ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9901ac250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9901ac250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef96c627d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef96c627d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9ec1d85d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef9ec1d85d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef96c61c1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef96c61c1d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef96c607d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef96c607d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9ec0f5c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9ec0f5c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef96c627490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef96c627490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef96c040f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef96c040f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef94c78bfd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef94c78bfd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9cc764810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9cc764810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef96c040210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef96c040210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ac30e5d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ac30e5d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef94c5205d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef94c5205d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef94c3f4e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef94c3f4e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ac331590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef9ac331590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef94c4cced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef94c4cced0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef94c3c1550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef94c3c1550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef94c3f4110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef94c3f4110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef94c09da50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef94c09da50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef94c1f6990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef94c1f6990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef94c3f4390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef94c3f4390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef96c2e5590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef96c2e5590>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 4:14 - loss: 0.7085 - acc: 0.5312
 128/1387 [=>............................] - ETA: 2:50 - loss: 0.8619 - acc: 0.4531
 192/1387 [===>..........................] - ETA: 2:18 - loss: 0.8198 - acc: 0.4792
 256/1387 [====>.........................] - ETA: 2:00 - loss: 0.8057 - acc: 0.4805
 320/1387 [=====>........................] - ETA: 1:48 - loss: 0.7835 - acc: 0.5000
 384/1387 [=======>......................] - ETA: 1:37 - loss: 0.7690 - acc: 0.5052
 448/1387 [========>.....................] - ETA: 1:29 - loss: 0.7670 - acc: 0.4955
 512/1387 [==========>...................] - ETA: 1:22 - loss: 0.7607 - acc: 0.5020
 576/1387 [===========>..................] - ETA: 1:15 - loss: 0.7555 - acc: 0.5052
 640/1387 [============>.................] - ETA: 1:08 - loss: 0.7521 - acc: 0.5078
 704/1387 [==============>...............] - ETA: 1:02 - loss: 0.7475 - acc: 0.5128
 768/1387 [===============>..............] - ETA: 56s - loss: 0.7463 - acc: 0.5104 
 832/1387 [================>.............] - ETA: 50s - loss: 0.7409 - acc: 0.5096
 896/1387 [==================>...........] - ETA: 44s - loss: 0.7380 - acc: 0.5078
 960/1387 [===================>..........] - ETA: 38s - loss: 0.7377 - acc: 0.5052
1024/1387 [=====================>........] - ETA: 32s - loss: 0.7405 - acc: 0.5020
1088/1387 [======================>.......] - ETA: 26s - loss: 0.7368 - acc: 0.5046
1152/1387 [=======================>......] - ETA: 20s - loss: 0.7395 - acc: 0.5026
1216/1387 [=========================>....] - ETA: 14s - loss: 0.7407 - acc: 0.5025
1280/1387 [==========================>...] - ETA: 9s - loss: 0.7372 - acc: 0.5102 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7364 - acc: 0.5074
1387/1387 [==============================] - 126s 91ms/step - loss: 0.7349 - acc: 0.5097 - val_loss: 0.6890 - val_acc: 0.5484

Epoch 00001: val_acc improved from -inf to 0.54839, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window07/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 2:12 - loss: 0.7134 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:56 - loss: 0.6805 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 1:45 - loss: 0.6865 - acc: 0.5625
 256/1387 [====>.........................] - ETA: 1:36 - loss: 0.6935 - acc: 0.5586
 320/1387 [=====>........................] - ETA: 1:29 - loss: 0.6924 - acc: 0.5594
 384/1387 [=======>......................] - ETA: 1:23 - loss: 0.6987 - acc: 0.5495
 448/1387 [========>.....................] - ETA: 1:16 - loss: 0.7064 - acc: 0.5469
 512/1387 [==========>...................] - ETA: 1:09 - loss: 0.7102 - acc: 0.5391
 576/1387 [===========>..................] - ETA: 1:04 - loss: 0.7006 - acc: 0.5486
 640/1387 [============>.................] - ETA: 58s - loss: 0.7067 - acc: 0.5422 
 704/1387 [==============>...............] - ETA: 53s - loss: 0.7071 - acc: 0.5440
 768/1387 [===============>..............] - ETA: 48s - loss: 0.7056 - acc: 0.5495
 832/1387 [================>.............] - ETA: 43s - loss: 0.7049 - acc: 0.5481
 896/1387 [==================>...........] - ETA: 37s - loss: 0.7048 - acc: 0.5435
 960/1387 [===================>..........] - ETA: 32s - loss: 0.7041 - acc: 0.5448
1024/1387 [=====================>........] - ETA: 27s - loss: 0.7010 - acc: 0.5488
1088/1387 [======================>.......] - ETA: 22s - loss: 0.7040 - acc: 0.5460
1152/1387 [=======================>......] - ETA: 17s - loss: 0.7021 - acc: 0.5486
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7036 - acc: 0.5436
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7037 - acc: 0.5414 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7064 - acc: 0.5379
1387/1387 [==============================] - 110s 79ms/step - loss: 0.7074 - acc: 0.5400 - val_loss: 0.6792 - val_acc: 0.5613

Epoch 00002: val_acc improved from 0.54839 to 0.56129, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window07/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 1:40 - loss: 0.6847 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:35 - loss: 0.6691 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 1:22 - loss: 0.6871 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 1:14 - loss: 0.6903 - acc: 0.5508
 320/1387 [=====>........................] - ETA: 1:10 - loss: 0.6846 - acc: 0.5563
 384/1387 [=======>......................] - ETA: 1:04 - loss: 0.6840 - acc: 0.5521
 448/1387 [========>.....................] - ETA: 1:00 - loss: 0.6823 - acc: 0.5692
 512/1387 [==========>...................] - ETA: 55s - loss: 0.6886 - acc: 0.5625 
 576/1387 [===========>..................] - ETA: 51s - loss: 0.6895 - acc: 0.5538
 640/1387 [============>.................] - ETA: 47s - loss: 0.6926 - acc: 0.5516
 704/1387 [==============>...............] - ETA: 43s - loss: 0.6963 - acc: 0.5497
 768/1387 [===============>..............] - ETA: 39s - loss: 0.6969 - acc: 0.5456
 832/1387 [================>.............] - ETA: 36s - loss: 0.6956 - acc: 0.5433
 896/1387 [==================>...........] - ETA: 31s - loss: 0.6963 - acc: 0.5446
 960/1387 [===================>..........] - ETA: 28s - loss: 0.6975 - acc: 0.5406
1024/1387 [=====================>........] - ETA: 23s - loss: 0.6970 - acc: 0.5430
1088/1387 [======================>.......] - ETA: 19s - loss: 0.6969 - acc: 0.5441
1152/1387 [=======================>......] - ETA: 15s - loss: 0.6992 - acc: 0.5399
1216/1387 [=========================>....] - ETA: 11s - loss: 0.7006 - acc: 0.5411
1280/1387 [==========================>...] - ETA: 7s - loss: 0.7017 - acc: 0.5445 
1344/1387 [============================>.] - ETA: 2s - loss: 0.7009 - acc: 0.5446
1387/1387 [==============================] - 96s 69ms/step - loss: 0.7026 - acc: 0.5429 - val_loss: 0.6981 - val_acc: 0.5806

Epoch 00003: val_acc improved from 0.56129 to 0.58065, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window07/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:24 - loss: 0.6551 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:26 - loss: 0.6840 - acc: 0.5547
 192/1387 [===>..........................] - ETA: 1:23 - loss: 0.6860 - acc: 0.5521
 256/1387 [====>.........................] - ETA: 1:16 - loss: 0.7037 - acc: 0.5312
 320/1387 [=====>........................] - ETA: 1:15 - loss: 0.7057 - acc: 0.5250
 384/1387 [=======>......................] - ETA: 1:12 - loss: 0.7049 - acc: 0.5312
 448/1387 [========>.....................] - ETA: 1:06 - loss: 0.6988 - acc: 0.5402
 512/1387 [==========>...................] - ETA: 1:01 - loss: 0.6936 - acc: 0.5488
 576/1387 [===========>..................] - ETA: 56s - loss: 0.6959 - acc: 0.5434 
 640/1387 [============>.................] - ETA: 52s - loss: 0.6954 - acc: 0.5469
 704/1387 [==============>...............] - ETA: 48s - loss: 0.6952 - acc: 0.5511
 768/1387 [===============>..............] - ETA: 44s - loss: 0.6998 - acc: 0.5482
 832/1387 [================>.............] - ETA: 40s - loss: 0.6979 - acc: 0.5493
 896/1387 [==================>...........] - ETA: 35s - loss: 0.6995 - acc: 0.5491
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6984 - acc: 0.5458
1024/1387 [=====================>........] - ETA: 26s - loss: 0.6961 - acc: 0.5527
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6970 - acc: 0.5524
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6959 - acc: 0.5521
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6953 - acc: 0.5543
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6945 - acc: 0.5555 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6923 - acc: 0.5595
1387/1387 [==============================] - 102s 73ms/step - loss: 0.6919 - acc: 0.5595 - val_loss: 0.6829 - val_acc: 0.5806

Epoch 00004: val_acc improved from 0.58065 to 0.58065, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window07/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:44 - loss: 0.6956 - acc: 0.4844
 128/1387 [=>............................] - ETA: 1:31 - loss: 0.6821 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 1:24 - loss: 0.6701 - acc: 0.5573
 256/1387 [====>.........................] - ETA: 1:17 - loss: 0.6722 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 1:12 - loss: 0.6737 - acc: 0.5594
 384/1387 [=======>......................] - ETA: 1:07 - loss: 0.6694 - acc: 0.5703
 448/1387 [========>.....................] - ETA: 1:03 - loss: 0.6727 - acc: 0.5670
 512/1387 [==========>...................] - ETA: 59s - loss: 0.6785 - acc: 0.5527 
 576/1387 [===========>..................] - ETA: 55s - loss: 0.6809 - acc: 0.5486
 640/1387 [============>.................] - ETA: 51s - loss: 0.6829 - acc: 0.5531
 704/1387 [==============>...............] - ETA: 46s - loss: 0.6810 - acc: 0.5582
 768/1387 [===============>..............] - ETA: 42s - loss: 0.6818 - acc: 0.5521
 832/1387 [================>.............] - ETA: 37s - loss: 0.6830 - acc: 0.5529
 896/1387 [==================>...........] - ETA: 33s - loss: 0.6787 - acc: 0.5603
 960/1387 [===================>..........] - ETA: 29s - loss: 0.6771 - acc: 0.5594
1024/1387 [=====================>........] - ETA: 24s - loss: 0.6764 - acc: 0.5605
1088/1387 [======================>.......] - ETA: 20s - loss: 0.6768 - acc: 0.5643
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6767 - acc: 0.5668
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6788 - acc: 0.5683
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6789 - acc: 0.5680 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6780 - acc: 0.5699
1387/1387 [==============================] - 101s 73ms/step - loss: 0.6779 - acc: 0.5696 - val_loss: 0.6757 - val_acc: 0.6065

Epoch 00005: val_acc improved from 0.58065 to 0.60645, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window07/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1387 [>.............................] - ETA: 1:30 - loss: 0.6947 - acc: 0.5625
 128/1387 [=>............................] - ETA: 1:24 - loss: 0.6775 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 1:19 - loss: 0.6741 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 1:14 - loss: 0.6716 - acc: 0.5625
 320/1387 [=====>........................] - ETA: 1:11 - loss: 0.6778 - acc: 0.5719
 384/1387 [=======>......................] - ETA: 1:06 - loss: 0.6828 - acc: 0.5651
 448/1387 [========>.....................] - ETA: 1:01 - loss: 0.6866 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 57s - loss: 0.6880 - acc: 0.5488 
 576/1387 [===========>..................] - ETA: 53s - loss: 0.6884 - acc: 0.5486
 640/1387 [============>.................] - ETA: 49s - loss: 0.6874 - acc: 0.5484
 704/1387 [==============>...............] - ETA: 46s - loss: 0.6886 - acc: 0.5483
 768/1387 [===============>..............] - ETA: 42s - loss: 0.6894 - acc: 0.5521
 832/1387 [================>.............] - ETA: 37s - loss: 0.6905 - acc: 0.5505
 896/1387 [==================>...........] - ETA: 32s - loss: 0.6891 - acc: 0.5547
 960/1387 [===================>..........] - ETA: 28s - loss: 0.6915 - acc: 0.5490
1024/1387 [=====================>........] - ETA: 24s - loss: 0.6901 - acc: 0.5479
1088/1387 [======================>.......] - ETA: 19s - loss: 0.6890 - acc: 0.5515
1152/1387 [=======================>......] - ETA: 15s - loss: 0.6907 - acc: 0.5495
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6904 - acc: 0.5493
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6905 - acc: 0.5516 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6881 - acc: 0.5573
1387/1387 [==============================] - 99s 71ms/step - loss: 0.6899 - acc: 0.5523 - val_loss: 0.6784 - val_acc: 0.5871

Epoch 00006: val_acc did not improve from 0.60645
Epoch 7/10

  64/1387 [>.............................] - ETA: 1:51 - loss: 0.7179 - acc: 0.5000
 128/1387 [=>............................] - ETA: 1:41 - loss: 0.7176 - acc: 0.4844
 192/1387 [===>..........................] - ETA: 1:35 - loss: 0.6991 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 1:29 - loss: 0.7040 - acc: 0.5117
 320/1387 [=====>........................] - ETA: 1:25 - loss: 0.6925 - acc: 0.5281
 384/1387 [=======>......................] - ETA: 1:20 - loss: 0.6989 - acc: 0.5234
 448/1387 [========>.....................] - ETA: 1:15 - loss: 0.6913 - acc: 0.5402
 512/1387 [==========>...................] - ETA: 1:10 - loss: 0.6864 - acc: 0.5547
 576/1387 [===========>..................] - ETA: 1:05 - loss: 0.6883 - acc: 0.5538
 640/1387 [============>.................] - ETA: 59s - loss: 0.6840 - acc: 0.5625 
 704/1387 [==============>...............] - ETA: 54s - loss: 0.6892 - acc: 0.5554
 768/1387 [===============>..............] - ETA: 49s - loss: 0.6866 - acc: 0.5625
 832/1387 [================>.............] - ETA: 44s - loss: 0.6826 - acc: 0.5721
 896/1387 [==================>...........] - ETA: 39s - loss: 0.6799 - acc: 0.5781
 960/1387 [===================>..........] - ETA: 34s - loss: 0.6823 - acc: 0.5719
1024/1387 [=====================>........] - ETA: 29s - loss: 0.6809 - acc: 0.5732
1088/1387 [======================>.......] - ETA: 23s - loss: 0.6836 - acc: 0.5689
1152/1387 [=======================>......] - ETA: 18s - loss: 0.6824 - acc: 0.5703
1216/1387 [=========================>....] - ETA: 13s - loss: 0.6812 - acc: 0.5715
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6820 - acc: 0.5727 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6829 - acc: 0.5707
1387/1387 [==============================] - 115s 83ms/step - loss: 0.6842 - acc: 0.5703 - val_loss: 0.6750 - val_acc: 0.5935

Epoch 00007: val_acc did not improve from 0.60645
Epoch 8/10

  64/1387 [>.............................] - ETA: 1:42 - loss: 0.7033 - acc: 0.5625
 128/1387 [=>............................] - ETA: 1:36 - loss: 0.6771 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 1:32 - loss: 0.6738 - acc: 0.6094
 256/1387 [====>.........................] - ETA: 1:25 - loss: 0.6836 - acc: 0.5977
 320/1387 [=====>........................] - ETA: 1:20 - loss: 0.6843 - acc: 0.5875
 384/1387 [=======>......................] - ETA: 1:14 - loss: 0.6883 - acc: 0.5833
 448/1387 [========>.....................] - ETA: 1:11 - loss: 0.6946 - acc: 0.5580
 512/1387 [==========>...................] - ETA: 1:06 - loss: 0.6938 - acc: 0.5547
 576/1387 [===========>..................] - ETA: 1:01 - loss: 0.6929 - acc: 0.5538
 640/1387 [============>.................] - ETA: 56s - loss: 0.6956 - acc: 0.5469 
 704/1387 [==============>...............] - ETA: 51s - loss: 0.6957 - acc: 0.5426
 768/1387 [===============>..............] - ETA: 46s - loss: 0.6951 - acc: 0.5456
 832/1387 [================>.............] - ETA: 41s - loss: 0.6961 - acc: 0.5445
 896/1387 [==================>...........] - ETA: 36s - loss: 0.6958 - acc: 0.5480
 960/1387 [===================>..........] - ETA: 31s - loss: 0.6954 - acc: 0.5427
1024/1387 [=====================>........] - ETA: 26s - loss: 0.6947 - acc: 0.5449
1088/1387 [======================>.......] - ETA: 22s - loss: 0.6936 - acc: 0.5478
1152/1387 [=======================>......] - ETA: 17s - loss: 0.6931 - acc: 0.5503
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6919 - acc: 0.5502
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6914 - acc: 0.5500 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6916 - acc: 0.5521
1387/1387 [==============================] - 109s 79ms/step - loss: 0.6909 - acc: 0.5552 - val_loss: 0.6772 - val_acc: 0.6000

Epoch 00008: val_acc did not improve from 0.60645
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:42 - loss: 0.6917 - acc: 0.4844
 128/1387 [=>............................] - ETA: 1:30 - loss: 0.6853 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 1:28 - loss: 0.6886 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 1:23 - loss: 0.6840 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 1:19 - loss: 0.6783 - acc: 0.5781
 384/1387 [=======>......................] - ETA: 1:15 - loss: 0.6777 - acc: 0.5807
 448/1387 [========>.....................] - ETA: 1:10 - loss: 0.6857 - acc: 0.5714
 512/1387 [==========>...................] - ETA: 1:05 - loss: 0.6864 - acc: 0.5723
 576/1387 [===========>..................] - ETA: 1:01 - loss: 0.6871 - acc: 0.5781
 640/1387 [============>.................] - ETA: 55s - loss: 0.6869 - acc: 0.5719 
 704/1387 [==============>...............] - ETA: 50s - loss: 0.6891 - acc: 0.5739
 768/1387 [===============>..............] - ETA: 45s - loss: 0.6903 - acc: 0.5755
 832/1387 [================>.............] - ETA: 40s - loss: 0.6887 - acc: 0.5757
 896/1387 [==================>...........] - ETA: 35s - loss: 0.6866 - acc: 0.5770
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6893 - acc: 0.5667
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6866 - acc: 0.5703
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6857 - acc: 0.5708
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6837 - acc: 0.5712
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6818 - acc: 0.5765
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6823 - acc: 0.5734 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6801 - acc: 0.5789
1387/1387 [==============================] - 100s 72ms/step - loss: 0.6798 - acc: 0.5797 - val_loss: 0.6829 - val_acc: 0.5742

Epoch 00009: val_acc did not improve from 0.60645
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:36 - loss: 0.6425 - acc: 0.6562
 128/1387 [=>............................] - ETA: 1:32 - loss: 0.6717 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 1:25 - loss: 0.6668 - acc: 0.6094
 256/1387 [====>.........................] - ETA: 1:20 - loss: 0.6733 - acc: 0.6016
 320/1387 [=====>........................] - ETA: 1:14 - loss: 0.6781 - acc: 0.5813
 384/1387 [=======>......................] - ETA: 1:10 - loss: 0.6764 - acc: 0.5885
 448/1387 [========>.....................] - ETA: 1:06 - loss: 0.6802 - acc: 0.5804
 512/1387 [==========>...................] - ETA: 1:01 - loss: 0.6801 - acc: 0.5762
 576/1387 [===========>..................] - ETA: 57s - loss: 0.6839 - acc: 0.5642 
 640/1387 [============>.................] - ETA: 53s - loss: 0.6851 - acc: 0.5656
 704/1387 [==============>...............] - ETA: 48s - loss: 0.6839 - acc: 0.5625
 768/1387 [===============>..............] - ETA: 44s - loss: 0.6856 - acc: 0.5573
 832/1387 [================>.............] - ETA: 39s - loss: 0.6842 - acc: 0.5601
 896/1387 [==================>...........] - ETA: 34s - loss: 0.6845 - acc: 0.5592
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6825 - acc: 0.5635
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6789 - acc: 0.5713
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6798 - acc: 0.5726
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6786 - acc: 0.5755
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6788 - acc: 0.5715
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6788 - acc: 0.5750 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6768 - acc: 0.5789
1387/1387 [==============================] - 103s 74ms/step - loss: 0.6763 - acc: 0.5797 - val_loss: 0.6695 - val_acc: 0.6129

Epoch 00010: val_acc improved from 0.60645 to 0.61290, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window07/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
样本个数 193
样本个数 386
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 20s
128/386 [========>.....................] - ETA: 11s
192/386 [=============>................] - ETA: 7s 
256/386 [==================>...........] - ETA: 4s
320/386 [=======================>......] - ETA: 2s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 13s 33ms/step
loss: 0.6793300503276173
acc: 0.5699481865284974
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7ef8c42e1810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7ef8c42e1810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7ef8c429ab90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7ef8c429ab90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00438fa490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00438fa490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0043848050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7f0043848050>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef86c2eb210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef86c2eb210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00542e6f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00542e6f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0043848890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0043848890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef88c3832d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef88c3832d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef8c40a2550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef8c40a2550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef88c6e36d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef88c6e36d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef88c37a0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef88c37a0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0043921610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f0043921610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8c4064d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8c4064d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef88c7afa50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef88c7afa50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef88c4fb890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef88c4fb890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef88c4ee310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef88c4ee310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef88c554c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef88c554c10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef88c52a210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef88c52a210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef86c27b0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef86c27b0d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef86c27b410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef86c27b410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef86c11f3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef86c11f3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef88c7284d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef88c7284d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef848750e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef848750e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef848698850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef848698850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef84854e790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef84854e790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef84849c250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef84849c250>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9ec5d0e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef9ec5d0e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef84878c450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef84878c450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef848273810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef848273810>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef84822fb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef84822fb90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef84825b850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef84825b850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef848343450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef848343450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef84814ab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef84814ab10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef8086c34d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef8086c34d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef8482dfe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef8482dfe10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef80863de10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef80863de10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef8086c3c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef8086c3c50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8480f8950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8480f8950>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef808732750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef808732750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef8083a8390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef8083a8390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8082cc3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8082cc3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef8086b9ed0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef8086b9ed0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8083fd4d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8083fd4d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef808123b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef808123b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef808146610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef808146610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef808121e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef808121e10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef808123a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef808123a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef80827f090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef80827f090>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef7e8544310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef7e8544310>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef7e83fcad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef7e83fcad0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7e855ff90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7e855ff90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef8082c9210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef8082c9210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7e8475850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7e8475850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef7e846aa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef7e846aa10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef7e8167350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef7e8167350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7c877d2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7c877d2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef7e846ab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef7e846ab10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7c8787850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7c8787850>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef7c86c5a50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef7c86c5a50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef7c864f250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef7c864f250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8c428a2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8c428a2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef7e820ab10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef7e820ab10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7c86eced0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7c86eced0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 4:55 - loss: 0.7824 - acc: 0.4219
 128/1387 [=>............................] - ETA: 3:07 - loss: 0.7316 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 2:30 - loss: 0.7647 - acc: 0.4948
 256/1387 [====>.........................] - ETA: 2:08 - loss: 0.7994 - acc: 0.4922
 320/1387 [=====>........................] - ETA: 1:54 - loss: 0.7817 - acc: 0.5000
 384/1387 [=======>......................] - ETA: 1:44 - loss: 0.7688 - acc: 0.5130
 448/1387 [========>.....................] - ETA: 1:35 - loss: 0.7670 - acc: 0.5000
 512/1387 [==========>...................] - ETA: 1:26 - loss: 0.7530 - acc: 0.5098
 576/1387 [===========>..................] - ETA: 1:18 - loss: 0.7502 - acc: 0.5122
 640/1387 [============>.................] - ETA: 1:11 - loss: 0.7622 - acc: 0.4922
 704/1387 [==============>...............] - ETA: 1:03 - loss: 0.7599 - acc: 0.4929
 768/1387 [===============>..............] - ETA: 56s - loss: 0.7548 - acc: 0.4935 
 832/1387 [================>.............] - ETA: 50s - loss: 0.7465 - acc: 0.4988
 896/1387 [==================>...........] - ETA: 43s - loss: 0.7429 - acc: 0.4955
 960/1387 [===================>..........] - ETA: 38s - loss: 0.7405 - acc: 0.5021
1024/1387 [=====================>........] - ETA: 32s - loss: 0.7382 - acc: 0.5078
1088/1387 [======================>.......] - ETA: 26s - loss: 0.7358 - acc: 0.5110
1152/1387 [=======================>......] - ETA: 20s - loss: 0.7348 - acc: 0.5156
1216/1387 [=========================>....] - ETA: 14s - loss: 0.7351 - acc: 0.5173
1280/1387 [==========================>...] - ETA: 9s - loss: 0.7343 - acc: 0.5164 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7309 - acc: 0.5201
1387/1387 [==============================] - 125s 90ms/step - loss: 0.7340 - acc: 0.5169 - val_loss: 0.7163 - val_acc: 0.5355

Epoch 00001: val_acc improved from -inf to 0.53548, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window08/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 1:50 - loss: 0.6932 - acc: 0.5781
 128/1387 [=>............................] - ETA: 1:37 - loss: 0.7084 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 1:36 - loss: 0.7012 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 1:31 - loss: 0.7071 - acc: 0.5273
 320/1387 [=====>........................] - ETA: 1:25 - loss: 0.7074 - acc: 0.5219
 384/1387 [=======>......................] - ETA: 1:19 - loss: 0.7139 - acc: 0.4974
 448/1387 [========>.....................] - ETA: 1:15 - loss: 0.7142 - acc: 0.5000
 512/1387 [==========>...................] - ETA: 1:09 - loss: 0.7150 - acc: 0.4863
 576/1387 [===========>..................] - ETA: 1:04 - loss: 0.7153 - acc: 0.4844
 640/1387 [============>.................] - ETA: 58s - loss: 0.7135 - acc: 0.4859 
 704/1387 [==============>...............] - ETA: 53s - loss: 0.7106 - acc: 0.4943
 768/1387 [===============>..............] - ETA: 48s - loss: 0.7100 - acc: 0.4974
 832/1387 [================>.............] - ETA: 43s - loss: 0.7085 - acc: 0.5060
 896/1387 [==================>...........] - ETA: 38s - loss: 0.7053 - acc: 0.5156
 960/1387 [===================>..........] - ETA: 33s - loss: 0.7045 - acc: 0.5188
1024/1387 [=====================>........] - ETA: 28s - loss: 0.7035 - acc: 0.5205
1088/1387 [======================>.......] - ETA: 23s - loss: 0.7062 - acc: 0.5202
1152/1387 [=======================>......] - ETA: 18s - loss: 0.7048 - acc: 0.5234
1216/1387 [=========================>....] - ETA: 13s - loss: 0.7065 - acc: 0.5238
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7090 - acc: 0.5227 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7090 - acc: 0.5246
1387/1387 [==============================] - 113s 81ms/step - loss: 0.7086 - acc: 0.5249 - val_loss: 0.6967 - val_acc: 0.5290

Epoch 00002: val_acc did not improve from 0.53548
Epoch 3/10

  64/1387 [>.............................] - ETA: 1:43 - loss: 0.7142 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:37 - loss: 0.7202 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 1:34 - loss: 0.7009 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 1:26 - loss: 0.7110 - acc: 0.5234
 320/1387 [=====>........................] - ETA: 1:22 - loss: 0.7053 - acc: 0.5312
 384/1387 [=======>......................] - ETA: 1:17 - loss: 0.7070 - acc: 0.5260
 448/1387 [========>.....................] - ETA: 1:12 - loss: 0.7102 - acc: 0.5112
 512/1387 [==========>...................] - ETA: 1:07 - loss: 0.7089 - acc: 0.5156
 576/1387 [===========>..................] - ETA: 1:02 - loss: 0.7081 - acc: 0.5156
 640/1387 [============>.................] - ETA: 58s - loss: 0.7053 - acc: 0.5203 
 704/1387 [==============>...............] - ETA: 53s - loss: 0.7052 - acc: 0.5298
 768/1387 [===============>..............] - ETA: 48s - loss: 0.7023 - acc: 0.5260
 832/1387 [================>.............] - ETA: 43s - loss: 0.6998 - acc: 0.5288
 896/1387 [==================>...........] - ETA: 37s - loss: 0.6970 - acc: 0.5368
 960/1387 [===================>..........] - ETA: 32s - loss: 0.6958 - acc: 0.5385
1024/1387 [=====================>........] - ETA: 27s - loss: 0.6962 - acc: 0.5430
1088/1387 [======================>.......] - ETA: 22s - loss: 0.6979 - acc: 0.5414
1152/1387 [=======================>......] - ETA: 17s - loss: 0.6985 - acc: 0.5434
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6961 - acc: 0.5477
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6973 - acc: 0.5461 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6992 - acc: 0.5432
1387/1387 [==============================] - 107s 77ms/step - loss: 0.6996 - acc: 0.5415 - val_loss: 0.7185 - val_acc: 0.4710

Epoch 00003: val_acc did not improve from 0.53548
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:30 - loss: 0.6691 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:18 - loss: 0.6862 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 1:19 - loss: 0.6966 - acc: 0.5573
 256/1387 [====>.........................] - ETA: 1:17 - loss: 0.6960 - acc: 0.5508
 320/1387 [=====>........................] - ETA: 1:10 - loss: 0.6825 - acc: 0.5719
 384/1387 [=======>......................] - ETA: 1:08 - loss: 0.6902 - acc: 0.5729
 448/1387 [========>.....................] - ETA: 1:04 - loss: 0.6939 - acc: 0.5625
 512/1387 [==========>...................] - ETA: 1:01 - loss: 0.6908 - acc: 0.5703
 576/1387 [===========>..................] - ETA: 57s - loss: 0.6945 - acc: 0.5538 
 640/1387 [============>.................] - ETA: 52s - loss: 0.6959 - acc: 0.5547
 704/1387 [==============>...............] - ETA: 47s - loss: 0.6938 - acc: 0.5540
 768/1387 [===============>..............] - ETA: 43s - loss: 0.6901 - acc: 0.5586
 832/1387 [================>.............] - ETA: 39s - loss: 0.6913 - acc: 0.5553
 896/1387 [==================>...........] - ETA: 34s - loss: 0.6920 - acc: 0.5592
 960/1387 [===================>..........] - ETA: 29s - loss: 0.6881 - acc: 0.5635
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6845 - acc: 0.5674
1088/1387 [======================>.......] - ETA: 20s - loss: 0.6846 - acc: 0.5699
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6840 - acc: 0.5694
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6837 - acc: 0.5674
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6873 - acc: 0.5641 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6893 - acc: 0.5610
1387/1387 [==============================] - 105s 75ms/step - loss: 0.6916 - acc: 0.5559 - val_loss: 0.6976 - val_acc: 0.5226

Epoch 00004: val_acc did not improve from 0.53548
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:31 - loss: 0.6749 - acc: 0.6094
 128/1387 [=>............................] - ETA: 1:32 - loss: 0.6883 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 1:28 - loss: 0.7010 - acc: 0.5781
 256/1387 [====>.........................] - ETA: 1:24 - loss: 0.6939 - acc: 0.5781
 320/1387 [=====>........................] - ETA: 1:17 - loss: 0.7021 - acc: 0.5594
 384/1387 [=======>......................] - ETA: 1:11 - loss: 0.6924 - acc: 0.5755
 448/1387 [========>.....................] - ETA: 1:06 - loss: 0.6952 - acc: 0.5714
 512/1387 [==========>...................] - ETA: 1:01 - loss: 0.6959 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 57s - loss: 0.7013 - acc: 0.5538 
 640/1387 [============>.................] - ETA: 52s - loss: 0.7011 - acc: 0.5516
 704/1387 [==============>...............] - ETA: 48s - loss: 0.6972 - acc: 0.5611
 768/1387 [===============>..............] - ETA: 43s - loss: 0.6962 - acc: 0.5599
 832/1387 [================>.............] - ETA: 39s - loss: 0.6957 - acc: 0.5577
 896/1387 [==================>...........] - ETA: 34s - loss: 0.6966 - acc: 0.5592
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6972 - acc: 0.5542
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6947 - acc: 0.5586
1088/1387 [======================>.......] - ETA: 20s - loss: 0.6956 - acc: 0.5542
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6967 - acc: 0.5530
1216/1387 [=========================>....] - ETA: 11s - loss: 0.6973 - acc: 0.5493
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6974 - acc: 0.5477 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6962 - acc: 0.5491
1387/1387 [==============================] - 102s 73ms/step - loss: 0.6976 - acc: 0.5479 - val_loss: 0.6820 - val_acc: 0.5484

Epoch 00005: val_acc improved from 0.53548 to 0.54839, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window08/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1387 [>.............................] - ETA: 1:31 - loss: 0.7283 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:26 - loss: 0.7160 - acc: 0.5312
 192/1387 [===>..........................] - ETA: 1:18 - loss: 0.7069 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 1:12 - loss: 0.6927 - acc: 0.5625
 320/1387 [=====>........................] - ETA: 1:04 - loss: 0.7001 - acc: 0.5469
 384/1387 [=======>......................] - ETA: 59s - loss: 0.6956 - acc: 0.5573 
 448/1387 [========>.....................] - ETA: 55s - loss: 0.6965 - acc: 0.5446
 512/1387 [==========>...................] - ETA: 50s - loss: 0.7019 - acc: 0.5352
 576/1387 [===========>..................] - ETA: 47s - loss: 0.6983 - acc: 0.5451
 640/1387 [============>.................] - ETA: 43s - loss: 0.6939 - acc: 0.5516
 704/1387 [==============>...............] - ETA: 40s - loss: 0.6956 - acc: 0.5497
 768/1387 [===============>..............] - ETA: 36s - loss: 0.6973 - acc: 0.5482
 832/1387 [================>.............] - ETA: 33s - loss: 0.6988 - acc: 0.5493
 896/1387 [==================>...........] - ETA: 29s - loss: 0.7018 - acc: 0.5413
 960/1387 [===================>..........] - ETA: 25s - loss: 0.7031 - acc: 0.5406
1024/1387 [=====================>........] - ETA: 21s - loss: 0.7020 - acc: 0.5410
1088/1387 [======================>.......] - ETA: 17s - loss: 0.7018 - acc: 0.5404
1152/1387 [=======================>......] - ETA: 14s - loss: 0.7004 - acc: 0.5425
1216/1387 [=========================>....] - ETA: 10s - loss: 0.6975 - acc: 0.5469
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6968 - acc: 0.5461 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6953 - acc: 0.5499
1387/1387 [==============================] - 88s 64ms/step - loss: 0.6954 - acc: 0.5508 - val_loss: 0.6915 - val_acc: 0.5355

Epoch 00006: val_acc did not improve from 0.54839
Epoch 7/10

  64/1387 [>.............................] - ETA: 1:15 - loss: 0.6453 - acc: 0.6406
 128/1387 [=>............................] - ETA: 1:12 - loss: 0.6705 - acc: 0.5781
 192/1387 [===>..........................] - ETA: 1:16 - loss: 0.6788 - acc: 0.5885
 256/1387 [====>.........................] - ETA: 1:11 - loss: 0.6944 - acc: 0.5625
 320/1387 [=====>........................] - ETA: 1:06 - loss: 0.6969 - acc: 0.5531
 384/1387 [=======>......................] - ETA: 1:03 - loss: 0.6960 - acc: 0.5599
 448/1387 [========>.....................] - ETA: 58s - loss: 0.6942 - acc: 0.5603 
 512/1387 [==========>...................] - ETA: 53s - loss: 0.6939 - acc: 0.5605
 576/1387 [===========>..................] - ETA: 49s - loss: 0.6921 - acc: 0.5677
 640/1387 [============>.................] - ETA: 45s - loss: 0.6928 - acc: 0.5641
 704/1387 [==============>...............] - ETA: 41s - loss: 0.6875 - acc: 0.5653
 768/1387 [===============>..............] - ETA: 37s - loss: 0.6834 - acc: 0.5742
 832/1387 [================>.............] - ETA: 33s - loss: 0.6873 - acc: 0.5697
 896/1387 [==================>...........] - ETA: 29s - loss: 0.6911 - acc: 0.5625
 960/1387 [===================>..........] - ETA: 26s - loss: 0.6911 - acc: 0.5625
1024/1387 [=====================>........] - ETA: 22s - loss: 0.6904 - acc: 0.5635
1088/1387 [======================>.......] - ETA: 18s - loss: 0.6946 - acc: 0.5551
1152/1387 [=======================>......] - ETA: 14s - loss: 0.6938 - acc: 0.5582
1216/1387 [=========================>....] - ETA: 10s - loss: 0.6920 - acc: 0.5600
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6919 - acc: 0.5602 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6951 - acc: 0.5551
1387/1387 [==============================] - 90s 65ms/step - loss: 0.6949 - acc: 0.5566 - val_loss: 0.6972 - val_acc: 0.5290

Epoch 00007: val_acc did not improve from 0.54839
Epoch 8/10

  64/1387 [>.............................] - ETA: 1:12 - loss: 0.6981 - acc: 0.5781
 128/1387 [=>............................] - ETA: 1:09 - loss: 0.6838 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 1:08 - loss: 0.6861 - acc: 0.5677
 256/1387 [====>.........................] - ETA: 1:02 - loss: 0.6909 - acc: 0.5664
 320/1387 [=====>........................] - ETA: 1:02 - loss: 0.6910 - acc: 0.5656
 384/1387 [=======>......................] - ETA: 58s - loss: 0.6936 - acc: 0.5573 
 448/1387 [========>.....................] - ETA: 55s - loss: 0.6932 - acc: 0.5580
 512/1387 [==========>...................] - ETA: 51s - loss: 0.6920 - acc: 0.5664
 576/1387 [===========>..................] - ETA: 48s - loss: 0.6938 - acc: 0.5590
 640/1387 [============>.................] - ETA: 45s - loss: 0.6936 - acc: 0.5625
 704/1387 [==============>...............] - ETA: 41s - loss: 0.6912 - acc: 0.5639
 768/1387 [===============>..............] - ETA: 37s - loss: 0.6929 - acc: 0.5586
 832/1387 [================>.............] - ETA: 32s - loss: 0.6931 - acc: 0.5589
 896/1387 [==================>...........] - ETA: 29s - loss: 0.6919 - acc: 0.5647
 960/1387 [===================>..........] - ETA: 25s - loss: 0.6922 - acc: 0.5615
1024/1387 [=====================>........] - ETA: 21s - loss: 0.6925 - acc: 0.5586
1088/1387 [======================>.......] - ETA: 18s - loss: 0.6920 - acc: 0.5561
1152/1387 [=======================>......] - ETA: 14s - loss: 0.6927 - acc: 0.5547
1216/1387 [=========================>....] - ETA: 10s - loss: 0.6890 - acc: 0.5625
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6922 - acc: 0.5594 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6912 - acc: 0.5573
1387/1387 [==============================] - 88s 63ms/step - loss: 0.6915 - acc: 0.5559 - val_loss: 0.6989 - val_acc: 0.5097

Epoch 00008: val_acc did not improve from 0.54839
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:21 - loss: 0.7059 - acc: 0.4688
 128/1387 [=>............................] - ETA: 1:17 - loss: 0.6627 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 1:16 - loss: 0.6652 - acc: 0.5833
 256/1387 [====>.........................] - ETA: 1:13 - loss: 0.6719 - acc: 0.5742
 320/1387 [=====>........................] - ETA: 1:08 - loss: 0.6770 - acc: 0.5781
 384/1387 [=======>......................] - ETA: 1:02 - loss: 0.6739 - acc: 0.5833
 448/1387 [========>.....................] - ETA: 59s - loss: 0.6727 - acc: 0.5960 
 512/1387 [==========>...................] - ETA: 55s - loss: 0.6717 - acc: 0.5996
 576/1387 [===========>..................] - ETA: 50s - loss: 0.6746 - acc: 0.5920
 640/1387 [============>.................] - ETA: 46s - loss: 0.6740 - acc: 0.5938
 704/1387 [==============>...............] - ETA: 42s - loss: 0.6727 - acc: 0.5952
 768/1387 [===============>..............] - ETA: 37s - loss: 0.6762 - acc: 0.5964
 832/1387 [================>.............] - ETA: 33s - loss: 0.6775 - acc: 0.5877
 896/1387 [==================>...........] - ETA: 29s - loss: 0.6777 - acc: 0.5848
 960/1387 [===================>..........] - ETA: 25s - loss: 0.6762 - acc: 0.5875
1024/1387 [=====================>........] - ETA: 21s - loss: 0.6763 - acc: 0.5859
1088/1387 [======================>.......] - ETA: 18s - loss: 0.6752 - acc: 0.5827
1152/1387 [=======================>......] - ETA: 14s - loss: 0.6764 - acc: 0.5799
1216/1387 [=========================>....] - ETA: 10s - loss: 0.6786 - acc: 0.5748
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6778 - acc: 0.5766 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6778 - acc: 0.5766
1387/1387 [==============================] - 90s 65ms/step - loss: 0.6763 - acc: 0.5826 - val_loss: 0.6941 - val_acc: 0.5226

Epoch 00009: val_acc did not improve from 0.54839
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:22 - loss: 0.7162 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:16 - loss: 0.7248 - acc: 0.4609
 192/1387 [===>..........................] - ETA: 1:14 - loss: 0.7015 - acc: 0.5260
 256/1387 [====>.........................] - ETA: 1:12 - loss: 0.7064 - acc: 0.5117
 320/1387 [=====>........................] - ETA: 1:06 - loss: 0.7052 - acc: 0.5125
 384/1387 [=======>......................] - ETA: 1:01 - loss: 0.6974 - acc: 0.5286
 448/1387 [========>.....................] - ETA: 56s - loss: 0.6943 - acc: 0.5268 
 512/1387 [==========>...................] - ETA: 52s - loss: 0.6902 - acc: 0.5391
 576/1387 [===========>..................] - ETA: 49s - loss: 0.6915 - acc: 0.5382
 640/1387 [============>.................] - ETA: 45s - loss: 0.6946 - acc: 0.5344
 704/1387 [==============>...............] - ETA: 41s - loss: 0.6929 - acc: 0.5355
 768/1387 [===============>..............] - ETA: 38s - loss: 0.6918 - acc: 0.5430
 832/1387 [================>.............] - ETA: 34s - loss: 0.6888 - acc: 0.5457
 896/1387 [==================>...........] - ETA: 30s - loss: 0.6872 - acc: 0.5480
 960/1387 [===================>..........] - ETA: 26s - loss: 0.6873 - acc: 0.5458
1024/1387 [=====================>........] - ETA: 22s - loss: 0.6852 - acc: 0.5508
1088/1387 [======================>.......] - ETA: 18s - loss: 0.6854 - acc: 0.5496
1152/1387 [=======================>......] - ETA: 14s - loss: 0.6881 - acc: 0.5443
1216/1387 [=========================>....] - ETA: 10s - loss: 0.6864 - acc: 0.5444
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6836 - acc: 0.5500 
1344/1387 [============================>.] - ETA: 2s - loss: 0.6839 - acc: 0.5513
1387/1387 [==============================] - 90s 65ms/step - loss: 0.6839 - acc: 0.5537 - val_loss: 0.7104 - val_acc: 0.5032

Epoch 00010: val_acc did not improve from 0.54839
样本个数 193
样本个数 386
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 21s
128/386 [========>.....................] - ETA: 11s
192/386 [=============>................] - ETA: 6s 
256/386 [==================>...........] - ETA: 4s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 11s 29ms/step
loss: 0.6813862533766989
acc: 0.5518134715025906
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7ef748075750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7ef748075750>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7ef72877acd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7ef72877acd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00438d4810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00438d4810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef7287b5e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef7287b5e50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef728734b50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef728734b50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef728618590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef728618590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef7287b5dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef7287b5dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00103e2910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7f00103e2910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef72852e190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef72852e190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef7284ef750>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef7284ef750>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef728400450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef728400450>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f00439a68d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7f00439a68d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7283bacd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7283bacd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef728288dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef728288dd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef72820d610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef72820d610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7284912d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7284912d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef7285987d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef7285987d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7284778d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef7284778d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef72813cb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef72813cb10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6e8486c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6e8486c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6e854d290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6e854d290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef72850b2d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef72850b2d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef72812ebd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef72812ebd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6e83cbdd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6e83cbdd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6e81ed190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6e81ed190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6e8344e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6e8344e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6e8286a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6e8286a90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6e82de310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6e82de310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6e81dc410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6e81dc410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6c86ccb90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6c86ccb90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6e824f9d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6e824f9d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6e81dca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6e81dca90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6c87a3810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6c87a3810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6c8750c10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6c8750c10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6c8361890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6c8361890>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6c8487f10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6c8487f10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6c8750d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6c8750d90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6c83cd890>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6c83cd890>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6c8277d90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6c8277d90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6c8125250>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6c8125250>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6c836e0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6c836e0d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6c81658d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6c81658d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a87b96d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a87b96d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6a85d5390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6a85d5390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6a8495fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6a8495fd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a863ffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a863ffd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6a87f5490>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6a87f5490>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8c44e5e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef8c44e5e50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6a84cf790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6a84cf790>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6a8179990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6a8179990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a84928d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a84928d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef74806b790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef74806b790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a81f3910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a81f3910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6a8179450>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef6a8179450>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6886ccb10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef6886ccb10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef688780910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef688780910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6a8096990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef6a8096990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef688606dd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef688606dd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef68845a410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef68845a410>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef68840d190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef68840d190>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6e83ed290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6e83ed290>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef68850f150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef68850f150>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a81a78d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a81a78d0>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 5:39 - loss: 0.7615 - acc: 0.5156
 128/1387 [=>............................] - ETA: 3:24 - loss: 0.9377 - acc: 0.4609
 192/1387 [===>..........................] - ETA: 2:37 - loss: 0.8697 - acc: 0.4792
 256/1387 [====>.........................] - ETA: 2:09 - loss: 0.8485 - acc: 0.4766
 320/1387 [=====>........................] - ETA: 1:53 - loss: 0.8327 - acc: 0.4531
 384/1387 [=======>......................] - ETA: 1:39 - loss: 0.8126 - acc: 0.4740
 448/1387 [========>.....................] - ETA: 1:28 - loss: 0.7998 - acc: 0.4777
 512/1387 [==========>...................] - ETA: 1:21 - loss: 0.7863 - acc: 0.4844
 576/1387 [===========>..................] - ETA: 1:13 - loss: 0.7781 - acc: 0.4826
 640/1387 [============>.................] - ETA: 1:06 - loss: 0.7711 - acc: 0.4859
 704/1387 [==============>...............] - ETA: 1:00 - loss: 0.7639 - acc: 0.4915
 768/1387 [===============>..............] - ETA: 53s - loss: 0.7671 - acc: 0.4870 
 832/1387 [================>.............] - ETA: 47s - loss: 0.7672 - acc: 0.4868
 896/1387 [==================>...........] - ETA: 41s - loss: 0.7651 - acc: 0.4877
 960/1387 [===================>..........] - ETA: 36s - loss: 0.7637 - acc: 0.4885
1024/1387 [=====================>........] - ETA: 30s - loss: 0.7595 - acc: 0.4941
1088/1387 [======================>.......] - ETA: 25s - loss: 0.7581 - acc: 0.4963
1152/1387 [=======================>......] - ETA: 19s - loss: 0.7557 - acc: 0.4974
1216/1387 [=========================>....] - ETA: 14s - loss: 0.7531 - acc: 0.4967
1280/1387 [==========================>...] - ETA: 8s - loss: 0.7488 - acc: 0.5023 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7480 - acc: 0.5007
1387/1387 [==============================] - 122s 88ms/step - loss: 0.7476 - acc: 0.5040 - val_loss: 0.6865 - val_acc: 0.5935

Epoch 00001: val_acc improved from -inf to 0.59355, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window09/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 1:30 - loss: 0.7209 - acc: 0.5156
 128/1387 [=>............................] - ETA: 1:23 - loss: 0.7126 - acc: 0.5078
 192/1387 [===>..........................] - ETA: 1:23 - loss: 0.7095 - acc: 0.5260
 256/1387 [====>.........................] - ETA: 1:17 - loss: 0.7129 - acc: 0.5195
 320/1387 [=====>........................] - ETA: 1:15 - loss: 0.7200 - acc: 0.5094
 384/1387 [=======>......................] - ETA: 1:11 - loss: 0.7104 - acc: 0.5417
 448/1387 [========>.....................] - ETA: 1:06 - loss: 0.7111 - acc: 0.5290
 512/1387 [==========>...................] - ETA: 1:02 - loss: 0.7098 - acc: 0.5273
 576/1387 [===========>..................] - ETA: 57s - loss: 0.7062 - acc: 0.5347 
 640/1387 [============>.................] - ETA: 53s - loss: 0.7065 - acc: 0.5297
 704/1387 [==============>...............] - ETA: 48s - loss: 0.7071 - acc: 0.5284
 768/1387 [===============>..............] - ETA: 44s - loss: 0.7044 - acc: 0.5365
 832/1387 [================>.............] - ETA: 39s - loss: 0.7055 - acc: 0.5349
 896/1387 [==================>...........] - ETA: 35s - loss: 0.7023 - acc: 0.5379
 960/1387 [===================>..........] - ETA: 30s - loss: 0.7032 - acc: 0.5375
1024/1387 [=====================>........] - ETA: 25s - loss: 0.7019 - acc: 0.5391
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6999 - acc: 0.5414
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6980 - acc: 0.5469
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6974 - acc: 0.5485
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6985 - acc: 0.5445 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6988 - acc: 0.5439
1387/1387 [==============================] - 105s 76ms/step - loss: 0.6992 - acc: 0.5436 - val_loss: 0.6883 - val_acc: 0.5742

Epoch 00002: val_acc did not improve from 0.59355
Epoch 3/10

  64/1387 [>.............................] - ETA: 1:32 - loss: 0.6493 - acc: 0.6406
 128/1387 [=>............................] - ETA: 1:32 - loss: 0.6542 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 1:28 - loss: 0.6703 - acc: 0.5625
 256/1387 [====>.........................] - ETA: 1:24 - loss: 0.6692 - acc: 0.5820
 320/1387 [=====>........................] - ETA: 1:19 - loss: 0.6623 - acc: 0.5938
 384/1387 [=======>......................] - ETA: 1:15 - loss: 0.6642 - acc: 0.5938
 448/1387 [========>.....................] - ETA: 1:11 - loss: 0.6613 - acc: 0.5982
 512/1387 [==========>...................] - ETA: 1:07 - loss: 0.6690 - acc: 0.5859
 576/1387 [===========>..................] - ETA: 1:01 - loss: 0.6761 - acc: 0.5781
 640/1387 [============>.................] - ETA: 56s - loss: 0.6797 - acc: 0.5781 
 704/1387 [==============>...............] - ETA: 51s - loss: 0.6819 - acc: 0.5781
 768/1387 [===============>..............] - ETA: 46s - loss: 0.6802 - acc: 0.5807
 832/1387 [================>.............] - ETA: 41s - loss: 0.6852 - acc: 0.5721
 896/1387 [==================>...........] - ETA: 37s - loss: 0.6846 - acc: 0.5737
 960/1387 [===================>..........] - ETA: 32s - loss: 0.6841 - acc: 0.5750
1024/1387 [=====================>........] - ETA: 27s - loss: 0.6844 - acc: 0.5742
1088/1387 [======================>.......] - ETA: 22s - loss: 0.6837 - acc: 0.5781
1152/1387 [=======================>......] - ETA: 17s - loss: 0.6846 - acc: 0.5781
1216/1387 [=========================>....] - ETA: 13s - loss: 0.6836 - acc: 0.5765
1280/1387 [==========================>...] - ETA: 8s - loss: 0.6836 - acc: 0.5781 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6867 - acc: 0.5737
1387/1387 [==============================] - 111s 80ms/step - loss: 0.6864 - acc: 0.5761 - val_loss: 0.6853 - val_acc: 0.5355

Epoch 00003: val_acc did not improve from 0.59355
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:31 - loss: 0.6521 - acc: 0.6094
 128/1387 [=>............................] - ETA: 1:27 - loss: 0.6753 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 1:25 - loss: 0.6677 - acc: 0.5990
 256/1387 [====>.........................] - ETA: 1:20 - loss: 0.6713 - acc: 0.5742
 320/1387 [=====>........................] - ETA: 1:16 - loss: 0.6786 - acc: 0.5719
 384/1387 [=======>......................] - ETA: 1:13 - loss: 0.6848 - acc: 0.5625
 448/1387 [========>.....................] - ETA: 1:08 - loss: 0.6951 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 1:04 - loss: 0.6973 - acc: 0.5566
 576/1387 [===========>..................] - ETA: 59s - loss: 0.6923 - acc: 0.5608 
 640/1387 [============>.................] - ETA: 55s - loss: 0.6958 - acc: 0.5594
 704/1387 [==============>...............] - ETA: 50s - loss: 0.6957 - acc: 0.5568
 768/1387 [===============>..............] - ETA: 45s - loss: 0.6987 - acc: 0.5508
 832/1387 [================>.............] - ETA: 40s - loss: 0.6988 - acc: 0.5493
 896/1387 [==================>...........] - ETA: 35s - loss: 0.6990 - acc: 0.5446
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6977 - acc: 0.5469
1024/1387 [=====================>........] - ETA: 26s - loss: 0.6973 - acc: 0.5498
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6946 - acc: 0.5524
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6955 - acc: 0.5469
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6989 - acc: 0.5428
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6969 - acc: 0.5453 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6947 - acc: 0.5499
1387/1387 [==============================] - 104s 75ms/step - loss: 0.6946 - acc: 0.5501 - val_loss: 0.6682 - val_acc: 0.5935

Epoch 00004: val_acc improved from 0.59355 to 0.59355, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window09/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:28 - loss: 0.6578 - acc: 0.6562
 128/1387 [=>............................] - ETA: 1:29 - loss: 0.6641 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 1:23 - loss: 0.6767 - acc: 0.5625
 256/1387 [====>.........................] - ETA: 1:18 - loss: 0.6887 - acc: 0.5469
 320/1387 [=====>........................] - ETA: 1:15 - loss: 0.6944 - acc: 0.5281
 384/1387 [=======>......................] - ETA: 1:10 - loss: 0.6991 - acc: 0.5208
 448/1387 [========>.....................] - ETA: 1:06 - loss: 0.7015 - acc: 0.5223
 512/1387 [==========>...................] - ETA: 1:01 - loss: 0.6974 - acc: 0.5273
 576/1387 [===========>..................] - ETA: 57s - loss: 0.6948 - acc: 0.5260 
 640/1387 [============>.................] - ETA: 52s - loss: 0.6896 - acc: 0.5375
 704/1387 [==============>...............] - ETA: 47s - loss: 0.6885 - acc: 0.5398
 768/1387 [===============>..............] - ETA: 43s - loss: 0.6865 - acc: 0.5443
 832/1387 [================>.............] - ETA: 39s - loss: 0.6872 - acc: 0.5469
 896/1387 [==================>...........] - ETA: 34s - loss: 0.6900 - acc: 0.5402
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6902 - acc: 0.5396
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6912 - acc: 0.5400
1088/1387 [======================>.......] - ETA: 20s - loss: 0.6931 - acc: 0.5377
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6926 - acc: 0.5408
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6938 - acc: 0.5419
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6933 - acc: 0.5422 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6950 - acc: 0.5402
1387/1387 [==============================] - 103s 74ms/step - loss: 0.6938 - acc: 0.5386 - val_loss: 0.6694 - val_acc: 0.5871

Epoch 00005: val_acc did not improve from 0.59355
Epoch 6/10

  64/1387 [>.............................] - ETA: 1:44 - loss: 0.6969 - acc: 0.5938
 128/1387 [=>............................] - ETA: 1:35 - loss: 0.6888 - acc: 0.5938
 192/1387 [===>..........................] - ETA: 1:28 - loss: 0.6771 - acc: 0.5990
 256/1387 [====>.........................] - ETA: 1:23 - loss: 0.6755 - acc: 0.5938
 320/1387 [=====>........................] - ETA: 1:17 - loss: 0.6995 - acc: 0.5594
 384/1387 [=======>......................] - ETA: 1:12 - loss: 0.6915 - acc: 0.5781
 448/1387 [========>.....................] - ETA: 1:07 - loss: 0.6850 - acc: 0.5826
 512/1387 [==========>...................] - ETA: 1:02 - loss: 0.6855 - acc: 0.5859
 576/1387 [===========>..................] - ETA: 57s - loss: 0.6977 - acc: 0.5694 
 640/1387 [============>.................] - ETA: 53s - loss: 0.6973 - acc: 0.5641
 704/1387 [==============>...............] - ETA: 48s - loss: 0.6952 - acc: 0.5696
 768/1387 [===============>..............] - ETA: 43s - loss: 0.6933 - acc: 0.5716
 832/1387 [================>.............] - ETA: 39s - loss: 0.6947 - acc: 0.5625
 896/1387 [==================>...........] - ETA: 34s - loss: 0.6948 - acc: 0.5647
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6951 - acc: 0.5635
1024/1387 [=====================>........] - ETA: 25s - loss: 0.6956 - acc: 0.5605
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6949 - acc: 0.5588
1152/1387 [=======================>......] - ETA: 16s - loss: 0.6942 - acc: 0.5590
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6931 - acc: 0.5625
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6945 - acc: 0.5594 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6937 - acc: 0.5595
1387/1387 [==============================] - 103s 74ms/step - loss: 0.6950 - acc: 0.5573 - val_loss: 0.6783 - val_acc: 0.6000

Epoch 00006: val_acc improved from 0.59355 to 0.60000, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window09/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 7/10

  64/1387 [>.............................] - ETA: 1:37 - loss: 0.7267 - acc: 0.4844
 128/1387 [=>............................] - ETA: 1:28 - loss: 0.6965 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 1:21 - loss: 0.6927 - acc: 0.5208
 256/1387 [====>.........................] - ETA: 1:22 - loss: 0.6831 - acc: 0.5547
 320/1387 [=====>........................] - ETA: 1:17 - loss: 0.6812 - acc: 0.5531
 384/1387 [=======>......................] - ETA: 1:12 - loss: 0.6805 - acc: 0.5521
 448/1387 [========>.....................] - ETA: 1:07 - loss: 0.6756 - acc: 0.5558
 512/1387 [==========>...................] - ETA: 1:02 - loss: 0.6758 - acc: 0.5508
 576/1387 [===========>..................] - ETA: 58s - loss: 0.6718 - acc: 0.5573 
 640/1387 [============>.................] - ETA: 53s - loss: 0.6755 - acc: 0.5594
 704/1387 [==============>...............] - ETA: 48s - loss: 0.6719 - acc: 0.5653
 768/1387 [===============>..............] - ETA: 44s - loss: 0.6739 - acc: 0.5664
 832/1387 [================>.............] - ETA: 39s - loss: 0.6706 - acc: 0.5745
 896/1387 [==================>...........] - ETA: 35s - loss: 0.6730 - acc: 0.5658
 960/1387 [===================>..........] - ETA: 30s - loss: 0.6757 - acc: 0.5625
1024/1387 [=====================>........] - ETA: 26s - loss: 0.6739 - acc: 0.5674
1088/1387 [======================>.......] - ETA: 21s - loss: 0.6755 - acc: 0.5689
1152/1387 [=======================>......] - ETA: 17s - loss: 0.6768 - acc: 0.5712
1216/1387 [=========================>....] - ETA: 12s - loss: 0.6774 - acc: 0.5715
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6764 - acc: 0.5719 
1344/1387 [============================>.] - ETA: 3s - loss: 0.6763 - acc: 0.5751
1387/1387 [==============================] - 107s 77ms/step - loss: 0.6766 - acc: 0.5753 - val_loss: 0.6726 - val_acc: 0.5742

Epoch 00007: val_acc did not improve from 0.60000
Epoch 8/10

  64/1387 [>.............................] - ETA: 1:31 - loss: 0.6839 - acc: 0.5312
 128/1387 [=>............................] - ETA: 1:22 - loss: 0.6752 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 1:11 - loss: 0.6662 - acc: 0.5990
 256/1387 [====>.........................] - ETA: 1:05 - loss: 0.6628 - acc: 0.6055
 320/1387 [=====>........................] - ETA: 59s - loss: 0.6709 - acc: 0.5938 
 384/1387 [=======>......................] - ETA: 54s - loss: 0.6649 - acc: 0.5807
 448/1387 [========>.....................] - ETA: 51s - loss: 0.6706 - acc: 0.5759
 512/1387 [==========>...................] - ETA: 46s - loss: 0.6767 - acc: 0.5723
 576/1387 [===========>..................] - ETA: 43s - loss: 0.6757 - acc: 0.5781
 640/1387 [============>.................] - ETA: 40s - loss: 0.6805 - acc: 0.5734
 704/1387 [==============>...............] - ETA: 37s - loss: 0.6815 - acc: 0.5724
 768/1387 [===============>..............] - ETA: 33s - loss: 0.6813 - acc: 0.5664
 832/1387 [================>.............] - ETA: 30s - loss: 0.6824 - acc: 0.5661
 896/1387 [==================>...........] - ETA: 26s - loss: 0.6839 - acc: 0.5647
 960/1387 [===================>..........] - ETA: 22s - loss: 0.6882 - acc: 0.5604
1024/1387 [=====================>........] - ETA: 19s - loss: 0.6859 - acc: 0.5654
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6850 - acc: 0.5680
1152/1387 [=======================>......] - ETA: 12s - loss: 0.6823 - acc: 0.5755
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6794 - acc: 0.5789 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6791 - acc: 0.5805
1344/1387 [============================>.] - ETA: 2s - loss: 0.6791 - acc: 0.5744
1387/1387 [==============================] - 78s 56ms/step - loss: 0.6803 - acc: 0.5710 - val_loss: 0.7020 - val_acc: 0.5161

Epoch 00008: val_acc did not improve from 0.60000
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:06 - loss: 0.6775 - acc: 0.5781
 128/1387 [=>............................] - ETA: 1:05 - loss: 0.6739 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:03 - loss: 0.6961 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 57s - loss: 0.6954 - acc: 0.5469 
 320/1387 [=====>........................] - ETA: 52s - loss: 0.6895 - acc: 0.5625
 384/1387 [=======>......................] - ETA: 50s - loss: 0.6876 - acc: 0.5651
 448/1387 [========>.....................] - ETA: 47s - loss: 0.6854 - acc: 0.5647
 512/1387 [==========>...................] - ETA: 44s - loss: 0.6800 - acc: 0.5762
 576/1387 [===========>..................] - ETA: 41s - loss: 0.6737 - acc: 0.5851
 640/1387 [============>.................] - ETA: 38s - loss: 0.6743 - acc: 0.5781
 704/1387 [==============>...............] - ETA: 35s - loss: 0.6702 - acc: 0.5824
 768/1387 [===============>..............] - ETA: 31s - loss: 0.6732 - acc: 0.5768
 832/1387 [================>.............] - ETA: 28s - loss: 0.6732 - acc: 0.5757
 896/1387 [==================>...........] - ETA: 25s - loss: 0.6726 - acc: 0.5748
 960/1387 [===================>..........] - ETA: 22s - loss: 0.6759 - acc: 0.5687
1024/1387 [=====================>........] - ETA: 18s - loss: 0.6777 - acc: 0.5684
1088/1387 [======================>.......] - ETA: 15s - loss: 0.6780 - acc: 0.5634
1152/1387 [=======================>......] - ETA: 12s - loss: 0.6811 - acc: 0.5608
1216/1387 [=========================>....] - ETA: 8s - loss: 0.6800 - acc: 0.5633 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6800 - acc: 0.5648
1344/1387 [============================>.] - ETA: 2s - loss: 0.6807 - acc: 0.5603
1387/1387 [==============================] - 75s 54ms/step - loss: 0.6796 - acc: 0.5602 - val_loss: 0.6905 - val_acc: 0.5419

Epoch 00009: val_acc did not improve from 0.60000
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:08 - loss: 0.7423 - acc: 0.4375
 128/1387 [=>............................] - ETA: 1:05 - loss: 0.6910 - acc: 0.5547
 192/1387 [===>..........................] - ETA: 1:01 - loss: 0.7042 - acc: 0.5625
 256/1387 [====>.........................] - ETA: 1:00 - loss: 0.6949 - acc: 0.5781
 320/1387 [=====>........................] - ETA: 56s - loss: 0.6981 - acc: 0.5625 
 384/1387 [=======>......................] - ETA: 53s - loss: 0.6913 - acc: 0.5547
 448/1387 [========>.....................] - ETA: 52s - loss: 0.6854 - acc: 0.5625
 512/1387 [==========>...................] - ETA: 48s - loss: 0.6921 - acc: 0.5469
 576/1387 [===========>..................] - ETA: 44s - loss: 0.6955 - acc: 0.5382
 640/1387 [============>.................] - ETA: 41s - loss: 0.6867 - acc: 0.5547
 704/1387 [==============>...............] - ETA: 37s - loss: 0.6842 - acc: 0.5568
 768/1387 [===============>..............] - ETA: 33s - loss: 0.6837 - acc: 0.5612
 832/1387 [================>.............] - ETA: 30s - loss: 0.6830 - acc: 0.5601
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6827 - acc: 0.5569
 960/1387 [===================>..........] - ETA: 23s - loss: 0.6819 - acc: 0.5615
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6809 - acc: 0.5664
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6821 - acc: 0.5689
1152/1387 [=======================>......] - ETA: 12s - loss: 0.6787 - acc: 0.5738
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6777 - acc: 0.5724 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6774 - acc: 0.5727
1344/1387 [============================>.] - ETA: 2s - loss: 0.6772 - acc: 0.5744
1387/1387 [==============================] - 80s 58ms/step - loss: 0.6768 - acc: 0.5753 - val_loss: 0.6738 - val_acc: 0.5742

Epoch 00010: val_acc did not improve from 0.60000
样本个数 193
样本个数 386
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 25s
128/386 [========>.....................] - ETA: 13s
192/386 [=============>................] - ETA: 8s 
256/386 [==================>...........] - ETA: 5s
320/386 [=======================>......] - ETA: 2s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 14s 35ms/step
loss: 0.6769108222556238
acc: 0.572538860103627
样本个数 771
样本个数 1542
WARNING:tensorflow:Entity <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7ef5e84c1b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenEmbedding.call of <keras_bert.layers.embedding.TokenEmbedding object at 0x7ef5e84c1b90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7ef5e84d8350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PositionEmbedding.call of <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7ef5e84d8350>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef92c1b1d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef92c1b1d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5cc5d03d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5cc5d03d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f00103c3b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7f00103c3b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5a0534550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5a0534550>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5a0534190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5a0534190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5e8492790>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5e8492790>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5a0529550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5a0529550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef5e8237210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef5e8237210>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5e833ba50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5e833ba50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5e829f910>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5e829f910>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5e8230310>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5e8230310>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5e8054c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5e8054c90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef5a04d1850>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef5a04d1850>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5cc6de3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5cc6de3d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5e822a990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5e822a990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5a0381fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5a0381fd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5a040edd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5a040edd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef5a042f990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef5a042f990>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a84c9e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef6a84c9e90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5a03b9990>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5a03b9990>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5a021ff10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5a021ff10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5a01d2f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5a01d2f50>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef58863ffd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef58863ffd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5a02291d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5a02291d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5e818f8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5e818f8d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5887113d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5887113d0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5a0135110>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5a0135110>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef5886ec610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef5886ec610>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5883e3690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5883e3690>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5a0359ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5a0359ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5883f2d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5883f2d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5881ac3d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5881ac3d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef588047b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef588047b90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef588168f50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef588168f50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5881ac590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5881ac590>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5881a3d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5881a3d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef56c675390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef56c675390>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef56c520e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef56c520e90>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef56c565710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef56c565710>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef588118610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef588118610>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef56c670810>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef56c670810>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef56c31df10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef56c31df10>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef56c340550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef56c340550>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef56c344350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef56c344350>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef56c5d3d50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef56c5d3d50>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef56c29e210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef56c29e210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef56c272cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef56c272cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef56c2087d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef56c2087d0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5506dc390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5506dc390>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef56c272c90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef56c272c90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef56c297d10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef56c297d10>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5506e7090>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef5506e7090>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef550419690>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef550419690>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5506e7190>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef5506e7190>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5506e7ad0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5506e7ad0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef550579bd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef550579bd0>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef56c340150>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiHeadAttention.call of <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7ef56c340150>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef5501b5cd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ScaledDotProductAttention.call of <keras_self_attention.scaled_dot_attention.ScaledDotProductAttention object at 0x7ef5501b5cd0>>: AttributeError: module 'gast' has no attribute 'Index'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef55009b210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef55009b210>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5501ccc90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method FeedForward.call of <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7ef5501ccc90>>: AttributeError: module 'gast' has no attribute 'Str'
WARNING:tensorflow:Entity <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef55005a290>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LayerNormalization.call of <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7ef55005a290>>: AttributeError: module 'gast' has no attribute 'Str'
Fitting first model...
Train on 1387 samples, validate on 155 samples
Epoch 1/10

  64/1387 [>.............................] - ETA: 6:01 - loss: 0.7725 - acc: 0.4219
 128/1387 [=>............................] - ETA: 3:31 - loss: 0.7636 - acc: 0.4766
 192/1387 [===>..........................] - ETA: 2:39 - loss: 0.7781 - acc: 0.4792
 256/1387 [====>.........................] - ETA: 2:12 - loss: 0.7557 - acc: 0.5000
 320/1387 [=====>........................] - ETA: 1:53 - loss: 0.7439 - acc: 0.5188
 384/1387 [=======>......................] - ETA: 1:38 - loss: 0.7512 - acc: 0.5260
 448/1387 [========>.....................] - ETA: 1:27 - loss: 0.7560 - acc: 0.5112
 512/1387 [==========>...................] - ETA: 1:19 - loss: 0.7529 - acc: 0.5137
 576/1387 [===========>..................] - ETA: 1:10 - loss: 0.7517 - acc: 0.5174
 640/1387 [============>.................] - ETA: 1:03 - loss: 0.7481 - acc: 0.5156
 704/1387 [==============>...............] - ETA: 56s - loss: 0.7499 - acc: 0.5114 
 768/1387 [===============>..............] - ETA: 49s - loss: 0.7446 - acc: 0.5208
 832/1387 [================>.............] - ETA: 43s - loss: 0.7438 - acc: 0.5252
 896/1387 [==================>...........] - ETA: 37s - loss: 0.7429 - acc: 0.5246
 960/1387 [===================>..........] - ETA: 32s - loss: 0.7445 - acc: 0.5177
1024/1387 [=====================>........] - ETA: 27s - loss: 0.7446 - acc: 0.5156
1088/1387 [======================>.......] - ETA: 22s - loss: 0.7457 - acc: 0.5147
1152/1387 [=======================>......] - ETA: 17s - loss: 0.7448 - acc: 0.5113
1216/1387 [=========================>....] - ETA: 12s - loss: 0.7453 - acc: 0.5107
1280/1387 [==========================>...] - ETA: 7s - loss: 0.7417 - acc: 0.5133 
1344/1387 [============================>.] - ETA: 3s - loss: 0.7402 - acc: 0.5126
1387/1387 [==============================] - 108s 78ms/step - loss: 0.7391 - acc: 0.5141 - val_loss: 0.6913 - val_acc: 0.5097

Epoch 00001: val_acc improved from -inf to 0.50968, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window10/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 2/10

  64/1387 [>.............................] - ETA: 1:34 - loss: 0.7684 - acc: 0.4219
 128/1387 [=>............................] - ETA: 1:23 - loss: 0.7190 - acc: 0.5156
 192/1387 [===>..........................] - ETA: 1:16 - loss: 0.6964 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 1:15 - loss: 0.6827 - acc: 0.5625
 320/1387 [=====>........................] - ETA: 1:10 - loss: 0.7119 - acc: 0.5375
 384/1387 [=======>......................] - ETA: 1:05 - loss: 0.7234 - acc: 0.5234
 448/1387 [========>.....................] - ETA: 1:02 - loss: 0.7272 - acc: 0.5246
 512/1387 [==========>...................] - ETA: 57s - loss: 0.7260 - acc: 0.5312 
 576/1387 [===========>..................] - ETA: 53s - loss: 0.7203 - acc: 0.5347
 640/1387 [============>.................] - ETA: 50s - loss: 0.7163 - acc: 0.5391
 704/1387 [==============>...............] - ETA: 46s - loss: 0.7156 - acc: 0.5412
 768/1387 [===============>..............] - ETA: 41s - loss: 0.7193 - acc: 0.5312
 832/1387 [================>.............] - ETA: 37s - loss: 0.7217 - acc: 0.5252
 896/1387 [==================>...........] - ETA: 33s - loss: 0.7170 - acc: 0.5312
 960/1387 [===================>..........] - ETA: 28s - loss: 0.7190 - acc: 0.5281
1024/1387 [=====================>........] - ETA: 24s - loss: 0.7182 - acc: 0.5273
1088/1387 [======================>.......] - ETA: 19s - loss: 0.7136 - acc: 0.5349
1152/1387 [=======================>......] - ETA: 15s - loss: 0.7156 - acc: 0.5330
1216/1387 [=========================>....] - ETA: 11s - loss: 0.7168 - acc: 0.5304
1280/1387 [==========================>...] - ETA: 7s - loss: 0.7164 - acc: 0.5281 
1344/1387 [============================>.] - ETA: 2s - loss: 0.7153 - acc: 0.5283
1387/1387 [==============================] - 97s 70ms/step - loss: 0.7140 - acc: 0.5292 - val_loss: 0.6897 - val_acc: 0.5677

Epoch 00002: val_acc improved from 0.50968 to 0.56774, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window10/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 3/10

  64/1387 [>.............................] - ETA: 1:18 - loss: 0.6988 - acc: 0.4531
 128/1387 [=>............................] - ETA: 1:22 - loss: 0.6778 - acc: 0.5469
 192/1387 [===>..........................] - ETA: 1:17 - loss: 0.6904 - acc: 0.5104
 256/1387 [====>.........................] - ETA: 1:14 - loss: 0.6816 - acc: 0.5312
 320/1387 [=====>........................] - ETA: 1:11 - loss: 0.6930 - acc: 0.5188
 384/1387 [=======>......................] - ETA: 1:06 - loss: 0.6883 - acc: 0.5339
 448/1387 [========>.....................] - ETA: 1:01 - loss: 0.6851 - acc: 0.5424
 512/1387 [==========>...................] - ETA: 57s - loss: 0.6861 - acc: 0.5410 
 576/1387 [===========>..................] - ETA: 54s - loss: 0.6850 - acc: 0.5434
 640/1387 [============>.................] - ETA: 49s - loss: 0.6908 - acc: 0.5297
 704/1387 [==============>...............] - ETA: 45s - loss: 0.6876 - acc: 0.5369
 768/1387 [===============>..............] - ETA: 40s - loss: 0.6882 - acc: 0.5339
 832/1387 [================>.............] - ETA: 36s - loss: 0.6886 - acc: 0.5337
 896/1387 [==================>...........] - ETA: 32s - loss: 0.6937 - acc: 0.5201
 960/1387 [===================>..........] - ETA: 27s - loss: 0.6954 - acc: 0.5167
1024/1387 [=====================>........] - ETA: 23s - loss: 0.6976 - acc: 0.5146
1088/1387 [======================>.......] - ETA: 19s - loss: 0.6986 - acc: 0.5129
1152/1387 [=======================>......] - ETA: 15s - loss: 0.7028 - acc: 0.5095
1216/1387 [=========================>....] - ETA: 11s - loss: 0.7007 - acc: 0.5173
1280/1387 [==========================>...] - ETA: 7s - loss: 0.6990 - acc: 0.5227 
1344/1387 [============================>.] - ETA: 2s - loss: 0.7005 - acc: 0.5186
1387/1387 [==============================] - 96s 69ms/step - loss: 0.7006 - acc: 0.5184 - val_loss: 0.6809 - val_acc: 0.5355

Epoch 00003: val_acc did not improve from 0.56774
Epoch 4/10

  64/1387 [>.............................] - ETA: 1:27 - loss: 0.7021 - acc: 0.5469
 128/1387 [=>............................] - ETA: 1:22 - loss: 0.7225 - acc: 0.5078
 192/1387 [===>..........................] - ETA: 1:21 - loss: 0.7011 - acc: 0.5521
 256/1387 [====>.........................] - ETA: 1:14 - loss: 0.7049 - acc: 0.5391
 320/1387 [=====>........................] - ETA: 1:10 - loss: 0.6993 - acc: 0.5500
 384/1387 [=======>......................] - ETA: 1:04 - loss: 0.7067 - acc: 0.5391
 448/1387 [========>.....................] - ETA: 1:02 - loss: 0.7039 - acc: 0.5402
 512/1387 [==========>...................] - ETA: 57s - loss: 0.7033 - acc: 0.5410 
 576/1387 [===========>..................] - ETA: 53s - loss: 0.7066 - acc: 0.5278
 640/1387 [============>.................] - ETA: 49s - loss: 0.7009 - acc: 0.5375
 704/1387 [==============>...............] - ETA: 44s - loss: 0.6959 - acc: 0.5384
 768/1387 [===============>..............] - ETA: 40s - loss: 0.6976 - acc: 0.5365
 832/1387 [================>.............] - ETA: 36s - loss: 0.6968 - acc: 0.5325
 896/1387 [==================>...........] - ETA: 32s - loss: 0.7018 - acc: 0.5279
 960/1387 [===================>..........] - ETA: 27s - loss: 0.7016 - acc: 0.5292
1024/1387 [=====================>........] - ETA: 23s - loss: 0.6998 - acc: 0.5322
1088/1387 [======================>.......] - ETA: 18s - loss: 0.7002 - acc: 0.5285
1152/1387 [=======================>......] - ETA: 14s - loss: 0.7027 - acc: 0.5217
1216/1387 [=========================>....] - ETA: 10s - loss: 0.7040 - acc: 0.5189
1280/1387 [==========================>...] - ETA: 6s - loss: 0.7039 - acc: 0.5203 
1344/1387 [============================>.] - ETA: 2s - loss: 0.7033 - acc: 0.5208
1387/1387 [==============================] - 90s 65ms/step - loss: 0.7023 - acc: 0.5249 - val_loss: 0.6830 - val_acc: 0.5677

Epoch 00004: val_acc did not improve from 0.56774
Epoch 5/10

  64/1387 [>.............................] - ETA: 1:11 - loss: 0.6523 - acc: 0.6250
 128/1387 [=>............................] - ETA: 1:09 - loss: 0.6520 - acc: 0.6250
 192/1387 [===>..........................] - ETA: 1:07 - loss: 0.6602 - acc: 0.6094
 256/1387 [====>.........................] - ETA: 1:03 - loss: 0.6718 - acc: 0.5820
 320/1387 [=====>........................] - ETA: 58s - loss: 0.6725 - acc: 0.5813 
 384/1387 [=======>......................] - ETA: 55s - loss: 0.6716 - acc: 0.5885
 448/1387 [========>.....................] - ETA: 52s - loss: 0.6758 - acc: 0.5848
 512/1387 [==========>...................] - ETA: 48s - loss: 0.6856 - acc: 0.5547
 576/1387 [===========>..................] - ETA: 45s - loss: 0.6851 - acc: 0.5521
 640/1387 [============>.................] - ETA: 42s - loss: 0.6851 - acc: 0.5500
 704/1387 [==============>...............] - ETA: 38s - loss: 0.6842 - acc: 0.5568
 768/1387 [===============>..............] - ETA: 35s - loss: 0.6841 - acc: 0.5599
 832/1387 [================>.............] - ETA: 31s - loss: 0.6853 - acc: 0.5505
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6884 - acc: 0.5446
 960/1387 [===================>..........] - ETA: 24s - loss: 0.6904 - acc: 0.5396
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6908 - acc: 0.5391
1088/1387 [======================>.......] - ETA: 17s - loss: 0.6907 - acc: 0.5386
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6928 - acc: 0.5356
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6924 - acc: 0.5337 
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6960 - acc: 0.5281
1344/1387 [============================>.] - ETA: 2s - loss: 0.6940 - acc: 0.5320
1387/1387 [==============================] - 83s 60ms/step - loss: 0.6955 - acc: 0.5299 - val_loss: 0.6787 - val_acc: 0.5677

Epoch 00005: val_acc improved from 0.56774 to 0.56774, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window10/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 6/10

  64/1387 [>.............................] - ETA: 1:13 - loss: 0.7050 - acc: 0.5156
 128/1387 [=>............................] - ETA: 1:07 - loss: 0.7027 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 1:04 - loss: 0.6899 - acc: 0.5365
 256/1387 [====>.........................] - ETA: 1:01 - loss: 0.6861 - acc: 0.5625
 320/1387 [=====>........................] - ETA: 59s - loss: 0.6877 - acc: 0.5469 
 384/1387 [=======>......................] - ETA: 54s - loss: 0.6802 - acc: 0.5677
 448/1387 [========>.....................] - ETA: 52s - loss: 0.6789 - acc: 0.5737
 512/1387 [==========>...................] - ETA: 49s - loss: 0.6848 - acc: 0.5625
 576/1387 [===========>..................] - ETA: 45s - loss: 0.6853 - acc: 0.5625
 640/1387 [============>.................] - ETA: 42s - loss: 0.6821 - acc: 0.5641
 704/1387 [==============>...............] - ETA: 38s - loss: 0.6837 - acc: 0.5582
 768/1387 [===============>..............] - ETA: 35s - loss: 0.6860 - acc: 0.5560
 832/1387 [================>.............] - ETA: 31s - loss: 0.6846 - acc: 0.5553
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6829 - acc: 0.5580
 960/1387 [===================>..........] - ETA: 24s - loss: 0.6849 - acc: 0.5542
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6878 - acc: 0.5547
1088/1387 [======================>.......] - ETA: 17s - loss: 0.6885 - acc: 0.5524
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6878 - acc: 0.5521
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6876 - acc: 0.5559 
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6872 - acc: 0.5563
1344/1387 [============================>.] - ETA: 2s - loss: 0.6878 - acc: 0.5528
1387/1387 [==============================] - 84s 61ms/step - loss: 0.6879 - acc: 0.5516 - val_loss: 0.6771 - val_acc: 0.5871

Epoch 00006: val_acc improved from 0.56774 to 0.58710, saving model to /data/lyli/Prostate-adenocarcinoma/PRAD-model/Seq_feature_exact/window10/checkpoints/final_seq_model/PRAD_seq_model_2_mer.hdf5
Epoch 7/10

  64/1387 [>.............................] - ETA: 1:24 - loss: 0.6475 - acc: 0.6562
 128/1387 [=>............................] - ETA: 1:13 - loss: 0.6815 - acc: 0.5625
 192/1387 [===>..........................] - ETA: 1:07 - loss: 0.6852 - acc: 0.5573
 256/1387 [====>.........................] - ETA: 1:01 - loss: 0.6847 - acc: 0.5664
 320/1387 [=====>........................] - ETA: 1:00 - loss: 0.6816 - acc: 0.5719
 384/1387 [=======>......................] - ETA: 56s - loss: 0.6890 - acc: 0.5495 
 448/1387 [========>.....................] - ETA: 52s - loss: 0.6880 - acc: 0.5446
 512/1387 [==========>...................] - ETA: 48s - loss: 0.6871 - acc: 0.5449
 576/1387 [===========>..................] - ETA: 44s - loss: 0.6864 - acc: 0.5417
 640/1387 [============>.................] - ETA: 41s - loss: 0.6905 - acc: 0.5344
 704/1387 [==============>...............] - ETA: 37s - loss: 0.6899 - acc: 0.5355
 768/1387 [===============>..............] - ETA: 34s - loss: 0.6917 - acc: 0.5326
 832/1387 [================>.............] - ETA: 31s - loss: 0.6903 - acc: 0.5337
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6917 - acc: 0.5312
 960/1387 [===================>..........] - ETA: 23s - loss: 0.6908 - acc: 0.5344
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6901 - acc: 0.5371
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6909 - acc: 0.5340
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6922 - acc: 0.5330
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6908 - acc: 0.5395 
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6912 - acc: 0.5414
1344/1387 [============================>.] - ETA: 2s - loss: 0.6899 - acc: 0.5439
1387/1387 [==============================] - 82s 59ms/step - loss: 0.6902 - acc: 0.5422 - val_loss: 0.6781 - val_acc: 0.5677

Epoch 00007: val_acc did not improve from 0.58710
Epoch 8/10

  64/1387 [>.............................] - ETA: 1:12 - loss: 0.6767 - acc: 0.5938
 128/1387 [=>............................] - ETA: 1:09 - loss: 0.6578 - acc: 0.6016
 192/1387 [===>..........................] - ETA: 1:06 - loss: 0.6782 - acc: 0.5417
 256/1387 [====>.........................] - ETA: 1:00 - loss: 0.6732 - acc: 0.5703
 320/1387 [=====>........................] - ETA: 59s - loss: 0.6841 - acc: 0.5531 
 384/1387 [=======>......................] - ETA: 55s - loss: 0.6821 - acc: 0.5625
 448/1387 [========>.....................] - ETA: 51s - loss: 0.6808 - acc: 0.5647
 512/1387 [==========>...................] - ETA: 48s - loss: 0.6829 - acc: 0.5645
 576/1387 [===========>..................] - ETA: 45s - loss: 0.6841 - acc: 0.5590
 640/1387 [============>.................] - ETA: 41s - loss: 0.6860 - acc: 0.5594
 704/1387 [==============>...............] - ETA: 38s - loss: 0.6856 - acc: 0.5511
 768/1387 [===============>..............] - ETA: 34s - loss: 0.6900 - acc: 0.5430
 832/1387 [================>.............] - ETA: 31s - loss: 0.6952 - acc: 0.5276
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6969 - acc: 0.5223
 960/1387 [===================>..........] - ETA: 24s - loss: 0.6928 - acc: 0.5323
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6921 - acc: 0.5342
1088/1387 [======================>.......] - ETA: 17s - loss: 0.6911 - acc: 0.5386
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6904 - acc: 0.5382
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6903 - acc: 0.5411 
1280/1387 [==========================>...] - ETA: 6s - loss: 0.6913 - acc: 0.5391
1344/1387 [============================>.] - ETA: 2s - loss: 0.6900 - acc: 0.5402
1387/1387 [==============================] - 83s 60ms/step - loss: 0.6899 - acc: 0.5415 - val_loss: 0.6736 - val_acc: 0.5613

Epoch 00008: val_acc did not improve from 0.58710
Epoch 9/10

  64/1387 [>.............................] - ETA: 1:06 - loss: 0.6765 - acc: 0.6250
 128/1387 [=>............................] - ETA: 1:03 - loss: 0.7074 - acc: 0.5234
 192/1387 [===>..........................] - ETA: 1:05 - loss: 0.7007 - acc: 0.5365
 256/1387 [====>.........................] - ETA: 1:03 - loss: 0.7019 - acc: 0.5273
 320/1387 [=====>........................] - ETA: 59s - loss: 0.7029 - acc: 0.5219 
 384/1387 [=======>......................] - ETA: 54s - loss: 0.7025 - acc: 0.5286
 448/1387 [========>.....................] - ETA: 51s - loss: 0.7017 - acc: 0.5335
 512/1387 [==========>...................] - ETA: 47s - loss: 0.7023 - acc: 0.5332
 576/1387 [===========>..................] - ETA: 44s - loss: 0.7003 - acc: 0.5347
 640/1387 [============>.................] - ETA: 40s - loss: 0.6989 - acc: 0.5328
 704/1387 [==============>...............] - ETA: 37s - loss: 0.6992 - acc: 0.5327
 768/1387 [===============>..............] - ETA: 34s - loss: 0.7022 - acc: 0.5260
 832/1387 [================>.............] - ETA: 31s - loss: 0.6990 - acc: 0.5373
 896/1387 [==================>...........] - ETA: 27s - loss: 0.6968 - acc: 0.5413
 960/1387 [===================>..........] - ETA: 24s - loss: 0.6981 - acc: 0.5417
1024/1387 [=====================>........] - ETA: 20s - loss: 0.6957 - acc: 0.5459
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6975 - acc: 0.5423
1152/1387 [=======================>......] - ETA: 13s - loss: 0.6974 - acc: 0.5399
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6969 - acc: 0.5370 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6972 - acc: 0.5344
1344/1387 [============================>.] - ETA: 2s - loss: 0.6951 - acc: 0.5372
1387/1387 [==============================] - 81s 59ms/step - loss: 0.6956 - acc: 0.5350 - val_loss: 0.6785 - val_acc: 0.5548

Epoch 00009: val_acc did not improve from 0.58710
Epoch 10/10

  64/1387 [>.............................] - ETA: 1:22 - loss: 0.7023 - acc: 0.5781
 128/1387 [=>............................] - ETA: 1:07 - loss: 0.6854 - acc: 0.5703
 192/1387 [===>..........................] - ETA: 1:00 - loss: 0.6785 - acc: 0.5729
 256/1387 [====>.........................] - ETA: 54s - loss: 0.6829 - acc: 0.5703 
 320/1387 [=====>........................] - ETA: 52s - loss: 0.6791 - acc: 0.5844
 384/1387 [=======>......................] - ETA: 47s - loss: 0.6880 - acc: 0.5651
 448/1387 [========>.....................] - ETA: 44s - loss: 0.6940 - acc: 0.5603
 512/1387 [==========>...................] - ETA: 42s - loss: 0.6985 - acc: 0.5410
 576/1387 [===========>..................] - ETA: 40s - loss: 0.6977 - acc: 0.5469
 640/1387 [============>.................] - ETA: 37s - loss: 0.6948 - acc: 0.5563
 704/1387 [==============>...............] - ETA: 34s - loss: 0.6976 - acc: 0.5511
 768/1387 [===============>..............] - ETA: 32s - loss: 0.6997 - acc: 0.5404
 832/1387 [================>.............] - ETA: 28s - loss: 0.6985 - acc: 0.5337
 896/1387 [==================>...........] - ETA: 25s - loss: 0.6938 - acc: 0.5458
 960/1387 [===================>..........] - ETA: 22s - loss: 0.6939 - acc: 0.5479
1024/1387 [=====================>........] - ETA: 19s - loss: 0.6934 - acc: 0.5459
1088/1387 [======================>.......] - ETA: 16s - loss: 0.6931 - acc: 0.5450
1152/1387 [=======================>......] - ETA: 12s - loss: 0.6937 - acc: 0.5443
1216/1387 [=========================>....] - ETA: 9s - loss: 0.6952 - acc: 0.5387 
1280/1387 [==========================>...] - ETA: 5s - loss: 0.6942 - acc: 0.5437
1344/1387 [============================>.] - ETA: 2s - loss: 0.6937 - acc: 0.5439
1387/1387 [==============================] - 80s 57ms/step - loss: 0.6929 - acc: 0.5472 - val_loss: 0.6828 - val_acc: 0.5742

Epoch 00010: val_acc did not improve from 0.58710
样本个数 193
样本个数 386
window_select6-10.py:146: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  model = Model(input=[inputs_seq1], output=[seq_dense])

 64/386 [===>..........................] - ETA: 25s
128/386 [========>.....................] - ETA: 12s
192/386 [=============>................] - ETA: 7s 
256/386 [==================>...........] - ETA: 4s
320/386 [=======================>......] - ETA: 1s
384/386 [============================>.] - ETA: 0s
386/386 [==============================] - 11s 28ms/step
loss: 0.6936182537227097
acc: 0.5284974093264249
